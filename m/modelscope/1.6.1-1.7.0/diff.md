# Comparing `tmp/modelscope-1.6.1.tar.gz` & `tmp/modelscope-1.7.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/modelscope-1.6.1.tar", last modified: Fri Jun  9 13:07:16 2023, max compression
+gzip compressed data, was "dist/modelscope-1.7.0.tar", last modified: Sun Jul  2 13:03:06 2023, max compression
```

## Comparing `modelscope-1.6.1.tar` & `modelscope-1.7.0.tar`

### file list

```diff
@@ -1,2766 +1,2822 @@
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/
--rw-r--r--   0 runner    (1001) docker     (122)       57 2023-06-09 13:07:15.000000 modelscope-1.6.1/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (122)    19082 2023-06-09 13:07:16.000000 modelscope-1.6.1/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (122)    15726 2023-06-09 13:07:15.000000 modelscope-1.6.1/README.md
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/
--rw-r--r--   0 runner    (1001) docker     (122)     3655 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/cli/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/cli/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      404 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/cli/base.py
--rw-r--r--   0 runner    (1001) docker     (122)      829 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/cli/cli.py
--rw-r--r--   0 runner    (1001) docker     (122)     1230 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/cli/download.py
--rw-r--r--   0 runner    (1001) docker     (122)     6240 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/cli/modelcard.py
--rw-r--r--   0 runner    (1001) docker     (122)     4369 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/cli/pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3304 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/cli/plugins.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/configs/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/configs/examples/
--rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/configs/examples/configuration.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/exporters/
--rw-r--r--   0 runner    (1001) docker     (122)     1255 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/exporters/audio/
--rw-r--r--   0 runner    (1001) docker     (122)      507 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2272 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/audio/ans_dfsmn_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     2667 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/base.py
--rw-r--r--   0 runner    (1001) docker     (122)      732 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/exporters/cv/
--rw-r--r--   0 runner    (1001) docker     (122)      869 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2593 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/cv/cartoon_translation_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     3619 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/cv/face_detection_scrfd_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     1358 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/cv/object_detection_damoyolo_exporter.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/exporters/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     1082 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7341 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/nlp/csanmt_for_translation_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     4579 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/nlp/model_for_token_classification_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     3409 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/nlp/sbert_for_sequence_classification_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     2316 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/nlp/sbert_for_zero_shot_classification_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     4809 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/tf_model_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)    15145 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/exporters/torch_model_exporter.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/fileio/
--rw-r--r--   0 runner    (1001) docker     (122)      122 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/fileio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10241 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/fileio/file.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/fileio/format/
--rw-r--r--   0 runner    (1001) docker     (122)      143 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/fileio/format/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      454 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/fileio/format/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1050 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/fileio/format/json.py
--rw-r--r--   0 runner    (1001) docker     (122)    13853 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/fileio/format/jsonplus.py
--rw-r--r--   0 runner    (1001) docker     (122)      669 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/fileio/format/yaml.py
--rw-r--r--   0 runner    (1001) docker     (122)     4254 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/fileio/io.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/hub/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    42147 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/api.py
--rw-r--r--   0 runner    (1001) docker     (122)     3649 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/check_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1395 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/constants.py
--rw-r--r--   0 runner    (1001) docker     (122)    11358 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/deploy.py
--rw-r--r--   0 runner    (1001) docker     (122)     4072 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/errors.py
--rw-r--r--   0 runner    (1001) docker     (122)    10249 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/file_download.py
--rw-r--r--   0 runner    (1001) docker     (122)     8958 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/git.py
--rw-r--r--   0 runner    (1001) docker     (122)     7272 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/push_to_hub.py
--rw-r--r--   0 runner    (1001) docker     (122)    12489 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/repository.py
--rw-r--r--   0 runner    (1001) docker     (122)     6535 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/snapshot_download.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/hub/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9916 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/utils/caching.py
--rw-r--r--   0 runner    (1001) docker     (122)     2978 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/hub/utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    54353 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metainfo.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/metrics/
--rw-r--r--   0 runner    (1001) docker     (122)     3978 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2510 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/accuracy_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     7530 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/action_detection_evaluator.py
--rw-r--r--   0 runner    (1001) docker     (122)     1925 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/audio_noise_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1454 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1726 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/bleu_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3715 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/metrics/ciderD/
--rwxr-xr-x   0 runner    (1001) docker     (122)       21 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/ciderD/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1926 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/ciderD/ciderD.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8931 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/ciderD/ciderD_scorer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8664 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/image_color_enhance_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)    13387 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/image_colorization_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)    10011 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/image_denoise_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     7612 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/image_inpainting_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)    13318 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/image_instance_segmentation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1739 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/image_portrait_enhancement_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2536 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/image_quality_assessment_degradation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1632 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/image_quality_assessment_mos_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2231 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/inbatch_recall_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1358 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/loss_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3002 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/map_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2032 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/movie_scene_segmentation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/ned_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2310 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/ocr_recognition_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2082 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/ppl_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1163 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/prediction_saving_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     4453 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/referring_video_object_segmentation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3112 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/sequence_classification_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3233 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/text_generation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/text_ranking_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5765 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/token_classification_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5703 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/translation_evaluation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5435 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/video_frame_interpolation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     8655 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/video_stabilization_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3092 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/video_summarization_metric.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/metrics/video_super_resolution_metric/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/video_super_resolution_metric/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7030 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/video_super_resolution_metric/matlab_functions.py
--rw-r--r--   0 runner    (1001) docker     (122)     4771 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/video_super_resolution_metric/metric_util.py
--rw-r--r--   0 runner    (1001) docker     (122)     8932 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/video_super_resolution_metric/niqe.py
--rw-r--r--   0 runner    (1001) docker     (122)     1710 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/metrics/video_super_resolution_metric/video_super_resolution_metric.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/
--rw-r--r--   0 runner    (1001) docker     (122)      519 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/
--rw-r--r--   0 runner    (1001) docker     (122)       93 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/aec/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/aec/layers/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/layers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1434 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/layers/activations.py
--rw-r--r--   0 runner    (1001) docker     (122)     2700 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/layers/affine_transform.py
--rw-r--r--   0 runner    (1001) docker     (122)     5630 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/layers/deep_fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     1322 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/layers/layer_base.py
--rw-r--r--   0 runner    (1001) docker     (122)    14384 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/layers/uni_deep_fsmn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/aec/network/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/network/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14438 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/network/loss.py
--rw-r--r--   0 runner    (1001) docker     (122)     9382 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/network/modulation_loss.py
--rw-r--r--   0 runner    (1001) docker     (122)    15396 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/aec/network/se_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/ans/
--rw-r--r--   0 runner    (1001) docker     (122)      515 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6475 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/complex_nn.py
--rw-r--r--   0 runner    (1001) docker     (122)     3688 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/conv_stft.py
--rw-r--r--   0 runner    (1001) docker     (122)     2513 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/denoise_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    10241 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/frcrn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/ans/layers/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/layers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1468 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/layers/activations.py
--rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/layers/affine_transform.py
--rw-r--r--   0 runner    (1001) docker     (122)      661 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/layers/layer_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     5284 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/layers/uni_deep_fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     1038 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/se_module_complex.py
--rw-r--r--   0 runner    (1001) docker     (122)     9833 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/ans/unet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/asr/
--rw-r--r--   0 runner    (1001) docker     (122)      585 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/asr/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/asr/generic_automatic_speech_recognition.py
--rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/asr/wenet_automatic_speech_recognition.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/itn/
--rw-r--r--   0 runner    (1001) docker     (122)      557 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/itn/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1462 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/itn/generic_inverse_text_processing.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/kws/
--rw-r--r--   0 runner    (1001) docker     (122)      735 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/kws/farfield/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/farfield/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14349 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/farfield/fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     7462 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/farfield/fsmn_sele_v2.py
--rw-r--r--   0 runner    (1001) docker     (122)     7861 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/farfield/fsmn_sele_v3.py
--rw-r--r--   0 runner    (1001) docker     (122)     3521 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/farfield/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     2608 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/farfield/model_def.py
--rw-r--r--   0 runner    (1001) docker     (122)      908 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/generic_key_word_spotting.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/kws/nearfield/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/nearfield/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3300 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/nearfield/cmvn.py
--rw-r--r--   0 runner    (1001) docker     (122)    17496 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/nearfield/fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     6079 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/kws/nearfield/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/punc/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/punc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1466 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/punc/generic_punctuation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/separation/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/separation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2240 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/separation/layer_norm.py
--rw-r--r--   0 runner    (1001) docker     (122)    13963 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/separation/mossformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9142 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/separation/mossformer_block.py
--rw-r--r--   0 runner    (1001) docker     (122)     9004 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/separation/mossformer_conv_module.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/sv/
--rw-r--r--   0 runner    (1001) docker     (122)     6905 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/sv/DTDNN.py
--rw-r--r--   0 runner    (1001) docker     (122)     8425 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/sv/DTDNN_layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    11515 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/sv/ERes2Net.py
--rw-r--r--   0 runner    (1001) docker     (122)      498 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/sv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14531 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/sv/ecapa_tdnn.py
--rw-r--r--   0 runner    (1001) docker     (122)      904 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/sv/fusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     1488 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/sv/generic_speaker_verification.py
--rw-r--r--   0 runner    (1001) docker     (122)     3630 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/sv/pooling_layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    16895 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/sv/rdino.py
--rw-r--r--   0 runner    (1001) docker     (122)    11975 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/sv/speaker_change_locator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/audio/tts/
--rw-r--r--   0 runner    (1001) docker     (122)      474 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/tts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11845 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/tts/sambert_hifi.py
--rw-r--r--   0 runner    (1001) docker     (122)    26390 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/audio/tts/voice.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/base/
--rw-r--r--   0 runner    (1001) docker     (122)      303 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/base/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/base/base_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     6994 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/base/base_model.py
--rw-r--r--   0 runner    (1001) docker     (122)      605 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/base/base_torch_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     5679 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/base/base_torch_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     3647 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/
--rw-r--r--   0 runner    (1001) docker     (122)     1812 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      490 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3806 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/
--rw-r--r--   0 runner    (1001) docker     (122)      113 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/
--rw-r--r--   0 runner    (1001) docker     (122)      211 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6414 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/
--rw-r--r--   0 runner    (1001) docker     (122)      145 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6729 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/action_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      493 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/action_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7307 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/action_detection/action_detection_onnx.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/action_detection/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/action_detection/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9364 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/action_detection/modules/action_detection_pytorch.py
--rw-r--r--   0 runner    (1001) docker     (122)    12132 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/action_detection/modules/resnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/action_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      709 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/action_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4304 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/action_recognition/models.py
--rw-r--r--   0 runner    (1001) docker     (122)    10276 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/action_recognition/s3dg.py
--rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/action_recognition/tada_convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)    45442 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/action_recognition/temporal_patch_shift_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/animal_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      558 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/animal_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14141 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/animal_recognition/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     3955 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/animal_recognition/splat.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/bad_image_detecting/
--rw-r--r--   0 runner    (1001) docker     (122)      496 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/bad_image_detecting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2589 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/bad_image_detecting/bad_image_detecting.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/body_2d_keypoints/
--rw-r--r--   0 runner    (1001) docker     (122)      502 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_2d_keypoints/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12660 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_2d_keypoints/hrnet_basic_modules.py
--rw-r--r--   0 runner    (1001) docker     (122)     8773 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_2d_keypoints/hrnet_v2.py
--rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_2d_keypoints/w48.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/
--rw-r--r--   0 runner    (1001) docker     (122)      601 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/
--rw-r--r--   0 runner    (1001) docker     (122)       51 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8957 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py
--rw-r--r--   0 runner    (1001) docker     (122)     8196 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/
--rw-r--r--   0 runner    (1001) docker     (122)       98 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11552 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    12870 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/block.py
--rw-r--r--   0 runner    (1001) docker     (122)     8080 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/directed_graph.py
--rw-r--r--   0 runner    (1001) docker     (122)     2516 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7719 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     3401 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/skeleton.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/
--rw-r--r--   0 runner    (1001) docker     (122)     1216 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/LK/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/LK/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3488 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/LK/lk.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      713 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/config.py
--rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/face_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     5158 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/face_landmark.py
--rw-r--r--   0 runner    (1001) docker     (122)     4563 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/facer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9075 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/loss.py
--rw-r--r--   0 runner    (1001) docker     (122)     2174 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/model_tf.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/mtcnn_pytorch/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/mtcnn_pytorch/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6072 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py
--rw-r--r--   0 runner    (1001) docker     (122)     8519 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py
--rw-r--r--   0 runner    (1001) docker     (122)     4404 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/network.py
--rw-r--r--   0 runner    (1001) docker     (122)     5265 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cartoon/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/cmdssl_video_embedding/
--rw-r--r--   0 runner    (1001) docker     (122)      647 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cmdssl_video_embedding/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3876 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cmdssl_video_embedding/c3d.py
--rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cmdssl_video_embedding/resnet2p1d.py
--rw-r--r--   0 runner    (1001) docker     (122)     8949 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/cmdssl_video_embedding/resnet3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      414 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13516 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/annotator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4960 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/api.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      504 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    10152 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py
--rw-r--r--   0 runner    (1001) docker     (122)     2746 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5829 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py
--rw-r--r--   0 runner    (1001) docker     (122)     8045 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    15438 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/vit.py
--rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9896 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py
--rw-r--r--   0 runner    (1001) docker     (122)    25158 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12595 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/body.py
--rw-r--r--   0 runner    (1001) docker     (122)     3894 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/hand.py
--rw-r--r--   0 runner    (1001) docker     (122)     9024 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     8031 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/util.py
--rw-r--r--   0 runner    (1001) docker     (122)     8546 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/controlnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/crowd_counting/
--rw-r--r--   0 runner    (1001) docker     (122)      491 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/crowd_counting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1100 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/crowd_counting/cc_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    22875 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/crowd_counting/hrnet_aspp_relu.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_attribute_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      490 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_attribute_recognition/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_attribute_recognition/fair_face/
--rw-r--r--   0 runner    (1001) docker     (122)      115 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_attribute_recognition/fair_face/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2559 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      930 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/
--rw-r--r--   0 runner    (1001) docker     (122)       96 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3032 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/detectors.py
--rw-r--r--   0 runner    (1001) docker     (122)     4675 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/mogface.py
--rw-r--r--   0 runner    (1001) docker     (122)     5578 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/mogprednet.py
--rw-r--r--   0 runner    (1001) docker     (122)     6264 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/resnet.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     7072 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/
--rw-r--r--   0 runner    (1001) docker     (122)       97 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7061 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/models/box_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     5415 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/models/detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/models/first_stage.py
--rw-r--r--   0 runner    (1001) docker     (122)     5232 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/models/get_nets.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/LK/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/LK/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3444 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/LK/lk.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3578 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/face_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     5129 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/face_landmark.py
--rw-r--r--   0 runner    (1001) docker     (122)     4210 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/facer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/
--rw-r--r--   0 runner    (1001) docker     (122)       93 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4832 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/detection.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/models/
--rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/models/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4766 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/models/net.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4590 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/models/retinaface.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/
--rw-r--r--   0 runner    (1001) docker     (122)      174 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      955 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/damofd_detect.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/
--rwxr-xr-x   0 runner    (1001) docker     (122)      192 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/
--rw-r--r--   0 runner    (1001) docker     (122)      325 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2945 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/
--rwxr-xr-x   0 runner    (1001) docker     (122)      292 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3401 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      276 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/
--rwxr-xr-x   0 runner    (1001) docker     (122)      471 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11707 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py
--rw-r--r--   0 runner    (1001) docker     (122)     4169 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py
--rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    30670 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5543 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/
--rwxr-xr-x   0 runner    (1001) docker     (122)      289 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/
--rwxr-xr-x   0 runner    (1001) docker     (122)      361 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4202 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     3590 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py
--rw-r--r--   0 runner    (1001) docker     (122)    16146 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/
--rwxr-xr-x   0 runner    (1001) docker     (122)      270 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    46999 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/
--rwxr-xr-x   0 runner    (1001) docker     (122)      295 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11062 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6092 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py
--rw-r--r--   0 runner    (1001) docker     (122)     6395 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5970 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py
--rw-r--r--   0 runner    (1001) docker     (122)     3451 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3869 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/scrfd_detect.py
--rw-r--r--   0 runner    (1001) docker     (122)      960 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/tinymog_detect.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/
--rw-r--r--   0 runner    (1001) docker     (122)       90 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1477 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/detection.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4126 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/box_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2058 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      571 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py
--rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     3719 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py
--rw-r--r--   0 runner    (1001) docker     (122)     2845 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4621 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py
--rw-r--r--   0 runner    (1001) docker     (122)     1497 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/
--rw-r--r--   0 runner    (1001) docker     (122)      540 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/efficient/
--rw-r--r--   0 runner    (1001) docker     (122)      327 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/efficient/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15911 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/efficient/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    20077 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/efficient/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2007 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/emotion_infer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/emotion_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/face_alignment/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/face_alignment/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2844 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/face_alignment/face.py
--rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_emotion/face_alignment/face_align.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      475 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_generation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_generation/op/
--rwxr-xr-x   0 runner    (1001) docker     (122)       89 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_generation/op/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6497 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_generation/op/conv2d_gradfix.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     3104 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_generation/op/fused_act.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5922 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_generation/op/upfirdn2d.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    19998 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_generation/stylegan2.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4109 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/det_infer.py
--rw-r--r--   0 runner    (1001) docker     (122)    12584 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/ghost_pan.py
--rw-r--r--   0 runner    (1001) docker     (122)    16846 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/nanodet_plus_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1833 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/one_stage_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     5791 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/shufflenetv2.py
--rw-r--r--   0 runner    (1001) docker     (122)     8874 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1572 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/align_face.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/
--rwxr-xr-x   0 runner    (1001) docker     (122)      473 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/
--rwxr-xr-x   0 runner    (1001) docker     (122)     1080 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1977 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     7572 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8551 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/model_irse.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4744 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/model_resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     7186 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/rts_backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    31337 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/bfm.py
--rw-r--r--   0 runner    (1001) docker     (122)     1428 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/de_retouching_module.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facelandmark/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facelandmark/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2583 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6561 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5124 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    30403 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facerecon_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    13171 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/losses.py
--rw-r--r--   0 runner    (1001) docker     (122)    21235 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/networks.py
--rw-r--r--   0 runner    (1001) docker     (122)     8821 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/nv_diffrast.py
--rw-r--r--   0 runner    (1001) docker     (122)      277 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/opt.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/pix2pix/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/pix2pix/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    31957 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/pix2pix/networks.py
--rw-r--r--   0 runner    (1001) docker     (122)     5908 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py
--rw-r--r--   0 runner    (1001) docker     (122)      779 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    13410 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/renderer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4933 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)    31247 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/face_reconstruction/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/facial_expression_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      484 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/facial_expression_recognition/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/facial_expression_recognition/fer/
--rw-r--r--   0 runner    (1001) docker     (122)      121 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/facial_expression_recognition/fer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py
--rw-r--r--   0 runner    (1001) docker     (122)     3277 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/facial_expression_recognition/fer/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/facial_expression_recognition/fer/vgg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/facial_landmark_confidence/
--rw-r--r--   0 runner    (1001) docker     (122)      478 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/facial_landmark_confidence/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/facial_landmark_confidence/flc/
--rw-r--r--   0 runner    (1001) docker     (122)      115 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/facial_landmark_confidence/flc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py
--rw-r--r--   0 runner    (1001) docker     (122)     4932 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/hand_static/
--rw-r--r--   0 runner    (1001) docker     (122)      502 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/hand_static/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2480 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/hand_static/hand_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    10891 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/hand_static/networks.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/
--rw-r--r--   0 runner    (1001) docker     (122)     5936 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/Reconstruction.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/
--rw-r--r--   0 runner    (1001) docker     (122)     1065 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/Embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     4542 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/PixToMesh.py
--rw-r--r--   0 runner    (1001) docker     (122)    11301 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/Res_backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     2418 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/Surface_head.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2716 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/detectors.py
--rw-r--r--   0 runner    (1001) docker     (122)     1982 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/geometry.py
--rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/human_segmenter.py
--rw-r--r--   0 runner    (1001) docker     (122)    11865 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/networks.py
--rw-r--r--   0 runner    (1001) docker     (122)     6105 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/human_reconstruction/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_binary_quant_classification/
--rw-r--r--   0 runner    (1001) docker     (122)      573 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_binary_quant_classification/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2859 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_binary_quant_classification/binary_quant_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    19111 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_binary_quant_classification/bnext.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/
--rw-r--r--   0 runner    (1001) docker     (122)      500 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3920 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/image_body_reshaping.py
--rw-r--r--   0 runner    (1001) docker     (122)     6541 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    13616 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/person_info.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/pose_estimator/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/pose_estimator/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12027 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/pose_estimator/body.py
--rw-r--r--   0 runner    (1001) docker     (122)     5673 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/pose_estimator/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/pose_estimator/util.py
--rw-r--r--   0 runner    (1001) docker     (122)    15760 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/slim_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_classification/
--rw-r--r--   0 runner    (1001) docker     (122)      598 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_classification/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_classification/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      107 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_classification/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    20295 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_classification/backbones/beit_v2.py
--rw-r--r--   0 runner    (1001) docker     (122)    17261 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_classification/backbones/nextvit.py
--rw-r--r--   0 runner    (1001) docker     (122)     2185 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_classification/mmcls_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1554 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_classification/resnet50_cc.py
--rw-r--r--   0 runner    (1001) docker     (122)     5255 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_classification/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/
--rw-r--r--   0 runner    (1001) docker     (122)      704 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/adaint/
--rw-r--r--   0 runner    (1001) docker     (122)       44 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/adaint/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14338 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/adaint/adaint.py
--rw-r--r--   0 runner    (1001) docker     (122)     3753 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/csrnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/deeplpf/
--rw-r--r--   0 runner    (1001) docker     (122)       66 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/deeplpf/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2575 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py
--rw-r--r--   0 runner    (1001) docker     (122)    31764 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/deeplpf/deeplpfnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     2821 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_color_enhance/image_color_enhance.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/
--rw-r--r--   0 runner    (1001) docker     (122)      640 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/
--rw-r--r--   0 runner    (1001) docker     (122)      122 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9385 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/ddcolor.py
--rw-r--r--   0 runner    (1001) docker     (122)     6437 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py
--rw-r--r--   0 runner    (1001) docker     (122)     9576 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/loss.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6857 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/position_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)     7796 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/transformer_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6465 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)     6510 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/vgg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/unet/
--rw-r--r--   0 runner    (1001) docker     (122)      129 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/unet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10574 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/unet/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)    10647 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_colorization/unet/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_debanding/
--rw-r--r--   0 runner    (1001) docker     (122)      483 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_debanding/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_debanding/rrdb/
--rw-r--r--   0 runner    (1001) docker     (122)       53 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_debanding/rrdb/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3005 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_debanding/rrdb/rrdb_image_debanding.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_deblur/
--rw-r--r--   0 runner    (1001) docker     (122)      510 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_deblur/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4241 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_deblur/nafnet_for_image_deblur.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4329 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12474 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py
--rw-r--r--   0 runner    (1001) docker     (122)     3141 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/evaluator.py
--rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/
--rw-r--r--   0 runner    (1001) docker     (122)      448 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6827 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/calibration_layer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7064 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/defrcn.py
--rw-r--r--   0 runner    (1001) docker     (122)    10779 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/fast_rcnn.py
--rw-r--r--   0 runner    (1001) docker     (122)     1220 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/gdl.py
--rw-r--r--   0 runner    (1001) docker     (122)     1732 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     4770 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/roi_heads.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    23599 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/coco_register.py
--rw-r--r--   0 runner    (1001) docker     (122)     4803 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     3595 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py
--rw-r--r--   0 runner    (1001) docker     (122)      583 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/register_data.py
--rw-r--r--   0 runner    (1001) docker     (122)     2617 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/requirements_check.py
--rw-r--r--   0 runner    (1001) docker     (122)    11013 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/voc_register.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_denoise/
--rw-r--r--   0 runner    (1001) docker     (122)      514 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_denoise/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_denoise/nafnet/
--rw-r--r--   0 runner    (1001) docker     (122)     6664 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_denoise/nafnet/NAFNet_arch.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_denoise/nafnet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1627 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_denoise/nafnet/arch_util.py
--rw-r--r--   0 runner    (1001) docker     (122)     2475 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_denoise/nafnet_for_image_denoise.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6757 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_depth.py
--rw-r--r--   0 runner    (1001) docker     (122)    18233 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    10106 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    26006 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/swin_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)    13560 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/uper_crf_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1600 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/newcrfs_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/
--rw-r--r--   0 runner    (1001) docker     (122)      536 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2606 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/networks/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/networks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1485 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/networks/bts_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     2819 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/networks/decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     2506 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/networks/encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     8545 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/networks/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_driving_perception/
--rw-r--r--   0 runner    (1001) docker     (122)      999 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_driving_perception/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2022 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_driving_perception/image_driving_percetion_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4352 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_driving_perception/preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     7475 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_driving_perception/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/
--rw-r--r--   0 runner    (1001) docker     (122)      488 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3124 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/gan_wrap.py
--rw-r--r--   0 runner    (1001) docker     (122)    21432 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/op/
--rw-r--r--   0 runner    (1001) docker     (122)      242 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/op/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6497 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py
--rw-r--r--   0 runner    (1001) docker     (122)     3094 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/op/fused_act.py
--rw-r--r--   0 runner    (1001) docker     (122)     5912 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/op/upfirdn2d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facelib/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facelib/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10514 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facelib/align_trans.py
--rw-r--r--   0 runner    (1001) docker     (122)     5955 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facelib/matlab_cp2tform.py
--rw-r--r--   0 runner    (1001) docker     (122)     9077 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/image_face_fusion.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3045 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/aad_layer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8555 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/aei_flow_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     9366 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/bfm.py
--rw-r--r--   0 runner    (1001) docker     (122)    12449 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/dense_motion.py
--rw-r--r--   0 runner    (1001) docker     (122)    20604 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/facerecon_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     7433 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/model_irse.py
--rw-r--r--   0 runner    (1001) docker     (122)     7790 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/ops.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/
--rw-r--r--   0 runner    (1001) docker     (122)      575 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      525 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11736 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/backbone/deeplab_resnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/m2fp/
--rw-r--r--   0 runner    (1001) docker     (122)      640 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/m2fp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8257 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/m2fp/m2fp_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     8361 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/m2fp/m2fp_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    15097 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/m2fp_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5633 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_human_parsing/parsing_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/
--rw-r--r--   0 runner    (1001) docker     (122)      475 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2690 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7605 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/default.py
--rw-r--r--   0 runner    (1001) docker     (122)     1253 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/ade20k/
--rw-r--r--   0 runner    (1001) docker     (122)       81 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/ade20k/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12202 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/ade20k/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     5348 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/ade20k/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     7509 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/adversarial.py
--rw-r--r--   0 runner    (1001) docker     (122)     1564 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/feature_matching.py
--rw-r--r--   0 runner    (1001) docker     (122)    19052 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/ffc.py
--rw-r--r--   0 runner    (1001) docker     (122)    11842 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/inception.py
--rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/perceptual.py
--rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/pix2pixhd.py
--rw-r--r--   0 runner    (1001) docker     (122)    13350 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_inpainting/refinement.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)     1065 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      664 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3826 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/backbones/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)    27174 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/backbones/swin_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9305 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      101 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3992 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/datasets/transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/fastinst/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/fastinst/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14867 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     6266 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     8692 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/fastinst_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/
--rw-r--r--   0 runner    (1001) docker     (122)      600 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10072 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/dino_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    15407 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    18188 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     7274 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py
--rw-r--r--   0 runner    (1001) docker     (122)     2720 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/position_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)     6712 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1429 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    11454 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino_swin.py
--rw-r--r--   0 runner    (1001) docker     (122)     1549 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     7886 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/postprocess_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/
--rw-r--r--   0 runner    (1001) docker     (122)      553 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/config/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/config/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6991 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/config/default.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/
--rw-r--r--   0 runner    (1001) docker     (122)      171 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      588 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7244 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     3784 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/
--rw-r--r--   0 runner    (1001) docker     (122)      239 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py
--rw-r--r--   0 runner    (1001) docker     (122)     3012 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     2994 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     9677 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10531 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py
--rw-r--r--   0 runner    (1001) docker     (122)     3048 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py
--rw-r--r--   0 runner    (1001) docker     (122)     2132 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)     2735 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/quadtree_attention_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      344 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_matching/utils/misc.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      521 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8546 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/cas_mvsnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/casmvs_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    18175 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     9861 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/depth_filter.py
--rw-r--r--   0 runner    (1001) docker     (122)     9404 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/general_eval_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    21735 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/module.py
--rw-r--r--   0 runner    (1001) docker     (122)     3367 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_paintbyexample/
--rw-r--r--   0 runner    (1001) docker     (122)      507 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_paintbyexample/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_paintbyexample/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_panoptic_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      513 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_panoptic_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1694 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_panoptic_segmentation/panseg_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8563 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/align_faces.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/eqface/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/eqface/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1836 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/eqface/fqa.py
--rw-r--r--   0 runner    (1001) docker     (122)     4710 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/eqface/model_resnet.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    22869 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/gpen.py
--rw-r--r--   0 runner    (1001) docker     (122)     7114 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/image_portrait_enhancement.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/losses/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/losses/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4336 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/losses/helpers.py
--rw-r--r--   0 runner    (1001) docker     (122)     3286 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/losses/losses.py
--rw-r--r--   0 runner    (1001) docker     (122)     3155 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/losses/model_irse.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     7313 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/detection.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/
--rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4845 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/net.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4676 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_probing_model/
--rw-r--r--   0 runner    (1001) docker     (122)      533 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_probing_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10076 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_probing_model/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     3319 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_probing_model/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5206 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_probing_model/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_degradation/
--rw-r--r--   0 runner    (1001) docker     (122)      584 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_degradation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5064 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_degradation/degradation_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4654 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_man/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_man/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2600 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_man/image_quality_assessment_man.py
--rw-r--r--   0 runner    (1001) docker     (122)     5163 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_man/maniqa.py
--rw-r--r--   0 runner    (1001) docker     (122)    23230 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_man/swin.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      272 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16222 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/backbones/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     1060 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/heads/
--rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      529 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/heads/simple_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2651 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_reid_person/
--rw-r--r--   0 runner    (1001) docker     (122)      467 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_reid_person/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5444 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_reid_person/pass_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    14108 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_reid_person/transreid_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_restoration/
--rw-r--r--   0 runner    (1001) docker     (122)      527 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_restoration/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_restoration/demoire_models/
--rw-r--r--   0 runner    (1001) docker     (122)       69 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_restoration/demoire_models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10243 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_restoration/demoire_models/nets.py
--rw-r--r--   0 runner    (1001) docker     (122)     2640 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_restoration/image_restoration_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      712 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7896 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py
--rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py
--rw-r--r--   0 runner    (1001) docker     (122)     5155 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py
--rw-r--r--   0 runner    (1001) docker     (122)     2273 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3208 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/
--rw-r--r--   0 runner    (1001) docker     (122)      111 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1516 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2122 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2566 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/semantic_seg_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/
--rw-r--r--   0 runner    (1001) docker     (122)      303 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/
--rw-r--r--   0 runner    (1001) docker     (122)      290 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      249 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17484 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/
--rw-r--r--   0 runner    (1001) docker     (122)      196 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18241 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py
--rw-r--r--   0 runner    (1001) docker     (122)     6379 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      251 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    26514 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/
--rw-r--r--   0 runner    (1001) docker     (122)      253 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12370 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py
--rw-r--r--   0 runner    (1001) docker     (122)    11715 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      368 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      398 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     1938 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py
--rw-r--r--   0 runner    (1001) docker     (122)     1788 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/
--rw-r--r--   0 runner    (1001) docker     (122)      650 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9312 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/ptsemseg/
--rw-r--r--   0 runner    (1001) docker     (122)     3740 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/ptsemseg/BlockModules.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/ptsemseg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21275 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/ptsemseg/hrnet_backnone.py
--rw-r--r--   0 runner    (1001) docker     (122)    18023 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py
--rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/ptsemseg/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)    11210 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/skychange.py
--rw-r--r--   0 runner    (1001) docker     (122)     7874 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_skychange/skychange_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      120 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/data/
--rw-r--r--   0 runner    (1001) docker     (122)      561 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/data/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    10476 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/models/
--rw-r--r--   0 runner    (1001) docker     (122)      603 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/models/autoencoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/models/clip.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/ops/
--rw-r--r--   0 runner    (1001) docker     (122)      561 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/ops/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    24469 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/ops/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/ops/losses.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/
--rw-r--r--   0 runner    (1001) docker     (122)      536 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/data/
--rw-r--r--   0 runner    (1001) docker     (122)      127 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/data/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    10527 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/model_translation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/models/
--rw-r--r--   0 runner    (1001) docker     (122)      161 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/models/autoencoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/models/clip.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/
--rw-r--r--   0 runner    (1001) docker     (122)      384 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21828 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/apps.py
--rw-r--r--   0 runner    (1001) docker     (122)    36549 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/degradation.py
--rw-r--r--   0 runner    (1001) docker     (122)    24615 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/losses.py
--rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/metrics.py
--rw-r--r--   0 runner    (1001) docker     (122)     6736 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/random_color.py
--rw-r--r--   0 runner    (1001) docker     (122)     2745 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/random_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     3777 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/svd.py
--rw-r--r--   0 runner    (1001) docker     (122)     6728 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      486 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      136 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4099 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py
--rw-r--r--   0 runner    (1001) docker     (122)     6931 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2510 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/fourier.py
--rw-r--r--   0 runner    (1001) docker     (122)     3251 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/panostretch.py
--rw-r--r--   0 runner    (1001) docker     (122)    14887 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/post_proc.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/modality/
--rw-r--r--   0 runner    (1001) docker     (122)       86 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/modality/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5518 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/modality/layout.py
--rw-r--r--   0 runner    (1001) docker     (122)     3406 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/panovit.py
--rw-r--r--   0 runner    (1001) docker     (122)     4808 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1834 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/panovit.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/
--rwxr-xr-x   0 runner    (1001) docker     (122)      542 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6441 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/summarizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/transformer/
--rwxr-xr-x   0 runner    (1001) docker     (122)      508 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/transformer/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1900 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/transformer/layers.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     7275 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/transformer/models.py
--rwxr-xr-x   0 runner    (1001) docker     (122)      826 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/transformer/modules.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2690 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/transformer/sub_layers.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      639 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2151 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/cfg_sampler.py
--rw-r--r--   0 runner    (1001) docker     (122)    26783 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/gaussian_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    13594 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/mdm.py
--rw-r--r--   0 runner    (1001) docker     (122)     5412 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/respace.py
--rw-r--r--   0 runner    (1001) docker     (122)     3914 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/rotation2xyz.py
--rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/smpl.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      615 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/get_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     8465 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      181 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      798 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/utils/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4291 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/utils/save_op.py
--rw-r--r--   0 runner    (1001) docker     (122)    10325 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/utils/shot_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     5057 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/utils/trn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/
--rw-r--r--   0 runner    (1001) docker     (122)      602 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/dataloader/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/dataloader/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18782 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    20567 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/dataloader/read_write_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     7297 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/nerf_preprocess.py
--rw-r--r--   0 runner    (1001) docker     (122)     7876 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/nerf_recon_acc.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/network/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/network/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13317 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/network/nerf.py
--rw-r--r--   0 runner    (1001) docker     (122)     1509 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/network/segmenter.py
--rw-r--r--   0 runner    (1001) docker     (122)     5720 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/network/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      606 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3432 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/
--rw-r--r--   0 runner    (1001) docker     (122)      321 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      211 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21306 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/backbones/vit.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      278 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2220 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    11529 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/necks/
--rw-r--r--   0 runner    (1001) docker     (122)      213 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/necks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9021 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/necks/fpn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      426 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      375 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8542 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      239 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17739 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      306 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21926 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/utils/checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/
--rw-r--r--   0 runner    (1001) docker     (122)      467 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/
--rw-r--r--   0 runner    (1001) docker     (122)       86 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2657 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/depe_detect.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/
--rw-r--r--   0 runner    (1001) docker     (122)      605 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/
--rw-r--r--   0 runner    (1001) docker     (122)      299 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6670 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/
--rw-r--r--   0 runner    (1001) docker     (122)      282 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4476 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/
--rw-r--r--   0 runner    (1001) docker     (122)      276 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1064 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py
--rw-r--r--   0 runner    (1001) docker     (122)     2041 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      294 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3095 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/
--rw-r--r--   0 runner    (1001) docker     (122)      522 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7936 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py
--rw-r--r--   0 runner    (1001) docker     (122)     8689 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      255 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12874 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      282 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7442 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    59197 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/
--rw-r--r--   0 runner    (1001) docker     (122)      255 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9533 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/
--rw-r--r--   0 runner    (1001) docker     (122)      256 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9032 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      562 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18126 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5175 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)    11047 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/result_vis.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/ocr_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      473 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2870 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_detection/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/ocr_detection/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_detection/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18335 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_detection/modules/dbnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     8217 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_detection/modules/seg_detector_loss.py
--rw-r--r--   0 runner    (1001) docker     (122)     2647 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_detection/preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     7972 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_detection/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      477 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6164 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)      517 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/convnextvit.py
--rw-r--r--   0 runner    (1001) docker     (122)     3451 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/crnn.py
--rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/timm_tinyc.py
--rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/vitstr.py
--rw-r--r--   0 runner    (1001) docker     (122)     3603 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/ocr_recognition/preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/open_vocabulary_detection_vild/
--rw-r--r--   0 runner    (1001) docker     (122)      501 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/open_vocabulary_detection_vild/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14225 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/open_vocabulary_detection_vild/vild.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      511 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)      102 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5077 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/equi.py
--rw-r--r--   0 runner    (1001) docker     (122)     7500 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/layers.py
--rw-r--r--   0 runner    (1001) docker     (122)     7839 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/mobilenet.py
--rw-r--r--   0 runner    (1001) docker     (122)    14421 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     9175 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/unifuse.py
--rw-r--r--   0 runner    (1001) docker     (122)     3962 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/util.py
--rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/unifuse_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/pedestrian_attribute_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      488 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/pedestrian_attribute_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3468 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/pedestrian_attribute_recognition/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/pointcloud_sceneflow_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      495 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/pointcloud_sceneflow_estimation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16147 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/pointcloud_sceneflow_estimation/common.py
--rw-r--r--   0 runner    (1001) docker     (122)    11898 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1797 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/pointcloud_sceneflow_estimation/rcp_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/product_retrieval_embedding/
--rw-r--r--   0 runner    (1001) docker     (122)      548 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/product_retrieval_embedding/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    20974 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/product_retrieval_embedding/item_detection.py
--rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/product_retrieval_embedding/item_embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     4340 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/product_retrieval_embedding/item_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/product_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      528 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/product_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7978 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/product_segmentation/net.py
--rw-r--r--   0 runner    (1001) docker     (122)     2194 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/product_segmentation/seg_infer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      514 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5832 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      318 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8504 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     9206 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/criterion.py
--rw-r--r--   0 runner    (1001) docker     (122)     7299 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/matcher.py
--rw-r--r--   0 runner    (1001) docker     (122)     7935 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/misc.py
--rw-r--r--   0 runner    (1001) docker     (122)     6242 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/mttr.py
--rw-r--r--   0 runner    (1001) docker     (122)    16610 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2091 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py
--rw-r--r--   0 runner    (1001) docker     (122)     5629 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/postprocessing.py
--rw-r--r--   0 runner    (1001) docker     (122)     5180 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/segmentation.py
--rw-r--r--   0 runner    (1001) docker     (122)    27941 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/swin_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/robust_image_classification/
--rw-r--r--   0 runner    (1001) docker     (122)      501 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/robust_image_classification/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2902 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/robust_image_classification/easyrobust_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      497 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/models/
--rw-r--r--   0 runner    (1001) docker     (122)      213 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/models/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)     6558 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/models/backbone/Res2Net_v1b.py
--rw-r--r--   0 runner    (1001) docker     (122)      256 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/models/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6525 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/models/modules.py
--rw-r--r--   0 runner    (1001) docker     (122)     3047 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/models/senet.py
--rw-r--r--   0 runner    (1001) docker     (122)    12007 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/models/u2net.py
--rw-r--r--   0 runner    (1001) docker     (122)     3524 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/models/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2704 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/salient_detection/salient_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/shop_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      464 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/shop_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2203 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/shop_segmentation/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     4385 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/shop_segmentation/head_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)    32989 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/shop_segmentation/models.py
--rw-r--r--   0 runner    (1001) docker     (122)     9319 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/shop_segmentation/neck_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     5632 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/shop_segmentation/shop_seg_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     4095 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/shop_segmentation/shop_seg_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6699 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/shop_segmentation/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/detection_model/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/detection_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/detection_model/detection_module.py
--rw-r--r--   0 runner    (1001) docker     (122)     2532 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/detection_model/detection_unet_in.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/inpainting_model/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/inpainting_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5759 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/inpainting_model/gconv.py
--rw-r--r--   0 runner    (1001) docker     (122)     3233 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/inpainting_model/inpainting_unet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10898 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/box_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3911 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/net.py
--rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/network.py
--rw-r--r--   0 runner    (1001) docker     (122)     5003 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/predict_single.py
--rw-r--r--   0 runner    (1001) docker     (122)     1035 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/prior_box.py
--rw-r--r--   0 runner    (1001) docker     (122)     2110 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/utils.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     3890 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/unet_deploy.py
--rw-r--r--   0 runner    (1001) docker     (122)     9917 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1169 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/skin_retouching/weights_init.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/
--rw-r--r--   0 runner    (1001) docker     (122)      526 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/data/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2094 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/data/data_augment.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/exp/
--rw-r--r--   0 runner    (1001) docker     (122)      165 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/exp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      274 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/exp/base_exp.py
--rw-r--r--   0 runner    (1001) docker     (122)      392 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/exp/build.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/exp/default/
--rw-r--r--   0 runner    (1001) docker     (122)      137 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/exp/default/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/exp/default/streamyolo.py
--rw-r--r--   0 runner    (1001) docker     (122)     1845 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/exp/yolox_base.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/
--rw-r--r--   0 runner    (1001) docker     (122)      238 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/darknet.py
--rw-r--r--   0 runner    (1001) docker     (122)    10911 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/dfp_pafpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     6156 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/network_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     1314 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/streamyolo.py
--rw-r--r--   0 runner    (1001) docker     (122)     5669 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/tal_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4352 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/realtime_video_detector.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      270 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3681 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/utils/boxes.py
--rw-r--r--   0 runner    (1001) docker     (122)      209 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/stream_yolo/utils/format.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/super_resolution/
--rw-r--r--   0 runner    (1001) docker     (122)      555 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/super_resolution/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7652 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/super_resolution/arch_util.py
--rw-r--r--   0 runner    (1001) docker     (122)    10508 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/super_resolution/ecb.py
--rw-r--r--   0 runner    (1001) docker     (122)     3525 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/super_resolution/ecbsr_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/super_resolution/rrdbnet_arch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/table_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      462 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/table_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16198 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/table_recognition/lineless_table_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     3360 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/table_recognition/model_lore.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/table_recognition/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/table_recognition/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12614 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/table_recognition/modules/lore_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)    15090 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/table_recognition/modules/lore_processor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)       96 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5488 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)      777 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/lseg_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7587 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/lseg_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     4143 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/lseg_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6145 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/lseg_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    18951 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/lseg_vit.py
--rw-r--r--   0 runner    (1001) docker     (122)    16418 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5165 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/simple_tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/
--rw-r--r--   0 runner    (1001) docker     (122)      594 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    43681 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/basic_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     2174 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/global_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2902 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/master_net.py
--rw-r--r--   0 runner    (1001) docker     (122)      766 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/model_zoo.py
--rw-r--r--   0 runner    (1001) docker     (122)     2892 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/plain_net_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     7405 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/super_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)    14983 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/super_res_idwexkx.py
--rw-r--r--   0 runner    (1001) docker     (122)     8709 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/super_res_k1kxk1.py
--rw-r--r--   0 runner    (1001) docker     (122)     6923 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/super_res_kxkx.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      699 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/apis/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/apis/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2067 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/apis/detector_evaluater.py
--rw-r--r--   0 runner    (1001) docker     (122)     4000 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/apis/detector_inference.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3460 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py
--rw-r--r--   0 runner    (1001) docker     (122)     8123 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py
--rw-r--r--   0 runner    (1001) docker     (122)     2345 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py
--rw-r--r--   0 runner    (1001) docker     (122)     5911 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py
--rw-r--r--   0 runner    (1001) docker     (122)     2842 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/
--rw-r--r--   0 runner    (1001) docker     (122)      148 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      621 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3701 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py
--rw-r--r--   0 runner    (1001) docker     (122)     9356 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py
--rw-r--r--   0 runner    (1001) docker     (122)     7465 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14261 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/base_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    10559 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    13101 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/ops.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    18626 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py
--rw-r--r--   0 runner    (1001) docker     (122)     7526 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py
--rw-r--r--   0 runner    (1001) docker     (122)     2572 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      561 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/weight_init.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/
--rw-r--r--   0 runner    (1001) docker     (122)      409 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12602 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py
--rw-r--r--   0 runner    (1001) docker     (122)    19162 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5588 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py
--rw-r--r--   0 runner    (1001) docker     (122)    12284 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/
--rw-r--r--   0 runner    (1001) docker     (122)      421 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7347 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py
--rw-r--r--   0 runner    (1001) docker     (122)    24842 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     3499 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/detectors/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/detectors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2809 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/detectors/detector.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/structures/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/structures/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9197 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/structures/bounding_box.py
--rw-r--r--   0 runner    (1001) docker     (122)     2627 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/structures/boxlist_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)     2774 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/structures/image_list.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      189 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11594 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/utils/boxes.py
--rw-r--r--   0 runner    (1001) docker     (122)     5838 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/utils/model_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1164 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/utils/scheduler.py
--rw-r--r--   0 runner    (1001) docker     (122)     6400 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/detector.py
--rw-r--r--   0 runner    (1001) docker     (122)      627 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/tinynas_damoyolo.py
--rw-r--r--   0 runner    (1001) docker     (122)      643 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/tinynas_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     1026 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/tinynas_detection/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/
--rw-r--r--   0 runner    (1001) docker     (122)     2896 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/UNet_for_video_deinterlace.py
--rw-r--r--   0 runner    (1001) docker     (122)      494 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      773 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/deinterlace_arch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3159 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/archs.py
--rw-r--r--   0 runner    (1001) docker     (122)     1441 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/deep_fourier_upsampling.py
--rw-r--r--   0 runner    (1001) docker     (122)     2972 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/enh.py
--rw-r--r--   0 runner    (1001) docker     (122)     3572 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/fre.py
--rw-r--r--   0 runner    (1001) docker     (122)     3716 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      483 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/configs/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/configs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12753 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/configs/default_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     6731 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/dro_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/geometry/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/geometry/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5494 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/geometry/camera.py
--rw-r--r--   0 runner    (1001) docker     (122)     2285 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/geometry/camera_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3737 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/geometry/pose.py
--rw-r--r--   0 runner    (1001) docker     (122)     3685 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/geometry/pose_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5277 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/model_checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)     2356 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/model_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    10098 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/model_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     7204 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/sfm_model_mf.py
--rw-r--r--   0 runner    (1001) docker     (122)     4387 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/sup_model_mf.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/depth_pose/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/depth_pose/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10532 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8902 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     1607 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/layers.py
--rw-r--r--   0 runner    (1001) docker     (122)     1915 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/optim/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/optim/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15781 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/optim/extractor.py
--rw-r--r--   0 runner    (1001) docker     (122)     8039 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/optim/update.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6815 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/augmentations.py
--rw-r--r--   0 runner    (1001) docker     (122)    10248 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/config.py
--rw-r--r--   0 runner    (1001) docker     (122)    15068 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/depth.py
--rw-r--r--   0 runner    (1001) docker     (122)     1153 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/horovod.py
--rw-r--r--   0 runner    (1001) docker     (122)    10965 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/image.py
--rw-r--r--   0 runner    (1001) docker     (122)     9407 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/image_gt.py
--rw-r--r--   0 runner    (1001) docker     (122)     6499 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/load.py
--rw-r--r--   0 runner    (1001) docker     (122)     2726 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/misc.py
--rw-r--r--   0 runner    (1001) docker     (122)     1348 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/types.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/
--rw-r--r--   0 runner    (1001) docker     (122)     1894 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/VFINet_arch.py
--rw-r--r--   0 runner    (1001) docker     (122)     3334 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py
--rw-r--r--   0 runner    (1001) docker     (122)      458 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/flow_model/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/flow_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3212 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/flow_model/corr.py
--rw-r--r--   0 runner    (1001) docker     (122)     9228 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/flow_model/extractor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5346 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/flow_model/raft.py
--rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/flow_model/update.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/
--rw-r--r--   0 runner    (1001) docker     (122)    13745 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py
--rw-r--r--   0 runner    (1001) docker     (122)     4049 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/UNet.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3823 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/flow_reversal.py
--rw-r--r--   0 runner    (1001) docker     (122)    16050 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py
--rw-r--r--   0 runner    (1001) docker     (122)    36415 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/transformer_layers.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3314 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/utils/scene_change_detection.py
--rw-r--r--   0 runner    (1001) docker     (122)     2907 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/utils/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_human_matting/
--rw-r--r--   0 runner    (1001) docker     (122)      558 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_human_matting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1324 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_human_matting/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/
--rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10465 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     2662 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/deep_guided_filter.py
--rw-r--r--   0 runner    (1001) docker     (122)     5506 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/effv2.py
--rw-r--r--   0 runner    (1001) docker     (122)     2904 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/lraspp.py
--rw-r--r--   0 runner    (1001) docker     (122)     2234 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/matting.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_inpainting/
--rw-r--r--   0 runner    (1001) docker     (122)      524 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_inpainting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11056 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_inpainting/inpainting.py
--rw-r--r--   0 runner    (1001) docker     (122)    13727 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_inpainting/inpainting_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      582 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18236 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    21551 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/kernel_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    16955 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/kernel_iter_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    20983 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/kernel_update_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4136 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/kernel_updator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/neck/
--rw-r--r--   0 runner    (1001) docker     (122)      525 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/neck/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11733 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/track/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/track/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    26843 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/track/kernel_update_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    10771 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py
--rw-r--r--   0 runner    (1001) docker     (122)     4163 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    18059 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/video_knet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/
--rw-r--r--   0 runner    (1001) docker     (122)      541 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2970 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/models/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     2420 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/models/decode.py
--rw-r--r--   0 runner    (1001) docker     (122)     1890 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/models/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4921 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/models/yolo.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/tracker/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/tracker/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1084 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/tracker/basetrack.py
--rw-r--r--   0 runner    (1001) docker     (122)     3117 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/tracker/matching.py
--rw-r--r--   0 runner    (1001) docker     (122)    14995 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/tracker/multitracker.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2230 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/utils/image.py
--rw-r--r--   0 runner    (1001) docker     (122)     9570 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/utils/kalman_filter.py
--rw-r--r--   0 runner    (1001) docker     (122)     7296 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2888 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/utils/visualization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      497 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      818 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/aggregate.py
--rw-r--r--   0 runner    (1001) docker     (122)     3582 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/cbam.py
--rw-r--r--   0 runner    (1001) docker     (122)     1979 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/eval_network.py
--rw-r--r--   0 runner    (1001) docker     (122)     3980 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/inference_core.py
--rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/inference_memory_bank.py
--rw-r--r--   0 runner    (1001) docker     (122)     7037 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/mod_resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)      974 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    15309 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/modules.py
--rw-r--r--   0 runner    (1001) docker     (122)     5593 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/network.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      477 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10040 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)    26628 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/
--rw-r--r--   0 runner    (1001) docker     (122)      515 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8349 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    20677 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    28653 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_update_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4081 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_updator.py
--rw-r--r--   0 runner    (1001) docker     (122)     6696 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     8627 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     5885 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/track_heads.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/neck/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/neck/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6255 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/neck/fpn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/track/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/track/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8508 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py
--rw-r--r--   0 runner    (1001) docker     (122)    17155 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/video_k_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5440 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/visualizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/config/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/config/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1024 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/config/ostrack.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/layers/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/layers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/layers/attn.py
--rw-r--r--   0 runner    (1001) docker     (122)     5004 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/layers/attn_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     4805 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/layers/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1234 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/layers/patch_embed.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3380 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     3393 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/ostrack.py
--rw-r--r--   0 runner    (1001) docker     (122)      653 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12278 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/procontext/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/procontext/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3497 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/procontext/procontext.py
--rw-r--r--   0 runner    (1001) docker     (122)      943 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/procontext/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4473 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/procontext/vit_ce.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/tracker/
--rw-r--r--   0 runner    (1001) docker     (122)      114 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/tracker/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5507 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/tracker/ostrack.py
--rw-r--r--   0 runner    (1001) docker     (122)     7123 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/tracker/procontext.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8488 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/utils/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/
--rw-r--r--   0 runner    (1001) docker     (122)    14702 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/DUT_raft.py
--rw-r--r--   0 runner    (1001) docker     (122)     4715 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/MotionPro.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/RAFT/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/RAFT/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3290 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/RAFT/corr.py
--rw-r--r--   0 runner    (1001) docker     (122)     9214 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/RAFT/extractor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5275 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/RAFT/raft.py
--rw-r--r--   0 runner    (1001) docker     (122)     5526 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/RAFT/update.py
--rw-r--r--   0 runner    (1001) docker     (122)     3922 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/Smoother.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1447 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/config.py
--rw-r--r--   0 runner    (1001) docker     (122)     7292 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/rf_det_module.py
--rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/rf_det_so.py
--rw-r--r--   0 runner    (1001) docker     (122)     3452 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUTRAFTStabilizer.py
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/
--rw-r--r--   0 runner    (1001) docker     (122)     4684 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/IterativeSmooth.py
--rw-r--r--   0 runner    (1001) docker     (122)    14212 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/MedianFilter.py
--rw-r--r--   0 runner    (1001) docker     (122)    22544 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/ProjectionUtils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2893 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/RAFTUtils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2817 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/WarpUtils.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14474 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/image_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4977 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/math_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/
--rw-r--r--   0 runner    (1001) docker     (122)      487 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/exp/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/exp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2488 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7097 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/longshortnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5774 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py
--rw-r--r--   0 runner    (1001) docker     (122)     4848 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py
--rw-r--r--   0 runner    (1001) docker     (122)     9990 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort.py
--rw-r--r--   0 runner    (1001) docker     (122)     3905 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_summarization/
--rw-r--r--   0 runner    (1001) docker     (122)      536 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_summarization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4959 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_summarization/base_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_summarization/kts/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_summarization/kts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1221 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_summarization/kts/cpd_auto.py
--rw-r--r--   0 runner    (1001) docker     (122)     3238 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_summarization/kts/cpd_nonlin.py
--rw-r--r--   0 runner    (1001) docker     (122)    13098 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_summarization/pgl_sum.py
--rw-r--r--   0 runner    (1001) docker     (122)     8812 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_summarization/summarizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/video_super_resolution/
--rw-r--r--   0 runner    (1001) docker     (122)      689 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_super_resolution/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14118 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_super_resolution/basicvsr_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     4727 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_super_resolution/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     4720 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_super_resolution/msrresnet_lite_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     3636 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py
--rw-r--r--   0 runner    (1001) docker     (122)     3637 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/video_super_resolution/real_basicvsr_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/vidt/
--rw-r--r--   0 runner    (1001) docker     (122)      464 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vidt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    40074 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vidt/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    25588 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vidt/deformable_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7436 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vidt/fpn_fusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    16697 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vidt/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     3651 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vidt/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/virual_tryon/
--rw-r--r--   0 runner    (1001) docker     (122)      464 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/virual_tryon/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17690 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/virual_tryon/sdafnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/
--rw-r--r--   0 runner    (1001) docker     (122)      502 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16102 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)      797 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1786 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     9340 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/petl.py
--rw-r--r--   0 runner    (1001) docker     (122)     5021 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/timm_helpers.py
--rw-r--r--   0 runner    (1001) docker     (122)    28715 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/timm_vision_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5040 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/timm_weight_init.py
--rw-r--r--   0 runner    (1001) docker     (122)     5614 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/vision_efficient_tuning.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/vision_middleware/
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_middleware/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5749 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_middleware/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    28089 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_middleware/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     6494 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_middleware/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6192 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vision_middleware/vim.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/cv/vop_retrieval/
--rw-r--r--   0 runner    (1001) docker     (122)      919 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vop_retrieval/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12238 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vop_retrieval/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5188 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vop_retrieval/basic_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    13520 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vop_retrieval/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5299 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vop_retrieval/model_se.py
--rw-r--r--   0 runner    (1001) docker     (122)     5177 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/cv/vop_retrieval/tokenization_clip.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/
--rw-r--r--   0 runner    (1001) docker     (122)     2182 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/clip/
--rw-r--r--   0 runner    (1001) docker     (122)       97 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/clip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14496 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/clip/bert_tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3898 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/clip/configuration_bert.py
--rw-r--r--   0 runner    (1001) docker     (122)    22351 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/clip/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    20998 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/clip/modeling_bert.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/clip_interrogator/
--rw-r--r--   0 runner    (1001) docker     (122)       37 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/clip_interrogator/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    24293 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/clip_interrogator/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      140 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    26652 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/diffusion/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    14427 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/diffusion/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    39910 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/diffusion/structbert.py
--rw-r--r--   0 runner    (1001) docker     (122)    11507 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/diffusion/tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)    11834 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/diffusion/unet_generator.py
--rw-r--r--   0 runner    (1001) docker     (122)     8566 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/diffusion/unet_upsampler_1024.py
--rw-r--r--   0 runner    (1001) docker     (122)    12361 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/diffusion/unet_upsampler_256.py
--rw-r--r--   0 runner    (1001) docker     (122)    44602 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/dpm_solver_pytorch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/efficient_diffusion_tuning/
--rw-r--r--   0 runner    (1001) docker     (122)      540 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/efficient_diffusion_tuning/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10302 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/gemm/
--rw-r--r--   0 runner    (1001) docker     (122)      139 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/gemm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21694 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/gemm/gemm_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     3718 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/gemm/gemm_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/gemm/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      548 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    36265 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/gaussian_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     2969 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/respace.py
--rw-r--r--   0 runner    (1001) docker     (122)     1365 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/script.py
--rw-r--r--   0 runner    (1001) docker     (122)    36898 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/unet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/mgeo/
--rw-r--r--   0 runner    (1001) docker     (122)     1444 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mgeo/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)   101942 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mgeo/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     8651 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mgeo/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     3268 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mgeo/text_ranking.py
--rw-r--r--   0 runner    (1001) docker     (122)    10331 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mgeo/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/
--rw-r--r--   0 runner    (1001) docker     (122)      141 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/dataloaders/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/dataloaders/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3789 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/dataloaders/rawvideo_util.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/
--rw-r--r--   0 runner    (1001) docker     (122)      162 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9790 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     1442 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/dynamic_inverted_softmax.py
--rw-r--r--   0 runner    (1001) docker     (122)    21257 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/modeling.py
--rw-r--r--   0 runner    (1001) docker     (122)    18790 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/module_clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     3577 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/module_cross.py
--rw-r--r--   0 runner    (1001) docker     (122)     5581 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/tokenization_clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     4116 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/until_module.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug/
--rw-r--r--   0 runner    (1001) docker     (122)      739 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug/clip/
--rw-r--r--   0 runner    (1001) docker     (122)       86 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug/clip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16605 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug/clip/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     6030 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug/configuration_mplug.py
--rwxr-xr-x   0 runner    (1001) docker     (122)   120753 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug/modeling_mplug.py
--rw-r--r--   0 runner    (1001) docker     (122)    34049 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug/mvit.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    21332 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug/predictor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5536 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug_for_all_tasks.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug_owl/
--rw-r--r--   0 runner    (1001) docker     (122)      835 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug_owl/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10293 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug_owl/configuration_mplug_owl.py
--rw-r--r--   0 runner    (1001) docker     (122)    64194 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/mplug_owl/modeling_mplug_owl.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      150 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10208 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)    11503 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    28436 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    13487 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/prior.py
--rw-r--r--   0 runner    (1001) docker     (122)     6898 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)    16675 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/upsampler.py
--rw-r--r--   0 runner    (1001) docker     (122)     6565 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/xglm.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/
--rw-r--r--   0 runner    (1001) docker     (122)      306 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/adaptor/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/adaptor/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18720 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/configuration_mmspeech.py
--rw-r--r--   0 runner    (1001) docker     (122)    16552 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/configuration_ofa.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1785 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/incremental_decoding_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    21049 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/multihead_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     5658 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/ngram_repeat_block.py
--rw-r--r--   0 runner    (1001) docker     (122)    43439 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/search.py
--rw-r--r--   0 runner    (1001) docker     (122)    41976 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/sequence_generator.py
--rw-r--r--   0 runner    (1001) docker     (122)    16690 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/token_generation_constraints.py
--rw-r--r--   0 runner    (1001) docker     (122)     4883 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    44296 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/modeling_mmspeech.py
--rw-r--r--   0 runner    (1001) docker     (122)   100933 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/modeling_ofa.py
--rw-r--r--   0 runner    (1001) docker     (122)    13226 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)    15028 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/tokenization_ofa.py
--rw-r--r--   0 runner    (1001) docker     (122)     8004 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/tokenization_ofa_fast.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/utils/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      676 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/utils/constant.py
--rw-r--r--   0 runner    (1001) docker     (122)     1877 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     8435 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa/vit.py
--rw-r--r--   0 runner    (1001) docker     (122)    24779 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa_for_all_tasks.py
--rw-r--r--   0 runner    (1001) docker     (122)    12983 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/ofa_for_text_to_image_synthesis_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/rleg/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/rleg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4865 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/rleg/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     3410 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/rleg/rleg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/soonet/
--rw-r--r--   0 runner    (1001) docker     (122)      678 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/soonet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9838 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/soonet/blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)    11896 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/soonet/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     6165 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/soonet/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    22584 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/soonet/swin_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4885 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/soonet/tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     1597 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/soonet/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/team/
--rw-r--r--   0 runner    (1001) docker     (122)      140 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/team/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5181 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/team/team_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    11502 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/team/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18477 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/autoencoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     9264 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     9504 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    38498 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/unet_sd.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/multi_modal/vldoc/
--rw-r--r--   0 runner    (1001) docker     (122)       93 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/vldoc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11339 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/vldoc/conv_fpn_trans.py
--rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/vldoc/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)    16687 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/vldoc/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    47348 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/vldoc/modeling_layout_roberta.py
--rw-r--r--   0 runner    (1001) docker     (122)    20956 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/vldoc/processing.py
--rw-r--r--   0 runner    (1001) docker     (122)     4680 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/vldoc/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)     7333 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/multi_modal/vldoc/transformer_local.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/T5/
--rw-r--r--   0 runner    (1001) docker     (122)      599 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/T5/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    67374 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/T5/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7541 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/T5/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    21467 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/T5/text2text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     6368 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/bart/
--rw-r--r--   0 runner    (1001) docker     (122)      112 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bart/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3058 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bart/text_error_correction.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/bert/
--rw-r--r--   0 runner    (1001) docker     (122)     1519 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    40458 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7308 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     4113 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/document_segmentation.py
--rw-r--r--   0 runner    (1001) docker     (122)      512 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     6074 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/sentence_embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     7153 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/siamese_uie.py
--rw-r--r--   0 runner    (1001) docker     (122)     1478 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     1138 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/text_ranking.py
--rw-r--r--   0 runner    (1001) docker     (122)     2140 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/token_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     6904 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bert/word_alignment.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/bloom/
--rw-r--r--   0 runner    (1001) docker     (122)      472 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bloom/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      505 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/bloom/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/canmt/
--rw-r--r--   0 runner    (1001) docker     (122)      102 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/canmt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    52235 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/canmt/canmt_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     2940 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/canmt/canmt_translation.py
--rw-r--r--   0 runner    (1001) docker     (122)    35688 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/canmt/sequence_generator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/codegeex/
--rwxr-xr-x   0 runner    (1001) docker     (122)      730 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/codegeex/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    35473 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/codegeex/codegeex.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     3995 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/codegeex/codegeex_for_code_generation.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4008 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/codegeex/codegeex_for_code_translation.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     9997 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/codegeex/inference.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6111 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/codegeex/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/csanmt/
--rw-r--r--   0 runner    (1001) docker     (122)       96 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/csanmt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    61868 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/csanmt/translation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/deberta_v2/
--rw-r--r--   0 runner    (1001) docker     (122)     1771 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/deberta_v2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    47998 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/deberta_v2/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     6771 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/deberta_v2/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    10364 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/deberta_v2/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)    21421 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/deberta_v2/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)    10698 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/deberta_v2/tokenization_fast.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/dgds/
--rw-r--r--   0 runner    (1001) docker     (122)      939 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/dgds/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7092 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/dgds/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     1656 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/dgds/document_grounded_dialog_generate.py
--rw-r--r--   0 runner    (1001) docker     (122)     1059 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/dgds/document_grounded_dialog_rerank.py
--rw-r--r--   0 runner    (1001) docker     (122)     2180 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/dgds/document_grounded_dialog_retrieval.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/fid_T5/
--rw-r--r--   0 runner    (1001) docker     (122)     1082 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/fid_T5/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8108 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/fid_T5/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/fid_plug/
--rw-r--r--   0 runner    (1001) docker     (122)     1181 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/fid_plug/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    45082 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/fid_plug/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5045 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/fid_plug/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     6709 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/fid_plug/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/
--rw-r--r--   0 runner    (1001) docker     (122)      540 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/generation/
--rw-r--r--   0 runner    (1001) docker     (122)       87 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/generation/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    10112 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/generation/strategies.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5152 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/initialize.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/kernels/
--rw-r--r--   0 runner    (1001) docker     (122)     3263 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/kernels/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/quantization/
--rw-r--r--   0 runner    (1001) docker     (122)     2635 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/quantization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/quantization/functional.py
--rw-r--r--   0 runner    (1001) docker     (122)     4510 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/quantization/layers.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    13504 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/glm_130b/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/gpt2/
--rw-r--r--   0 runner    (1001) docker     (122)      470 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      498 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt2/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/gpt3/
--rw-r--r--   0 runner    (1001) docker     (122)      852 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt3/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15811 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt3/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     8971 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt3/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    51600 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt3/distributed_gpt3.py
--rw-r--r--   0 runner    (1001) docker     (122)     2847 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt3/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2586 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt3/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/
--rw-r--r--   0 runner    (1001) docker     (122)      874 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13129 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5198 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/checkpointing.py
--rw-r--r--   0 runner    (1001) docker     (122)     4930 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    49316 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/distributed_gpt_moe.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/experts.py
--rw-r--r--   0 runner    (1001) docker     (122)     3504 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/layer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2553 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/mappings.py
--rw-r--r--   0 runner    (1001) docker     (122)    23756 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/sharded_moe.py
--rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2717 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2277 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_moe/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_neo/
--rw-r--r--   0 runner    (1001) docker     (122)      474 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_neo/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      518 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/gpt_neo/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/heads/
--rw-r--r--   0 runner    (1001) docker     (122)      661 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    25248 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/heads/crf_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     6947 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/heads/fill_mask_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     5145 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/heads/infromation_extraction_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2056 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/heads/text_classification_head.py
--rw-r--r--   0 runner    (1001) docker     (122)      964 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/heads/text_generation_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2029 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/heads/text_ranking_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2596 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/heads/token_classification_head.py
--rw-r--r--   0 runner    (1001) docker     (122)      948 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/heads/torch_pretrain_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/hf_transformers/
--rw-r--r--   0 runner    (1001) docker     (122)      488 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/hf_transformers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4897 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/hf_transformers/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/llama/
--rw-r--r--   0 runner    (1001) docker     (122)      866 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/llama/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    29197 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/llama/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     4695 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/llama/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    11349 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/llama/convert_llama_weights_to_hf.py
--rw-r--r--   0 runner    (1001) docker     (122)     7212 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/llama/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)    10333 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/llama/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)     4720 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/llama/tokenization_fast.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/lstm/
--rw-r--r--   0 runner    (1001) docker     (122)      610 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/lstm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1312 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/lstm/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     2187 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/lstm/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/megatron_bert/
--rw-r--r--   0 runner    (1001) docker     (122)      688 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/megatron_bert/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    39864 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/megatron_bert/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     6599 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/megatron_bert/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    12452 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/megatron_bert/fill_mask.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/
--rw-r--r--   0 runner    (1001) docker     (122)      572 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    28115 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/arguments.py
--rw-r--r--   0 runner    (1001) docker     (122)    28162 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/blocklm_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    17995 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/configure_data.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/
--rw-r--r--   0 runner    (1001) docker     (122)    13656 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    20350 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/corpora.py
--rw-r--r--   0 runner    (1001) docker     (122)    45765 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/datasets.py
--rw-r--r--   0 runner    (1001) docker     (122)     3342 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/extraction.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8459 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/file_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     9797 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/lazy_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     7221 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/samplers.py
--rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/sp_tokenizer.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    53304 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)    14551 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/tokenization_gpt2.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    15773 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/wordpiece.py
--rw-r--r--   0 runner    (1001) docker     (122)    21669 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/generation_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    16247 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/mglm_for_text_summarization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/model/
--rwxr-xr-x   0 runner    (1001) docker     (122)      984 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/model/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5443 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/model/distributed.py
--rw-r--r--   0 runner    (1001) docker     (122)     9967 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/model/downstream.py
--rw-r--r--   0 runner    (1001) docker     (122)    70249 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/model/modeling_bert.py
--rw-r--r--   0 runner    (1001) docker     (122)     8743 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/model/modeling_glm.py
--rw-r--r--   0 runner    (1001) docker     (122)     2531 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/model/prompt.py
--rw-r--r--   0 runner    (1001) docker     (122)    48886 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/model/transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/process_grid.py
--rw-r--r--   0 runner    (1001) docker     (122)      203 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/run_test.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/test/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/test/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      950 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/test/test_block.py
--rw-r--r--   0 runner    (1001) docker     (122)      704 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/test/test_rel_shift.py
--rw-r--r--   0 runner    (1001) docker     (122)    17815 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/train_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    19029 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/mglm/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/palm_v2/
--rw-r--r--   0 runner    (1001) docker     (122)     1268 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/palm_v2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5532 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/palm_v2/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    29453 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/palm_v2/dureader_eval.py
--rw-r--r--   0 runner    (1001) docker     (122)    55450 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/palm_v2/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/peer/
--rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/peer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    55780 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/peer/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    11716 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/peer/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     6166 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/peer/sas_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4933 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/peer/text_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/plug/
--rwxr-xr-x   0 runner    (1001) docker     (122)     3321 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug/AnnealingLR.py
--rw-r--r--   0 runner    (1001) docker     (122)      660 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    41209 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    11797 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    10983 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug/distributed_plug.py
--rw-r--r--   0 runner    (1001) docker     (122)     8427 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug/generator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/plug_mental/
--rw-r--r--   0 runner    (1001) docker     (122)     1359 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug_mental/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7671 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug_mental/adv_utils.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    47486 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug_mental/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7956 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug_mental/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    10881 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/plug_mental/text_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/ponet/
--rw-r--r--   0 runner    (1001) docker     (122)     1490 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/ponet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    37918 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/ponet/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     6366 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/ponet/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     4176 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/ponet/document_segmentation.py
--rw-r--r--   0 runner    (1001) docker     (122)    11011 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/ponet/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     7147 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/ponet/tokenization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)      987 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1208 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     3832 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/dialog_intent_prediction.py
--rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/dialog_modeling.py
--rw-r--r--   0 runner    (1001) docker     (122)    16648 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/dialog_state_tracking.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/space/model/
--rw-r--r--   0 runner    (1001) docker     (122)      421 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10281 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/model/gen_unified_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10757 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/model/generator.py
--rw-r--r--   0 runner    (1001) docker     (122)     7505 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/model/intent_unified_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3032 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/model/model_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/model/tokenization_space.py
--rw-r--r--   0 runner    (1001) docker     (122)    11941 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/model/unified_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/space/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2398 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/modules/embedder.py
--rw-r--r--   0 runner    (1001) docker     (122)      956 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/modules/feedforward.py
--rw-r--r--   0 runner    (1001) docker     (122)     1721 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/modules/functions.py
--rw-r--r--   0 runner    (1001) docker     (122)     3397 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/modules/multihead_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     1922 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space/modules/transformer_block.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/space_T_cn/
--rw-r--r--   0 runner    (1001) docker     (122)      529 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space_T_cn/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    44438 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space_T_cn/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5194 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space_T_cn/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    30117 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space_T_cn/table_question_answering.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/space_T_en/
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space_T_en/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3715 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/space_T_en/text_to_sql.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/structbert/
--rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/structbert/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7673 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/structbert/adv_utils.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    40848 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/structbert/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7686 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/structbert/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    27203 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/structbert/faq_question_answering.py
--rw-r--r--   0 runner    (1001) docker     (122)    12581 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/structbert/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)    11862 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/structbert/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)    11074 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/structbert/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/task_models/
--rw-r--r--   0 runner    (1001) docker     (122)     1453 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/task_models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5323 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/task_models/feature_extraction.py
--rw-r--r--   0 runner    (1001) docker     (122)     2698 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/task_models/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)      766 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/task_models/information_extraction.py
--rw-r--r--   0 runner    (1001) docker     (122)    28991 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/task_models/task_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1912 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/task_models/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     8678 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/task_models/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2092 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/task_models/text_ranking.py
--rw-r--r--   0 runner    (1001) docker     (122)     5116 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/task_models/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/unite/
--rw-r--r--   0 runner    (1001) docker     (122)      626 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/unite/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      409 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/unite/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    18320 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/unite/translation_evaluation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/use/
--rw-r--r--   0 runner    (1001) docker     (122)      545 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/use/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5133 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/use/transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5795 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/use/user_satisfaction_estimation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/veco/
--rw-r--r--   0 runner    (1001) docker     (122)     1479 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/veco/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4031 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/veco/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     1192 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/veco/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     4278 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/veco/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     6643 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/veco/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     4129 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/veco/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/nlp/xlm_roberta/
--rw-r--r--   0 runner    (1001) docker     (122)     1156 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/xlm_roberta/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    42932 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/xlm_roberta/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7697 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/nlp/xlm_roberta/configuration.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/science/
--rw-r--r--   0 runner    (1001) docker     (122)      491 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/science/unifold/
--rw-r--r--   0 runner    (1001) docker     (122)       46 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    24057 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/science/unifold/data/
--rw-r--r--   0 runner    (1001) docker     (122)      634 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    49139 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/data/data_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    19691 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/data/msa_pairing.py
--rw-r--r--   0 runner    (1001) docker     (122)     8941 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/data/process.py
--rw-r--r--   0 runner    (1001) docker     (122)    14792 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/data/process_multimer.py
--rw-r--r--   0 runner    (1001) docker     (122)    11422 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/data/protein.py
--rw-r--r--   0 runner    (1001) docker     (122)    42023 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/data/residue_constants.py
--rw-r--r--   0 runner    (1001) docker     (122)     4628 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/data/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    19250 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/
--rw-r--r--   0 runner    (1001) docker     (122)      187 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17066 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/alphafold.py
--rw-r--r--   0 runner    (1001) docker     (122)    12323 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/attentions.py
--rw-r--r--   0 runner    (1001) docker     (122)     5403 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/auxillary_heads.py
--rw-r--r--   0 runner    (1001) docker     (122)    10676 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     5814 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/confidence.py
--rw-r--r--   0 runner    (1001) docker     (122)     8771 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/embedders.py
--rw-r--r--   0 runner    (1001) docker     (122)    11078 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/evoformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     6820 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/featurization.py
--rw-r--r--   0 runner    (1001) docker     (122)    18025 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/frame.py
--rw-r--r--   0 runner    (1001) docker     (122)    18476 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/structure_module.py
--rw-r--r--   0 runner    (1001) docker     (122)     9771 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/template.py
--rw-r--r--   0 runner    (1001) docker     (122)     5623 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/modules/triangle_multiplication.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/
--rw-r--r--   0 runner    (1001) docker     (122)       46 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17940 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/mmcif.py
--rw-r--r--   0 runner    (1001) docker     (122)     3128 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/msa_identifiers.py
--rw-r--r--   0 runner    (1001) docker     (122)    23503 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/parsers.py
--rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    45468 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/templates.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/
--rw-r--r--   0 runner    (1001) docker     (122)      639 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6218 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/hhblits.py
--rw-r--r--   0 runner    (1001) docker     (122)     3991 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/hhsearch.py
--rw-r--r--   0 runner    (1001) docker     (122)     5098 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/hmmbuild.py
--rw-r--r--   0 runner    (1001) docker     (122)     5013 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/hmmsearch.py
--rw-r--r--   0 runner    (1001) docker     (122)     8662 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/jackhmmer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3752 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/kalign.py
--rw-r--r--   0 runner    (1001) docker     (122)     1255 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2892 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/models/science/unifold/msa/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/
--rw-r--r--   0 runner    (1001) docker     (122)       84 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/audio/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      346 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/audio/asr_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/auth/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/auth/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1326 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/auth/auth_config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/context/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/context/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3369 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/context/dataset_context_config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/data_files/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/data_files/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5110 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/data_files/data_files_manager.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/data_loader/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/data_loader/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12636 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/data_loader/data_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     5764 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/data_loader/data_loader_manager.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/
--rw-r--r--   0 runner    (1001) docker     (122)      111 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/
--rw-r--r--   0 runner    (1001) docker     (122)     4111 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/
--rw-r--r--   0 runner    (1001) docker     (122)      730 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1737 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     8512 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     7723 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    11689 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/
--rw-r--r--   0 runner    (1001) docker     (122)      541 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1264 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      791 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/
--rw-r--r--   0 runner    (1001) docker     (122)      134 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4708 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py
--rw-r--r--   0 runner    (1001) docker     (122)      945 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      177 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3815 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py
--rw-r--r--   0 runner    (1001) docker     (122)    16180 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/
--rw-r--r--   0 runner    (1001) docker     (122)      934 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11572 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/
--rw-r--r--   0 runner    (1001) docker     (122)      312 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2622 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py
--rw-r--r--   0 runner    (1001) docker     (122)     4858 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py
--rw-r--r--   0 runner    (1001) docker     (122)     1469 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/
--rw-r--r--   0 runner    (1001) docker     (122)      196 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1086 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py
--rw-r--r--   0 runner    (1001) docker     (122)     2509 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/easycv_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     2141 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/
--rw-r--r--   0 runner    (1001) docker     (122)      539 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/
--rw-r--r--   0 runner    (1001) docker     (122)      529 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py
--rw-r--r--   0 runner    (1001) docker     (122)    12152 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    12574 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/
--rw-r--r--   0 runner    (1001) docker     (122)      577 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1629 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/
--rw-r--r--   0 runner    (1001) docker     (122)      615 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1487 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/
--rw-r--r--   0 runner    (1001) docker     (122)      583 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     4849 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     6225 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      559 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6171 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     4013 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      161 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1589 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py
--rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     5437 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/
--rw-r--r--   0 runner    (1001) docker     (122)       40 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7547 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py
--rw-r--r--   0 runner    (1001) docker     (122)     3416 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/
--rw-r--r--   0 runner    (1001) docker     (122)      309 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3172 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py
--rw-r--r--   0 runner    (1001) docker     (122)      971 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     5818 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py
--rw-r--r--   0 runner    (1001) docker     (122)     2000 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py
--rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py
--rw-r--r--   0 runner    (1001) docker     (122)      707 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py
--rw-r--r--   0 runner    (1001) docker     (122)     4912 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py
--rw-r--r--   0 runner    (1001) docker     (122)     2393 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2017 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      599 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16767 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     8725 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/
--rw-r--r--   0 runner    (1001) docker     (122)      545 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1475 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1984 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2684 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     5114 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     1635 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2664 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/veco_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/
--rw-r--r--   0 runner    (1001) docker     (122)      573 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1390 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/
--rw-r--r--   0 runner    (1001) docker     (122)      543 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      809 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2624 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/
--rw-r--r--   0 runner    (1001) docker     (122)      553 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2370 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    10687 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/dataset_cls/dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/download/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/download/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    20261 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/download/dataset_builder.py
--rw-r--r--   0 runner    (1001) docker     (122)      609 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/download/download_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     2487 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/download/download_manager.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/meta/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/meta/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1772 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/meta/data_meta_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     8634 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/meta/data_meta_manager.py
--rw-r--r--   0 runner    (1001) docker     (122)    36692 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/ms_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/task_datasets/
--rw-r--r--   0 runner    (1001) docker     (122)     1072 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/task_datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      408 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/task_datasets/gopro_image_deblurring_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      401 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/task_datasets/reds_image_deblurring_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      404 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/task_datasets/sidd_image_denoising.py
--rw-r--r--   0 runner    (1001) docker     (122)      410 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/task_datasets/torch_base_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      404 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/task_datasets/video_summarization_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/msdatasets/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7610 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/utils/dataset_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1026 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/utils/delete_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/utils/maxcompute_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6124 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/utils/oss_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2496 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/msdatasets/utils/upload_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/ops/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/ops/ailut/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/ops/ailut/Ailut/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/ailut/Ailut/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/ops/ailut/Ailut/csrc/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/ailut/Ailut/csrc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      105 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/ailut/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4314 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/ailut/pyinterfaces.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/ops/quadtree_attention/
--rw-r--r--   0 runner    (1001) docker     (122)      106 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/quadtree_attention/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/ops/quadtree_attention/functions/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/quadtree_attention/functions/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2925 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/quadtree_attention/functions/quadtree_attention.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/ops/quadtree_attention/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/quadtree_attention/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13956 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/quadtree_attention/modules/quadtree_attention.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/ops/quadtree_attention/src/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/ops/quadtree_attention/src/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/outputs/
--rw-r--r--   0 runner    (1001) docker     (122)      132 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/outputs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      908 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/outputs/cv_outputs.py
--rw-r--r--   0 runner    (1001) docker     (122)    19855 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/outputs/nlp_outputs.py
--rw-r--r--   0 runner    (1001) docker     (122)    51098 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/outputs/outputs.py
--rw-r--r--   0 runner    (1001) docker     (122)    11135 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipeline_inputs.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/
--rw-r--r--   0 runner    (1001) docker     (122)      150 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/audio/
--rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7481 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/ans_dfsmn_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5016 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/ans_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    23877 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/asr_inference_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/asr_wenet_inference_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4357 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/inverse_text_processing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3830 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/kws_farfield_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7276 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/kws_kwsbp_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5555 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/linear_aec_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     8056 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/lm_infer_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6469 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/punctuation_processing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2560 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/separation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4042 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/speaker_change_locating_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    11089 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/speaker_diarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4078 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4118 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/speaker_verification_light_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    10499 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/speaker_verification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4072 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1789 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/text_to_speech_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    11925 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/timestamp_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9684 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/audio/voice_activity_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    22849 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7279 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/cv/
--rw-r--r--   0 runner    (1001) docker     (122)    16252 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2545 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/action_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4852 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/action_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4024 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/animal_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2576 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/arc_face_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2614 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/bad_image_detecting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/body_2d_keypoints_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    14219 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/body_3d_keypoints_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4740 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/card_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5307 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/cmdssl_video_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2528 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/content_check_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5055 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/controllable_image_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5942 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/crowd_counting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5136 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ddcolor_image_colorization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ddpm_semantic_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2498 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_attribute_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3980 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1531 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_emotion_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1648 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_human_hand_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2894 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_image_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3312 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_liveness_ir_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3573 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_liveness_xc_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7748 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_processing_base_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3872 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_quality_assessment_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3528 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_recognition_onnx_fm_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3493 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_recognition_onnx_ir_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2878 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_recognition_ood_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2498 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    19630 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/face_reconstruction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2400 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/facial_expression_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2681 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/facial_landmark_confidence_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4442 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/fast_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4030 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/general_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1360 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/hand_static_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2982 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/hicossl_video_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4372 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/human_reconstruction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1399 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_body_reshaping_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2919 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_bts_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5251 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_cartoon_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5857 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3296 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_color_enhance_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4441 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_colorization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2648 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_debanding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4624 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_deblur_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3517 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_defrcn_fewshot_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4160 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_denoise_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1943 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1854 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4134 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_driving_perception_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2317 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_face_fusion_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4866 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_human_parsing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5854 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_inpainting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4673 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_inpainting_sdv2_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3903 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5929 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_matching_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2607 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_matting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2796 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_mvs_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2770 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_open_vocabulary_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6113 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_paintbyexample_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     8567 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_portrait_enhancement_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3549 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_quality_assessment_degradation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2835 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_quality_assessment_man_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2801 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_quality_assessment_mos_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2026 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_reid_person_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1702 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_restoration_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1644 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_salient_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3207 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_semantic_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2237 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_skychange_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2839 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_structured_model_probing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4615 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_style_transfer_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3138 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_super_resolution_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9718 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_to_image_generate_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    12737 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/image_to_image_translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1883 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/indoor_layout_estimation_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     9872 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/language_guided_video_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4570 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/license_plate_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4182 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/lineless_table_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/live_category_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2757 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/mask_face_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2787 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/maskdino_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3670 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/mobile_image_super_resolution_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1857 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/mog_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4844 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/motion_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2628 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/movie_scene_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1953 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/mtcnn_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3328 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/nerf_recon_acc_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6018 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/object_detection_3d_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    11033 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2500 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_recognition_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/
--rw-r--r--   0 runner    (1001) docker     (122)      966 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      720 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/model_convnext_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)    19821 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/model_dla34.py
--rw-r--r--   0 runner    (1001) docker     (122)     8768 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/model_resnet18_half.py
--rw-r--r--   0 runner    (1001) docker     (122)     5286 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py
--rw-r--r--   0 runner    (1001) docker     (122)    15421 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/model_vlpt.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/
--rw-r--r--   0 runner    (1001) docker     (122)      550 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py
--rw-r--r--   0 runner    (1001) docker     (122)     1560 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/vitstr.py
--rw-r--r--   0 runner    (1001) docker     (122)    38278 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    19004 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/resnet18_v1.py
--rw-r--r--   0 runner    (1001) docker     (122)    11371 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/resnet_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    11168 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/table_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     7971 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3029 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/panorama_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9781 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/pedestrian_attribute_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4199 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1457 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/product_retrieval_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1451 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/product_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2020 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/realtime_video_object_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9239 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/referring_video_object_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1956 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/retina_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1760 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/shop_segmentation_pipleline.py
--rw-r--r--   0 runner    (1001) docker     (122)    12129 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/skin_retouching_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4446 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/table_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4899 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/tbs_detection_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/cv/tbs_detection_utils/
--rw-r--r--   0 runner    (1001) docker     (122)       10 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/tbs_detection_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15542 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/tbs_detection_utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1841 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/text_driven_segmentation_pipleline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3246 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/tinynas_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3244 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/tinynas_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1888 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/ulfd_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    13776 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_category_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6097 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_colorization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7757 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_deinterlace_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1565 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    24271 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_frame_interpolation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3635 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_human_matting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1719 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_inpainting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9652 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3294 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_multi_object_tracking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4724 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_object_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4683 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_panoptic_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3436 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_single_object_tracking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4647 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_stabilization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4289 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7078 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/video_super_resolution_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7564 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/vidt_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5240 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/virtual_try_on_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3986 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/vision_efficient_tuning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2180 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/vision_middleware_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4762 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/vop_retrieval_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5787 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/cv/vop_retrieval_se_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/
--rw-r--r--   0 runner    (1001) docker     (122)     3071 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2366 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/asr_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/
--rw-r--r--   0 runner    (1001) docker     (122)      636 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2013 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      718 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11691 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2880 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/
--rw-r--r--   0 runner    (1001) docker     (122)      585 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15631 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    18987 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2311 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/document_vl_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2931 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1093 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9352 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/gridvlp_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3219 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/image_captioning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1612 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/image_text_retrieval_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7869 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/mgeo_ranking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1648 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/multi_modal_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3325 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/multimodal_dialogue_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/ocr_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     8561 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1848 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/sudoku_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1059 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1789 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/text2sql_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2064 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/text_to_image_synthesis_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3556 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/text_to_video_synthesis_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2150 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/video_captioning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1329 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1956 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/video_question_answering_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/visual_entailment_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1781 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/visual_grounding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2396 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/multi_modal/visual_question_answering_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     6798 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6939 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/automatic_post_editing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3696 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/canmt_translation_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2202 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/codegeex_code_generation_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2885 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/codegeex_code_translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2251 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/conversational_text_to_sql_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2577 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/dialog_intent_prediction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2308 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/dialog_modeling_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7663 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/dialog_state_tracking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2218 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/distributed_gpt3_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1851 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/distributed_gpt_moe_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4425 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/distributed_plug_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2754 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/document_grounded_dialog_generate_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    25997 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5480 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9623 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/document_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6259 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/extractive_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3348 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/faq_question_answering_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2437 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/fasttext_text_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3258 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/feature_extraction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    10171 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/fid_dialogue_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4655 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/fill_mask_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)      999 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/glm130b_text_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2383 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/information_extraction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6363 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/interactive_translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9928 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/language_identification_pipline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1776 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/mglm_text_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2955 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/named_entity_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3184 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/sentence_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    14334 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/siamese_uie_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2566 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    16315 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/table_question_answering_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6787 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/text_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3490 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/text_error_correction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7735 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/text_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2877 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/text_ranking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6399 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/token_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4372 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/translation_evaluation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5586 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2339 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/translation_quality_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4613 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/user_satisfaction_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2713 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/word_alignment_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4523 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/word_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5875 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/nlp/zero_shot_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2816 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/pipeline_template.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/pipelines/science/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/science/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/science/protein_structure_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3492 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/pipelines/util.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/
--rw-r--r--   0 runner    (1001) docker     (122)     5792 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10063 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/asr.py
--rw-r--r--   0 runner    (1001) docker     (122)     8680 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/audio.py
--rw-r--r--   0 runner    (1001) docker     (122)    15312 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/base.py
--rw-r--r--   0 runner    (1001) docker     (122)      812 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/common.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/cv/
--rw-r--r--   0 runner    (1001) docker     (122)     1896 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7446 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/action_detection_mapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     1126 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/bad_image_detecting_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     7789 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/controllable_image_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)    20909 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/cv2_transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    12826 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/image_classification_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1250 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/image_quality_assessment_man.py
--rw-r--r--   0 runner    (1001) docker     (122)     2113 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/image_quality_assessment_mos.py
--rw-r--r--   0 runner    (1001) docker     (122)     2790 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/image_restoration_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     2625 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/mmcls_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3050 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/timer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3606 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/util.py
--rw-r--r--   0 runner    (1001) docker     (122)     1501 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/video_stabilization.py
--rw-r--r--   0 runner    (1001) docker     (122)     8579 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/cv/video_super_resolution.py
--rw-r--r--   0 runner    (1001) docker     (122)    13406 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/image.py
--rw-r--r--   0 runner    (1001) docker     (122)     4884 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/kws.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/movie_scene_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      483 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/movie_scene_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10809 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/movie_scene_segmentation/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    30147 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/multi_modal.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     5966 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      762 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/bert_seq_cls_tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3929 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/canmt_translation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2572 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/dialog_classification_use_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4102 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4391 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4086 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    11004 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/document_segmentation_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     6844 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/faq_question_answering_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3304 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/feature_extraction_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    12086 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/fill_mask_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     8199 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/mgeo_ranking_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1168 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/mglm_summarization_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1799 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/relation_extraction_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4023 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/sentence_embedding_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1424 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/siamese_uie_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)     1219 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1908 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/args.py
--rw-r--r--   0 runner    (1001) docker     (122)     1555 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/batch.py
--rw-r--r--   0 runner    (1001) docker     (122)     3629 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/data_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     2701 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     2789 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/dialog_modeling_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5457 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    56779 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/dst_processors.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/fields/
--rw-r--r--   0 runner    (1001) docker     (122)      592 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/fields/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    33884 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/fields/gen_field.py
--rw-r--r--   0 runner    (1001) docker     (122)    42465 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/fields/intent_field.py
--rw-r--r--   0 runner    (1001) docker     (122)     1147 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/lazy_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     1935 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/preprocess.py
--rw-r--r--   0 runner    (1001) docker     (122)     1610 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/sampler.py
--rw-r--r--   0 runner    (1001) docker     (122)     2084 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/tensorlistdataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    24803 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/
--rw-r--r--   0 runner    (1001) docker     (122)      654 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/fields/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/fields/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4936 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/fields/database.py
--rw-r--r--   0 runner    (1001) docker     (122)    15867 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/fields/schema_link.py
--rw-r--r--   0 runner    (1001) docker     (122)     4888 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/fields/struct.py
--rw-r--r--   0 runner    (1001) docker     (122)     4175 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/
--rw-r--r--   0 runner    (1001) docker     (122)      846 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4902 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/
--rw-r--r--   0 runner    (1001) docker     (122)      818 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21521 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/common_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12500 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/parse.py
--rw-r--r--   0 runner    (1001) docker     (122)     1380 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2111 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/process_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/text_classification_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/text_clean.py
--rw-r--r--   0 runner    (1001) docker     (122)     2298 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/text_error_correction.py
--rw-r--r--   0 runner    (1001) docker     (122)    13896 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/text_generation_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3834 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/text_ranking_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    19629 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/token_classification_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1640 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/token_classification_thai_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1238 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/token_classification_viet_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4482 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/transformers_tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7304 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/translation_evaluation_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3622 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4962 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/word_alignment_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     2584 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/nlp/zero_shot_classification_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/
--rw-r--r--   0 runner    (1001) docker     (122)      762 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4839 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/asr.py
--rw-r--r--   0 runner    (1001) docker     (122)    11909 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     4172 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/image_captioning.py
--rw-r--r--   0 runner    (1001) docker     (122)     6461 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/image_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     5740 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/ocr_recognition.py
--rw-r--r--   0 runner    (1001) docker     (122)     4603 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/sudoku.py
--rw-r--r--   0 runner    (1001) docker     (122)     5210 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/summarization.py
--rw-r--r--   0 runner    (1001) docker     (122)    16449 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/text2sql.py
--rw-r--r--   0 runner    (1001) docker     (122)     5368 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     2164 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/text_to_image_synthesis.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3221 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/audio_helper.py
--rw-r--r--   0 runner    (1001) docker     (122)     8936 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/bridge_content_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     6809 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/collate.py
--rw-r--r--   0 runner    (1001) docker     (122)      660 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/constant.py
--rw-r--r--   0 runner    (1001) docker     (122)     3421 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/get_tables.py
--rw-r--r--   0 runner    (1001) docker     (122)     1302 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/random_help.py
--rw-r--r--   0 runner    (1001) docker     (122)     5459 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/text2phone.py
--rw-r--r--   0 runner    (1001) docker     (122)    19116 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/utils/vision_helper.py
--rw-r--r--   0 runner    (1001) docker     (122)     7664 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/visual_entailment.py
--rw-r--r--   0 runner    (1001) docker     (122)     8484 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/visual_grounding.py
--rw-r--r--   0 runner    (1001) docker     (122)     6796 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/ofa/visual_question_answering.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/preprocessors/science/
--rw-r--r--   0 runner    (1001) docker     (122)      478 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/science/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21698 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/science/uni_fold.py
--rw-r--r--   0 runner    (1001) docker     (122)     2101 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/tts.py
--rw-r--r--   0 runner    (1001) docker     (122)    13168 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/preprocessors/video.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/tools/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/tools/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      772 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/tools/eval.py
--rw-r--r--   0 runner    (1001) docker     (122)     5362 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/tools/speech_tts_autolabel.py
--rw-r--r--   0 runner    (1001) docker     (122)      607 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/tools/train.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/
--rw-r--r--   0 runner    (1001) docker     (122)     1799 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/audio/
--rw-r--r--   0 runner    (1001) docker     (122)      826 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1873 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/ans_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     6969 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/asr_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    12816 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/kws_farfield_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    22065 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/kws_nearfield_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/audio/kws_utils/
--rw-r--r--   0 runner    (1001) docker     (122)     1768 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/kws_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    22114 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/kws_utils/batch_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    11499 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/kws_utils/det_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     7022 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/kws_utils/file_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/kws_utils/model_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2854 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/kws_utils/runtime_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    21962 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/separation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10858 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/audio/tts_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1808 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     5553 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cli_argument_parser.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/cv/
--rw-r--r--   0 runner    (1001) docker     (122)     1974 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7494 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/action_detection_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      668 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/card_detection_scrfd_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10044 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/cartoon_translation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     6737 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/face_detection_scrfd_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    20323 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/image_classifition_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    11655 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/image_defrcn_fewshot_detection_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    22965 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/image_detection_damoyolo_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4405 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/image_inpainting_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      816 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/image_instance_segmentation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5520 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/image_portrait_enhancement_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      680 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/movie_scene_segmentation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    20149 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/nerf_recon_acc_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    16911 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/ocr_detection_db_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3153 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/ocr_recognition_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/referring_video_object_segmentation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4602 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/cv/vision_efficient_tuning_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2607 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/default_config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/hooks/
--rw-r--r--   0 runner    (1001) docker     (122)     2064 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      296 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/hooks/checkpoint/
--rw-r--r--   0 runner    (1001) docker     (122)      116 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/checkpoint/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    19053 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/checkpoint/checkpoint_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)    10797 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/checkpoint/checkpoint_processor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5541 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/checkpoint/load_checkpoint_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)      764 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/clip_clamp_logit_scale_hook.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/hooks/compression/
--rw-r--r--   0 runner    (1001) docker     (122)      610 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/compression/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4812 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/compression/sparsity_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6915 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/compression/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/hooks/distributed/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/distributed/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1458 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/distributed/ddp_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     8200 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/distributed/deepspeed_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6905 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/distributed/megatron_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     4398 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/early_stop_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     3825 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/evaluation_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/hook.py
--rw-r--r--   0 runner    (1001) docker     (122)      731 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/iter_timer_hook.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/hooks/logger/
--rw-r--r--   0 runner    (1001) docker     (122)      718 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/logger/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4498 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/logger/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     4507 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/logger/tensorboard_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     7443 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/logger/text_logger_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6402 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/lr_scheduler_hook.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/hooks/optimizer/
--rw-r--r--   0 runner    (1001) docker     (122)      743 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/optimizer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3139 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/optimizer/apex_optimizer_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     3786 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/optimizer/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     3729 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/optimizer/torch_optimizer_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/hooks/priority.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/lrscheduler/
--rw-r--r--   0 runner    (1001) docker     (122)      699 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/lrscheduler/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2040 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/lrscheduler/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/lrscheduler/warmup/
--rw-r--r--   0 runner    (1001) docker     (122)      614 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/lrscheduler/warmup/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2547 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/lrscheduler/warmup/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     2934 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/lrscheduler/warmup/warmup.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/
--rw-r--r--   0 runner    (1001) docker     (122)      682 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/clip/
--rw-r--r--   0 runner    (1001) docker     (122)       89 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/clip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9702 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/clip/clip_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4388 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/clip/clip_trainer_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/efficient_diffusion_tuning/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/efficient_diffusion_tuning/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2874 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8086 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/mgeo_ranking_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/mplug/
--rw-r--r--   0 runner    (1001) docker     (122)       91 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/mplug/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1642 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/mplug/mplug_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/ofa/
--rw-r--r--   0 runner    (1001) docker     (122)       87 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/ofa/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10186 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/ofa/ofa_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    17647 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/ofa/ofa_trainer_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/team/
--rw-r--r--   0 runner    (1001) docker     (122)       95 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/team/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5429 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/team/team_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2443 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/multi_modal/team/team_trainer_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     1332 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14266 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/csanmt_translation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9999 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/document_grounded_dialog_generate_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    24284 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/document_grounded_dialog_rerank_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/document_grounded_dialog_retrieval_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    12769 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/faq_question_answering_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3064 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/gpt3_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2097 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/gpt_moe_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8171 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/plug_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3869 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/sentence_embedding_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8378 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/sequence_classification_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    17110 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/siamese_uie_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5324 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/dialog_intent_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4229 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/dialog_modeling_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    36354 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/eval.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/metrics/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/metrics/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2447 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/metrics/metrics_tracker.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/trainer/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/trainer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    30567 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/trainer/gen_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    29570 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/space/trainer/intent_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    20453 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/table_question_answering_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      991 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/text_generation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7514 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/text_ranking_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    15326 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp/translation_evaluation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7129 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/nlp_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/optimizer/
--rw-r--r--   0 runner    (1001) docker     (122)      223 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/optimizer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1753 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/optimizer/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     7081 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/optimizer/child_tuning_adamw_optimizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/parallel/
--rw-r--r--   0 runner    (1001) docker     (122)       80 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/parallel/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      681 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/parallel/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)      754 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/parallel/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    59078 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    17723 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/training_args.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/trainers/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11090 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/utils/inference.py
--rw-r--r--   0 runner    (1001) docker     (122)     1294 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/trainers/utils/log_buffer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/tuners/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/tuners/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    38904 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/tuners/control_sd_lora.py
--rw-r--r--   0 runner    (1001) docker     (122)    24058 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/tuners/lora.py
--rw-r--r--   0 runner    (1001) docker     (122)     8840 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/tuners/sd_lora.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)   519119 2023-06-09 13:07:15.000000 modelscope-1.6.1/modelscope/utils/ast_index_file.py
--rw-r--r--   0 runner    (1001) docker     (122)    28920 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/ast_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/utils/audio/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11795 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/audio/audio_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2428 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/audio/tts_exceptions.py
--rw-r--r--   0 runner    (1001) docker     (122)    26430 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)     2573 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/chinese_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    27433 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/config.py
--rw-r--r--   0 runner    (1001) docker     (122)     1027 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/config_ds.py
--rw-r--r--   0 runner    (1001) docker     (122)    18753 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/constant.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/utils/cv/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    23195 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/cv/image_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/utils/cv/motion_utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/cv/motion_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/cv/motion_utils/motion_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     3847 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/cv/motion_utils/plot_script.py
--rw-r--r--   0 runner    (1001) docker     (122)     4290 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/cv/motion_utils/rotation_conversions.py
--rw-r--r--   0 runner    (1001) docker     (122)     3153 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/data_collators.py
--rw-r--r--   0 runner    (1001) docker     (122)     1279 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3744 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/device.py
--rw-r--r--   0 runner    (1001) docker     (122)     6339 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/error.py
--rw-r--r--   0 runner    (1001) docker     (122)     1128 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/file_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     5939 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/hub.py
--rw-r--r--   0 runner    (1001) docker     (122)    15823 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/import_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    25538 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/input_output.py
--rw-r--r--   0 runner    (1001) docker     (122)      478 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/json_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2789 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/logger.py
--rw-r--r--   0 runner    (1001) docker     (122)     7612 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/megatron_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2335 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5099 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/model_tag.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/utils/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)      499 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4424 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/distributed.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4526 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/load_checkpoint.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/utils/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1909 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space/args.py
--rw-r--r--   0 runner    (1001) docker     (122)    11818 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space/clean_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     1439 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space/criterions.py
--rw-r--r--   0 runner    (1001) docker     (122)    11252 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space/db_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)     6174 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space/ontology.py
--rw-r--r--   0 runner    (1001) docker     (122)      197 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space/scores.py
--rw-r--r--   0 runner    (1001) docker     (122)     6356 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1054 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space/utils_dst.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope/utils/nlp/space_T_en/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space_T_en/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      859 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/space_T_en/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2554 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/nlp/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    40106 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/plugins.py
--rw-r--r--   0 runner    (1001) docker     (122)     7833 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/registry.py
--rw-r--r--   0 runner    (1001) docker     (122)    30195 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/regress_test_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6127 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/service_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2500 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/task_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1593 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/tensor_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12532 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/test_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/timer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10966 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/torch_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      597 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/trie.py
--rw-r--r--   0 runner    (1001) docker     (122)     1696 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/type_assert.py
--rw-r--r--   0 runner    (1001) docker     (122)      296 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/typing.py
--rw-r--r--   0 runner    (1001) docker     (122)      783 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/utils/url_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      272 2023-06-09 13:06:34.000000 modelscope-1.6.1/modelscope/version.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope.egg-info/
--rw-r--r--   0 runner    (1001) docker     (122)    19082 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (122)   131512 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (122)        1 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (122)       59 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (122)        1 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (122)     4738 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (122)       11 2023-06-09 13:07:16.000000 modelscope-1.6.1/modelscope.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (122)       38 2023-06-09 13:07:16.000000 modelscope-1.6.1/setup.cfg
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/
+-rw-r--r--   0 runner    (1001) docker     (122)      105 2023-07-02 13:03:05.000000 modelscope-1.7.0/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (122)    19397 2023-07-02 13:03:06.000000 modelscope-1.7.0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (122)    15977 2023-07-02 13:03:05.000000 modelscope-1.7.0/README.md
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/
+-rw-r--r--   0 runner    (1001) docker     (122)     3655 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/cli/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/cli/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      404 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/cli/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)      829 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/cli/cli.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1230 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/cli/download.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6242 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/cli/modelcard.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4371 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/cli/pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3304 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/cli/plugins.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/cli/template/
+-rw-r--r--   0 runner    (1001) docker     (122)      523 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/cli/template/readme.tpl
+-rw-r--r--   0 runner    (1001) docker     (122)     4912 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/cli/template/template.tpl
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/configs/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/configs/examples/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/configs/examples/configuration.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/exporters/
+-rw-r--r--   0 runner    (1001) docker     (122)     1360 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/exporters/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)      507 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2272 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/audio/ans_dfsmn_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2667 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)      732 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/exporters/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)      869 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2593 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/cv/cartoon_translation_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3619 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/cv/face_detection_scrfd_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1358 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/cv/object_detection_damoyolo_exporter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/exporters/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)      531 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/multi_modal/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11238 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/multi_modal/stable_diffusion_exporter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/exporters/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     1082 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7341 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/nlp/csanmt_for_translation_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4579 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/nlp/model_for_token_classification_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3409 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/nlp/sbert_for_sequence_classification_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2316 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/nlp/sbert_for_zero_shot_classification_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4809 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/tf_model_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15145 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/exporters/torch_model_exporter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/fileio/
+-rw-r--r--   0 runner    (1001) docker     (122)      122 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/fileio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10241 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/fileio/file.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/fileio/format/
+-rw-r--r--   0 runner    (1001) docker     (122)      143 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/fileio/format/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      454 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/fileio/format/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1050 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/fileio/format/json.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13853 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/fileio/format/jsonplus.py
+-rw-r--r--   0 runner    (1001) docker     (122)      669 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/fileio/format/yaml.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4254 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/fileio/io.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/hub/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42783 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/api.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3649 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/check_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1628 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/constants.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11358 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/deploy.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4072 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/errors.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12706 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/file_download.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8958 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/git.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7272 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/push_to_hub.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12489 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/repository.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7178 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/snapshot_download.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/hub/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9916 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/utils/caching.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2978 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/hub/utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    54722 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metainfo.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/metrics/
+-rw-r--r--   0 runner    (1001) docker     (122)     3978 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2510 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/accuracy_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7530 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/action_detection_evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1925 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/audio_noise_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1454 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1726 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/bleu_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3715 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/metrics/ciderD/
+-rwxr-xr-x   0 runner    (1001) docker     (122)       21 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/ciderD/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1926 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/ciderD/ciderD.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8931 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/ciderD/ciderD_scorer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8664 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/image_color_enhance_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13387 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/image_colorization_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10011 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/image_denoise_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7612 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/image_inpainting_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13318 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/image_instance_segmentation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1739 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/image_portrait_enhancement_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2536 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/image_quality_assessment_degradation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1632 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/image_quality_assessment_mos_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2231 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/inbatch_recall_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1358 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/loss_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3002 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/map_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2032 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/movie_scene_segmentation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/ned_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2310 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/ocr_recognition_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2082 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/ppl_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1163 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/prediction_saving_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4453 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/referring_video_object_segmentation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3112 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/sequence_classification_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3694 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/text_generation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/text_ranking_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5765 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/token_classification_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5703 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/translation_evaluation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5435 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/video_frame_interpolation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8655 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/video_stabilization_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3092 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/video_summarization_metric.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/metrics/video_super_resolution_metric/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/video_super_resolution_metric/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7030 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/video_super_resolution_metric/matlab_functions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4771 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/video_super_resolution_metric/metric_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8932 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/video_super_resolution_metric/niqe.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1710 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/metrics/video_super_resolution_metric/video_super_resolution_metric.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      519 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)       93 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/aec/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/aec/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/layers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1434 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/layers/activations.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2700 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/layers/affine_transform.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5630 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/layers/deep_fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1322 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/layers/layer_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14384 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/layers/uni_deep_fsmn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/aec/network/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/network/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14438 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/network/loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9382 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/network/modulation_loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15396 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/aec/network/se_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/ans/
+-rw-r--r--   0 runner    (1001) docker     (122)      515 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6475 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/complex_nn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3688 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/conv_stft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2513 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/denoise_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10241 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/frcrn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/ans/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/layers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1468 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/layers/activations.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/layers/affine_transform.py
+-rw-r--r--   0 runner    (1001) docker     (122)      661 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/layers/layer_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5284 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/layers/uni_deep_fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1038 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/se_module_complex.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9833 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/ans/unet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/asr/
+-rw-r--r--   0 runner    (1001) docker     (122)      585 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/asr/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/asr/generic_automatic_speech_recognition.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/asr/wenet_automatic_speech_recognition.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/itn/
+-rw-r--r--   0 runner    (1001) docker     (122)      557 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/itn/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1462 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/itn/generic_inverse_text_processing.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/kws/
+-rw-r--r--   0 runner    (1001) docker     (122)      735 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/kws/farfield/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/farfield/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14349 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/farfield/fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7462 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/farfield/fsmn_sele_v2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7861 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/farfield/fsmn_sele_v3.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3521 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/farfield/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2608 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/farfield/model_def.py
+-rw-r--r--   0 runner    (1001) docker     (122)      908 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/generic_key_word_spotting.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/kws/nearfield/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/nearfield/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3300 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/nearfield/cmvn.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17496 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/nearfield/fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6079 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/kws/nearfield/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/punc/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/punc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1466 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/punc/generic_punctuation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/separation/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/separation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2240 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/separation/layer_norm.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13963 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/separation/mossformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9142 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/separation/mossformer_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9004 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/separation/mossformer_conv_module.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/sv/
+-rw-r--r--   0 runner    (1001) docker     (122)     7326 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/DTDNN.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8425 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/DTDNN_layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11515 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/ERes2Net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11358 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/ERes2Net_aug.py
+-rw-r--r--   0 runner    (1001) docker     (122)      498 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5612 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/cluster_backend.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14980 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/ecapa_tdnn.py
+-rw-r--r--   0 runner    (1001) docker     (122)      904 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/fusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1488 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/generic_speaker_verification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3630 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/pooling_layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16895 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/rdino.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12338 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/sv/speaker_change_locator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/audio/tts/
+-rw-r--r--   0 runner    (1001) docker     (122)      474 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/tts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11845 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/tts/sambert_hifi.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26390 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/audio/tts/voice.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/base/
+-rw-r--r--   0 runner    (1001) docker     (122)      303 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/base/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/base/base_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6994 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/base/base_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)      605 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/base/base_torch_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5679 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/base/base_torch_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3647 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)     1812 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      490 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3806 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/
+-rw-r--r--   0 runner    (1001) docker     (122)      113 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/
+-rw-r--r--   0 runner    (1001) docker     (122)      211 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6414 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/
+-rw-r--r--   0 runner    (1001) docker     (122)      145 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6729 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/action_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      493 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/action_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7307 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/action_detection/action_detection_onnx.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/action_detection/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/action_detection/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9364 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/action_detection/modules/action_detection_pytorch.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12132 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/action_detection/modules/resnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/action_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      709 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/action_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4304 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/action_recognition/models.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10276 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/action_recognition/s3dg.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/action_recognition/tada_convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45442 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/action_recognition/temporal_patch_shift_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/animal_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      558 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/animal_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14141 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/animal_recognition/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3955 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/animal_recognition/splat.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/bad_image_detecting/
+-rw-r--r--   0 runner    (1001) docker     (122)      496 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/bad_image_detecting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2589 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/bad_image_detecting/bad_image_detecting.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/body_2d_keypoints/
+-rw-r--r--   0 runner    (1001) docker     (122)      502 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_2d_keypoints/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12660 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_2d_keypoints/hrnet_basic_modules.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8773 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_2d_keypoints/hrnet_v2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_2d_keypoints/w48.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/
+-rw-r--r--   0 runner    (1001) docker     (122)      601 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/
+-rw-r--r--   0 runner    (1001) docker     (122)       51 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8957 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8196 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/
+-rw-r--r--   0 runner    (1001) docker     (122)       98 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11552 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12870 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/block.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8080 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/directed_graph.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2516 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7719 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3401 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/skeleton.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/
+-rw-r--r--   0 runner    (1001) docker     (122)     1216 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/LK/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/LK/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3488 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/LK/lk.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      713 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/face_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5158 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/face_landmark.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4563 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/facer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9075 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2174 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/model_tf.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/mtcnn_pytorch/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/mtcnn_pytorch/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6072 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8519 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4404 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/network.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5265 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cartoon/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/cmdssl_video_embedding/
+-rw-r--r--   0 runner    (1001) docker     (122)      647 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cmdssl_video_embedding/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3876 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cmdssl_video_embedding/c3d.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cmdssl_video_embedding/resnet2p1d.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8949 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/cmdssl_video_embedding/resnet3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      414 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13516 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/annotator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4960 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/api.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      504 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10152 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2746 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5829 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8045 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15438 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/vit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9896 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25158 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/openpose/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/openpose/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12595 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/openpose/body.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3894 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/openpose/hand.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9024 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/openpose/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8031 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/openpose/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8546 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/controlnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/crowd_counting/
+-rw-r--r--   0 runner    (1001) docker     (122)      491 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/crowd_counting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1100 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/crowd_counting/cc_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22875 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/crowd_counting/hrnet_aspp_relu.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_attribute_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      490 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_attribute_recognition/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_attribute_recognition/fair_face/
+-rw-r--r--   0 runner    (1001) docker     (122)      115 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_attribute_recognition/fair_face/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2559 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      930 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/
+-rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3032 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/detectors.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4675 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/mogface.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5578 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/mogprednet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6264 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/resnet.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     7072 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/
+-rw-r--r--   0 runner    (1001) docker     (122)       97 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7061 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/models/box_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5415 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/models/detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/models/first_stage.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5232 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/models/get_nets.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/LK/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/LK/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3444 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/LK/lk.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3578 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/face_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5129 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/face_landmark.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4210 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/facer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/
+-rw-r--r--   0 runner    (1001) docker     (122)       93 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4832 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/detection.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/models/
+-rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/models/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4766 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/models/net.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4590 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/models/retinaface.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/
+-rw-r--r--   0 runner    (1001) docker     (122)      174 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      955 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/damofd_detect.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      192 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/
+-rw-r--r--   0 runner    (1001) docker     (122)      325 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2945 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      292 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3423 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      276 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      471 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11707 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4169 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    30670 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5543 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      289 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      361 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4202 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3590 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16146 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      270 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    46999 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      295 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11062 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6092 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6395 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5970 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3451 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3869 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/scrfd_detect.py
+-rw-r--r--   0 runner    (1001) docker     (122)      960 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/tinymog_detect.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/
+-rw-r--r--   0 runner    (1001) docker     (122)       90 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1477 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/detection.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4126 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/box_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2058 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      571 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3719 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2845 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4621 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1497 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/
+-rw-r--r--   0 runner    (1001) docker     (122)      540 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/efficient/
+-rw-r--r--   0 runner    (1001) docker     (122)      327 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/efficient/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15911 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/efficient/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20077 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/efficient/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2007 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/emotion_infer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/emotion_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/face_alignment/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/face_alignment/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2844 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/face_alignment/face.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_emotion/face_alignment/face_align.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      475 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_generation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_generation/op/
+-rwxr-xr-x   0 runner    (1001) docker     (122)       89 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_generation/op/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6497 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_generation/op/conv2d_gradfix.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3104 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_generation/op/fused_act.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5922 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_generation/op/upfirdn2d.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    19998 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_generation/stylegan2.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4109 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/det_infer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12584 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/ghost_pan.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16846 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/nanodet_plus_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1833 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/one_stage_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5791 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/shufflenetv2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8874 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1572 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/align_face.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      473 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1080 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1977 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7572 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8551 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/model_irse.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4744 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/model_resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7186 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/rts_backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31337 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/bfm.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1428 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/de_retouching_module.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facelandmark/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facelandmark/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2583 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6561 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5124 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30403 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facerecon_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13171 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/losses.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21235 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/networks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8821 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/nv_diffrast.py
+-rw-r--r--   0 runner    (1001) docker     (122)      277 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/opt.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/pix2pix/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/pix2pix/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31957 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/pix2pix/networks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5908 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)      779 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    13410 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/renderer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4933 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31247 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/face_reconstruction/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/facial_expression_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      484 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/facial_expression_recognition/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/facial_expression_recognition/fer/
+-rw-r--r--   0 runner    (1001) docker     (122)      121 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/facial_expression_recognition/fer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3277 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/facial_expression_recognition/fer/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/facial_expression_recognition/fer/vgg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/facial_landmark_confidence/
+-rw-r--r--   0 runner    (1001) docker     (122)      478 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/facial_landmark_confidence/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/facial_landmark_confidence/flc/
+-rw-r--r--   0 runner    (1001) docker     (122)      115 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/facial_landmark_confidence/flc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4932 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/hand_static/
+-rw-r--r--   0 runner    (1001) docker     (122)      502 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/hand_static/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2480 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/hand_static/hand_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10891 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/hand_static/networks.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/
+-rw-r--r--   0 runner    (1001) docker     (122)     5936 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/Reconstruction.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/
+-rw-r--r--   0 runner    (1001) docker     (122)     1065 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/Embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4542 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/PixToMesh.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11301 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/Res_backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2418 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/Surface_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2716 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/detectors.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1982 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/geometry.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/human_segmenter.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11865 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/networks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6105 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/human_reconstruction/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_binary_quant_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)      573 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_binary_quant_classification/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2859 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_binary_quant_classification/binary_quant_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19111 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_binary_quant_classification/bnext.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/
+-rw-r--r--   0 runner    (1001) docker     (122)      500 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3920 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/image_body_reshaping.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6541 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13616 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/person_info.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/pose_estimator/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/pose_estimator/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12027 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/pose_estimator/body.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5673 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/pose_estimator/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/pose_estimator/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15760 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/slim_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)      598 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_classification/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_classification/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      107 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_classification/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20295 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_classification/backbones/beit_v2.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17261 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_classification/backbones/nextvit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2185 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_classification/mmcls_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1554 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_classification/resnet50_cc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5255 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_classification/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/
+-rw-r--r--   0 runner    (1001) docker     (122)      704 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/adaint/
+-rw-r--r--   0 runner    (1001) docker     (122)       44 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/adaint/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14338 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/adaint/adaint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3753 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/csrnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/deeplpf/
+-rw-r--r--   0 runner    (1001) docker     (122)       66 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/deeplpf/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2575 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31764 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/deeplpf/deeplpfnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2821 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_color_enhance/image_color_enhance.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/
+-rw-r--r--   0 runner    (1001) docker     (122)      640 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/
+-rw-r--r--   0 runner    (1001) docker     (122)      122 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9385 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/ddcolor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6437 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9576 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/loss.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6857 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/position_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7796 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/transformer_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6465 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6510 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/vgg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/unet/
+-rw-r--r--   0 runner    (1001) docker     (122)      129 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/unet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10574 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/unet/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10647 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_colorization/unet/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_debanding/
+-rw-r--r--   0 runner    (1001) docker     (122)      483 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_debanding/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_debanding/rrdb/
+-rw-r--r--   0 runner    (1001) docker     (122)       53 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_debanding/rrdb/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3005 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_debanding/rrdb/rrdb_image_debanding.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_deblur/
+-rw-r--r--   0 runner    (1001) docker     (122)      510 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_deblur/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4241 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_deblur/nafnet_for_image_deblur.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/
+-rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4329 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/evaluation/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/evaluation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12474 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3141 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/evaluation/evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      448 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6827 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/calibration_layer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7064 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/defrcn.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10779 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/fast_rcnn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1220 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/gdl.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1732 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4770 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/roi_heads.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23599 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/coco_register.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4803 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3595 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py
+-rw-r--r--   0 runner    (1001) docker     (122)      583 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/register_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2617 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/requirements_check.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11013 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/voc_register.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_denoise/
+-rw-r--r--   0 runner    (1001) docker     (122)      514 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_denoise/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_denoise/nafnet/
+-rw-r--r--   0 runner    (1001) docker     (122)     6664 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_denoise/nafnet/NAFNet_arch.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_denoise/nafnet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1627 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_denoise/nafnet/arch_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2475 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_denoise/nafnet_for_image_denoise.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6757 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/newcrf_depth.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18233 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/newcrf_layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10106 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/newcrf_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26006 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/swin_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13560 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/uper_crf_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1600 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/newcrfs_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/
+-rw-r--r--   0 runner    (1001) docker     (122)      536 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2606 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1485 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/networks/bts_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2819 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/networks/decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2506 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/networks/encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8545 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/networks/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_driving_perception/
+-rw-r--r--   0 runner    (1001) docker     (122)      999 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_driving_perception/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2022 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_driving_perception/image_driving_percetion_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4352 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_driving_perception/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7475 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_driving_perception/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      488 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3124 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/gan_wrap.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21432 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/op/
+-rw-r--r--   0 runner    (1001) docker     (122)      242 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/op/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6497 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3094 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/op/fused_act.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5912 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/op/upfirdn2d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facelib/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facelib/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10514 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facelib/align_trans.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5955 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facelib/matlab_cp2tform.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9077 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/image_face_fusion.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3045 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/aad_layer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8555 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/aei_flow_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9366 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/bfm.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12449 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/dense_motion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20604 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/facerecon_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7433 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/model_irse.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7790 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/ops.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/
+-rw-r--r--   0 runner    (1001) docker     (122)      575 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      525 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11736 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/backbone/deeplab_resnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/m2fp/
+-rw-r--r--   0 runner    (1001) docker     (122)      640 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/m2fp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8257 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/m2fp/m2fp_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8361 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/m2fp/m2fp_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15097 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/m2fp_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5634 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_human_parsing/parsing_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/
+-rw-r--r--   0 runner    (1001) docker     (122)      475 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2690 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7605 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/default.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1253 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/ade20k/
+-rw-r--r--   0 runner    (1001) docker     (122)       81 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/ade20k/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12202 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/ade20k/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5348 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/ade20k/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7509 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/adversarial.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1564 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/feature_matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19052 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/ffc.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11842 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/inception.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/perceptual.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/pix2pixhd.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13350 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_inpainting/refinement.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)     1065 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      664 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3826 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/backbones/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27174 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/backbones/swin_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9305 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      101 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3992 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/datasets/transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/fastinst/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/fastinst/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14867 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6266 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8692 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/fastinst_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/
+-rw-r--r--   0 runner    (1001) docker     (122)      600 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10072 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/dino_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15407 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18188 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7274 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2720 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/position_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6712 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1429 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11454 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino_swin.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1549 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7886 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/postprocess_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/
+-rw-r--r--   0 runner    (1001) docker     (122)      553 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/config/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6991 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/config/default.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/
+-rw-r--r--   0 runner    (1001) docker     (122)      171 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      588 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7244 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3784 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/
+-rw-r--r--   0 runner    (1001) docker     (122)      239 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3012 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2994 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9677 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10531 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3048 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2132 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2735 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/quadtree_attention_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      344 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_matching/utils/misc.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      521 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8546 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/cas_mvsnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/casmvs_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18175 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9861 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/depth_filter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9404 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/general_eval_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21735 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3367 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_paintbyexample/
+-rw-r--r--   0 runner    (1001) docker     (122)      507 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_paintbyexample/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_paintbyexample/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_panoptic_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      513 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_panoptic_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1694 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_panoptic_segmentation/panseg_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/
+-rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8563 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/align_faces.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/eqface/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/eqface/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1836 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/eqface/fqa.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4710 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/eqface/model_resnet.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    22869 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/gpen.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7114 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/image_portrait_enhancement.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/losses/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/losses/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4336 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/losses/helpers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3286 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/losses/losses.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3155 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/losses/model_irse.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     7313 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/detection.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/
+-rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4845 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/net.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4676 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_probing_model/
+-rw-r--r--   0 runner    (1001) docker     (122)      533 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_probing_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10076 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_probing_model/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3319 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_probing_model/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5206 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_probing_model/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_degradation/
+-rw-r--r--   0 runner    (1001) docker     (122)      584 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_degradation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5064 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_degradation/degradation_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4654 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_man/
+-rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_man/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2600 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_man/image_quality_assessment_man.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5163 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_man/maniqa.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23230 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_man/swin.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/
+-rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      272 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16222 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/backbones/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1060 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/heads/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      529 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/heads/simple_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2651 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_reid_person/
+-rw-r--r--   0 runner    (1001) docker     (122)      467 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_reid_person/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5444 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_reid_person/pass_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14108 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_reid_person/transreid_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_restoration/
+-rw-r--r--   0 runner    (1001) docker     (122)      527 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_restoration/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_restoration/demoire_models/
+-rw-r--r--   0 runner    (1001) docker     (122)       69 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_restoration/demoire_models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10243 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_restoration/demoire_models/nets.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2640 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_restoration/image_restoration_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      712 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7896 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5155 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2273 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3208 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/pan_merge/
+-rw-r--r--   0 runner    (1001) docker     (122)      111 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/pan_merge/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1516 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2122 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2566 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/semantic_seg_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/
+-rw-r--r--   0 runner    (1001) docker     (122)      303 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      290 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      249 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17484 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/
+-rw-r--r--   0 runner    (1001) docker     (122)      196 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18241 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6379 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      251 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26514 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/
+-rw-r--r--   0 runner    (1001) docker     (122)      253 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12370 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11715 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      368 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      398 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1938 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1788 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/
+-rw-r--r--   0 runner    (1001) docker     (122)      650 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9312 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/ptsemseg/
+-rw-r--r--   0 runner    (1001) docker     (122)     3740 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/ptsemseg/BlockModules.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/ptsemseg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21275 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/ptsemseg/hrnet_backnone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18023 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/ptsemseg/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11210 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/skychange.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7874 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_skychange/skychange_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      120 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/data/
+-rw-r--r--   0 runner    (1001) docker     (122)      561 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/data/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10476 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      603 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/models/autoencoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/models/clip.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/ops/
+-rw-r--r--   0 runner    (1001) docker     (122)      561 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/ops/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24469 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/ops/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/ops/losses.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/
+-rw-r--r--   0 runner    (1001) docker     (122)      536 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/data/
+-rw-r--r--   0 runner    (1001) docker     (122)      127 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/data/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10527 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/model_translation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      161 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/models/autoencoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/models/clip.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/
+-rw-r--r--   0 runner    (1001) docker     (122)      384 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21828 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/apps.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36549 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/degradation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24615 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/losses.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/metrics.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6736 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/random_color.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2745 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/random_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3777 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/svd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6728 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      486 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      136 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4099 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6931 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/misc/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/misc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2510 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/misc/fourier.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3251 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/misc/panostretch.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14887 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/misc/post_proc.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/modality/
+-rw-r--r--   0 runner    (1001) docker     (122)       86 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/modality/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5518 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/modality/layout.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3406 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/panovit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4808 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1834 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/panovit.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      542 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6441 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/summarizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/transformer/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      508 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/transformer/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1900 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/transformer/layers.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     7275 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/transformer/models.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)      826 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/transformer/modules.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2690 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/transformer/sub_layers.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      639 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2151 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/cfg_sampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26783 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/gaussian_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13594 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/mdm.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5412 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/respace.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3914 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/rotation2xyz.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/smpl.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      615 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/get_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8465 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      181 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      798 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/utils/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4291 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/utils/save_op.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10325 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/utils/shot_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5057 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/utils/trn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/
+-rw-r--r--   0 runner    (1001) docker     (122)      602 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/dataloader/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/dataloader/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18782 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20567 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/dataloader/read_write_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7297 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/nerf_preprocess.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7876 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/nerf_recon_acc.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/network/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/network/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13317 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/network/nerf.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1509 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/network/segmenter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5720 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/network/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      606 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3432 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/
+-rw-r--r--   0 runner    (1001) docker     (122)      321 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      211 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21306 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/backbones/vit.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      278 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2220 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11529 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/necks/
+-rw-r--r--   0 runner    (1001) docker     (122)      213 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/necks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9021 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/necks/fpn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      426 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      375 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8542 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      239 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17739 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      306 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21926 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/utils/checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/
+-rw-r--r--   0 runner    (1001) docker     (122)      467 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/
+-rw-r--r--   0 runner    (1001) docker     (122)       86 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2657 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/depe_detect.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/
+-rw-r--r--   0 runner    (1001) docker     (122)      605 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/
+-rw-r--r--   0 runner    (1001) docker     (122)      299 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6670 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/
+-rw-r--r--   0 runner    (1001) docker     (122)      282 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4476 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/
+-rw-r--r--   0 runner    (1001) docker     (122)      276 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1064 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2041 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      294 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3095 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/
+-rw-r--r--   0 runner    (1001) docker     (122)      522 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7936 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8689 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      255 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12874 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      282 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7442 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    59197 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/
+-rw-r--r--   0 runner    (1001) docker     (122)      255 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9533 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/
+-rw-r--r--   0 runner    (1001) docker     (122)      256 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9032 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      562 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18126 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5175 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11047 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/result_vis.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      473 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2969 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26142 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/modules/dbnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28715 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/modules/layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31084 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/modules/mix_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5974 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/modules/proxyless.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8217 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/modules/seg_detector_loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2647 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7972 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_detection/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      477 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6378 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/CRNN/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/CRNN/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3724 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/CRNN/main_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)      753 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1458 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/main_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/
+-rw-r--r--   0 runner    (1001) docker     (122)       43 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25097 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10662 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/mix_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5031 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/proxyless.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3710 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/ocr_recognition/preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/open_vocabulary_detection_vild/
+-rw-r--r--   0 runner    (1001) docker     (122)      501 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/open_vocabulary_detection_vild/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14225 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/open_vocabulary_detection_vild/vild.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      511 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)      102 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5077 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/equi.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7500 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7839 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/mobilenet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14421 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9175 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/unifuse.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3962 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/unifuse_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/pedestrian_attribute_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      488 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/pedestrian_attribute_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3468 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/pedestrian_attribute_recognition/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/pointcloud_sceneflow_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      495 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/pointcloud_sceneflow_estimation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16147 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/pointcloud_sceneflow_estimation/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11898 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1797 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/pointcloud_sceneflow_estimation/rcp_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/product_retrieval_embedding/
+-rw-r--r--   0 runner    (1001) docker     (122)      548 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/product_retrieval_embedding/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20974 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/product_retrieval_embedding/item_detection.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/product_retrieval_embedding/item_embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4340 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/product_retrieval_embedding/item_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/product_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      528 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/product_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7978 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/product_segmentation/net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2194 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/product_segmentation/seg_infer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      514 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5832 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      318 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8504 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9206 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/criterion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7299 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/matcher.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7935 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/misc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6242 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/mttr.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16610 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2091 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5629 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/postprocessing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5180 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27941 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/swin_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/robust_image_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)      501 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/robust_image_classification/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2902 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/robust_image_classification/easyrobust_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      497 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      213 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/models/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)     6558 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/models/backbone/Res2Net_v1b.py
+-rw-r--r--   0 runner    (1001) docker     (122)      256 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/models/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6525 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/models/modules.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3047 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/models/senet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12007 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/models/u2net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3524 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/models/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2704 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/salient_detection/salient_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/shop_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      464 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/shop_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2203 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/shop_segmentation/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4385 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/shop_segmentation/head_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)    32989 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/shop_segmentation/models.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9319 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/shop_segmentation/neck_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5632 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/shop_segmentation/shop_seg_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4095 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/shop_segmentation/shop_seg_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6699 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/shop_segmentation/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/detection_model/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/detection_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/detection_model/detection_module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2532 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/detection_model/detection_unet_in.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/inpainting_model/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/inpainting_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5759 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/inpainting_model/gconv.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3233 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/inpainting_model/inpainting_unet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10898 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/box_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3911 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/network.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5003 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/predict_single.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1035 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/prior_box.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2110 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/utils.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3890 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/unet_deploy.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9917 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1169 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/skin_retouching/weights_init.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/
+-rw-r--r--   0 runner    (1001) docker     (122)      526 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/data/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2094 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/data/data_augment.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/exp/
+-rw-r--r--   0 runner    (1001) docker     (122)      165 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/exp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      274 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/exp/base_exp.py
+-rw-r--r--   0 runner    (1001) docker     (122)      392 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/exp/build.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/exp/default/
+-rw-r--r--   0 runner    (1001) docker     (122)      137 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/exp/default/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/exp/default/streamyolo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1845 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/exp/yolox_base.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      238 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/darknet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10911 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/dfp_pafpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6156 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/network_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1314 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/streamyolo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5669 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/tal_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4352 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/realtime_video_detector.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      270 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3681 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/utils/boxes.py
+-rw-r--r--   0 runner    (1001) docker     (122)      209 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/stream_yolo/utils/format.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/super_resolution/
+-rw-r--r--   0 runner    (1001) docker     (122)      555 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/super_resolution/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7652 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/super_resolution/arch_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10508 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/super_resolution/ecb.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3525 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/super_resolution/ecbsr_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/super_resolution/rrdbnet_arch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/table_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      462 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/table_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16198 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/table_recognition/lineless_table_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3360 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/table_recognition/model_lore.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/table_recognition/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/table_recognition/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12614 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/table_recognition/modules/lore_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15090 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/table_recognition/modules/lore_processor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5488 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)      777 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/lseg_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7587 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/lseg_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4143 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/lseg_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6145 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/lseg_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18951 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/lseg_vit.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16418 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5165 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/simple_tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/
+-rw-r--r--   0 runner    (1001) docker     (122)      594 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    43681 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/basic_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2174 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/global_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2902 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/master_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)      766 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/model_zoo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2892 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/plain_net_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7405 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/super_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14983 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/super_res_idwexkx.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8709 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/super_res_k1kxk1.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6923 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/super_res_kxkx.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      699 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/apis/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/apis/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2067 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/apis/detector_evaluater.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4000 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/apis/detector_inference.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3460 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8123 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2345 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5911 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2842 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/
+-rw-r--r--   0 runner    (1001) docker     (122)      148 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      621 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3701 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9356 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7465 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14261 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/base_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10559 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13101 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/ops.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    18626 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7526 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2572 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      561 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/weight_init.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      409 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12602 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19162 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5588 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12284 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/
+-rw-r--r--   0 runner    (1001) docker     (122)      421 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7347 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24842 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3499 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/detectors/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/detectors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2809 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/detectors/detector.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/structures/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/structures/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9197 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/structures/bounding_box.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2627 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/structures/boxlist_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2774 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/structures/image_list.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      189 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11594 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/utils/boxes.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5838 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/utils/model_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1164 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/utils/scheduler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6400 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)      627 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/tinynas_damoyolo.py
+-rw-r--r--   0 runner    (1001) docker     (122)      643 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/tinynas_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1026 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/tinynas_detection/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/
+-rw-r--r--   0 runner    (1001) docker     (122)     2896 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/UNet_for_video_deinterlace.py
+-rw-r--r--   0 runner    (1001) docker     (122)      494 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      773 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/deinterlace_arch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3159 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/archs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1441 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/deep_fourier_upsampling.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2972 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/enh.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3572 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/fre.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3716 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      483 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/configs/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/configs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12753 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/configs/default_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6731 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/dro_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/geometry/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/geometry/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5494 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/geometry/camera.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2285 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/geometry/camera_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3737 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/geometry/pose.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3685 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/geometry/pose_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5277 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/model_checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2356 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/model_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10098 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/model_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7204 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/sfm_model_mf.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4387 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/sup_model_mf.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/depth_pose/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/depth_pose/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10532 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8902 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1607 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1915 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/optim/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/optim/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15781 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/optim/extractor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8039 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/optim/update.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6815 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/augmentations.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10248 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15068 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/depth.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1153 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/horovod.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10965 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9407 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/image_gt.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6499 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/load.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2726 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/misc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1348 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/types.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/
+-rw-r--r--   0 runner    (1001) docker     (122)     1894 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/VFINet_arch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3334 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py
+-rw-r--r--   0 runner    (1001) docker     (122)      458 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/flow_model/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/flow_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3212 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/flow_model/corr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9228 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/flow_model/extractor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5346 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/flow_model/raft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/flow_model/update.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/
+-rw-r--r--   0 runner    (1001) docker     (122)    13745 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4049 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/UNet.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3823 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/flow_reversal.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16050 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36415 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/transformer_layers.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3314 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/utils/scene_change_detection.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2907 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/utils/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_human_matting/
+-rw-r--r--   0 runner    (1001) docker     (122)      558 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_human_matting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1324 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_human_matting/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10465 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2662 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/deep_guided_filter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5506 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/effv2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2904 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/lraspp.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2234 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/matting.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_inpainting/
+-rw-r--r--   0 runner    (1001) docker     (122)      524 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_inpainting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11056 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_inpainting/inpainting.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13727 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_inpainting/inpainting_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      582 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18236 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21551 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/kernel_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16955 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/kernel_iter_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20983 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/kernel_update_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4136 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/kernel_updator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/neck/
+-rw-r--r--   0 runner    (1001) docker     (122)      525 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/neck/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11733 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/track/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/track/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26843 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/track/kernel_update_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10771 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4163 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18059 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/video_knet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/
+-rw-r--r--   0 runner    (1001) docker     (122)      541 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2970 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/models/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2420 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/models/decode.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1890 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/models/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4921 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/models/yolo.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/tracker/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/tracker/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1084 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/tracker/basetrack.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3117 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/tracker/matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14995 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/tracker/multitracker.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2230 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/utils/image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9570 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/utils/kalman_filter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7296 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2888 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/utils/visualization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      497 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      818 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/aggregate.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3582 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/cbam.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1979 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/eval_network.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3980 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/inference_core.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/inference_memory_bank.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7037 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/mod_resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)      974 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15309 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/modules.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5593 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/network.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      477 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10040 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26628 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/
+-rw-r--r--   0 runner    (1001) docker     (122)      515 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8349 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20677 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28653 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_update_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4081 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_updator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6696 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8627 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5885 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/track_heads.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/neck/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/neck/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6255 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/neck/fpn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/track/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/track/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8508 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17155 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/video_k_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5440 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/visualizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/config/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1024 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/config/ostrack.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/layers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/layers/attn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5004 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/layers/attn_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4805 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/layers/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1234 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/layers/patch_embed.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/ostrack/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/ostrack/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3380 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3393 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/ostrack/ostrack.py
+-rw-r--r--   0 runner    (1001) docker     (122)      653 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/ostrack/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12278 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/procontext/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/procontext/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3497 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/procontext/procontext.py
+-rw-r--r--   0 runner    (1001) docker     (122)      943 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/procontext/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4473 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/procontext/vit_ce.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/tracker/
+-rw-r--r--   0 runner    (1001) docker     (122)      114 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/tracker/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5507 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/tracker/ostrack.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7123 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/tracker/procontext.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8488 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/utils/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/
+-rw-r--r--   0 runner    (1001) docker     (122)    14702 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/DUT_raft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4715 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/MotionPro.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/RAFT/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/RAFT/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3290 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/RAFT/corr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9214 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/RAFT/extractor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5275 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/RAFT/raft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5526 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/RAFT/update.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3922 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/Smoother.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1447 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7292 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/rf_det_module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/rf_det_so.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3452 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUTRAFTStabilizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)     4684 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/IterativeSmooth.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14212 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/MedianFilter.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22544 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/ProjectionUtils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2893 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/RAFTUtils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2817 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/WarpUtils.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14474 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/image_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4977 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/math_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/
+-rw-r--r--   0 runner    (1001) docker     (122)      487 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/exp/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/exp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2488 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7097 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/longshortnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5774 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4848 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9990 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3905 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_summarization/
+-rw-r--r--   0 runner    (1001) docker     (122)      536 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_summarization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4959 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_summarization/base_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_summarization/kts/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_summarization/kts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1221 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_summarization/kts/cpd_auto.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3238 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_summarization/kts/cpd_nonlin.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13098 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_summarization/pgl_sum.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8812 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_summarization/summarizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/video_super_resolution/
+-rw-r--r--   0 runner    (1001) docker     (122)      689 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_super_resolution/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14118 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_super_resolution/basicvsr_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4727 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_super_resolution/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4720 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_super_resolution/msrresnet_lite_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3636 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3637 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/video_super_resolution/real_basicvsr_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/vidt/
+-rw-r--r--   0 runner    (1001) docker     (122)      464 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vidt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    40074 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vidt/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25588 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vidt/deformable_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7436 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vidt/fpn_fusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16697 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vidt/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3651 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vidt/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/virual_tryon/
+-rw-r--r--   0 runner    (1001) docker     (122)      464 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/virual_tryon/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17690 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/virual_tryon/sdafnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/
+-rw-r--r--   0 runner    (1001) docker     (122)      502 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16152 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)      797 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1786 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9340 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/petl.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5021 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/timm_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28715 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/timm_vision_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5040 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/timm_weight_init.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5614 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/vision_efficient_tuning.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/vision_middleware/
+-rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_middleware/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5749 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_middleware/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28089 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_middleware/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6494 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_middleware/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6192 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vision_middleware/vim.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/cv/vop_retrieval/
+-rw-r--r--   0 runner    (1001) docker     (122)      919 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vop_retrieval/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12238 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vop_retrieval/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5188 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vop_retrieval/basic_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13520 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vop_retrieval/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5299 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vop_retrieval/model_se.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5177 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/cv/vop_retrieval/tokenization_clip.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)     2182 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/clip/
+-rw-r--r--   0 runner    (1001) docker     (122)       97 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/clip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14496 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/clip/bert_tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3898 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/clip/configuration_bert.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22351 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/clip/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20998 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/clip/modeling_bert.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/clip_interrogator/
+-rw-r--r--   0 runner    (1001) docker     (122)       37 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/clip_interrogator/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24293 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/clip_interrogator/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      140 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26652 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/diffusion/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14447 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/diffusion/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    39910 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/diffusion/structbert.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11507 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/diffusion/tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11834 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/diffusion/unet_generator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8566 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/diffusion/unet_upsampler_1024.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12361 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/diffusion/unet_upsampler_256.py
+-rw-r--r--   0 runner    (1001) docker     (122)    44602 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/dpm_solver_pytorch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/efficient_diffusion_tuning/
+-rw-r--r--   0 runner    (1001) docker     (122)      540 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/efficient_diffusion_tuning/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10300 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/gemm/
+-rw-r--r--   0 runner    (1001) docker     (122)      139 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/gemm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21694 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/gemm/gemm_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3718 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/gemm/gemm_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/gemm/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      548 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36265 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/gaussian_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2969 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/respace.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1365 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/script.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36898 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/unet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/mgeo/
+-rw-r--r--   0 runner    (1001) docker     (122)     1444 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mgeo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)   101942 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mgeo/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8651 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mgeo/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3268 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mgeo/text_ranking.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10331 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mgeo/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/
+-rw-r--r--   0 runner    (1001) docker     (122)      141 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/dataloaders/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/dataloaders/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3789 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/dataloaders/rawvideo_util.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      162 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9790 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1442 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/dynamic_inverted_softmax.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21257 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/modeling.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18790 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/module_clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3577 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/module_cross.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5581 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/tokenization_clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4116 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/until_module.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug/
+-rw-r--r--   0 runner    (1001) docker     (122)      739 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug/clip/
+-rw-r--r--   0 runner    (1001) docker     (122)       86 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug/clip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16605 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug/clip/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6030 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug/configuration_mplug.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)   120753 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug/modeling_mplug.py
+-rw-r--r--   0 runner    (1001) docker     (122)    34049 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug/mvit.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    21332 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug/predictor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5536 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug_for_all_tasks.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug_owl/
+-rw-r--r--   0 runner    (1001) docker     (122)      835 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug_owl/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10293 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug_owl/configuration_mplug_owl.py
+-rw-r--r--   0 runner    (1001) docker     (122)    64194 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/mplug_owl/modeling_mplug_owl.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      150 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10208 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11503 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28436 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13487 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/prior.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6898 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16675 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/upsampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6565 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/xglm.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/
+-rw-r--r--   0 runner    (1001) docker     (122)      306 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/adaptor/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/adaptor/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18720 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/configuration_mmspeech.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16552 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/configuration_ofa.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1785 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/incremental_decoding_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21049 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/multihead_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5658 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/ngram_repeat_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)    43439 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/search.py
+-rw-r--r--   0 runner    (1001) docker     (122)    41976 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/sequence_generator.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16690 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/token_generation_constraints.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4883 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    44296 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/modeling_mmspeech.py
+-rw-r--r--   0 runner    (1001) docker     (122)   100933 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/modeling_ofa.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13226 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15028 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/tokenization_ofa.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8004 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/tokenization_ofa_fast.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      676 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/utils/constant.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1877 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8435 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa/vit.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24779 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa_for_all_tasks.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12983 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/ofa_for_text_to_image_synthesis_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/rleg/
+-rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/rleg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4865 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/rleg/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3410 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/rleg/rleg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/soonet/
+-rw-r--r--   0 runner    (1001) docker     (122)      678 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/soonet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9838 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/soonet/blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11896 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/soonet/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6165 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/soonet/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22584 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/soonet/swin_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4885 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/soonet/tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1597 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/soonet/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/stable_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/stable_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6267 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/stable_diffusion/stable_diffusion.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/team/
+-rw-r--r--   0 runner    (1001) docker     (122)      140 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/team/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5181 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/team/team_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11502 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/team/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/
+-rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18477 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/autoencoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9264 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9504 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    38498 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/unet_sd.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/multi_modal/vldoc/
+-rw-r--r--   0 runner    (1001) docker     (122)       93 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/vldoc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11339 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/vldoc/conv_fpn_trans.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/vldoc/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16687 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/vldoc/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    47348 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/vldoc/modeling_layout_roberta.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20956 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/vldoc/processing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4680 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/vldoc/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7333 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/multi_modal/vldoc/transformer_local.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/T5/
+-rw-r--r--   0 runner    (1001) docker     (122)      599 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/T5/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    67374 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/T5/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7541 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/T5/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21517 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/T5/text2text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6810 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/bart/
+-rw-r--r--   0 runner    (1001) docker     (122)      112 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bart/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3058 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bart/text_error_correction.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/bert/
+-rw-r--r--   0 runner    (1001) docker     (122)     1519 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    40458 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7308 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4113 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/document_segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (122)      512 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6074 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/sentence_embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7153 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/siamese_uie.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1478 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1138 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/text_ranking.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2140 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/token_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6904 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bert/word_alignment.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/bloom/
+-rw-r--r--   0 runner    (1001) docker     (122)      472 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bloom/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      505 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/bloom/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/canmt/
+-rw-r--r--   0 runner    (1001) docker     (122)      102 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/canmt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    52235 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/canmt/canmt_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2940 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/canmt/canmt_translation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    35688 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/canmt/sequence_generator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm/
+-rw-r--r--   0 runner    (1001) docker     (122)     1578 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4402 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15788 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm/quantization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    60907 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17391 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm/tokenization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm2/
+-rw-r--r--   0 runner    (1001) docker     (122)     1584 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2397 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm2/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15263 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm2/quantization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    50579 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm2/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9669 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/chatglm2/tokenization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/codegeex/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      730 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/codegeex/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    35473 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/codegeex/codegeex.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3995 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/codegeex/codegeex_for_code_generation.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4008 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/codegeex/codegeex_for_code_translation.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     9997 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/codegeex/inference.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6111 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/codegeex/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/csanmt/
+-rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/csanmt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    61868 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/csanmt/translation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/deberta_v2/
+-rw-r--r--   0 runner    (1001) docker     (122)     1771 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/deberta_v2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    47998 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/deberta_v2/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6771 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/deberta_v2/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10364 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/deberta_v2/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21421 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/deberta_v2/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10698 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/deberta_v2/tokenization_fast.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/dgds/
+-rw-r--r--   0 runner    (1001) docker     (122)      939 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/dgds/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7092 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/dgds/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1656 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/dgds/document_grounded_dialog_generate.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1059 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/dgds/document_grounded_dialog_rerank.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2180 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/dgds/document_grounded_dialog_retrieval.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/fid_T5/
+-rw-r--r--   0 runner    (1001) docker     (122)     1082 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/fid_T5/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8108 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/fid_T5/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/fid_plug/
+-rw-r--r--   0 runner    (1001) docker     (122)     1181 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/fid_plug/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45082 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/fid_plug/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5045 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/fid_plug/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6709 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/fid_plug/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/
+-rw-r--r--   0 runner    (1001) docker     (122)      540 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/generation/
+-rw-r--r--   0 runner    (1001) docker     (122)       87 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/generation/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    10112 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/generation/strategies.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5152 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/initialize.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/kernels/
+-rw-r--r--   0 runner    (1001) docker     (122)     3263 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/kernels/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/quantization/
+-rw-r--r--   0 runner    (1001) docker     (122)     2635 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/quantization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/quantization/functional.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4510 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/quantization/layers.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    13504 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/glm_130b/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/gpt2/
+-rw-r--r--   0 runner    (1001) docker     (122)      470 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      498 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt2/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/gpt3/
+-rw-r--r--   0 runner    (1001) docker     (122)      852 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt3/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16094 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt3/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8971 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt3/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    52130 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt3/distributed_gpt3.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3198 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt3/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2586 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt3/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/
+-rw-r--r--   0 runner    (1001) docker     (122)      874 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13129 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5198 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/checkpointing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4930 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    49316 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/distributed_gpt_moe.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/experts.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3504 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/layer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2553 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/mappings.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23756 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/sharded_moe.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2717 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2277 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_moe/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_neo/
+-rw-r--r--   0 runner    (1001) docker     (122)      474 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_neo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      518 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/gpt_neo/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      661 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25248 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/heads/crf_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6947 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/heads/fill_mask_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5145 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/heads/infromation_extraction_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2056 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/heads/text_classification_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)      964 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/heads/text_generation_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2029 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/heads/text_ranking_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2596 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/heads/token_classification_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)      948 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/heads/torch_pretrain_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/hf_transformers/
+-rw-r--r--   0 runner    (1001) docker     (122)      488 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/hf_transformers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4897 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/hf_transformers/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/llama/
+-rw-r--r--   0 runner    (1001) docker     (122)      866 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/llama/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    29197 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/llama/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4695 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/llama/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11349 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/llama/convert_llama_weights_to_hf.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7212 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/llama/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10333 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/llama/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4720 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/llama/tokenization_fast.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/lstm/
+-rw-r--r--   0 runner    (1001) docker     (122)      610 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/lstm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1312 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/lstm/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2187 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/lstm/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/megatron_bert/
+-rw-r--r--   0 runner    (1001) docker     (122)      688 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/megatron_bert/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    39864 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/megatron_bert/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6599 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/megatron_bert/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12452 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/megatron_bert/fill_mask.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/
+-rw-r--r--   0 runner    (1001) docker     (122)      572 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    28115 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/arguments.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28162 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/blocklm_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17995 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/configure_data.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)    13656 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    20350 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/corpora.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45765 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/datasets.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3342 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/extraction.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8459 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/file_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9797 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/lazy_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7221 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/samplers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/sp_tokenizer.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    53304 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14551 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/tokenization_gpt2.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    15773 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/wordpiece.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21669 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/generation_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16247 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/mglm_for_text_summarization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/model/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      984 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/model/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5443 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/model/distributed.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9967 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/model/downstream.py
+-rw-r--r--   0 runner    (1001) docker     (122)    70249 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/model/modeling_bert.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8743 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/model/modeling_glm.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2531 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/model/prompt.py
+-rw-r--r--   0 runner    (1001) docker     (122)    48886 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/model/transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/process_grid.py
+-rw-r--r--   0 runner    (1001) docker     (122)      203 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/run_test.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/test/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/test/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      950 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/test/test_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)      704 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/test/test_rel_shift.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17815 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/train_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19029 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/mglm/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/palm_v2/
+-rw-r--r--   0 runner    (1001) docker     (122)     1268 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/palm_v2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5532 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/palm_v2/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    29453 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/palm_v2/dureader_eval.py
+-rw-r--r--   0 runner    (1001) docker     (122)    55450 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/palm_v2/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/peer/
+-rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/peer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    55780 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/peer/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11716 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/peer/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6166 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/peer/sas_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4933 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/peer/text_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/plug/
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3321 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug/AnnealingLR.py
+-rw-r--r--   0 runner    (1001) docker     (122)      660 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    41209 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11797 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10983 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug/distributed_plug.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8427 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug/generator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/plug_mental/
+-rw-r--r--   0 runner    (1001) docker     (122)     1359 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug_mental/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7671 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug_mental/adv_utils.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    47486 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug_mental/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7956 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug_mental/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10881 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/plug_mental/text_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/ponet/
+-rw-r--r--   0 runner    (1001) docker     (122)     1490 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/ponet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    37918 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/ponet/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6366 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/ponet/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4176 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/ponet/document_segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11011 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/ponet/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7147 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/ponet/tokenization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)      987 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1208 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3832 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/dialog_intent_prediction.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/dialog_modeling.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16648 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/dialog_state_tracking.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/space/model/
+-rw-r--r--   0 runner    (1001) docker     (122)      421 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10281 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/model/gen_unified_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10757 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/model/generator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7505 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/model/intent_unified_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3032 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/model/model_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/model/tokenization_space.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11941 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/model/unified_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/space/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2398 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/modules/embedder.py
+-rw-r--r--   0 runner    (1001) docker     (122)      956 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/modules/feedforward.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1721 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/modules/functions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3397 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/modules/multihead_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1922 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space/modules/transformer_block.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/space_T_cn/
+-rw-r--r--   0 runner    (1001) docker     (122)      529 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space_T_cn/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    44438 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space_T_cn/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5194 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space_T_cn/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30117 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space_T_cn/table_question_answering.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/space_T_en/
+-rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space_T_en/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3715 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/space_T_en/text_to_sql.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/structbert/
+-rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/structbert/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7673 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/structbert/adv_utils.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    40848 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/structbert/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7686 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/structbert/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27203 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/structbert/faq_question_answering.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12581 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/structbert/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11862 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/structbert/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11074 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/structbert/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/task_models/
+-rw-r--r--   0 runner    (1001) docker     (122)     1453 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/task_models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5323 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/task_models/feature_extraction.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2698 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/task_models/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)      766 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/task_models/information_extraction.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28991 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/task_models/task_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1912 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/task_models/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8678 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/task_models/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2092 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/task_models/text_ranking.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5116 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/task_models/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/unite/
+-rw-r--r--   0 runner    (1001) docker     (122)      626 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/unite/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      409 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/unite/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18320 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/unite/translation_evaluation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/use/
+-rw-r--r--   0 runner    (1001) docker     (122)      545 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/use/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5133 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/use/transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5832 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/use/user_satisfaction_estimation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/veco/
+-rw-r--r--   0 runner    (1001) docker     (122)     1479 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/veco/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4031 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/veco/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1192 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/veco/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4278 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/veco/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6643 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/veco/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4129 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/veco/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/nlp/xlm_roberta/
+-rw-r--r--   0 runner    (1001) docker     (122)     1156 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/xlm_roberta/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42932 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/xlm_roberta/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7697 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/nlp/xlm_roberta/configuration.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/science/
+-rw-r--r--   0 runner    (1001) docker     (122)      491 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/science/unifold/
+-rw-r--r--   0 runner    (1001) docker     (122)       46 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24057 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/config.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/science/unifold/data/
+-rw-r--r--   0 runner    (1001) docker     (122)      634 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    49139 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/data/data_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19691 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/data/msa_pairing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8941 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/data/process.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14792 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/data/process_multimer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11422 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/data/protein.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42023 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/data/residue_constants.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4628 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/data/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19250 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)      187 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17066 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/alphafold.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12323 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/attentions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5403 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/auxillary_heads.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10676 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5814 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/confidence.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8771 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/embedders.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11078 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/evoformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6820 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/featurization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18025 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/frame.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18476 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/structure_module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9771 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/template.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5623 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/modules/triangle_multiplication.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/
+-rw-r--r--   0 runner    (1001) docker     (122)       46 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17940 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/mmcif.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3128 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/msa_identifiers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23503 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/parsers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45468 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/templates.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/
+-rw-r--r--   0 runner    (1001) docker     (122)      639 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6218 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/hhblits.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3991 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/hhsearch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5098 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/hmmbuild.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5013 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/hmmsearch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8662 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/jackhmmer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3752 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/kalign.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1255 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2892 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/models/science/unifold/msa/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/
+-rw-r--r--   0 runner    (1001) docker     (122)       84 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      346 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/audio/asr_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/auth/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/auth/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1326 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/auth/auth_config.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/context/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/context/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3444 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/context/dataset_context_config.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/data_files/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/data_files/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5270 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/data_files/data_files_manager.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/data_loader/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/data_loader/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12636 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/data_loader/data_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5764 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/data_loader/data_loader_manager.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/
+-rw-r--r--   0 runner    (1001) docker     (122)      111 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)     4111 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)      730 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1737 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8512 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7723 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11689 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/
+-rw-r--r--   0 runner    (1001) docker     (122)      541 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1264 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)      791 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/
+-rw-r--r--   0 runner    (1001) docker     (122)      134 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4708 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py
+-rw-r--r--   0 runner    (1001) docker     (122)      945 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      177 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3815 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16180 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/
+-rw-r--r--   0 runner    (1001) docker     (122)      934 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/
+-rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11572 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/
+-rw-r--r--   0 runner    (1001) docker     (122)      312 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2622 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4858 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1469 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/
+-rw-r--r--   0 runner    (1001) docker     (122)      196 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1086 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2509 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/easycv_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2141 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/
+-rw-r--r--   0 runner    (1001) docker     (122)      539 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/
+-rw-r--r--   0 runner    (1001) docker     (122)      529 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12152 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12574 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/
+-rw-r--r--   0 runner    (1001) docker     (122)      577 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1629 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/
+-rw-r--r--   0 runner    (1001) docker     (122)      615 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1487 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/
+-rw-r--r--   0 runner    (1001) docker     (122)      583 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4849 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6225 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      559 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6171 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4013 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      161 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1589 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5437 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/
+-rw-r--r--   0 runner    (1001) docker     (122)       40 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7547 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3416 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/
+-rw-r--r--   0 runner    (1001) docker     (122)      309 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3172 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)      971 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5818 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2000 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)      707 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4912 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2402 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2017 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      599 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16767 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8725 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/
+-rw-r--r--   0 runner    (1001) docker     (122)      545 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1475 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1984 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2684 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5114 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1635 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2664 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/veco_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/
+-rw-r--r--   0 runner    (1001) docker     (122)      573 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1390 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/
+-rw-r--r--   0 runner    (1001) docker     (122)      543 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      809 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2624 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/
+-rw-r--r--   0 runner    (1001) docker     (122)      553 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2370 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11485 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/dataset_cls/dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/download/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/download/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20627 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/download/dataset_builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)      640 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/download/download_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2487 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/download/download_manager.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/meta/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/meta/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1772 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/meta/data_meta_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8679 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/meta/data_meta_manager.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36737 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/ms_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/task_datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)     1072 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/task_datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      408 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/task_datasets/gopro_image_deblurring_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)      401 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/task_datasets/reds_image_deblurring_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)      404 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/task_datasets/sidd_image_denoising.py
+-rw-r--r--   0 runner    (1001) docker     (122)      410 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/task_datasets/torch_base_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)      404 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/task_datasets/video_summarization_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/msdatasets/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8124 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/utils/dataset_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1026 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/utils/delete_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/utils/maxcompute_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6200 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/utils/oss_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2496 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/msdatasets/utils/upload_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/ops/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/ops/ailut/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/ops/ailut/Ailut/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/ailut/Ailut/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/ops/ailut/Ailut/csrc/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/ailut/Ailut/csrc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      105 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/ailut/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4314 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/ailut/pyinterfaces.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/ops/quadtree_attention/
+-rw-r--r--   0 runner    (1001) docker     (122)      106 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/quadtree_attention/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/ops/quadtree_attention/functions/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/quadtree_attention/functions/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2925 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/quadtree_attention/functions/quadtree_attention.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/ops/quadtree_attention/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/quadtree_attention/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13956 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/quadtree_attention/modules/quadtree_attention.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/ops/quadtree_attention/src/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/ops/quadtree_attention/src/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/outputs/
+-rw-r--r--   0 runner    (1001) docker     (122)      132 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/outputs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      908 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/outputs/cv_outputs.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19855 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/outputs/nlp_outputs.py
+-rw-r--r--   0 runner    (1001) docker     (122)    51098 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/outputs/outputs.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11135 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipeline_inputs.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/
+-rw-r--r--   0 runner    (1001) docker     (122)      150 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7519 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/ans_dfsmn_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5016 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/ans_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23889 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/asr_inference_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/asr_wenet_inference_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4357 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/inverse_text_processing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3830 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/kws_farfield_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7276 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/kws_kwsbp_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5642 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/linear_aec_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8068 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/lm_infer_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6481 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/punctuation_processing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13047 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/segmentation_clustering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2560 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/separation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4763 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/speaker_change_locating_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11117 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/speaker_diarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4078 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6271 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/speaker_verification_light_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10527 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/speaker_verification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4072 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1789 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/text_to_speech_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11937 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/timestamp_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9696 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/audio/voice_activity_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23113 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7702 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)    16450 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2545 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/action_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4852 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/action_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4024 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/animal_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2576 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/arc_face_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2614 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/bad_image_detecting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/body_2d_keypoints_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14219 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/body_3d_keypoints_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4753 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/card_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5307 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/cmdssl_video_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2528 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/content_check_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5055 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/controllable_image_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5942 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/crowd_counting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5136 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ddcolor_image_colorization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ddpm_semantic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2498 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_attribute_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3993 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1531 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_emotion_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1648 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_human_hand_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2894 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_image_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3312 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_liveness_ir_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3573 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_liveness_xc_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7748 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_processing_base_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3872 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_quality_assessment_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3528 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_recognition_onnx_fm_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3493 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_recognition_onnx_ir_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2878 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_recognition_ood_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2498 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19634 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/face_reconstruction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2400 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/facial_expression_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2681 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/facial_landmark_confidence_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4442 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/fast_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4030 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/general_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1360 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/hand_static_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2982 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/hicossl_video_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4372 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/human_reconstruction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1399 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_body_reshaping_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2919 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_bts_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5251 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_cartoon_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5857 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3296 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_color_enhance_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4441 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_colorization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2648 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_debanding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4624 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_deblur_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3517 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_defrcn_fewshot_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4160 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_denoise_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1943 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1854 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4134 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_driving_perception_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2317 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_face_fusion_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4866 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_human_parsing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5854 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_inpainting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4673 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_inpainting_sdv2_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3903 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5929 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_matching_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2607 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_matting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2796 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_mvs_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2770 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_open_vocabulary_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6113 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_paintbyexample_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3622 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_panoptic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8567 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_portrait_enhancement_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3549 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_quality_assessment_degradation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2835 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_quality_assessment_man_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2801 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_quality_assessment_mos_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2026 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_reid_person_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1702 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_restoration_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1644 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_salient_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3207 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_semantic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2237 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_skychange_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2839 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_structured_model_probing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4615 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_style_transfer_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3138 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_super_resolution_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9718 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_to_image_generate_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12737 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/image_to_image_translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1883 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/indoor_layout_estimation_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     9872 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/language_guided_video_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4570 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/license_plate_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4182 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/lineless_table_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/live_category_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2757 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/mask_face_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2787 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/maskdino_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3670 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/mobile_image_super_resolution_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1857 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/mog_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4844 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/motion_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2628 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/movie_scene_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1953 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/mtcnn_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3328 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/nerf_recon_acc_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6018 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/object_detection_3d_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11033 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2509 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_recognition_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      966 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      720 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/model_convnext_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19821 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/model_dla34.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8768 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/model_resnet18_half.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5286 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15421 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/model_vlpt.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ocr_modules/
+-rw-r--r--   0 runner    (1001) docker     (122)      550 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ocr_modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ocr_modules/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1560 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ocr_modules/vitstr.py
+-rw-r--r--   0 runner    (1001) docker     (122)    38278 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19004 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/resnet18_v1.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11371 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/resnet_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11168 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/table_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7971 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3029 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/panorama_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9781 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/pedestrian_attribute_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4199 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1457 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/product_retrieval_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1451 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/product_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2020 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/realtime_video_object_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9239 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/referring_video_object_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1956 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/retina_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1760 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/shop_segmentation_pipleline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12129 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/skin_retouching_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4446 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/table_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4899 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/tbs_detection_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/cv/tbs_detection_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)       10 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/tbs_detection_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15542 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/tbs_detection_utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1841 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/text_driven_segmentation_pipleline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3246 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/tinynas_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3244 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/tinynas_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1888 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/ulfd_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13776 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_category_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6097 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_colorization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7757 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_deinterlace_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1565 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24271 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_frame_interpolation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3635 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_human_matting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1719 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_inpainting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9652 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3294 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_multi_object_tracking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4724 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_object_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4683 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_panoptic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3436 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_single_object_tracking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4647 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_stabilization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4289 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7078 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/video_super_resolution_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7564 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/vidt_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5240 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/virtual_try_on_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3986 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/vision_efficient_tuning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2180 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/vision_middleware_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4762 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/vop_retrieval_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5787 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/cv/vop_retrieval_se_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)     3057 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2366 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/asr_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/
+-rw-r--r--   0 runner    (1001) docker     (122)      622 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2013 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      704 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11691 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2537 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/
+-rw-r--r--   0 runner    (1001) docker     (122)      585 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15631 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18987 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2311 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/document_vl_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2931 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1093 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9352 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/gridvlp_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3219 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/image_captioning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1612 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/image_text_retrieval_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7869 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/mgeo_ranking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1648 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/multi_modal_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3325 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/multimodal_dialogue_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/ocr_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8561 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1848 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/sudoku_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1059 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1789 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/text2sql_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2064 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/text_to_image_synthesis_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3556 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/text_to_video_synthesis_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2150 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/video_captioning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1329 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1956 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/video_question_answering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/visual_entailment_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1781 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/visual_grounding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2396 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/multi_modal/visual_question_answering_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     6798 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6939 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/automatic_post_editing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3696 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/canmt_translation_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2202 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/codegeex_code_generation_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2885 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/codegeex_code_translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2251 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/conversational_text_to_sql_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2577 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/dialog_intent_prediction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2308 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/dialog_modeling_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7663 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/dialog_state_tracking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3825 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/distributed_gpt3_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1851 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/distributed_gpt_moe_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4425 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/distributed_plug_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2754 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/document_grounded_dialog_generate_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25997 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5480 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9623 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/document_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6259 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/extractive_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3348 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/faq_question_answering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2437 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/fasttext_text_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3258 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/feature_extraction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10171 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/fid_dialogue_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4655 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/fill_mask_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)      999 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/glm130b_text_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2383 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/information_extraction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6363 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/interactive_translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9928 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/language_identification_pipline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1776 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/mglm_text_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2955 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/named_entity_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3184 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/sentence_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14334 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/siamese_uie_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2566 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16315 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/table_question_answering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6787 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/text_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3490 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/text_error_correction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10337 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/text_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2877 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/text_ranking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6399 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/token_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4372 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/translation_evaluation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5586 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2339 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/translation_quality_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4613 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/user_satisfaction_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2713 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/word_alignment_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4523 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/word_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5875 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/nlp/zero_shot_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2816 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/pipeline_template.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/pipelines/science/
+-rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/science/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/science/protein_structure_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3492 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/pipelines/util.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/
+-rw-r--r--   0 runner    (1001) docker     (122)     5792 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10063 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/asr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8680 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/audio.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15312 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)      812 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/common.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)     1896 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7446 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/action_detection_mapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1126 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/bad_image_detecting_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7789 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/controllable_image_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20909 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/cv2_transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12826 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/image_classification_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1250 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/image_quality_assessment_man.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2113 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/image_quality_assessment_mos.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2790 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/image_restoration_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2625 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/mmcls_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3050 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/timer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3606 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1501 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/video_stabilization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8579 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/cv/video_super_resolution.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13406 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4884 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/kws.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/movie_scene_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      483 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/movie_scene_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10809 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/movie_scene_segmentation/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30172 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/multi_modal.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     5966 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      762 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/bert_seq_cls_tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3929 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/canmt_translation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2572 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/dialog_classification_use_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4102 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4391 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4086 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11004 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/document_segmentation_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6844 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/faq_question_answering_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3304 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/feature_extraction_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12086 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/fill_mask_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8199 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/mgeo_ranking_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1168 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/mglm_summarization_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1799 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/relation_extraction_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4023 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/sentence_embedding_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1424 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/siamese_uie_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)     1219 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1908 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/args.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1553 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/batch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3629 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/data_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2701 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2789 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/dialog_modeling_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5457 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    56779 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/dst_processors.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/fields/
+-rw-r--r--   0 runner    (1001) docker     (122)      592 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/fields/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    33884 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/fields/gen_field.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42467 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/fields/intent_field.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1147 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/lazy_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1935 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/preprocess.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1610 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/sampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2084 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/tensorlistdataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24803 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/
+-rw-r--r--   0 runner    (1001) docker     (122)      654 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/fields/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/fields/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4936 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/fields/database.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15867 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/fields/schema_link.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4888 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/fields/struct.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4175 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/
+-rw-r--r--   0 runner    (1001) docker     (122)      846 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4902 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/
+-rw-r--r--   0 runner    (1001) docker     (122)      818 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21521 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/common_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12500 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/parse.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1380 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2111 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/process_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/text_classification_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/text_clean.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2298 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/text_error_correction.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14124 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/text_generation_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3834 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/text_ranking_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19629 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/token_classification_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1640 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/token_classification_thai_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1238 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/token_classification_viet_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4482 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/transformers_tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7304 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/translation_evaluation_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3622 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4962 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/word_alignment_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2584 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/nlp/zero_shot_classification_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/
+-rw-r--r--   0 runner    (1001) docker     (122)      762 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4839 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/asr.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11909 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4172 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/image_captioning.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6461 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/image_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5740 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/ocr_recognition.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4603 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/sudoku.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5210 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/summarization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16449 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/text2sql.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5368 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2164 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/text_to_image_synthesis.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3221 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/audio_helper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8936 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/bridge_content_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6809 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/collate.py
+-rw-r--r--   0 runner    (1001) docker     (122)      660 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/constant.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3421 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/get_tables.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1302 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/random_help.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5459 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/text2phone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19116 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/utils/vision_helper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7664 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/visual_entailment.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8484 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/visual_grounding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6796 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/ofa/visual_question_answering.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/preprocessors/science/
+-rw-r--r--   0 runner    (1001) docker     (122)      478 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/science/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21698 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/science/uni_fold.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2101 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/tts.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13168 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/preprocessors/video.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/swift/
+-rw-r--r--   0 runner    (1001) docker     (122)     1394 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/swift/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7288 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/swift/adapter.py
+-rw-r--r--   0 runner    (1001) docker     (122)      841 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/swift/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)    38973 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/swift/control_sd_lora.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27160 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/swift/lora.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/swift/optimizers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/swift/optimizers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6931 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/swift/optimizers/child_tuning_adamw_optimizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8586 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/swift/prompt.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8811 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/swift/sd_lora.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/tools/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/tools/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      772 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/tools/eval.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5359 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/tools/speech_tts_autolabel.py
+-rw-r--r--   0 runner    (1001) docker     (122)      607 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/tools/train.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/
+-rw-r--r--   0 runner    (1001) docker     (122)     1799 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)      826 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1873 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/ans_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6969 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/asr_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12816 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/kws_farfield_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22065 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/kws_nearfield_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/audio/kws_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)     1768 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/kws_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22114 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/kws_utils/batch_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11499 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/kws_utils/det_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7022 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/kws_utils/file_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/kws_utils/model_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2854 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/kws_utils/runtime_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21962 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/separation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10858 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/audio/tts_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1808 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5553 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cli_argument_parser.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)     1974 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7494 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/action_detection_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      668 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/card_detection_scrfd_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10044 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/cartoon_translation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6737 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/face_detection_scrfd_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20323 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/image_classifition_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11655 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/image_defrcn_fewshot_detection_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22965 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/image_detection_damoyolo_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4405 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/image_inpainting_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      816 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/image_instance_segmentation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5520 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/image_portrait_enhancement_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      680 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/movie_scene_segmentation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20149 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/nerf_recon_acc_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16911 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/ocr_detection_db_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3153 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/ocr_recognition_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/referring_video_object_segmentation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4602 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/cv/vision_efficient_tuning_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2607 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/default_config.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/hooks/
+-rw-r--r--   0 runner    (1001) docker     (122)     2064 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      296 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/hooks/checkpoint/
+-rw-r--r--   0 runner    (1001) docker     (122)      116 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/checkpoint/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19086 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/checkpoint/checkpoint_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10690 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/checkpoint/checkpoint_processor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5541 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/checkpoint/load_checkpoint_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)      764 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/clip_clamp_logit_scale_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/hooks/compression/
+-rw-r--r--   0 runner    (1001) docker     (122)      610 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/compression/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4812 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/compression/sparsity_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6915 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/compression/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/hooks/distributed/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/distributed/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1458 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/distributed/ddp_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17072 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/distributed/deepspeed_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6925 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/distributed/megatron_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4398 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/early_stop_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3825 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/evaluation_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)      731 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/iter_timer_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/hooks/logger/
+-rw-r--r--   0 runner    (1001) docker     (122)      718 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/logger/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4498 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/logger/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4507 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/logger/tensorboard_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7443 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/logger/text_logger_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6567 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/lr_scheduler_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/hooks/optimizer/
+-rw-r--r--   0 runner    (1001) docker     (122)      743 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/optimizer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3139 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/optimizer/apex_optimizer_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3786 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/optimizer/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3729 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/optimizer/torch_optimizer_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/hooks/priority.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/lrscheduler/
+-rw-r--r--   0 runner    (1001) docker     (122)      699 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/lrscheduler/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2040 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/lrscheduler/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/lrscheduler/warmup/
+-rw-r--r--   0 runner    (1001) docker     (122)      614 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/lrscheduler/warmup/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2547 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/lrscheduler/warmup/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2934 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/lrscheduler/warmup/warmup.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)      682 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/clip/
+-rw-r--r--   0 runner    (1001) docker     (122)       89 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/clip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9702 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/clip/clip_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4388 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/clip/clip_trainer_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/dreambooth_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      118 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/dreambooth_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15330 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/efficient_diffusion_tuning/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/efficient_diffusion_tuning/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2874 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/lora_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      106 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/lora_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3224 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8086 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/mgeo_ranking_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/mplug/
+-rw-r--r--   0 runner    (1001) docker     (122)       91 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/mplug/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1642 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/mplug/mplug_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/ofa/
+-rw-r--r--   0 runner    (1001) docker     (122)       87 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/ofa/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10186 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/ofa/ofa_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17647 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/ofa/ofa_trainer_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/stable_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      112 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/stable_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1144 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/team/
+-rw-r--r--   0 runner    (1001) docker     (122)       95 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/team/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5429 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/team/team_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2443 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/multi_modal/team/team_trainer_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     1332 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14266 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/csanmt_translation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9999 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/document_grounded_dialog_generate_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24284 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/document_grounded_dialog_rerank_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/document_grounded_dialog_retrieval_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12769 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/faq_question_answering_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3064 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/gpt3_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2097 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/gpt_moe_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8171 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/plug_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3869 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/sentence_embedding_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8378 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/sequence_classification_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17110 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/siamese_uie_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5324 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/dialog_intent_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4229 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/dialog_modeling_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36354 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/eval.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/metrics/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/metrics/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2447 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/metrics/metrics_tracker.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/trainer/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/trainer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30567 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/trainer/gen_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    29570 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/space/trainer/intent_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20453 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/table_question_answering_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      991 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/text_generation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7514 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/text_ranking_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15326 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp/translation_evaluation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7129 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/nlp_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/optimizer/
+-rw-r--r--   0 runner    (1001) docker     (122)      210 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/optimizer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1753 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/optimizer/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/parallel/
+-rw-r--r--   0 runner    (1001) docker     (122)       80 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/parallel/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      681 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/parallel/builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)      754 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/parallel/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    59000 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17846 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/training_args.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/trainers/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11090 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/utils/inference.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1294 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/trainers/utils/log_buffer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)       56 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)   527369 2023-07-02 13:03:05.000000 modelscope-1.7.0/modelscope/utils/ast_index_file.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28920 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/ast_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/utils/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11795 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/audio/audio_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2428 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/audio/tts_exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26430 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2573 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/chinese_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27433 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1027 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/config_ds.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18793 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/constant.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/utils/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23195 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/cv/image_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/utils/cv/motion_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/cv/motion_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/cv/motion_utils/motion_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3847 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/cv/motion_utils/plot_script.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4290 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/cv/motion_utils/rotation_conversions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3153 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/data_collators.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1279 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3744 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/device.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6339 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/error.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1128 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/file_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5939 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/hub.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15823 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/import_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25538 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/input_output.py
+-rw-r--r--   0 runner    (1001) docker     (122)      296 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/input_output_typing.py
+-rw-r--r--   0 runner    (1001) docker     (122)      478 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/json_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2789 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/logger.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7612 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/megatron_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2335 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5099 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/model_tag.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/utils/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)      499 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4424 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/distributed.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4526 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/load_checkpoint.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/utils/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1909 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space/args.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11818 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space/clean_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1439 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space/criterions.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11252 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space/db_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6174 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space/ontology.py
+-rw-r--r--   0 runner    (1001) docker     (122)      197 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space/scores.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6356 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1054 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space/utils_dst.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope/utils/nlp/space_T_en/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space_T_en/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      859 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/space_T_en/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2554 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/nlp/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    40106 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/plugins.py
+-rw-r--r--   0 runner    (1001) docker     (122)      572 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/pre_compile.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7833 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/registry.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30195 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/regress_test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6127 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/service_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6243 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/streaming_output.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2500 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/task_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1593 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/tensor_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12532 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/timer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10966 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/torch_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      597 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/trie.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1696 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/type_assert.py
+-rw-r--r--   0 runner    (1001) docker     (122)      783 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/utils/url_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      272 2023-07-02 13:02:13.000000 modelscope-1.7.0/modelscope/version.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (122)    19397 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (122)   133944 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (122)        1 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (122)       59 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (122)        1 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (122)     4850 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (122)       11 2023-07-02 13:03:06.000000 modelscope-1.7.0/modelscope.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (122)       38 2023-07-02 13:03:06.000000 modelscope-1.7.0/setup.cfg
```

### Comparing `modelscope-1.6.1/PKG-INFO` & `modelscope-1.7.0/PKG-INFO`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: modelscope
-Version: 1.6.1
+Version: 1.7.0
 Summary: ModelScope: bring the notion of Model-as-a-Service to life.
 Home-page: https://github.com/modelscope/modelscope
 Author: ModelScope team
 Author-email: contact@modelscope.cn
 License: Apache License 2.0
 Description: 
         <p align="center">
@@ -207,20 +207,28 @@
         
         ModelScope Library currently supports popular deep learning framework for model training and inference, including PyTorch, TensorFlow and ONNX. All releases are tested and run on Python 3.7+, Pytorch 1.8+, Tensorflow1.15 or Tensorflow2.0+.
         
         To allow out-of-box usage for all the models on ModelScope, official docker images are provided for all releases. Based on the docker image, developers can skip all environment installation and configuration and use it directly. Currently, the latest version of the CPU image and GPU image can be obtained from:
         
         CPU docker image
         ```shell
-        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.3.0
+        # py37
+        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.6.1
+        
+        # py38
+        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py38-torch1.11.0-tf1.15.5-1.6.1
         ```
         
         GPU docker image
         ```shell
-        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py37-torch1.11.0-tf1.15.5-1.3.0
+        # py37
+        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py37-torch1.11.0-tf1.15.5-1.6.1
+        
+        # py38
+        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py38-torch1.11.0-tf1.15.5-1.6.1
         ```
         
         ## Setup Local Python Environment
         
         One can also set up local ModelScope environment using pip and conda.  We suggest [anaconda](https://docs.anaconda.com/anaconda/install/) for creating local python environment:
         
         ```shell
```

#### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: modelscope Version: 1.6.1 Summary: ModelScope:
+Metadata-Version: 2.1 Name: modelscope Version: 1.7.0 Summary: ModelScope:
 bring the notion of Model-as-a-Service to life. Home-page: https://github.com/
 modelscope/modelscope Author: ModelScope team Author-email:
 contact@modelscope.cn License: Apache License 2.0 Description:
 
        [https://modelscope.oss-cn-beijing.aliyuncs.com/modelscope.gif]
  [![PyPI](https://img.shields.io/pypi/v/modelscope)](https://pypi.org/project/
   modelscope/)  [![license](https://img.shields.io/github/license/modelscope/
@@ -154,42 +154,46 @@
 supports popular deep learning framework for model training and inference,
 including PyTorch, TensorFlow and ONNX. All releases are tested and run on
 Python 3.7+, Pytorch 1.8+, Tensorflow1.15 or Tensorflow2.0+. To allow out-of-
 box usage for all the models on ModelScope, official docker images are provided
 for all releases. Based on the docker image, developers can skip all
 environment installation and configuration and use it directly. Currently, the
 latest version of the CPU image and GPU image can be obtained from: CPU docker
-image ```shell registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:
-ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.3.0 ``` GPU docker image ```shell
-registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-
-cuda11.3.0-py37-torch1.11.0-tf1.15.5-1.3.0 ``` ## Setup Local Python
-Environment One can also set up local ModelScope environment using pip and
-conda. We suggest [anaconda](https://docs.anaconda.com/anaconda/install/) for
-creating local python environment: ```shell conda create -n modelscope
-python=3.7 conda activate modelscope ``` PyTorch or TensorFlow can be installed
-separately according to each model's requirements. * Install pytorch [doc]
-(https://pytorch.org/get-started/locally/) * Install tensorflow [doc](https://
-www.tensorflow.org/install/pip) After installing the necessary machine-learning
-framework, you can install modelscope library as follows: If you only want to
-play around with the modelscope framework, of trying out model/dataset
-download, you can install the core modelscope components: ```shell pip install
-modelscope ``` If you want to use multi-modal models: ```shell pip install
-modelscope[multi-modal] ``` If you want to use nlp models: ```shell pip install
-modelscope[nlp] -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/
-repo.html ``` If you want to use cv models: ```shell pip install modelscope[cv]
--f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html ``` If you
-want to use audio models: ```shell pip install modelscope[audio] -f https://
-modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html ``` If you want to
-use science models: ```shell pip install modelscope[science] -f https://
-modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html ``` `Notes`: 1.
-Currently, some audio-task models only support python3.7, tensorflow1.15.4
-Linux environments. Most other models can be installed and used on Windows and
-Mac (x86). 2. Some models in the audio field use the third-party library
-SoundFile for wav file processing. On the Linux system, users need to manually
-install libsndfile of SoundFile([doc link](https://github.com/bastibe/python-
+image ```shell # py37 registry.cn-hangzhou.aliyuncs.com/modelscope-repo/
+modelscope:ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.6.1 # py38 registry.cn-
+hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py38-torch1.11.0-
+tf1.15.5-1.6.1 ``` GPU docker image ```shell # py37 registry.cn-
+hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py37-
+torch1.11.0-tf1.15.5-1.6.1 # py38 registry.cn-hangzhou.aliyuncs.com/modelscope-
+repo/modelscope:ubuntu20.04-cuda11.3.0-py38-torch1.11.0-tf1.15.5-1.6.1 ``` ##
+Setup Local Python Environment One can also set up local ModelScope environment
+using pip and conda. We suggest [anaconda](https://docs.anaconda.com/anaconda/
+install/) for creating local python environment: ```shell conda create -
+n modelscope python=3.7 conda activate modelscope ``` PyTorch or TensorFlow can
+be installed separately according to each model's requirements. * Install
+pytorch [doc](https://pytorch.org/get-started/locally/) * Install tensorflow
+[doc](https://www.tensorflow.org/install/pip) After installing the necessary
+machine-learning framework, you can install modelscope library as follows: If
+you only want to play around with the modelscope framework, of trying out
+model/dataset download, you can install the core modelscope components:
+```shell pip install modelscope ``` If you want to use multi-modal models:
+```shell pip install modelscope[multi-modal] ``` If you want to use nlp models:
+```shell pip install modelscope[nlp] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` If you want to use cv models:
+```shell pip install modelscope[cv] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` If you want to use audio models:
+```shell pip install modelscope[audio] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` If you want to use science models:
+```shell pip install modelscope[science] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` `Notes`: 1. Currently, some audio-
+task models only support python3.7, tensorflow1.15.4 Linux environments. Most
+other models can be installed and used on Windows and Mac (x86). 2. Some models
+in the audio field use the third-party library SoundFile for wav file
+processing. On the Linux system, users need to manually install libsndfile of
+SoundFile([doc link](https://github.com/bastibe/python-
 soundfile#installation)). On Windows and MacOS, it will be installed
 automatically without user operation. For example, on Ubuntu, you can use
 following commands: ```shell sudo apt-get update sudo apt-get install
 libsndfile1 ``` 3. Some models in computer vision need mmcv-full, you can refer
 to mmcv [installation guide](https://github.com/open-mmlab/mmcv#installation),
 a minimal installation is as follows: ```shell pip uninstall mmcv # if you have
 installed mmcv, uninstall it pip install -U openmim mim install mmcv-full ``` #
```

### Comparing `modelscope-1.6.1/README.md` & `modelscope-1.7.0/README.md`

 * *Files 7% similar despite different names*

```diff
@@ -199,20 +199,28 @@
 
 ModelScope Library currently supports popular deep learning framework for model training and inference, including PyTorch, TensorFlow and ONNX. All releases are tested and run on Python 3.7+, Pytorch 1.8+, Tensorflow1.15 or Tensorflow2.0+.
 
 To allow out-of-box usage for all the models on ModelScope, official docker images are provided for all releases. Based on the docker image, developers can skip all environment installation and configuration and use it directly. Currently, the latest version of the CPU image and GPU image can be obtained from:
 
 CPU docker image
 ```shell
-registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.3.0
+# py37
+registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.6.1
+
+# py38
+registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py38-torch1.11.0-tf1.15.5-1.6.1
 ```
 
 GPU docker image
 ```shell
-registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py37-torch1.11.0-tf1.15.5-1.3.0
+# py37
+registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py37-torch1.11.0-tf1.15.5-1.6.1
+
+# py38
+registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py38-torch1.11.0-tf1.15.5-1.6.1
 ```
 
 ## Setup Local Python Environment
 
 One can also set up local ModelScope environment using pip and conda.  We suggest [anaconda](https://docs.anaconda.com/anaconda/install/) for creating local python environment:
 
 ```shell
```

#### html2text {}

```diff
@@ -150,42 +150,46 @@
 supports popular deep learning framework for model training and inference,
 including PyTorch, TensorFlow and ONNX. All releases are tested and run on
 Python 3.7+, Pytorch 1.8+, Tensorflow1.15 or Tensorflow2.0+. To allow out-of-
 box usage for all the models on ModelScope, official docker images are provided
 for all releases. Based on the docker image, developers can skip all
 environment installation and configuration and use it directly. Currently, the
 latest version of the CPU image and GPU image can be obtained from: CPU docker
-image ```shell registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:
-ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.3.0 ``` GPU docker image ```shell
-registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-
-cuda11.3.0-py37-torch1.11.0-tf1.15.5-1.3.0 ``` ## Setup Local Python
-Environment One can also set up local ModelScope environment using pip and
-conda. We suggest [anaconda](https://docs.anaconda.com/anaconda/install/) for
-creating local python environment: ```shell conda create -n modelscope
-python=3.7 conda activate modelscope ``` PyTorch or TensorFlow can be installed
-separately according to each model's requirements. * Install pytorch [doc]
-(https://pytorch.org/get-started/locally/) * Install tensorflow [doc](https://
-www.tensorflow.org/install/pip) After installing the necessary machine-learning
-framework, you can install modelscope library as follows: If you only want to
-play around with the modelscope framework, of trying out model/dataset
-download, you can install the core modelscope components: ```shell pip install
-modelscope ``` If you want to use multi-modal models: ```shell pip install
-modelscope[multi-modal] ``` If you want to use nlp models: ```shell pip install
-modelscope[nlp] -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/
-repo.html ``` If you want to use cv models: ```shell pip install modelscope[cv]
--f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html ``` If you
-want to use audio models: ```shell pip install modelscope[audio] -f https://
-modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html ``` If you want to
-use science models: ```shell pip install modelscope[science] -f https://
-modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html ``` `Notes`: 1.
-Currently, some audio-task models only support python3.7, tensorflow1.15.4
-Linux environments. Most other models can be installed and used on Windows and
-Mac (x86). 2. Some models in the audio field use the third-party library
-SoundFile for wav file processing. On the Linux system, users need to manually
-install libsndfile of SoundFile([doc link](https://github.com/bastibe/python-
+image ```shell # py37 registry.cn-hangzhou.aliyuncs.com/modelscope-repo/
+modelscope:ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.6.1 # py38 registry.cn-
+hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py38-torch1.11.0-
+tf1.15.5-1.6.1 ``` GPU docker image ```shell # py37 registry.cn-
+hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py37-
+torch1.11.0-tf1.15.5-1.6.1 # py38 registry.cn-hangzhou.aliyuncs.com/modelscope-
+repo/modelscope:ubuntu20.04-cuda11.3.0-py38-torch1.11.0-tf1.15.5-1.6.1 ``` ##
+Setup Local Python Environment One can also set up local ModelScope environment
+using pip and conda. We suggest [anaconda](https://docs.anaconda.com/anaconda/
+install/) for creating local python environment: ```shell conda create -
+n modelscope python=3.7 conda activate modelscope ``` PyTorch or TensorFlow can
+be installed separately according to each model's requirements. * Install
+pytorch [doc](https://pytorch.org/get-started/locally/) * Install tensorflow
+[doc](https://www.tensorflow.org/install/pip) After installing the necessary
+machine-learning framework, you can install modelscope library as follows: If
+you only want to play around with the modelscope framework, of trying out
+model/dataset download, you can install the core modelscope components:
+```shell pip install modelscope ``` If you want to use multi-modal models:
+```shell pip install modelscope[multi-modal] ``` If you want to use nlp models:
+```shell pip install modelscope[nlp] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` If you want to use cv models:
+```shell pip install modelscope[cv] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` If you want to use audio models:
+```shell pip install modelscope[audio] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` If you want to use science models:
+```shell pip install modelscope[science] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` `Notes`: 1. Currently, some audio-
+task models only support python3.7, tensorflow1.15.4 Linux environments. Most
+other models can be installed and used on Windows and Mac (x86). 2. Some models
+in the audio field use the third-party library SoundFile for wav file
+processing. On the Linux system, users need to manually install libsndfile of
+SoundFile([doc link](https://github.com/bastibe/python-
 soundfile#installation)). On Windows and MacOS, it will be installed
 automatically without user operation. For example, on Ubuntu, you can use
 following commands: ```shell sudo apt-get update sudo apt-get install
 libsndfile1 ``` 3. Some models in computer vision need mmcv-full, you can refer
 to mmcv [installation guide](https://github.com/open-mmlab/mmcv#installation),
 a minimal installation is as follows: ```shell pip uninstall mmcv # if you have
 installed mmcv, uninstall it pip install -U openmim mim install mmcv-full ``` #
```

### Comparing `modelscope-1.6.1/modelscope/__init__.py` & `modelscope-1.7.0/modelscope/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/cli/cli.py` & `modelscope-1.7.0/modelscope/cli/cli.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/cli/download.py` & `modelscope-1.7.0/modelscope/cli/download.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/cli/modelcard.py` & `modelscope-1.7.0/modelscope/cli/modelcard.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,16 +9,16 @@
 from modelscope.hub.api import HubApi
 from modelscope.hub.snapshot_download import snapshot_download
 from modelscope.hub.utils.utils import get_endpoint
 from modelscope.utils.logger import get_logger
 
 logger = get_logger()
 
-curren_path = os.path.dirname(os.path.abspath(__file__))
-template_path = os.path.join(curren_path, 'template')
+current_path = os.path.dirname(os.path.abspath(__file__))
+template_path = os.path.join(current_path, 'template')
 
 
 def subparser_func(args):
     """ Function which will be called for a specific sub parser.
     """
     return ModelCardCMD(args)
```

### Comparing `modelscope-1.6.1/modelscope/cli/pipeline.py` & `modelscope-1.7.0/modelscope/cli/pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 from string import Template
 
 from modelscope.cli.base import CLICommand
 from modelscope.utils.logger import get_logger
 
 logger = get_logger()
 
-curren_path = os.path.dirname(os.path.abspath(__file__))
-template_path = os.path.join(curren_path, 'template')
+current_path = os.path.dirname(os.path.abspath(__file__))
+template_path = os.path.join(current_path, 'template')
 
 
 def subparser_func(args):
     """ Function which will be called for a specific sub parser.
     """
     return PipelineCMD(args)
```

### Comparing `modelscope-1.6.1/modelscope/cli/plugins.py` & `modelscope-1.7.0/modelscope/cli/plugins.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/__init__.py` & `modelscope-1.7.0/modelscope/exporters/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -9,19 +9,21 @@
     from .builder import build_exporter
     from .cv import CartoonTranslationExporter
     from .nlp import CsanmtForTranslationExporter
     from .tf_model_exporter import TfModelExporter
     from .nlp import SbertForSequenceClassificationExporter, SbertForZeroShotClassificationExporter
     from .torch_model_exporter import TorchModelExporter
     from .cv import FaceDetectionSCRFDExporter
+    from .multi_modal import StableDiffuisonExporter
 else:
     _import_structure = {
         'base': ['Exporter'],
         'builder': ['build_exporter'],
         'cv': ['CartoonTranslationExporter', 'FaceDetectionSCRFDExporter'],
+        'multi_modal': ['StableDiffuisonExporter'],
         'nlp': [
             'CsanmtForTranslationExporter',
             'SbertForSequenceClassificationExporter',
             'SbertForZeroShotClassificationExporter'
         ],
         'tf_model_exporter': ['TfModelExporter'],
         'torch_model_exporter': ['TorchModelExporter'],
```

### Comparing `modelscope-1.6.1/modelscope/exporters/audio/ans_dfsmn_exporter.py` & `modelscope-1.7.0/modelscope/exporters/audio/ans_dfsmn_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/base.py` & `modelscope-1.7.0/modelscope/exporters/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/builder.py` & `modelscope-1.7.0/modelscope/exporters/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/cv/__init__.py` & `modelscope-1.7.0/modelscope/exporters/cv/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/cv/cartoon_translation_exporter.py` & `modelscope-1.7.0/modelscope/exporters/cv/cartoon_translation_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/cv/face_detection_scrfd_exporter.py` & `modelscope-1.7.0/modelscope/exporters/cv/face_detection_scrfd_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/cv/object_detection_damoyolo_exporter.py` & `modelscope-1.7.0/modelscope/exporters/cv/object_detection_damoyolo_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/nlp/__init__.py` & `modelscope-1.7.0/modelscope/exporters/nlp/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/nlp/csanmt_for_translation_exporter.py` & `modelscope-1.7.0/modelscope/exporters/nlp/csanmt_for_translation_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/nlp/model_for_token_classification_exporter.py` & `modelscope-1.7.0/modelscope/exporters/nlp/model_for_token_classification_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/nlp/sbert_for_sequence_classification_exporter.py` & `modelscope-1.7.0/modelscope/exporters/nlp/sbert_for_sequence_classification_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/nlp/sbert_for_zero_shot_classification_exporter.py` & `modelscope-1.7.0/modelscope/exporters/nlp/sbert_for_zero_shot_classification_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/tf_model_exporter.py` & `modelscope-1.7.0/modelscope/exporters/tf_model_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/exporters/torch_model_exporter.py` & `modelscope-1.7.0/modelscope/exporters/torch_model_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/fileio/file.py` & `modelscope-1.7.0/modelscope/fileio/file.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/fileio/format/json.py` & `modelscope-1.7.0/modelscope/fileio/format/json.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/fileio/format/jsonplus.py` & `modelscope-1.7.0/modelscope/fileio/format/jsonplus.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/fileio/format/yaml.py` & `modelscope-1.7.0/modelscope/fileio/format/yaml.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/fileio/io.py` & `modelscope-1.7.0/modelscope/fileio/io.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/hub/api.py` & `modelscope-1.7.0/modelscope/hub/api.py`

 * *Files 2% similar despite different names*

```diff
@@ -40,18 +40,19 @@
                                    handle_http_response, is_ok,
                                    raise_for_http_status, raise_on_error)
 from modelscope.hub.git import GitCommandWrapper
 from modelscope.hub.repository import Repository
 from modelscope.utils.constant import (DEFAULT_DATASET_REVISION,
                                        DEFAULT_MODEL_REVISION,
                                        DEFAULT_REPOSITORY_REVISION,
-                                       MASTER_MODEL_BRANCH, DatasetFormations,
-                                       DatasetMetaFormats,
+                                       MASTER_MODEL_BRANCH, META_FILES_FORMAT,
+                                       DatasetFormations, DatasetMetaFormats,
                                        DatasetVisibilityMap, DownloadChannel,
-                                       ModelFile, VirgoDatasetConfig)
+                                       DownloadMode, ModelFile,
+                                       VirgoDatasetConfig)
 from modelscope.utils.logger import get_logger
 from .utils.utils import (get_endpoint, get_release_datetime,
                           model_id_to_group_owner_name)
 
 logger = get_logger()
 
 
@@ -637,67 +638,76 @@
                     continue
                 with open(local_path, 'wb') as f:
                     f.write(r.content)
                 local_paths[extension].append(local_path)
 
         return local_paths, dataset_formation
 
-    def fetch_single_csv_script(self, script_url: str):
-        cookies = ModelScopeConfig.get_cookies()
-        resp = self.session.get(script_url, cookies=cookies, headers=self.headers)
-        if not resp or not resp.text:
-            raise 'The meta-csv file cannot be empty when the meta-args `big_data` is true.'
-        text_list = resp.text.strip().split('\n')
-        text_headers = text_list[0]
-        text_content = text_list[1:]
-
-        return text_headers, text_content
-
     @staticmethod
-    def fetch_csv_from_url(url, out_path, chunk_size=1000000):
-        from io import StringIO
+    def fetch_meta_files_from_url(url, out_path, chunk_size=1024, mode=DownloadMode.REUSE_DATASET_IF_EXISTS):
+        """
+        Fetch the meta-data files from the url, e.g. csv/jsonl files.
+        """
         import hashlib
+        import json
+        from tqdm import tqdm
         out_path = os.path.join(out_path, hashlib.md5(url.encode(encoding='UTF-8')).hexdigest())
+        if mode == DownloadMode.FORCE_REDOWNLOAD and os.path.exists(out_path):
+            os.remove(out_path)
         if os.path.exists(out_path):
+            logger.info(f'Reusing cached meta-data file: {out_path}')
             return out_path
         cookies = ModelScopeConfig.get_cookies()
 
         # Make the request and get the response content as TextIO
-        response = requests.get(url, cookies=cookies)
-        data = StringIO(response.text)
+        logger.info('Loading meta-data file ...')
+        response = requests.get(url, cookies=cookies, stream=True)
+        total_size = int(response.headers.get('content-length', 0))
+        progress = tqdm(total=total_size, dynamic_ncols=True)
+
+        def get_chunk(resp):
+            chunk_data = []
+            for data in resp.iter_lines():
+                data = data.decode('utf-8')
+                chunk_data.append(data)
+                if len(chunk_data) >= chunk_size:
+                    yield chunk_data
+                    chunk_data = []
+            yield chunk_data
 
-        # Use read_csv with the TextIO object
-        csv_file_reader = pd.read_csv(data, iterator=True, dtype=str, delimiter=None)
-
-        loop = True
         iter_num = 0
-        while loop:
-            try:
-                chunk = csv_file_reader.get_chunk(size=chunk_size)
-
-                if iter_num == 0:
-                    with_header = True
+        with open(out_path, 'a') as f:
+            for chunk in get_chunk(response):
+                progress.update(len(chunk))
+                if url.endswith('jsonl'):
+                    chunk = [json.loads(line) for line in chunk if line.strip()]
+                    if len(chunk) == 0:
+                        continue
+                    if iter_num == 0:
+                        with_header = True
+                    else:
+                        with_header = False
+                    chunk_df = pd.DataFrame(chunk)
+                    chunk_df.to_csv(f, index=False, header=with_header)
+                    iter_num += 1
                 else:
-                    with_header = False
-
-                chunk.to_csv(out_path, mode='a', index=False, header=with_header)
-                iter_num += 1
-            except StopIteration:
-                loop = False
-                logger.info('stop chunk iteration')
+                    # csv or others
+                    for line in chunk:
+                        f.write(line + '\n')
+        progress.close()
 
         return out_path
 
     def get_dataset_file_url(
             self,
             file_name: str,
             dataset_name: str,
             namespace: str,
             revision: Optional[str] = DEFAULT_DATASET_REVISION):
-        if file_name.endswith('.csv'):
+        if file_name and os.path.splitext(file_name)[-1] in META_FILES_FORMAT:
             file_name = f'{self.endpoint}/api/v1/datasets/{namespace}/{dataset_name}/repo?' \
                         f'Revision={revision}&FilePath={file_name}'
         return file_name
 
     def get_dataset_access_config(
             self,
             dataset_name: str,
```

### Comparing `modelscope-1.6.1/modelscope/hub/check_model.py` & `modelscope-1.7.0/modelscope/hub/check_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/hub/constants.py` & `modelscope-1.7.0/modelscope/hub/constants.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,26 +1,30 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
+import os
 from pathlib import Path
 
 MODELSCOPE_URL_SCHEME = 'http://'
 DEFAULT_MODELSCOPE_DOMAIN = 'www.modelscope.cn'
 DEFAULT_MODELSCOPE_DATA_ENDPOINT = MODELSCOPE_URL_SCHEME + DEFAULT_MODELSCOPE_DOMAIN
-
+MODELSCOPE_PARALLEL_DOWNLOAD_THRESHOLD_MB = int(
+    os.environ.get('MODELSCOPE_PARALLEL_DOWNLOAD_THRESHOLD_MB', 500))
+MODELSCOPE_DOWNLOAD_PARALLELS = int(
+    os.environ.get('MODELSCOPE_DOWNLOAD_PARALLELS', 4))
 DEFAULT_MODELSCOPE_GROUP = 'damo'
 MODEL_ID_SEPARATOR = '/'
 FILE_HASH = 'Sha256'
 LOGGER_NAME = 'ModelScopeHub'
 DEFAULT_CREDENTIALS_PATH = Path.home().joinpath('.modelscope', 'credentials')
 REQUESTS_API_HTTP_METHOD = ['get', 'head', 'post', 'put', 'patch', 'delete']
 API_HTTP_CLIENT_TIMEOUT = 60
 API_RESPONSE_FIELD_DATA = 'Data'
 API_FILE_DOWNLOAD_RETRY_TIMES = 5
 API_FILE_DOWNLOAD_TIMEOUT = 60 * 5
-API_FILE_DOWNLOAD_CHUNK_SIZE = 4096
+API_FILE_DOWNLOAD_CHUNK_SIZE = 1024 * 1024 * 16
 API_RESPONSE_FIELD_GIT_ACCESS_TOKEN = 'AccessToken'
 API_RESPONSE_FIELD_USERNAME = 'Username'
 API_RESPONSE_FIELD_EMAIL = 'Email'
 API_RESPONSE_FIELD_MESSAGE = 'Message'
 MODELSCOPE_CLOUD_ENVIRONMENT = 'MODELSCOPE_ENVIRONMENT'
 MODELSCOPE_CLOUD_USERNAME = 'MODELSCOPE_USERNAME'
 MODELSCOPE_SDK_DEBUG = 'MODELSCOPE_SDK_DEBUG'
```

### Comparing `modelscope-1.6.1/modelscope/hub/deploy.py` & `modelscope-1.7.0/modelscope/hub/deploy.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/hub/errors.py` & `modelscope-1.7.0/modelscope/hub/errors.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/hub/file_download.py` & `modelscope-1.7.0/modelscope/hub/file_download.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,25 +1,28 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
 import copy
 import os
 import tempfile
+import threading
+from concurrent.futures import ThreadPoolExecutor
 from functools import partial
 from http.cookiejar import CookieJar
 from pathlib import Path
 from typing import Dict, Optional, Union
 
 import requests
 from requests.adapters import Retry
 from tqdm import tqdm
 
 from modelscope.hub.api import HubApi, ModelScopeConfig
-from modelscope.hub.constants import (API_FILE_DOWNLOAD_CHUNK_SIZE,
-                                      API_FILE_DOWNLOAD_RETRY_TIMES,
-                                      API_FILE_DOWNLOAD_TIMEOUT, FILE_HASH)
+from modelscope.hub.constants import (
+    API_FILE_DOWNLOAD_CHUNK_SIZE, API_FILE_DOWNLOAD_RETRY_TIMES,
+    API_FILE_DOWNLOAD_TIMEOUT, FILE_HASH, MODELSCOPE_DOWNLOAD_PARALLELS,
+    MODELSCOPE_PARALLEL_DOWNLOAD_THRESHOLD_MB)
 from modelscope.utils.constant import DEFAULT_MODEL_REVISION
 from modelscope.utils.logger import get_logger
 from .errors import FileDownloadError, NotExistError
 from .utils.caching import ModelFileSystemCache
 from .utils.utils import (file_integrity_validation, get_cache_dir,
                           get_endpoint, model_id_to_group_owner_name)
 
@@ -130,27 +133,33 @@
 
     if file_to_download_info is None:
         raise NotExistError('The file path: %s not exist in: %s' %
                             (file_path, model_id))
 
     # we need to download again
     url_to_download = get_file_download_url(model_id, file_path, revision)
-    file_to_download_info = {
-        'Path': file_path,
-        'Revision': file_to_download_info['Revision'],
-        FILE_HASH: file_to_download_info[FILE_HASH]
-    }
-
     temp_file_name = next(tempfile._get_candidate_names())
-    http_get_file(
-        url_to_download,
-        temporary_cache_dir,
-        temp_file_name,
-        headers=headers,
-        cookies=None if cookies is None else cookies.get_dict())
+
+    if MODELSCOPE_PARALLEL_DOWNLOAD_THRESHOLD_MB * 1000 * 1000 < file_to_download_info[
+            'Size'] and MODELSCOPE_DOWNLOAD_PARALLELS > 1:
+        parallel_download(
+            url_to_download,
+            temporary_cache_dir,
+            temp_file_name,
+            headers=headers,
+            cookies=None if cookies is None else cookies.get_dict(),
+            file_size=file_to_download_info['Size'])
+    else:
+        http_get_file(
+            url_to_download,
+            temporary_cache_dir,
+            temp_file_name,
+            headers=headers,
+            cookies=None if cookies is None else cookies.get_dict())
+
     temp_file_path = os.path.join(temporary_cache_dir, temp_file_name)
     # for download with commit we can't get Sha256
     if file_to_download_info[FILE_HASH] is not None:
         file_integrity_validation(temp_file_path,
                                   file_to_download_info[FILE_HASH])
     return cache.put_file(file_to_download_info,
                           os.path.join(temporary_cache_dir, temp_file_name))
@@ -174,14 +183,74 @@
         endpoint=get_endpoint(),
         model_id=model_id,
         revision=revision,
         file_path=file_path,
     )
 
 
+def download_part(params):
+    # unpack parameters
+    progress, start, end, url, file_name, cookies, headers = params
+    get_headers = {} if headers is None else copy.deepcopy(headers)
+    get_headers['Range'] = 'bytes=%s-%s' % (start, end)
+    with open(file_name, 'rb+') as f:
+        f.seek(start)
+        r = requests.get(
+            url,
+            stream=True,
+            headers=get_headers,
+            cookies=cookies,
+            timeout=API_FILE_DOWNLOAD_TIMEOUT)
+        for chunk in r.iter_content(chunk_size=API_FILE_DOWNLOAD_CHUNK_SIZE):
+            if chunk:  # filter out keep-alive new chunks
+                f.write(chunk)
+                progress.update(len(chunk))
+
+
+def parallel_download(
+    url: str,
+    local_dir: str,
+    file_name: str,
+    cookies: CookieJar,
+    headers: Optional[Dict[str, str]] = None,
+    file_size: int = None,
+):
+    # create temp file
+    temp_file_manager = partial(
+        tempfile.NamedTemporaryFile, mode='wb', dir=local_dir, delete=False)
+    with temp_file_manager() as temp_file:
+        progress = tqdm(
+            unit='B',
+            unit_scale=True,
+            unit_divisor=1024,
+            total=file_size,
+            initial=0,
+            desc='Downloading',
+        )
+        PART_SIZE = 160 * 1024 * 1012  # every part is 160M
+        tasks = []
+        for idx in range(int(file_size / PART_SIZE)):
+            start = idx * PART_SIZE
+            end = (idx + 1) * PART_SIZE - 1
+            tasks.append(
+                (progress, start, end, url, temp_file.name, cookies, headers))
+        if end + 1 < file_size:
+            tasks.append((progress, end + 1, file_size - 1, url,
+                          temp_file.name, cookies, headers))
+        parallels = MODELSCOPE_DOWNLOAD_PARALLELS if MODELSCOPE_DOWNLOAD_PARALLELS <= 4 else 4
+        with ThreadPoolExecutor(
+                max_workers=parallels,
+                thread_name_prefix='download') as executor:
+            list(executor.map(download_part, tasks))
+
+        progress.close()
+
+    os.replace(temp_file.name, os.path.join(local_dir, file_name))
+
+
 def http_get_file(
     url: str,
     local_dir: str,
     file_name: str,
     cookies: CookieJar,
     headers: Optional[Dict[str, str]] = None,
 ):
```

### Comparing `modelscope-1.6.1/modelscope/hub/git.py` & `modelscope-1.7.0/modelscope/hub/git.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/hub/push_to_hub.py` & `modelscope-1.7.0/modelscope/hub/push_to_hub.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/hub/repository.py` & `modelscope-1.7.0/modelscope/hub/repository.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/hub/snapshot_download.py` & `modelscope-1.7.0/modelscope/hub/snapshot_download.py`

 * *Files 7% similar despite different names*

```diff
@@ -6,16 +6,18 @@
 from http.cookiejar import CookieJar
 from pathlib import Path
 from typing import Dict, List, Optional, Union
 
 from modelscope.hub.api import HubApi, ModelScopeConfig
 from modelscope.utils.constant import DEFAULT_MODEL_REVISION
 from modelscope.utils.logger import get_logger
-from .constants import FILE_HASH
-from .file_download import get_file_download_url, http_get_file
+from .constants import (FILE_HASH, MODELSCOPE_DOWNLOAD_PARALLELS,
+                        MODELSCOPE_PARALLEL_DOWNLOAD_THRESHOLD_MB)
+from .file_download import (get_file_download_url, http_get_file,
+                            parallel_download)
 from .utils.caching import ModelFileSystemCache
 from .utils.utils import (file_integrity_validation, get_cache_dir,
                           model_id_to_group_owner_name)
 
 logger = get_logger()
 
 
@@ -129,21 +131,32 @@
 
                 # get download url
                 url = get_file_download_url(
                     model_id=model_id,
                     file_path=model_file['Path'],
                     revision=revision)
 
-                # First download to /tmp
-                http_get_file(
-                    url=url,
-                    local_dir=temp_cache_dir,
-                    file_name=model_file['Name'],
-                    headers=headers,
-                    cookies=cookies)
+                if MODELSCOPE_PARALLEL_DOWNLOAD_THRESHOLD_MB * 1000 * 1000 < model_file[
+                        'Size'] and MODELSCOPE_DOWNLOAD_PARALLELS > 1:
+                    parallel_download(
+                        url,
+                        temp_cache_dir,
+                        model_file['Name'],
+                        headers=headers,
+                        cookies=None
+                        if cookies is None else cookies.get_dict(),
+                        file_size=model_file['Size'])
+                else:
+                    http_get_file(
+                        url,
+                        temp_cache_dir,
+                        model_file['Name'],
+                        headers=headers,
+                        cookies=cookies)
+
                 # check file integrity
                 temp_file = os.path.join(temp_cache_dir, model_file['Name'])
                 if FILE_HASH in model_file:
                     file_integrity_validation(temp_file, model_file[FILE_HASH])
                 # put file to cache
                 cache.put_file(model_file, temp_file)
```

### Comparing `modelscope-1.6.1/modelscope/hub/utils/caching.py` & `modelscope-1.7.0/modelscope/hub/utils/caching.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/hub/utils/utils.py` & `modelscope-1.7.0/modelscope/hub/utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metainfo.py` & `modelscope-1.7.0/modelscope/metainfo.py`

 * *Files 1% similar despite different names*

```diff
@@ -161,14 +161,16 @@
     lstm = 'lstm'
     xlm_roberta = 'xlm-roberta'
     transformers = 'transformers'
     plug_mental = 'plug-mental'
     doc2bot = 'doc2bot'
     peer = 'peer'
     llama = 'llama'
+    chatglm_6b = 'chatglm6b'
+    chatglm2_6b = 'chatglm2-6b'
 
     # audio models
     sambert_hifigan = 'sambert-hifigan'
     speech_frcrn_ans_cirm_16k = 'speech_frcrn_ans_cirm_16k'
     speech_dfsmn_ans = 'speech_dfsmn_ans'
     speech_dfsmn_kws_char_farfield = 'speech_dfsmn_kws_char_farfield'
     speech_dfsmn_kws_char_farfield_iot = 'speech_dfsmn_kws_char_farfield_iot'
@@ -179,15 +181,17 @@
     wenet_asr = 'wenet-asr'
     generic_itn = 'generic-itn'
     generic_punc = 'generic-punc'
     generic_sv = 'generic-sv'
     ecapa_tdnn_sv = 'ecapa-tdnn-sv'
     campplus_sv = 'cam++-sv'
     eres2net_sv = 'eres2net-sv'
+    eres2net_aug_sv = 'eres2net-aug-sv'
     scl_sd = 'scl-sd'
+    cluster_backend = 'cluster-backend'
     rdino_tdnn_sv = 'rdino_ecapa-tdnn-sv'
     generic_lm = 'generic-lm'
 
     # multi-modal models
     ofa = 'ofa'
     clip = 'clip-multi-modal-embedding'
     gemm = 'gemm-generative-multi-modal'
@@ -201,14 +205,15 @@
     mgeo = 'mgeo'
     vldoc = 'vldoc'
     hitea = 'hitea'
     soonet = 'soonet'
     efficient_diffusion_tuning = 'efficient-diffusion-tuning'
     mplug_owl = 'mplug-owl'
     clip_interrogator = 'clip-interrogator'
+    stable_diffusion = 'stable-diffusion'
 
     # science models
     unifold = 'unifold'
     unifold_symmetry = 'unifold-symmetry'
 
 
 class TaskModels(object):
@@ -482,14 +487,15 @@
     sv_inference = 'sv-inference'
     speaker_diarization_inference = 'speaker-diarization-inference'
     vad_inference = 'vad-inference'
     speaker_verification = 'speaker-verification'
     speaker_verification_rdino = 'speaker-verification-rdino'
     speaker_verification_eres2net = 'speaker-verification-eres2net'
     speaker_change_locating = 'speaker-change-locating'
+    segmentation_clustering = 'segmentation-clustering'
     lm_inference = 'language-score-prediction'
     speech_timestamp_inference = 'speech-timestamp-inference'
 
     # multi-modal tasks
     image_captioning = 'image-captioning'
     multi_modal_embedding = 'multi-modal-embedding'
     generative_multi_modal_embedding = 'generative-multi-modal-embedding'
@@ -888,14 +894,17 @@
 
 class MultiModalTrainers(object):
     clip_multi_modal_embedding = 'clip-multi-modal-embedding'
     ofa = 'ofa'
     mplug = 'mplug'
     mgeo_ranking_trainer = 'mgeo-ranking-trainer'
     efficient_diffusion_tuning = 'efficient-diffusion-tuning'
+    stable_diffusion = 'stable-diffusion'
+    lora_diffusion = 'lora-diffusion'
+    dreambooth_diffusion = 'dreambooth-diffusion'
 
 
 class AudioTrainers(object):
     speech_frcrn_ans_cirm_16k = 'speech_frcrn_ans_cirm_16k'
     speech_dfsmn_kws_char_farfield = 'speech_dfsmn_kws_char_farfield'
     speech_kws_fsmn_char_ctc_nearfield = 'speech_kws_fsmn_char_ctc_nearfield'
     speech_kantts_trainer = 'speech-kantts-trainer'
```

### Comparing `modelscope-1.6.1/modelscope/metrics/__init__.py` & `modelscope-1.7.0/modelscope/metrics/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/accuracy_metric.py` & `modelscope-1.7.0/modelscope/metrics/accuracy_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/action_detection_evaluator.py` & `modelscope-1.7.0/modelscope/metrics/action_detection_evaluator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/audio_noise_metric.py` & `modelscope-1.7.0/modelscope/metrics/audio_noise_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/base.py` & `modelscope-1.7.0/modelscope/metrics/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/bleu_metric.py` & `modelscope-1.7.0/modelscope/metrics/bleu_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/builder.py` & `modelscope-1.7.0/modelscope/metrics/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/ciderD/ciderD.py` & `modelscope-1.7.0/modelscope/metrics/ciderD/ciderD.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/ciderD/ciderD_scorer.py` & `modelscope-1.7.0/modelscope/metrics/ciderD/ciderD_scorer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/image_color_enhance_metric.py` & `modelscope-1.7.0/modelscope/metrics/image_color_enhance_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/image_colorization_metric.py` & `modelscope-1.7.0/modelscope/metrics/image_colorization_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/image_denoise_metric.py` & `modelscope-1.7.0/modelscope/metrics/image_denoise_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/image_inpainting_metric.py` & `modelscope-1.7.0/modelscope/metrics/image_inpainting_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/image_instance_segmentation_metric.py` & `modelscope-1.7.0/modelscope/metrics/image_instance_segmentation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/image_portrait_enhancement_metric.py` & `modelscope-1.7.0/modelscope/metrics/image_portrait_enhancement_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/image_quality_assessment_degradation_metric.py` & `modelscope-1.7.0/modelscope/metrics/image_quality_assessment_degradation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/image_quality_assessment_mos_metric.py` & `modelscope-1.7.0/modelscope/metrics/image_quality_assessment_mos_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/inbatch_recall_metric.py` & `modelscope-1.7.0/modelscope/metrics/inbatch_recall_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/loss_metric.py` & `modelscope-1.7.0/modelscope/metrics/loss_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/map_metric.py` & `modelscope-1.7.0/modelscope/metrics/map_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/movie_scene_segmentation_metric.py` & `modelscope-1.7.0/modelscope/metrics/movie_scene_segmentation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/ned_metric.py` & `modelscope-1.7.0/modelscope/metrics/ned_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/ocr_recognition_metric.py` & `modelscope-1.7.0/modelscope/metrics/ocr_recognition_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/ppl_metric.py` & `modelscope-1.7.0/modelscope/metrics/ppl_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/prediction_saving_wrapper.py` & `modelscope-1.7.0/modelscope/metrics/prediction_saving_wrapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/referring_video_object_segmentation_metric.py` & `modelscope-1.7.0/modelscope/metrics/referring_video_object_segmentation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/sequence_classification_metric.py` & `modelscope-1.7.0/modelscope/metrics/sequence_classification_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/text_generation_metric.py` & `modelscope-1.7.0/modelscope/metrics/text_generation_metric.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,12 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
-from typing import Dict, Iterable, List
+import sys
+from contextlib import contextmanager
+from typing import Dict, Iterable, List, Tuple
 
 from nltk.translate.bleu_score import SmoothingFunction, corpus_bleu
 from rouge import Rouge
 
 from modelscope.metainfo import Metrics
 from modelscope.metrics.base import Metric
 from modelscope.metrics.builder import METRICS, MetricKeys
@@ -51,15 +53,16 @@
         tmp = [(pred, tgt) for pred, tgt in zip(self.preds, self.tgts)
                if self._check(pred, tgt)]
         preds, tgts = zip(*tmp)
 
         def mean(iter: Iterable) -> float:
             return sum(iter) / len(self.preds)
 
-        rouge_scores = self.rouge.get_scores(hyps=preds, refs=tgts)
+        with extend_recursion_limit(preds, tgts):
+            rouge_scores = self.rouge.get_scores(hyps=preds, refs=tgts)
         rouge_1 = mean(map(lambda score: score['rouge-1']['f'], rouge_scores))
         rouge_l = mean(map(lambda score: score['rouge-l']['f'], rouge_scores))
 
         pred_list = [each.strip().split(' ') for each in self.preds]
         tgt_list = [[each.strip().split(' ')] for each in self.tgts]
         bleu_1 = corpus_bleu(
             tgt_list,
@@ -83,7 +86,18 @@
 
     def __getstate__(self):
         return self.preds, self.tgts
 
     def __setstate__(self, state):
         self.__init__()
         self.preds, self.tgts = state
+
+
+@contextmanager
+def extend_recursion_limit(preds: Tuple[str], tgts: Tuple[str]):
+    origin_limit = sys.getrecursionlimit()
+    new_limit = max(len(pred)
+                    for pred in preds) * max(len(tgt) for tgt in tgts)
+    if new_limit > origin_limit:
+        sys.setrecursionlimit(new_limit)
+    yield
+    sys.setrecursionlimit(origin_limit)
```

### Comparing `modelscope-1.6.1/modelscope/metrics/text_ranking_metric.py` & `modelscope-1.7.0/modelscope/metrics/text_ranking_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/token_classification_metric.py` & `modelscope-1.7.0/modelscope/metrics/token_classification_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/translation_evaluation_metric.py` & `modelscope-1.7.0/modelscope/metrics/translation_evaluation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/video_frame_interpolation_metric.py` & `modelscope-1.7.0/modelscope/metrics/video_frame_interpolation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/video_stabilization_metric.py` & `modelscope-1.7.0/modelscope/metrics/video_stabilization_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/video_summarization_metric.py` & `modelscope-1.7.0/modelscope/metrics/video_summarization_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/video_super_resolution_metric/matlab_functions.py` & `modelscope-1.7.0/modelscope/metrics/video_super_resolution_metric/matlab_functions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/video_super_resolution_metric/metric_util.py` & `modelscope-1.7.0/modelscope/metrics/video_super_resolution_metric/metric_util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/video_super_resolution_metric/niqe.py` & `modelscope-1.7.0/modelscope/metrics/video_super_resolution_metric/niqe.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/metrics/video_super_resolution_metric/video_super_resolution_metric.py` & `modelscope-1.7.0/modelscope/metrics/video_super_resolution_metric/video_super_resolution_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/__init__.py` & `modelscope-1.7.0/modelscope/models/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/aec/layers/activations.py` & `modelscope-1.7.0/modelscope/models/audio/aec/layers/activations.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/aec/layers/affine_transform.py` & `modelscope-1.7.0/modelscope/models/audio/aec/layers/affine_transform.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/aec/layers/deep_fsmn.py` & `modelscope-1.7.0/modelscope/models/audio/aec/layers/deep_fsmn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/aec/layers/layer_base.py` & `modelscope-1.7.0/modelscope/models/audio/aec/layers/layer_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/aec/layers/uni_deep_fsmn.py` & `modelscope-1.7.0/modelscope/models/audio/aec/layers/uni_deep_fsmn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/aec/network/loss.py` & `modelscope-1.7.0/modelscope/models/audio/aec/network/loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/aec/network/modulation_loss.py` & `modelscope-1.7.0/modelscope/models/audio/aec/network/modulation_loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/aec/network/se_net.py` & `modelscope-1.7.0/modelscope/models/audio/aec/network/se_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/__init__.py` & `modelscope-1.7.0/modelscope/models/audio/ans/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/complex_nn.py` & `modelscope-1.7.0/modelscope/models/audio/ans/complex_nn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/conv_stft.py` & `modelscope-1.7.0/modelscope/models/audio/ans/conv_stft.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/denoise_net.py` & `modelscope-1.7.0/modelscope/models/audio/ans/denoise_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/frcrn.py` & `modelscope-1.7.0/modelscope/models/audio/ans/frcrn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/layers/activations.py` & `modelscope-1.7.0/modelscope/models/audio/ans/layers/activations.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/layers/affine_transform.py` & `modelscope-1.7.0/modelscope/models/audio/ans/layers/affine_transform.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/layers/layer_base.py` & `modelscope-1.7.0/modelscope/models/audio/ans/layers/layer_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/layers/uni_deep_fsmn.py` & `modelscope-1.7.0/modelscope/models/audio/ans/layers/uni_deep_fsmn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/se_module_complex.py` & `modelscope-1.7.0/modelscope/models/audio/ans/se_module_complex.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/ans/unet.py` & `modelscope-1.7.0/modelscope/models/audio/ans/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/asr/__init__.py` & `modelscope-1.7.0/modelscope/models/audio/asr/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/asr/generic_automatic_speech_recognition.py` & `modelscope-1.7.0/modelscope/models/audio/asr/generic_automatic_speech_recognition.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/asr/wenet_automatic_speech_recognition.py` & `modelscope-1.7.0/modelscope/models/audio/asr/wenet_automatic_speech_recognition.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/itn/__init__.py` & `modelscope-1.7.0/modelscope/models/audio/itn/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/itn/generic_inverse_text_processing.py` & `modelscope-1.7.0/modelscope/models/audio/itn/generic_inverse_text_processing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/kws/__init__.py` & `modelscope-1.7.0/modelscope/models/audio/kws/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/kws/farfield/fsmn.py` & `modelscope-1.7.0/modelscope/models/audio/kws/farfield/fsmn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/kws/farfield/fsmn_sele_v2.py` & `modelscope-1.7.0/modelscope/models/audio/kws/farfield/fsmn_sele_v2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/kws/farfield/fsmn_sele_v3.py` & `modelscope-1.7.0/modelscope/models/audio/kws/farfield/fsmn_sele_v3.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/kws/farfield/model.py` & `modelscope-1.7.0/modelscope/models/audio/kws/farfield/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/kws/farfield/model_def.py` & `modelscope-1.7.0/modelscope/models/audio/kws/farfield/model_def.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/kws/generic_key_word_spotting.py` & `modelscope-1.7.0/modelscope/models/audio/kws/generic_key_word_spotting.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/kws/nearfield/cmvn.py` & `modelscope-1.7.0/modelscope/models/audio/kws/nearfield/cmvn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/kws/nearfield/fsmn.py` & `modelscope-1.7.0/modelscope/models/audio/kws/nearfield/fsmn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/kws/nearfield/model.py` & `modelscope-1.7.0/modelscope/models/audio/kws/nearfield/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/punc/generic_punctuation.py` & `modelscope-1.7.0/modelscope/models/audio/punc/generic_punctuation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/separation/layer_norm.py` & `modelscope-1.7.0/modelscope/models/audio/separation/layer_norm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/separation/mossformer.py` & `modelscope-1.7.0/modelscope/models/audio/separation/mossformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/separation/mossformer_block.py` & `modelscope-1.7.0/modelscope/models/audio/separation/mossformer_block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/separation/mossformer_conv_module.py` & `modelscope-1.7.0/modelscope/models/audio/separation/mossformer_conv_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/sv/DTDNN.py` & `modelscope-1.7.0/modelscope/models/audio/sv/DTDNN.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,26 +1,28 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
 import os
 from collections import OrderedDict
 from typing import Any, Dict, Union
 
+import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torchaudio.compliance.kaldi as Kaldi
 
 from modelscope.metainfo import Models
 from modelscope.models import MODELS, TorchModel
 from modelscope.models.audio.sv.DTDNN_layers import (BasicResBlock,
                                                      CAMDenseTDNNBlock,
                                                      DenseLayer, StatsPool,
                                                      TDNNLayer, TransitLayer,
                                                      get_nonlinear)
 from modelscope.utils.constant import Tasks
+from modelscope.utils.device import create_device
 
 
 class FCM(nn.Module):
 
     def __init__(self,
                  block=BasicResBlock,
                  num_blocks=[2, 2],
@@ -158,38 +160,45 @@
                  **kwargs):
         super().__init__(model_dir, model_config, *args, **kwargs)
         self.model_config = model_config
         self.other_config = kwargs
 
         self.feature_dim = self.model_config['fbank_dim']
         self.emb_size = self.model_config['emb_size']
+        self.device = create_device(self.other_config['device'])
 
         self.embedding_model = CAMPPlus(self.feature_dim, self.emb_size)
-
         pretrained_model_name = kwargs['pretrained_model']
         self.__load_check_point(pretrained_model_name)
 
+        self.embedding_model.to(self.device)
         self.embedding_model.eval()
 
     def forward(self, audio):
-        assert len(audio.shape) == 2 and audio.shape[
-            0] == 1, 'modelscope error: the shape of input audio to model needs to be [1, T]'
-        # audio shape: [1, T]
+        if isinstance(audio, np.ndarray):
+            audio = torch.from_numpy(audio)
+        if len(audio.shape) == 1:
+            audio = audio.unsqueeze(0)
+        assert len(
+            audio.shape
+        ) == 2, 'modelscope error: the shape of input audio to model needs to be [N, T]'
+        # audio shape: [N, T]
         feature = self.__extract_feature(audio)
-        embedding = self.embedding_model(feature)
-
-        return embedding
+        embedding = self.embedding_model(feature.to(self.device))
+        return embedding.detach().cpu()
 
     def __extract_feature(self, audio):
-        feature = Kaldi.fbank(audio, num_mel_bins=self.feature_dim)
-        feature = feature - feature.mean(dim=0, keepdim=True)
-        feature = feature.unsqueeze(0)
-        return feature
-
-    def __load_check_point(self, pretrained_model_name, device=None):
-        if not device:
-            device = torch.device('cpu')
+        features = []
+        for au in audio:
+            feature = Kaldi.fbank(
+                au.unsqueeze(0), num_mel_bins=self.feature_dim)
+            feature = feature - feature.mean(dim=0, keepdim=True)
+            features.append(feature.unsqueeze(0))
+        features = torch.cat(features)
+        return features
+
+    def __load_check_point(self, pretrained_model_name):
         self.embedding_model.load_state_dict(
             torch.load(
                 os.path.join(self.model_dir, pretrained_model_name),
-                map_location=device),
+                map_location=torch.device('cpu')),
             strict=True)
```

### Comparing `modelscope-1.6.1/modelscope/models/audio/sv/DTDNN_layers.py` & `modelscope-1.7.0/modelscope/models/audio/sv/DTDNN_layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/sv/ERes2Net.py` & `modelscope-1.7.0/modelscope/models/audio/sv/ERes2Net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/sv/ecapa_tdnn.py` & `modelscope-1.7.0/modelscope/models/audio/sv/ecapa_tdnn.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,22 +1,24 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 """ This ECAPA-TDNN implementation is adapted from https://github.com/speechbrain/speechbrain.
 """
 import math
 import os
 from typing import Any, Dict, Union
 
+import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torchaudio.compliance.kaldi as Kaldi
 
 from modelscope.metainfo import Models
 from modelscope.models import MODELS, TorchModel
 from modelscope.utils.constant import Tasks
+from modelscope.utils.device import create_device
 
 
 def length_to_mask(length, max_len=None, dtype=None, device=None):
     assert len(length.shape) == 1
 
     if max_len is None:
         max_len = length.max().long().item()
@@ -466,39 +468,48 @@
         if self.model_config['channel'] != 1024:
             raise ValueError(
                 'modelscope error: Currently only 1024-channel ecapa tdnn is supported.'
             )
 
         self.feature_dim = 80
         channels_config = [1024, 1024, 1024, 1024, 3072]
+        self.device = create_device(self.other_config['device'])
+        print(self.device)
 
         self.embedding_model = ECAPA_TDNN(
             self.feature_dim, channels=channels_config)
-
         pretrained_model_name = kwargs['pretrained_model']
         self.__load_check_point(pretrained_model_name)
 
+        self.embedding_model.to(self.device)
         self.embedding_model.eval()
 
     def forward(self, audio):
-        assert len(audio.shape) == 2 and audio.shape[
-            0] == 1, 'modelscope error: the shape of input audio to model needs to be [1, T]'
-        # audio shape: [1, T]
+        if isinstance(audio, np.ndarray):
+            audio = torch.from_numpy(audio)
+        if len(audio.shape) == 1:
+            audio = audio.unsqueeze(0)
+        assert len(
+            audio.shape
+        ) == 2, 'modelscope error: the shape of input audio to model needs to be [N, T]'
+        # audio shape: [N, T]
         feature = self.__extract_feature(audio)
-        embedding = self.embedding_model(feature)
+        embedding = self.embedding_model(feature.to(self.device))
 
-        return embedding
+        return embedding.detach().cpu()
 
     def __extract_feature(self, audio):
-        feature = Kaldi.fbank(audio, num_mel_bins=self.feature_dim)
-        feature = feature - feature.mean(dim=0, keepdim=True)
-        feature = feature.unsqueeze(0)
-        return feature
-
-    def __load_check_point(self, pretrained_model_name, device=None):
-        if not device:
-            device = torch.device('cpu')
+        features = []
+        for au in audio:
+            feature = Kaldi.fbank(
+                au.unsqueeze(0), num_mel_bins=self.feature_dim)
+            feature = feature - feature.mean(dim=0, keepdim=True)
+            features.append(feature.unsqueeze(0))
+        features = torch.cat(features)
+        return features
+
+    def __load_check_point(self, pretrained_model_name):
         self.embedding_model.load_state_dict(
             torch.load(
                 os.path.join(self.model_dir, pretrained_model_name),
-                map_location=device),
+                map_location=torch.device('cpu')),
             strict=True)
```

### Comparing `modelscope-1.6.1/modelscope/models/audio/sv/fusion.py` & `modelscope-1.7.0/modelscope/models/audio/sv/fusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/sv/generic_speaker_verification.py` & `modelscope-1.7.0/modelscope/models/audio/sv/generic_speaker_verification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/sv/pooling_layers.py` & `modelscope-1.7.0/modelscope/models/audio/sv/pooling_layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/sv/rdino.py` & `modelscope-1.7.0/modelscope/models/audio/sv/rdino.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/sv/speaker_change_locator.py` & `modelscope-1.7.0/modelscope/models/audio/sv/speaker_change_locator.py`

 * *Files 4% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 import torch.nn.functional as F
 import torchaudio.compliance.kaldi as Kaldi
 
 from modelscope.metainfo import Models
 from modelscope.models import MODELS, TorchModel
 from modelscope.models.audio.sv.DTDNN import CAMPPlus
 from modelscope.utils.constant import Tasks
+from modelscope.utils.device import create_device
 
 
 class MultiHeadSelfAttention(nn.Module):
 
     def __init__(self, n_units, h=8, dropout=0.1):
         super(MultiHeadSelfAttention, self).__init__()
         self.linearQ = nn.Linear(n_units, n_units)
@@ -79,14 +80,15 @@
     def forward(self, input_len):
         max_len = torch.max(input_len)
         input_pos = torch.LongTensor([
             list(range(1, len + 1)) + [0] * (max_len - len)
             for len in input_len
         ])
 
+        input_pos = input_pos.to(list(self.pos_enc.parameters())[0].device)
         return self.pos_enc(input_pos)
 
 
 class TransformerEncoder(nn.Module):
 
     def __init__(self,
                  idim,
@@ -261,59 +263,65 @@
                  **kwargs):
         super().__init__(model_dir, model_config, *args, **kwargs)
         self.model_config = model_config
 
         self.feature_dim = self.model_config['fbank_dim']
         frame_size = self.model_config['frame_size']
         anchor_size = self.model_config['anchor_size']
+        self.device = create_device(kwargs['device'])
 
         self.encoder = CAMPPlus(self.feature_dim, output_level='frame')
         self.backend = TransformerDetector(
             frame_dim=frame_size, anchor_dim=anchor_size)
 
         pretrained_encoder = kwargs['pretrained_encoder']
         pretrained_backend = kwargs['pretrained_backend']
 
         self.__load_check_point(pretrained_encoder, pretrained_backend)
 
+        self.encoder.to(self.device)
+        self.backend.to(self.device)
         self.encoder.eval()
         self.backend.eval()
 
     def forward(self, audio, anchors):
+        if isinstance(audio, np.ndarray):
+            audio = torch.from_numpy(audio)
+        if isinstance(anchors, np.ndarray):
+            anchors = torch.from_numpy(anchors)
         assert len(audio.shape) == 2 and audio.shape[
             0] == 1, 'modelscope error: the shape of input audio to model needs to be [1, T]'
         assert len(
             anchors.shape
         ) == 3 and anchors.shape[0] == 1 and anchors.shape[
             1] == 2, 'modelscope error: the shape of input anchors to model needs to be [1, 2, D]'
         # audio shape: [1, T]
         feature = self.__extract_feature(audio)
-        frame_state = self.encoder(feature)
-        output = self.backend(frame_state, anchors)
+        frame_state = self.encoder(feature.to(self.device))
+        output = self.backend(frame_state, anchors.to(self.device))
         output = output.squeeze(0).detach().cpu().sigmoid()
 
         time_scale_factor = int(np.ceil(feature.shape[1] / output.shape[0]))
         output = output.unsqueeze(1).expand(-1, time_scale_factor,
                                             -1).reshape(-1, output.shape[-1])
         return output
 
     def __extract_feature(self, audio):
         feature = Kaldi.fbank(audio, num_mel_bins=self.feature_dim)
         feature = feature - feature.mean(dim=0, keepdim=True)
         feature = feature.unsqueeze(0)
         return feature
 
-    def __load_check_point(self,
-                           pretrained_encoder,
-                           pretrained_backend,
-                           device=None):
-        if not device:
-            device = torch.device('cpu')
+    def __load_check_point(
+        self,
+        pretrained_encoder,
+        pretrained_backend,
+    ):
         self.encoder.load_state_dict(
             torch.load(
                 os.path.join(self.model_dir, pretrained_encoder),
-                map_location=device))
+                map_location=torch.device('cpu')))
 
         self.backend.load_state_dict(
             torch.load(
                 os.path.join(self.model_dir, pretrained_backend),
-                map_location=device))
+                map_location=torch.device('cpu')))
```

### Comparing `modelscope-1.6.1/modelscope/models/audio/tts/sambert_hifi.py` & `modelscope-1.7.0/modelscope/models/audio/tts/sambert_hifi.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/audio/tts/voice.py` & `modelscope-1.7.0/modelscope/models/audio/tts/voice.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/base/base_head.py` & `modelscope-1.7.0/modelscope/models/base/base_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/base/base_model.py` & `modelscope-1.7.0/modelscope/models/base/base_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/base/base_torch_head.py` & `modelscope-1.7.0/modelscope/models/base/base_torch_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/base/base_torch_model.py` & `modelscope-1.7.0/modelscope/models/base/base_torch_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/builder.py` & `modelscope-1.7.0/modelscope/models/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_model.py` & `modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py` & `modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py` & `modelscope-1.7.0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/action_detection/action_detection_onnx.py` & `modelscope-1.7.0/modelscope/models/cv/action_detection/action_detection_onnx.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/action_detection/modules/action_detection_pytorch.py` & `modelscope-1.7.0/modelscope/models/cv/action_detection/modules/action_detection_pytorch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/action_detection/modules/resnet.py` & `modelscope-1.7.0/modelscope/models/cv/action_detection/modules/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/action_recognition/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/action_recognition/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/action_recognition/models.py` & `modelscope-1.7.0/modelscope/models/cv/action_recognition/models.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/action_recognition/s3dg.py` & `modelscope-1.7.0/modelscope/models/cv/action_recognition/s3dg.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/action_recognition/tada_convnext.py` & `modelscope-1.7.0/modelscope/models/cv/action_recognition/tada_convnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/action_recognition/temporal_patch_shift_transformer.py` & `modelscope-1.7.0/modelscope/models/cv/action_recognition/temporal_patch_shift_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/animal_recognition/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/animal_recognition/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/animal_recognition/resnet.py` & `modelscope-1.7.0/modelscope/models/cv/animal_recognition/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/animal_recognition/splat.py` & `modelscope-1.7.0/modelscope/models/cv/animal_recognition/splat.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/bad_image_detecting/bad_image_detecting.py` & `modelscope-1.7.0/modelscope/models/cv/bad_image_detecting/bad_image_detecting.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_2d_keypoints/hrnet_basic_modules.py` & `modelscope-1.7.0/modelscope/models/cv/body_2d_keypoints/hrnet_basic_modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_2d_keypoints/hrnet_v2.py` & `modelscope-1.7.0/modelscope/models/cv/body_2d_keypoints/hrnet_v2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_2d_keypoints/w48.py` & `modelscope-1.7.0/modelscope/models/cv/body_2d_keypoints/w48.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py` & `modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py` & `modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/backbone.py` & `modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/block.py` & `modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/directed_graph.py` & `modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/directed_graph.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer.py` & `modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py` & `modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/body_3d_keypoints/hdformer/skeleton.py` & `modelscope-1.7.0/modelscope/models/cv/body_3d_keypoints/hdformer/skeleton.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/LK/lk.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/LK/lk.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/config.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/face_detector.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/face_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/face_landmark.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/face_landmark.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/facelib/facer.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/facelib/facer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/loss.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/model_tf.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/model_tf.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/network.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/network.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cartoon/utils.py` & `modelscope-1.7.0/modelscope/models/cv/cartoon/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cmdssl_video_embedding/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/cmdssl_video_embedding/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cmdssl_video_embedding/c3d.py` & `modelscope-1.7.0/modelscope/models/cv/cmdssl_video_embedding/c3d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cmdssl_video_embedding/resnet2p1d.py` & `modelscope-1.7.0/modelscope/models/cv/cmdssl_video_embedding/resnet2p1d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/cmdssl_video_embedding/resnet3d.py` & `modelscope-1.7.0/modelscope/models/cv/cmdssl_video_embedding/resnet3d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/annotator.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/annotator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/api.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/api.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/vit.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/vit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/midas/utils.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/midas/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/utils.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/body.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/openpose/body.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/hand.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/openpose/hand.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/model.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/openpose/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/util.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/annotator/openpose/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/controllable_image_generation/controlnet.py` & `modelscope-1.7.0/modelscope/models/cv/controllable_image_generation/controlnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/crowd_counting/cc_model.py` & `modelscope-1.7.0/modelscope/models/cv/crowd_counting/cc_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/crowd_counting/hrnet_aspp_relu.py` & `modelscope-1.7.0/modelscope/models/cv/crowd_counting/hrnet_aspp_relu.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py` & `modelscope-1.7.0/modelscope/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/detectors.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/detectors.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/mogface.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/mogface.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/mogprednet.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/mogprednet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/resnet.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/mogface/models/utils.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/mogface/models/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/models/box_utils.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/models/box_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/models/detector.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/models/detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/models/first_stage.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/models/first_stage.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/mtcnn/models/get_nets.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/mtcnn/models/get_nets.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/LK/lk.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/LK/lk.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/face_detector.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/face_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/face_landmark.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/face_landmark.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/peppa_pig_face/facer.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/peppa_pig_face/facer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/detection.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/detection.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/models/net.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/models/net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/models/retinaface.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/models/retinaface.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/retinaface/utils.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/retinaface/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/damofd_detect.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/damofd_detect.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py`

 * *Files 4% similar despite different names*

```diff
@@ -50,15 +50,15 @@
             kps = multi_kps[:, None].expand(
                 multi_scores.size(0), num_classes, num_kps * 2)
 
     scores = multi_scores[:, :-1]
     if score_factors is not None:
         scores = scores * score_factors[:, None]
 
-    labels = torch.arange(num_classes, dtype=torch.long)
+    labels = torch.arange(num_classes, dtype=torch.long, device=scores.device)
     labels = labels.view(1, -1).expand_as(scores)
 
     bboxes = bboxes.reshape(-1, 4)
     if kps is not None:
         kps = kps.reshape(-1, num_kps * 2)
     scores = scores.reshape(-1)
     labels = labels.reshape(-1)
```

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/preprocessor.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/scrfd_detect.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/scrfd_detect.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/scrfd/tinymog_detect.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/scrfd/tinymog_detect.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/detection.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/detection.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/box_utils.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/box_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_detection/ulfd_slim/vision/transforms.py` & `modelscope-1.7.0/modelscope/models/cv/face_detection/ulfd_slim/vision/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_emotion/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/face_emotion/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_emotion/efficient/model.py` & `modelscope-1.7.0/modelscope/models/cv/face_emotion/efficient/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_emotion/efficient/utils.py` & `modelscope-1.7.0/modelscope/models/cv/face_emotion/efficient/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_emotion/emotion_infer.py` & `modelscope-1.7.0/modelscope/models/cv/face_emotion/emotion_infer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_emotion/emotion_model.py` & `modelscope-1.7.0/modelscope/models/cv/face_emotion/emotion_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_emotion/face_alignment/face.py` & `modelscope-1.7.0/modelscope/models/cv/face_emotion/face_alignment/face.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_emotion/face_alignment/face_align.py` & `modelscope-1.7.0/modelscope/models/cv/face_emotion/face_alignment/face_align.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_generation/op/conv2d_gradfix.py` & `modelscope-1.7.0/modelscope/models/cv/face_generation/op/conv2d_gradfix.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_generation/op/fused_act.py` & `modelscope-1.7.0/modelscope/models/cv/face_generation/op/fused_act.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_generation/op/upfirdn2d.py` & `modelscope-1.7.0/modelscope/models/cv/face_generation/op/upfirdn2d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_generation/stylegan2.py` & `modelscope-1.7.0/modelscope/models/cv/face_generation/stylegan2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/det_infer.py` & `modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/det_infer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/ghost_pan.py` & `modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/ghost_pan.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/nanodet_plus_head.py` & `modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/nanodet_plus_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/one_stage_detector.py` & `modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/one_stage_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/shufflenetv2.py` & `modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/shufflenetv2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_human_hand_detection/utils.py` & `modelscope-1.7.0/modelscope/models/cv/face_human_hand_detection/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_recognition/align_face.py` & `modelscope-1.7.0/modelscope/models/cv/face_recognition/align_face.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py` & `modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/common.py` & `modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py` & `modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/model_irse.py` & `modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/model_irse.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/backbone/model_resnet.py` & `modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/backbone/model_resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_recognition/torchkit/rts_backbone.py` & `modelscope-1.7.0/modelscope/models/cv/face_recognition/torchkit/rts_backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/bfm.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/bfm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/de_retouching_module.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/de_retouching_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/facerecon_model.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/facerecon_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/losses.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/losses.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/networks.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/networks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/nv_diffrast.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/nv_diffrast.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/pix2pix/networks.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/pix2pix/networks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/renderer.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/renderer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/models/unet.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/models/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/face_reconstruction/utils.py` & `modelscope-1.7.0/modelscope/models/cv/face_reconstruction/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py` & `modelscope-1.7.0/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/facial_expression_recognition/fer/transforms.py` & `modelscope-1.7.0/modelscope/models/cv/facial_expression_recognition/fer/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/facial_expression_recognition/fer/vgg.py` & `modelscope-1.7.0/modelscope/models/cv/facial_expression_recognition/fer/vgg.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py` & `modelscope-1.7.0/modelscope/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py` & `modelscope-1.7.0/modelscope/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/hand_static/hand_model.py` & `modelscope-1.7.0/modelscope/models/cv/hand_static/hand_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/hand_static/networks.py` & `modelscope-1.7.0/modelscope/models/cv/hand_static/networks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/human_reconstruction/Reconstruction.py` & `modelscope-1.7.0/modelscope/models/cv/human_reconstruction/Reconstruction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/Embedding.py` & `modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/Embedding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/PixToMesh.py` & `modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/PixToMesh.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/Res_backbone.py` & `modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/Res_backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/Surface_head.py` & `modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/Surface_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/detectors.py` & `modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/detectors.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/geometry.py` & `modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/geometry.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/human_segmenter.py` & `modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/human_segmenter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/human_reconstruction/models/networks.py` & `modelscope-1.7.0/modelscope/models/cv/human_reconstruction/models/networks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/human_reconstruction/utils.py` & `modelscope-1.7.0/modelscope/models/cv/human_reconstruction/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_binary_quant_classification/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_binary_quant_classification/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_binary_quant_classification/binary_quant_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_binary_quant_classification/binary_quant_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_binary_quant_classification/bnext.py` & `modelscope-1.7.0/modelscope/models/cv/image_binary_quant_classification/bnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/image_body_reshaping.py` & `modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/image_body_reshaping.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/model.py` & `modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/person_info.py` & `modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/person_info.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/pose_estimator/body.py` & `modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/pose_estimator/body.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/pose_estimator/model.py` & `modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/pose_estimator/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/pose_estimator/util.py` & `modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/pose_estimator/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_body_reshaping/slim_utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_body_reshaping/slim_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_classification/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_classification/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_classification/backbones/beit_v2.py` & `modelscope-1.7.0/modelscope/models/cv/image_classification/backbones/beit_v2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_classification/backbones/nextvit.py` & `modelscope-1.7.0/modelscope/models/cv/image_classification/backbones/nextvit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_classification/mmcls_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_classification/mmcls_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_classification/resnet50_cc.py` & `modelscope-1.7.0/modelscope/models/cv/image_classification/resnet50_cc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_classification/utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_classification/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_color_enhance/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_color_enhance/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_color_enhance/adaint/adaint.py` & `modelscope-1.7.0/modelscope/models/cv/image_color_enhance/adaint/adaint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_color_enhance/csrnet.py` & `modelscope-1.7.0/modelscope/models/cv/image_color_enhance/csrnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py` & `modelscope-1.7.0/modelscope/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_color_enhance/deeplpf/deeplpfnet.py` & `modelscope-1.7.0/modelscope/models/cv/image_color_enhance/deeplpf/deeplpfnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_color_enhance/image_color_enhance.py` & `modelscope-1.7.0/modelscope/models/cv/image_color_enhance/image_color_enhance.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/ddcolor.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/ddcolor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/loss.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/convnext.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/convnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/position_encoding.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/position_encoding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/transformer_utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/transformer_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/unet.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/ddcolor/utils/vgg.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/ddcolor/utils/vgg.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/unet/unet.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/unet/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_colorization/unet/utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_colorization/unet/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_debanding/rrdb/rrdb_image_debanding.py` & `modelscope-1.7.0/modelscope/models/cv/image_debanding/rrdb/rrdb_image_debanding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_deblur/nafnet_for_image_deblur.py` & `modelscope-1.7.0/modelscope/models/cv/image_deblur/nafnet_for_image_deblur.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/evaluator.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/evaluation/evaluator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/calibration_layer.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/calibration_layer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/defrcn.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/defrcn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/fast_rcnn.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/fast_rcnn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/gdl.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/gdl.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/resnet.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/models/roi_heads.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/models/roi_heads.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/coco_register.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/coco_register.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/register_data.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/register_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/requirements_check.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/requirements_check.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_defrcn_fewshot/utils/voc_register.py` & `modelscope-1.7.0/modelscope/models/cv/image_defrcn_fewshot/utils/voc_register.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_denoise/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_denoise/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_denoise/nafnet/NAFNet_arch.py` & `modelscope-1.7.0/modelscope/models/cv/image_denoise/nafnet/NAFNet_arch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_denoise/nafnet/arch_util.py` & `modelscope-1.7.0/modelscope/models/cv/image_denoise/nafnet/arch_util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_denoise/nafnet_for_image_denoise.py` & `modelscope-1.7.0/modelscope/models/cv/image_denoise/nafnet_for_image_denoise.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_depth.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/newcrf_depth.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_layers.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/newcrf_layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/newcrf_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/swin_transformer.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/networks/uper_crf_head.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/networks/uper_crf_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation/newcrfs_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation/newcrfs_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/networks/bts_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/networks/bts_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/networks/decoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/networks/decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/networks/encoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/networks/encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_depth_estimation_bts/networks/utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_depth_estimation_bts/networks/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_driving_perception/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_driving_perception/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_driving_perception/image_driving_percetion_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_driving_perception/image_driving_percetion_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_driving_perception/preprocessor.py` & `modelscope-1.7.0/modelscope/models/cv/image_driving_perception/preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_driving_perception/utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_driving_perception/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/gan_wrap.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/gan_wrap.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/model.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/op/fused_act.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/op/fused_act.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facegan/op/upfirdn2d.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facegan/op/upfirdn2d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facelib/align_trans.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facelib/align_trans.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/facelib/matlab_cp2tform.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/facelib/matlab_cp2tform.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/image_face_fusion.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/image_face_fusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/aad_layer.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/aad_layer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/aei_flow_net.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/aei_flow_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/bfm.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/bfm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/dense_motion.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/dense_motion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/facerecon_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/facerecon_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/model_irse.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/model_irse.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_face_fusion/network/ops.py` & `modelscope-1.7.0/modelscope/models/cv/image_face_fusion/network/ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_human_parsing/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_human_parsing/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_human_parsing/backbone/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_human_parsing/backbone/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_human_parsing/backbone/deeplab_resnet.py` & `modelscope-1.7.0/modelscope/models/cv/image_human_parsing/backbone/deeplab_resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_human_parsing/m2fp/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_human_parsing/m2fp/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_human_parsing/m2fp/m2fp_decoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_human_parsing/m2fp/m2fp_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_human_parsing/m2fp/m2fp_encoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_human_parsing/m2fp/m2fp_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_human_parsing/m2fp_net.py` & `modelscope-1.7.0/modelscope/models/cv/image_human_parsing/m2fp_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_human_parsing/parsing_utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_human_parsing/parsing_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 def center_to_target_size_test(img, target_size):
     src_h, src_w = img.shape[0], img.shape[1]
     trg_h, trg_w = target_size[1], target_size[0]
 
     new_h, new_w = 0, 0
     tfm_list = []
     if src_h > trg_h and src_w > trg_w:
-        if src_h > src_w:
+        if src_h >= src_w:
             new_h = trg_h
             new_w = int(new_h * src_w / src_h)
             if new_w > trg_w:
                 new_w = trg_w
                 new_h = int(new_w * src_h / src_w)
         elif src_w > src_h:
             new_w = trg_w
```

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/base.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/default.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/default.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/model.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/ade20k/base.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/ade20k/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/ade20k/resnet.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/ade20k/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/adversarial.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/adversarial.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/feature_matching.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/feature_matching.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/ffc.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/ffc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/inception.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/inception.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/perceptual.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/perceptual.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/modules/pix2pixhd.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/modules/pix2pixhd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_inpainting/refinement.py` & `modelscope-1.7.0/modelscope/models/cv/image_inpainting/refinement.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/backbones/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/backbones/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/backbones/resnet.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/backbones/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/backbones/swin_transformer.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/backbones/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/datasets/transforms.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/datasets/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/fastinst_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/fastinst_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/dino_decoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/dino_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/position_encoding.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/position_encoding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino/utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/maskdino_swin.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/maskdino_swin.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/model.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_instance_segmentation/postprocess_utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_instance_segmentation/postprocess_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/config/default.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/config/default.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/backbone/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/backbone/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_matching/quadtree_attention_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_matching/quadtree_attention_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/cas_mvsnet.py` & `modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/cas_mvsnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/casmvs_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/casmvs_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py` & `modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/depth_filter.py` & `modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/depth_filter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/general_eval_dataset.py` & `modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/general_eval_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/module.py` & `modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_mvs_depth_estimation/utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_mvs_depth_estimation/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_paintbyexample/model.py` & `modelscope-1.7.0/modelscope/models/cv/image_paintbyexample/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_panoptic_segmentation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_panoptic_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_panoptic_segmentation/panseg_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_panoptic_segmentation/panseg_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/align_faces.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/align_faces.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/eqface/fqa.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/eqface/fqa.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/eqface/model_resnet.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/eqface/model_resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/gpen.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/gpen.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/image_portrait_enhancement.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/image_portrait_enhancement.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/losses/helpers.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/losses/helpers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/losses/losses.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/losses/losses.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/losses/model_irse.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/losses/model_irse.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/detection.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/detection.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/net.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_portrait_enhancement/retinaface/utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_portrait_enhancement/retinaface/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_probing_model/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_probing_model/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_probing_model/backbone.py` & `modelscope-1.7.0/modelscope/models/cv/image_probing_model/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_probing_model/model.py` & `modelscope-1.7.0/modelscope/models/cv/image_probing_model/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_probing_model/utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_probing_model/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_degradation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_degradation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_degradation/degradation_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_degradation/degradation_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_man/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_man/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_man/image_quality_assessment_man.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_man/image_quality_assessment_man.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_man/maniqa.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_man/maniqa.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_man/swin.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_man/swin.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/backbones/resnet.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/backbones/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/heads/simple_head.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/heads/simple_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py` & `modelscope-1.7.0/modelscope/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_reid_person/pass_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_reid_person/pass_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_reid_person/transreid_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_reid_person/transreid_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_restoration/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_restoration/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_restoration/demoire_models/nets.py` & `modelscope-1.7.0/modelscope/models/cv/image_restoration/demoire_models/nets.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_restoration/image_restoration_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_restoration/image_restoration_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/semantic_seg_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/semantic_seg_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py` & `modelscope-1.7.0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_skychange/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_skychange/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_skychange/preprocessor.py` & `modelscope-1.7.0/modelscope/models/cv/image_skychange/preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_skychange/ptsemseg/BlockModules.py` & `modelscope-1.7.0/modelscope/models/cv/image_skychange/ptsemseg/BlockModules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_skychange/ptsemseg/hrnet_backnone.py` & `modelscope-1.7.0/modelscope/models/cv/image_skychange/ptsemseg/hrnet_backnone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py` & `modelscope-1.7.0/modelscope/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_skychange/ptsemseg/unet.py` & `modelscope-1.7.0/modelscope/models/cv/image_skychange/ptsemseg/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_skychange/skychange.py` & `modelscope-1.7.0/modelscope/models/cv/image_skychange/skychange.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_skychange/skychange_model.py` & `modelscope-1.7.0/modelscope/models/cv/image_skychange/skychange_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/data/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/data/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/data/transforms.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/data/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/model.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/models/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/models/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/models/autoencoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/models/autoencoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/models/clip.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/models/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/ops/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/ops/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/ops/diffusion.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/ops/diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_generation/ops/losses.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_generation/ops/losses.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/data/transforms.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/data/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/model_translation.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/model_translation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/models/autoencoder.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/models/autoencoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/models/clip.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/models/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/apps.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/apps.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/degradation.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/degradation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/diffusion.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/losses.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/losses.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/metrics.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/metrics.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/random_color.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/random_color.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/random_mask.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/random_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/svd.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/svd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/image_to_image_translation/ops/utils.py` & `modelscope-1.7.0/modelscope/models/cv/image_to_image_translation/ops/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py` & `modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py` & `modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/fourier.py` & `modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/misc/fourier.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/panostretch.py` & `modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/misc/panostretch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/post_proc.py` & `modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/misc/post_proc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/modality/layout.py` & `modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/modality/layout.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/panovit.py` & `modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/panovit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/networks/utils.py` & `modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/networks/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/indoor_layout_estimation/panovit.py` & `modelscope-1.7.0/modelscope/models/cv/indoor_layout_estimation/panovit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/summarizer.py` & `modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/summarizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/transformer/layers.py` & `modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/transformer/layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/transformer/models.py` & `modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/transformer/models.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/transformer/modules.py` & `modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/transformer/modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/language_guided_video_summarization/transformer/sub_layers.py` & `modelscope-1.7.0/modelscope/models/cv/language_guided_video_summarization/transformer/sub_layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/motion_generation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/motion_generation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/motion_generation/model.py` & `modelscope-1.7.0/modelscope/models/cv/motion_generation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/cfg_sampler.py` & `modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/cfg_sampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/gaussian_diffusion.py` & `modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/gaussian_diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/mdm.py` & `modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/mdm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/respace.py` & `modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/respace.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/rotation2xyz.py` & `modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/rotation2xyz.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/motion_generation/modules/smpl.py` & `modelscope-1.7.0/modelscope/models/cv/motion_generation/modules/smpl.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/get_model.py` & `modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/get_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/model.py` & `modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/utils/head.py` & `modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/utils/head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/utils/save_op.py` & `modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/utils/save_op.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/utils/shot_encoder.py` & `modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/utils/shot_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/movie_scene_segmentation/utils/trn.py` & `modelscope-1.7.0/modelscope/models/cv/movie_scene_segmentation/utils/trn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py` & `modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/dataloader/read_write_model.py` & `modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/dataloader/read_write_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/nerf_preprocess.py` & `modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/nerf_preprocess.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/nerf_recon_acc.py` & `modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/nerf_recon_acc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/network/nerf.py` & `modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/network/nerf.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/network/segmenter.py` & `modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/network/segmenter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/nerf_recon_acc/network/utils.py` & `modelscope-1.7.0/modelscope/models/cv/nerf_recon_acc/network/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_model.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/backbones/vit.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/backbones/vit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/necks/fpn.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/necks/fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/utils/checkpoint.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/utils/checkpoint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/depe_detect.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/depe_detect.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/object_detection_3d/depe/result_vis.py` & `modelscope-1.7.0/modelscope/models/cv/object_detection_3d/depe/result_vis.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_detection/model.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_detection/model.py`

 * *Files 3% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 
 from modelscope.metainfo import Models
 from modelscope.models.base.base_torch_model import TorchModel
 from modelscope.models.builder import MODELS
 from modelscope.utils.config import Config
 from modelscope.utils.constant import ModelFile, Tasks
 from modelscope.utils.logger import get_logger
-from .modules.dbnet import DBModel, VLPTModel
+from .modules.dbnet import DBModel, DBNasModel, VLPTModel
 from .utils import boxes_from_bitmap, polygons_from_bitmap
 
 LOGGER = get_logger()
 
 
 @MODELS.register_module(Tasks.ocr_detection, module_name=Models.ocr_detection)
 class OCRDetection(TorchModel):
@@ -36,14 +36,16 @@
         self.return_polygon = cfgs.model.inference_kwargs.return_polygon
         self.backbone = cfgs.model.backbone
         self.detector = None
         if self.backbone == 'resnet50':
             self.detector = VLPTModel()
         elif self.backbone == 'resnet18':
             self.detector = DBModel()
+        elif self.backbone == 'proxylessnas':
+            self.detector = DBNasModel()
         else:
             raise TypeError(
                 f'detector backbone should be either resnet18, resnet50, but got {cfgs.model.backbone}'
             )
         if model_path != '':
             self.detector.load_state_dict(
                 torch.load(model_path, map_location='cpu'), strict=False)
```

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_detection/modules/dbnet.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/model_vlpt.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # ------------------------------------------------------------------------------
 # Part of implementation is adopted from ViLT,
 # made publicly available under the Apache License 2.0 at https://github.com/dandelin/ViLT.
 # ------------------------------------------------------------------------------
+
 import math
 import os
 import sys
-from collections import OrderedDict
 
 import torch
 import torch.nn as nn
 
 BatchNorm2d = nn.BatchNorm2d
 
 
@@ -409,120 +409,35 @@
         p3 = self.out3(out3)
         p2 = self.out2(out2)
 
         fuse = torch.cat((p5, p4, p3, p2), 1)
         # this is the pred module, not binarization module;
         # We do not correct the name due to the trained model.
         binary = self.binarize(fuse)
-        if self.training:
-            result = OrderedDict(binary=binary)
-        else:
-            return binary
-        if self.adaptive and self.training:
-            if self.serial:
-                fuse = torch.cat(
-                    (fuse, nn.functional.interpolate(binary, fuse.shape[2:])),
-                    1)
-            thresh = self.thresh(fuse)
-            thresh_binary = self.step_function(binary, thresh)
-            result.update(thresh=thresh, thresh_binary=thresh_binary)
-        return result
+        return binary
 
     def step_function(self, x, y):
         return torch.reciprocal(1 + torch.exp(-self.k * (x - y)))
 
 
-class BasicModel(nn.Module):
-
-    def __init__(self, *args, **kwargs):
-        nn.Module.__init__(self)
-
-        self.backbone = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
-        self.decoder = SegDetector(
-            in_channels=[64, 128, 256, 512], adaptive=True, k=50, **kwargs)
-
-    def forward(self, data, *args, **kwargs):
-        return self.decoder(self.backbone(data), *args, **kwargs)
-
-
-def parallelize(model, distributed, local_rank):
-    if distributed:
-        return nn.parallel.DistributedDataParallel(
-            model,
-            device_ids=[local_rank],
-            output_device=[local_rank],
-            find_unused_parameters=True)
-    else:
-        return nn.DataParallel(model)
-
-
 class VLPTModel(nn.Module):
 
     def __init__(self, *args, **kwargs):
-        """
-        VLPT-STD pretrained DBNet-resnet50 model,
-        paper reference: https://arxiv.org/pdf/2204.13867.pdf
-        """
         super(VLPTModel, self).__init__()
         self.backbone = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
         self.decoder = SegDetector(
             in_channels=[256, 512, 1024, 2048], adaptive=True, k=50, **kwargs)
 
     def forward(self, x):
         return self.decoder(self.backbone(x))
 
 
 class DBModel(nn.Module):
 
     def __init__(self, *args, **kwargs):
-        """
-        DBNet-resnet18 model without deformable conv,
-        paper reference: https://arxiv.org/pdf/1911.08947.pdf
-        """
         super(DBModel, self).__init__()
         self.backbone = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
         self.decoder = SegDetector(
             in_channels=[64, 128, 256, 512], adaptive=True, k=50, **kwargs)
 
     def forward(self, x):
         return self.decoder(self.backbone(x))
-
-
-class DBModel_v2(nn.Module):
-
-    def __init__(self,
-                 device,
-                 distributed: bool = False,
-                 local_rank: int = 0,
-                 *args,
-                 **kwargs):
-        """
-        DBNet-resnet18 model without deformable conv,
-        paper reference: https://arxiv.org/pdf/1911.08947.pdf
-        """
-        super(DBModel_v2, self).__init__()
-        from .seg_detector_loss import L1BalanceCELoss
-
-        self.model = BasicModel(*args, **kwargs)
-        self.model = parallelize(self.model, distributed, local_rank)
-        self.criterion = L1BalanceCELoss()
-        self.criterion = parallelize(self.criterion, distributed, local_rank)
-        self.device = device
-        self.to(self.device)
-
-    def forward(self, batch, training=False):
-        if isinstance(batch, dict):
-            data = batch['image'].to(self.device)
-        else:
-            data = batch.to(self.device)
-        data = data.float()
-        pred = self.model(data, training=self.training)
-
-        if self.training:
-            for key, value in batch.items():
-                if value is not None:
-                    if hasattr(value, 'to'):
-                        batch[key] = value.to(self.device)
-            loss_with_metrics = self.criterion(pred, batch)
-            loss, metrics = loss_with_metrics
-            return loss, pred, metrics
-        return pred
```

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_detection/modules/seg_detector_loss.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_detection/modules/seg_detector_loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_detection/preprocessor.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_detection/preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_detection/utils.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_detection/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_recognition/model.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_recognition/model.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,16 +6,17 @@
 
 from modelscope.metainfo import Models
 from modelscope.models.base.base_torch_model import TorchModel
 from modelscope.models.builder import MODELS
 from modelscope.utils.config import Config
 from modelscope.utils.constant import ModelFile, Tasks
 from modelscope.utils.logger import get_logger
-from .modules.convnextvit import ConvNextViT
-from .modules.crnn import CRNN
+from .modules.ConvNextViT.main_model import ConvNextViT
+from .modules.CRNN.main_model import CRNN
+from .modules.LightweightEdge.main_model import LightweightEdge
 
 LOGGER = get_logger()
 
 
 def flatten_label(target):
     label_flatten = []
     label_length = []
@@ -81,24 +82,26 @@
         self.target_height = cfgs.model.inference_kwargs.img_height
         self.target_width = cfgs.model.inference_kwargs.img_width
         self.recognizer = None
         if cfgs.model.recognizer == 'ConvNextViT':
             self.recognizer = ConvNextViT()
         elif cfgs.model.recognizer == 'CRNN':
             self.recognizer = CRNN()
+        elif cfgs.model.recognizer == 'LightweightEdge':
+            self.recognizer = LightweightEdge()
         else:
             raise TypeError(
                 f'recognizer should be either ConvNextViT, CRNN, but got {cfgs.model.recognizer}'
             )
         if model_path != '':
             params_pretrained = torch.load(model_path, map_location='cpu')
             model_dict = self.recognizer.state_dict()
             # remove prefix for finetuned models
             check_point = {
-                k.replace('recognizer.', ''): v
+                k.replace('recognizer.', '').replace('module.', ''): v
                 for k, v in params_pretrained.items()
             }
             model_dict.update(check_point)
             self.recognizer.load_state_dict(model_dict)
 
         dict_path = os.path.join(model_dir, ModelFile.VOCAB_FILE)
         self.labelMapping = dict()
@@ -130,17 +133,17 @@
         return self.recognizer(inputs)
 
     def do_step(self, batch):
         inputs = batch['images']
         labels = batch['labels']
         bs = inputs.shape[0]
         if self.do_chunking:
-            inputs = inputs.view(bs * 3, 1, self.target_height, 300)
+            inputs = inputs.view(bs * 3, 3, self.target_height, 300)
         else:
-            inputs = inputs.view(bs, 1, self.target_height, self.target_width)
+            inputs = inputs.view(bs, 3, self.target_height, self.target_width)
         output = self(inputs)
         probs = output['probs'].permute(1, 0, 2)
         _, label_length, label_flatten = self.encdec.encode(labels)
         probs_sizes = torch.IntTensor([probs.size(0)] * probs.size(1))
         loss = self.criterion_CTC(
             probs.log_softmax(2), label_flatten, probs_sizes, label_length)
         output = dict(loss=loss, preds=output['preds'])
```

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/convnext.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/convnextvit.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py`

 * *Files 17% similar despite different names*

```diff
@@ -10,11 +10,15 @@
 
     def __init__(self):
         super(ConvNextViT, self).__init__()
         self.cnn_model = convnext_tiny()
         self.vitstr = vitstr_tiny(num_tokens=7644)
 
     def forward(self, input):
-        """ Transformation stage """
+        # RGB2GRAY
+        input = input[:, 0:
+                      1, :, :] * 0.2989 + input[:, 1:
+                                                2, :, :] * 0.5870 + input[:, 2:
+                                                                          3, :, :] * 0.1140
         features = self.cnn_model(input)
         output = self.vitstr(features)
         return output
```

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/crnn.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/CRNN/main_model.py`

 * *Files 12% similar despite different names*

```diff
@@ -75,14 +75,19 @@
 
         self.rnn = nn.Sequential(
             BidirectionalLSTM(512, 256, 256), BidirectionalLSTM(256, 256, 512))
 
         self.cls = nn.Linear(512, 7644, bias=False)
 
     def forward(self, input):
+        # RGB2GRAY
+        input = input[:, 0:
+                      1, :, :] * 0.2989 + input[:, 1:
+                                                2, :, :] * 0.5870 + input[:, 2:
+                                                                          3, :, :] * 0.1140
         feats = self.conv0(input)
         feats = self.p0(feats)
         feats = self.conv1(feats)
         feats = self.p1(feats)
         feats = self.conv2(feats)
         feats = self.p2(feats)
         feats = self.conv3(feats)
```

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/timm_tinyc.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_recognition/modules/vitstr.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/ocr_recognition/preprocessor.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_recognition/preprocessor.py`

 * *Files 14% similar despite different names*

```diff
@@ -27,30 +27,28 @@
         """
         super().__init__(mode)
         cfgs = Config.from_file(
             os.path.join(model_dir, ModelFile.CONFIGURATION))
         self.do_chunking = cfgs.model.inference_kwargs.do_chunking
         self.target_height = cfgs.model.inference_kwargs.img_height
         self.target_width = cfgs.model.inference_kwargs.img_width
-        if self.do_chunking:
-            self.target_width = 804
 
     def keepratio_resize(self, img):
         cur_ratio = img.shape[1] / float(img.shape[0])
         mask_height = self.target_height
         mask_width = self.target_width
         if cur_ratio > float(self.target_width) / self.target_height:
             cur_target_height = self.target_height
             cur_target_width = self.target_width
         else:
             cur_target_height = self.target_height
             cur_target_width = int(self.target_height * cur_ratio)
         img = cv2.resize(img, (cur_target_width, cur_target_height))
-        mask = np.zeros([mask_height, mask_width]).astype(np.uint8)
-        mask[:img.shape[0], :img.shape[1]] = img
+        mask = np.zeros([mask_height, mask_width, 3]).astype(np.uint8)
+        mask[:img.shape[0], :img.shape[1], :] = img
         img = mask
         return img
 
     def __call__(self, inputs):
         """process the raw input data
         Args:
             inputs:
@@ -61,33 +59,36 @@
             outputs: the preprocessed image
         """
         if not isinstance(inputs, list):
             inputs = [inputs]
         data_batch = []
         for item in inputs:
             if isinstance(item, str):
-                img = np.array(load_image(item).convert('L'))
+                img = np.array(load_image(item).convert('RGB'))
             elif isinstance(item, PIL.Image.Image):
-                img = np.array(item.convert('L'))
+                img = np.array(item.convert('RGB'))
             elif isinstance(item, np.ndarray):
-                if len(item.shape) == 3:
-                    img = cv2.cvtColor(item, cv2.COLOR_RGB2GRAY)
+                if len(item.shape) == 2:
+                    img = cv2.cvtColor(item, cv2.COLOR_GRAY2RGB)
+                else:
+                    img = item
             else:
                 raise TypeError(
                     f'inputs should be either (a list of) str, PIL.Image, np.array, but got {type(item)}'
                 )
-
             img = self.keepratio_resize(img)
             img = torch.FloatTensor(img)
             if self.do_chunking:
                 chunk_img = []
                 for i in range(3):
                     left = (300 - 48) * i
-                    chunk_img.append(img[:, left:left + 300])
+                    chunk_img.append(img[:, left:left + 300, :])
                 merge_img = torch.cat(chunk_img, 0)
-                data = merge_img.view(3, 1, self.target_height, 300) / 255.
+                data = merge_img.view(3, self.target_height, 300, 3) / 255.
+                data = data.permute(0, 3, 1, 2)
             else:
-                data = img.view(1, 1, self.target_height,
-                                self.target_width) / 255.
+                data = img.view(1, self.target_height, self.target_width,
+                                3) / 255.
+                data = data.permute(0, 3, 1, 2)
             data_batch.append(data)
         data_batch = torch.cat(data_batch, 0)
-        return data_batch
+        return {'image': data_batch}
```

### Comparing `modelscope-1.6.1/modelscope/models/cv/open_vocabulary_detection_vild/vild.py` & `modelscope-1.7.0/modelscope/models/cv/open_vocabulary_detection_vild/vild.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/equi.py` & `modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/equi.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/layers.py` & `modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/mobilenet.py` & `modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/mobilenet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/resnet.py` & `modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/unifuse.py` & `modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/unifuse.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/networks/util.py` & `modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/networks/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/panorama_depth_estimation/unifuse_model.py` & `modelscope-1.7.0/modelscope/models/cv/panorama_depth_estimation/unifuse_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/pedestrian_attribute_recognition/model.py` & `modelscope-1.7.0/modelscope/models/cv/pedestrian_attribute_recognition/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/pointcloud_sceneflow_estimation/common.py` & `modelscope-1.7.0/modelscope/models/cv/pointcloud_sceneflow_estimation/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py` & `modelscope-1.7.0/modelscope/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/pointcloud_sceneflow_estimation/rcp_model.py` & `modelscope-1.7.0/modelscope/models/cv/pointcloud_sceneflow_estimation/rcp_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py` & `modelscope-1.7.0/modelscope/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/product_retrieval_embedding/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/product_retrieval_embedding/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/product_retrieval_embedding/item_detection.py` & `modelscope-1.7.0/modelscope/models/cv/product_retrieval_embedding/item_detection.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/product_retrieval_embedding/item_embedding.py` & `modelscope-1.7.0/modelscope/models/cv/product_retrieval_embedding/item_embedding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/product_retrieval_embedding/item_model.py` & `modelscope-1.7.0/modelscope/models/cv/product_retrieval_embedding/item_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/product_segmentation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/product_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/product_segmentation/net.py` & `modelscope-1.7.0/modelscope/models/cv/product_segmentation/net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/product_segmentation/seg_infer.py` & `modelscope-1.7.0/modelscope/models/cv/product_segmentation/seg_infer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/model.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/backbone.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/criterion.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/criterion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/matcher.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/matcher.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/misc.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/misc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/mttr.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/mttr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/postprocessing.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/postprocessing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/segmentation.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/segmentation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/referring_video_object_segmentation/utils/swin_transformer.py` & `modelscope-1.7.0/modelscope/models/cv/referring_video_object_segmentation/utils/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/robust_image_classification/easyrobust_model.py` & `modelscope-1.7.0/modelscope/models/cv/robust_image_classification/easyrobust_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/salient_detection/models/backbone/Res2Net_v1b.py` & `modelscope-1.7.0/modelscope/models/cv/salient_detection/models/backbone/Res2Net_v1b.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/salient_detection/models/modules.py` & `modelscope-1.7.0/modelscope/models/cv/salient_detection/models/modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/salient_detection/models/senet.py` & `modelscope-1.7.0/modelscope/models/cv/salient_detection/models/senet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/salient_detection/models/u2net.py` & `modelscope-1.7.0/modelscope/models/cv/salient_detection/models/u2net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/salient_detection/models/utils.py` & `modelscope-1.7.0/modelscope/models/cv/salient_detection/models/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/salient_detection/salient_model.py` & `modelscope-1.7.0/modelscope/models/cv/salient_detection/salient_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/shop_segmentation/common.py` & `modelscope-1.7.0/modelscope/models/cv/shop_segmentation/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/shop_segmentation/head_fpn.py` & `modelscope-1.7.0/modelscope/models/cv/shop_segmentation/head_fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/shop_segmentation/models.py` & `modelscope-1.7.0/modelscope/models/cv/shop_segmentation/models.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/shop_segmentation/neck_fpn.py` & `modelscope-1.7.0/modelscope/models/cv/shop_segmentation/neck_fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/shop_segmentation/shop_seg_base.py` & `modelscope-1.7.0/modelscope/models/cv/shop_segmentation/shop_seg_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/shop_segmentation/shop_seg_model.py` & `modelscope-1.7.0/modelscope/models/cv/shop_segmentation/shop_seg_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/shop_segmentation/utils.py` & `modelscope-1.7.0/modelscope/models/cv/shop_segmentation/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/detection_model/detection_module.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/detection_model/detection_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/detection_model/detection_unet_in.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/detection_model/detection_unet_in.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/inpainting_model/gconv.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/inpainting_model/gconv.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/inpainting_model/inpainting_unet.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/inpainting_model/inpainting_unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/box_utils.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/box_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/net.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/network.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/network.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/predict_single.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/predict_single.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/prior_box.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/prior_box.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/retinaface/utils.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/retinaface/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/unet_deploy.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/unet_deploy.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/utils.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/skin_retouching/weights_init.py` & `modelscope-1.7.0/modelscope/models/cv/skin_retouching/weights_init.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/data/data_augment.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/data/data_augment.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/exp/default/streamyolo.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/exp/default/streamyolo.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/exp/yolox_base.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/exp/yolox_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/darknet.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/darknet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/dfp_pafpn.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/dfp_pafpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/network_blocks.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/network_blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/streamyolo.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/streamyolo.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/models/tal_head.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/models/tal_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/realtime_video_detector.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/realtime_video_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/stream_yolo/utils/boxes.py` & `modelscope-1.7.0/modelscope/models/cv/stream_yolo/utils/boxes.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/super_resolution/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/super_resolution/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/super_resolution/arch_util.py` & `modelscope-1.7.0/modelscope/models/cv/super_resolution/arch_util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/super_resolution/ecb.py` & `modelscope-1.7.0/modelscope/models/cv/super_resolution/ecb.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/super_resolution/ecbsr_model.py` & `modelscope-1.7.0/modelscope/models/cv/super_resolution/ecbsr_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/super_resolution/rrdbnet_arch.py` & `modelscope-1.7.0/modelscope/models/cv/super_resolution/rrdbnet_arch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/table_recognition/lineless_table_process.py` & `modelscope-1.7.0/modelscope/models/cv/table_recognition/lineless_table_process.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/table_recognition/model_lore.py` & `modelscope-1.7.0/modelscope/models/cv/table_recognition/model_lore.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/table_recognition/modules/lore_detector.py` & `modelscope-1.7.0/modelscope/models/cv/table_recognition/modules/lore_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/table_recognition/modules/lore_processor.py` & `modelscope-1.7.0/modelscope/models/cv/table_recognition/modules/lore_processor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/clip.py` & `modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/lseg_base.py` & `modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/lseg_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/lseg_blocks.py` & `modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/lseg_blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/lseg_model.py` & `modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/lseg_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/lseg_net.py` & `modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/lseg_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/lseg_vit.py` & `modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/lseg_vit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/model.py` & `modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/text_driven_segmentation/simple_tokenizer.py` & `modelscope-1.7.0/modelscope/models/cv/text_driven_segmentation/simple_tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/basic_blocks.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/basic_blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/global_utils.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/global_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/master_net.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/master_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/model_zoo.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/model_zoo.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/plain_net_utils.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/plain_net_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/super_blocks.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/super_blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/super_res_idwexkx.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/super_res_idwexkx.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/super_res_k1kxk1.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/super_res_k1kxk1.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_classfication/super_res_kxkx.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_classfication/super_res_kxkx.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/apis/detector_evaluater.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/apis/detector_evaluater.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/apis/detector_inference.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/apis/detector_inference.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/base_ops.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/base_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/ops.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/utils.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/weight_init.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/core/weight_init.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/detectors/detector.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/detectors/detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/structures/bounding_box.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/structures/bounding_box.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/structures/boxlist_ops.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/structures/boxlist_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/structures/image_list.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/structures/image_list.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/utils/boxes.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/utils/boxes.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/utils/model_utils.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/utils/model_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/damo/utils/scheduler.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/damo/utils/scheduler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/detector.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/tinynas_damoyolo.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/tinynas_damoyolo.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/tinynas_detector.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/tinynas_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/tinynas_detection/utils.py` & `modelscope-1.7.0/modelscope/models/cv/tinynas_detection/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_deinterlace/UNet_for_video_deinterlace.py` & `modelscope-1.7.0/modelscope/models/cv/video_deinterlace/UNet_for_video_deinterlace.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_deinterlace/deinterlace_arch.py` & `modelscope-1.7.0/modelscope/models/cv/video_deinterlace/deinterlace_arch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/archs.py` & `modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/archs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/deep_fourier_upsampling.py` & `modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/deep_fourier_upsampling.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/enh.py` & `modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/enh.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/fre.py` & `modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/fre.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_deinterlace/models/utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_deinterlace/models/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/configs/default_config.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/configs/default_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/dro_model.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/dro_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/geometry/camera.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/geometry/camera.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/geometry/camera_utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/geometry/camera_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/geometry/pose.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/geometry/pose.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/geometry/pose_utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/geometry/pose_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/model_checkpoint.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/model_checkpoint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/model_utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/model_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/model_wrapper.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/model_wrapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/sfm_model_mf.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/sfm_model_mf.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/models/sup_model_mf.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/models/sup_model_mf.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/layers.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/optim/extractor.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/optim/extractor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/networks/optim/update.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/networks/optim/update.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/augmentations.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/augmentations.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/config.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/depth.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/depth.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/horovod.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/horovod.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/image.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/image.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/image_gt.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/image_gt.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/load.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/load.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/misc.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/misc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_depth_estimation/utils/types.py` & `modelscope-1.7.0/modelscope/models/cv/video_depth_estimation/utils/types.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/VFINet_arch.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/VFINet_arch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/flow_model/corr.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/flow_model/corr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/flow_model/extractor.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/flow_model/extractor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/flow_model/raft.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/flow_model/raft.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/flow_model/update.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/flow_model/update.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/UNet.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/UNet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/flow_reversal.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/flow_reversal.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/interp_model/transformer_layers.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/interp_model/transformer_layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/utils/scene_change_detection.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/utils/scene_change_detection.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_frame_interpolation/utils/utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_frame_interpolation/utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_human_matting/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/video_human_matting/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_human_matting/model.py` & `modelscope-1.7.0/modelscope/models/cv/video_human_matting/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/decoder.py` & `modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/deep_guided_filter.py` & `modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/deep_guided_filter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/effv2.py` & `modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/effv2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/lraspp.py` & `modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/lraspp.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_human_matting/models/matting.py` & `modelscope-1.7.0/modelscope/models/cv/video_human_matting/models/matting.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_inpainting/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/video_inpainting/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_inpainting/inpainting.py` & `modelscope-1.7.0/modelscope/models/cv/video_inpainting/inpainting.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_inpainting/inpainting_model.py` & `modelscope-1.7.0/modelscope/models/cv/video_inpainting/inpainting_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/kernel_head.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/kernel_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/kernel_iter_head.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/kernel_iter_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/kernel_update_head.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/kernel_update_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/head/kernel_updator.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/head/kernel_updator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/neck/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/neck/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/track/kernel_update_head.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/track/kernel_update_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_instance_segmentation/video_knet.py` & `modelscope-1.7.0/modelscope/models/cv/video_instance_segmentation/video_knet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/models/common.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/models/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/models/decode.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/models/decode.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/models/model.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/models/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/models/yolo.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/models/yolo.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/tracker/basetrack.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/tracker/basetrack.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/tracker/matching.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/tracker/matching.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/tracker/multitracker.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/tracker/multitracker.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/utils/image.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/utils/image.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/utils/kalman_filter.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/utils/kalman_filter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/utils/utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_multi_object_tracking/utils/visualization.py` & `modelscope-1.7.0/modelscope/models/cv/video_multi_object_tracking/utils/visualization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/aggregate.py` & `modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/aggregate.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/cbam.py` & `modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/cbam.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/eval_network.py` & `modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/eval_network.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/inference_core.py` & `modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/inference_core.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/inference_memory_bank.py` & `modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/inference_memory_bank.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/mod_resnet.py` & `modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/mod_resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/model.py` & `modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/modules.py` & `modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_object_segmentation/network.py` & `modelscope-1.7.0/modelscope/models/cv/video_object_segmentation/network.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_head.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_update_head.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_update_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_updator.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_updator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/mask.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/head/track_heads.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/head/track_heads.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/neck/fpn.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/neck/fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/video_k_net.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/video_k_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_panoptic_segmentation/visualizer.py` & `modelscope-1.7.0/modelscope/models/cv/video_panoptic_segmentation/visualizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/config/ostrack.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/config/ostrack.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/layers/attn.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/layers/attn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/layers/attn_blocks.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/layers/attn_blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/layers/head.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/layers/head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/layers/patch_embed.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/layers/patch_embed.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/ostrack.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/ostrack/ostrack.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/ostrack/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/procontext/procontext.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/procontext/procontext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/procontext/utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/procontext/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/models/procontext/vit_ce.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/models/procontext/vit_ce.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/tracker/ostrack.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/tracker/ostrack.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/tracker/procontext.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/tracker/procontext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_single_object_tracking/utils/utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_single_object_tracking/utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/DUT_raft.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/DUT_raft.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/MotionPro.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/MotionPro.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/RAFT/corr.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/RAFT/corr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/RAFT/extractor.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/RAFT/extractor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/RAFT/raft.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/RAFT/raft.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/RAFT/update.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/RAFT/update.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/Smoother.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/Smoother.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/config.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/rf_det_module.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/rf_det_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUT/rf_det_so.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUT/rf_det_so.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/DUTRAFTStabilizer.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/DUTRAFTStabilizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/IterativeSmooth.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/IterativeSmooth.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/MedianFilter.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/MedianFilter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/ProjectionUtils.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/ProjectionUtils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/RAFTUtils.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/RAFTUtils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/WarpUtils.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/WarpUtils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/image_utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/image_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_stabilization/utils/math_utils.py` & `modelscope-1.7.0/modelscope/models/cv/video_stabilization/utils/math_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py` & `modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/longshortnet.py` & `modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/longshortnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py` & `modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py` & `modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort.py` & `modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py` & `modelscope-1.7.0/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_summarization/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/video_summarization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_summarization/base_model.py` & `modelscope-1.7.0/modelscope/models/cv/video_summarization/base_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_summarization/kts/cpd_auto.py` & `modelscope-1.7.0/modelscope/models/cv/video_summarization/kts/cpd_auto.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_summarization/kts/cpd_nonlin.py` & `modelscope-1.7.0/modelscope/models/cv/video_summarization/kts/cpd_nonlin.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_summarization/pgl_sum.py` & `modelscope-1.7.0/modelscope/models/cv/video_summarization/pgl_sum.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_summarization/summarizer.py` & `modelscope-1.7.0/modelscope/models/cv/video_summarization/summarizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_super_resolution/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/video_super_resolution/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_super_resolution/basicvsr_net.py` & `modelscope-1.7.0/modelscope/models/cv/video_super_resolution/basicvsr_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_super_resolution/common.py` & `modelscope-1.7.0/modelscope/models/cv/video_super_resolution/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_super_resolution/msrresnet_lite_model.py` & `modelscope-1.7.0/modelscope/models/cv/video_super_resolution/msrresnet_lite_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py` & `modelscope-1.7.0/modelscope/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/video_super_resolution/real_basicvsr_net.py` & `modelscope-1.7.0/modelscope/models/cv/video_super_resolution/real_basicvsr_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vidt/backbone.py` & `modelscope-1.7.0/modelscope/models/cv/vidt/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vidt/deformable_transformer.py` & `modelscope-1.7.0/modelscope/models/cv/vidt/deformable_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vidt/fpn_fusion.py` & `modelscope-1.7.0/modelscope/models/cv/vidt/fpn_fusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vidt/head.py` & `modelscope-1.7.0/modelscope/models/cv/vidt/head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vidt/model.py` & `modelscope-1.7.0/modelscope/models/cv/vidt/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/virual_tryon/sdafnet.py` & `modelscope-1.7.0/modelscope/models/cv/virual_tryon/sdafnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/backbone.py` & `modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -187,15 +187,15 @@
                 layer_num=layer_num,
                 prompt_length=prompt_length,
                 prompt_type=prompt_type)
         else:
             self.prompt = None
 
     def forward(self, x):
-        if self.prompt is not None:
+        if self.prompt is not None and self.prompt_length and self.prompt_length > 0:
             x = self.prompt(x)
 
         x = x + self.drop_path1(self.ls1(self.attn(self.norm1(x))))
 
         if self.adapter is not None:
             x = x + self.adapter(
                 self.drop_path2(self.ls2(self.mlp(self.norm2(x)))))
```

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/head.py` & `modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/model.py` & `modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/petl.py` & `modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/petl.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/timm_helpers.py` & `modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/timm_helpers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/timm_vision_transformer.py` & `modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/timm_vision_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/timm_weight_init.py` & `modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/timm_weight_init.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_efficient_tuning/vision_efficient_tuning.py` & `modelscope-1.7.0/modelscope/models/cv/vision_efficient_tuning/vision_efficient_tuning.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_middleware/backbone.py` & `modelscope-1.7.0/modelscope/models/cv/vision_middleware/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_middleware/head.py` & `modelscope-1.7.0/modelscope/models/cv/vision_middleware/head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_middleware/model.py` & `modelscope-1.7.0/modelscope/models/cv/vision_middleware/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vision_middleware/vim.py` & `modelscope-1.7.0/modelscope/models/cv/vision_middleware/vim.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vop_retrieval/__init__.py` & `modelscope-1.7.0/modelscope/models/cv/vop_retrieval/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vop_retrieval/backbone.py` & `modelscope-1.7.0/modelscope/models/cv/vop_retrieval/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vop_retrieval/basic_utils.py` & `modelscope-1.7.0/modelscope/models/cv/vop_retrieval/basic_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vop_retrieval/model.py` & `modelscope-1.7.0/modelscope/models/cv/vop_retrieval/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vop_retrieval/model_se.py` & `modelscope-1.7.0/modelscope/models/cv/vop_retrieval/model_se.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/cv/vop_retrieval/tokenization_clip.py` & `modelscope-1.7.0/modelscope/models/cv/vop_retrieval/tokenization_clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/__init__.py` & `modelscope-1.7.0/modelscope/models/multi_modal/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/clip/bert_tokenizer.py` & `modelscope-1.7.0/modelscope/models/multi_modal/clip/bert_tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/clip/configuration_bert.py` & `modelscope-1.7.0/modelscope/models/multi_modal/clip/configuration_bert.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/clip/model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/clip/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/clip/modeling_bert.py` & `modelscope-1.7.0/modelscope/models/multi_modal/clip/modeling_bert.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/clip_interrogator/model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/clip_interrogator/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/diffusion/diffusion.py` & `modelscope-1.7.0/modelscope/models/multi_modal/diffusion/diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/diffusion/model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/diffusion/model.py`

 * *Files 0% similar despite different names*

```diff
@@ -110,17 +110,17 @@
         return x
 
 
 @MODELS.register_module(
     Tasks.text_to_image_synthesis, module_name=Models.diffusion)
 class DiffusionForTextToImageSynthesis(Model):
 
-    def __init__(self, model_dir, device='gpu'):
+    def __init__(self, model_dir, device='gpu', **kwargs):
         device = 'gpu' if torch.cuda.is_available() else 'cpu'
-        super().__init__(model_dir=model_dir, device=device)
+        super().__init__(model_dir=model_dir, device=device, **kwargs)
         diffusion_model = DiffusionModel(model_dir=model_dir)
         pretrained_params = torch.load(
             osp.join(model_dir, ModelFile.TORCH_MODEL_BIN_FILE), 'cpu')
         diffusion_model.load_state_dict(pretrained_params)
         diffusion_model.eval().to()
 
         self.device = create_device(device)
```

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/diffusion/structbert.py` & `modelscope-1.7.0/modelscope/models/multi_modal/diffusion/structbert.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/diffusion/tokenizer.py` & `modelscope-1.7.0/modelscope/models/multi_modal/diffusion/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/diffusion/unet_generator.py` & `modelscope-1.7.0/modelscope/models/multi_modal/diffusion/unet_generator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/diffusion/unet_upsampler_1024.py` & `modelscope-1.7.0/modelscope/models/multi_modal/diffusion/unet_upsampler_1024.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/diffusion/unet_upsampler_256.py` & `modelscope-1.7.0/modelscope/models/multi_modal/diffusion/unet_upsampler_256.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/dpm_solver_pytorch.py` & `modelscope-1.7.0/modelscope/models/multi_modal/dpm_solver_pytorch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/efficient_diffusion_tuning/__init__.py` & `modelscope-1.7.0/modelscope/models/multi_modal/efficient_diffusion_tuning/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py` & `modelscope-1.7.0/modelscope/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,16 +15,16 @@
 from diffusers.utils import deprecation_utils
 from transformers import CLIPTextModel, CLIPTokenizer
 
 from modelscope.metainfo import Models
 from modelscope.models import TorchModel
 from modelscope.models.builder import MODELS
 from modelscope.outputs import OutputKeys
-from modelscope.tuners.control_sd_lora import ControlLoRATuner
-from modelscope.tuners.sd_lora import LoRATuner
+from modelscope.swift.control_sd_lora import ControlLoRATuner
+from modelscope.swift.sd_lora import LoRATuner
 from modelscope.utils.checkpoint import save_checkpoint, save_configuration
 from modelscope.utils.config import Config
 from modelscope.utils.constant import ModelFile, Tasks
 
 utils.deprecate = lambda *arg, **kwargs: None
 deprecation_utils.deprecate = lambda *arg, **kwargs: None
 cross_attention.deprecate = lambda *arg, **kwargs: None
```

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/gemm/gemm_base.py` & `modelscope-1.7.0/modelscope/models/multi_modal/gemm/gemm_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/gemm/gemm_model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/gemm/gemm_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/gemm/tokenizer.py` & `modelscope-1.7.0/modelscope/models/multi_modal/gemm/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/__init__.py` & `modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/gaussian_diffusion.py` & `modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/gaussian_diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/respace.py` & `modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/respace.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/script.py` & `modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/script.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/guided_diffusion/unet.py` & `modelscope-1.7.0/modelscope/models/multi_modal/guided_diffusion/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mgeo/__init__.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mgeo/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mgeo/backbone.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mgeo/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mgeo/text_classification.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mgeo/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mgeo/text_ranking.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mgeo/text_ranking.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mgeo/token_classification.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mgeo/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mmr/dataloaders/rawvideo_util.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mmr/dataloaders/rawvideo_util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/dynamic_inverted_softmax.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/dynamic_inverted_softmax.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/modeling.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/modeling.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/module_clip.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/module_clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/module_cross.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/module_cross.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/tokenization_clip.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/tokenization_clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mmr/models/until_module.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mmr/models/until_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mplug/__init__.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mplug/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mplug/clip/clip.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mplug/clip/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mplug/configuration_mplug.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mplug/configuration_mplug.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mplug/modeling_mplug.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mplug/modeling_mplug.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mplug/mvit.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mplug/mvit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mplug/predictor.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mplug/predictor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mplug_for_all_tasks.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mplug_for_all_tasks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mplug_owl/__init__.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mplug_owl/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mplug_owl/configuration_mplug_owl.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mplug_owl/configuration_mplug_owl.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/mplug_owl/modeling_mplug_owl.py` & `modelscope-1.7.0/modelscope/models/multi_modal/mplug_owl/modeling_mplug_owl.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/clip.py` & `modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/decoder.py` & `modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py` & `modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/prior.py` & `modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/prior.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/tokenizer.py` & `modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/upsampler.py` & `modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/upsampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/multi_stage_diffusion/xglm.py` & `modelscope-1.7.0/modelscope/models/multi_modal/multi_stage_diffusion/xglm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/configuration_mmspeech.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/configuration_mmspeech.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/configuration_ofa.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/configuration_ofa.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/incremental_decoding_utils.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/incremental_decoding_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/multihead_attention.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/multihead_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/ngram_repeat_block.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/ngram_repeat_block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/search.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/search.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/sequence_generator.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/sequence_generator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/token_generation_constraints.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/token_generation_constraints.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/generate/utils.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/generate/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/modeling_mmspeech.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/modeling_mmspeech.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/modeling_ofa.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/modeling_ofa.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/resnet.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/tokenization_ofa.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/tokenization_ofa.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/tokenization_ofa_fast.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/tokenization_ofa_fast.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/utils/constant.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/utils/constant.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/utils/utils.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa/vit.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa/vit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa_for_all_tasks.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa_for_all_tasks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/ofa_for_text_to_image_synthesis_model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/ofa_for_text_to_image_synthesis_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/rleg/__init__.py` & `modelscope-1.7.0/modelscope/models/multi_modal/rleg/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/rleg/model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/rleg/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/rleg/rleg.py` & `modelscope-1.7.0/modelscope/models/multi_modal/rleg/rleg.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/soonet/__init__.py` & `modelscope-1.7.0/modelscope/models/multi_modal/soonet/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/soonet/blocks.py` & `modelscope-1.7.0/modelscope/models/multi_modal/soonet/blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/soonet/clip.py` & `modelscope-1.7.0/modelscope/models/multi_modal/soonet/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/soonet/model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/soonet/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/soonet/swin_transformer.py` & `modelscope-1.7.0/modelscope/models/multi_modal/soonet/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/soonet/tokenizer.py` & `modelscope-1.7.0/modelscope/models/multi_modal/soonet/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/soonet/utils.py` & `modelscope-1.7.0/modelscope/models/multi_modal/soonet/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/team/team_model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/team/team_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/team/utils.py` & `modelscope-1.7.0/modelscope/models/multi_modal/team/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/__init__.py` & `modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/autoencoder.py` & `modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/autoencoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/diffusion.py` & `modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/video_synthesis/unet_sd.py` & `modelscope-1.7.0/modelscope/models/multi_modal/video_synthesis/unet_sd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/vldoc/conv_fpn_trans.py` & `modelscope-1.7.0/modelscope/models/multi_modal/vldoc/conv_fpn_trans.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/vldoc/convnext.py` & `modelscope-1.7.0/modelscope/models/multi_modal/vldoc/convnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/vldoc/model.py` & `modelscope-1.7.0/modelscope/models/multi_modal/vldoc/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/vldoc/modeling_layout_roberta.py` & `modelscope-1.7.0/modelscope/models/multi_modal/vldoc/modeling_layout_roberta.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/vldoc/processing.py` & `modelscope-1.7.0/modelscope/models/multi_modal/vldoc/processing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/vldoc/tokenization.py` & `modelscope-1.7.0/modelscope/models/multi_modal/vldoc/tokenization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/multi_modal/vldoc/transformer_local.py` & `modelscope-1.7.0/modelscope/models/multi_modal/vldoc/transformer_local.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/T5/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/T5/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/T5/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/T5/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/T5/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/T5/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/T5/text2text_generation.py` & `modelscope-1.7.0/modelscope/models/nlp/T5/text2text_generation.py`

 * *Files 0% similar despite different names*

```diff
@@ -53,15 +53,15 @@
         r'decoder\.embed_tokens\.weight',
         r'lm_head\.weight',
     ]
     _keys_to_ignore_on_load_unexpected = [
         r'decoder\.block\.0\.layer\.1\.EncDecAttention\.relative_attention_bias\.weight',
     ]
 
-    def __init__(self, config: T5Config, **kwargs):
+    def __init__(self, config: T5Config, device_map=None, **kwargs):
         super().__init__(config)
         self.model_dim = config.d_model
 
         self.shared = nn.Embedding(config.vocab_size, config.d_model)
 
         encoder_config = copy.deepcopy(config)
         encoder_config.is_decoder = False
@@ -78,15 +78,16 @@
         self.lm_head = nn.Linear(config.d_model, config.vocab_size, bias=False)
 
         # Initialize weights and apply final processing
         self.post_init()
 
         # Model parallel
         self.model_parallel = False
-        self.device_map = None
+        if device_map == 'auto':
+            self.parallelize()
 
     def parallelize(self, device_map=None):
         self.device_map = (
             get_device_map(
                 len(self.encoder.block), range(torch.cuda.device_count()))
             if device_map is None else device_map)
         assert_device_map(self.device_map, len(self.encoder.block))
```

### Comparing `modelscope-1.6.1/modelscope/models/nlp/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -18,14 +18,16 @@
     )
     from .bloom import BloomModel
     from .codegeex import CodeGeeXForCodeTranslation, CodeGeeXForCodeGeneration
     from .glm_130b import GLM130bForTextGeneration
     from .csanmt import CsanmtForTranslation
     from .canmt import CanmtForTranslation
     from .deberta_v2 import DebertaV2ForMaskedLM, DebertaV2Model
+    from .chatglm import ChatGLMForConditionalGeneration, ChatGLMTokenizer, ChatGLMConfig
+    from .chatglm2 import ChatGLM2ForConditionalGeneration, ChatGLM2Tokenizer, ChatGLM2Config
     from .gpt_neo import GPTNeoModel
     from .gpt2 import GPT2Model
     from .gpt3 import GPT3ForTextGeneration, DistributedGPT3
     from .gpt_moe import GPTMoEForTextGeneration, DistributedGPTMoE
     from .heads import TextClassificationHead
     from .hf_transformers import TransformersModel
     from .lstm import (
@@ -91,14 +93,22 @@
         'bloom': ['BloomModel'],
         'csanmt': ['CsanmtForTranslation'],
         'canmt': ['CanmtForTranslation'],
         'codegeex':
         ['CodeGeeXForCodeTranslation', 'CodeGeeXForCodeGeneration'],
         'glm_130b': ['GLM130bForTextGeneration'],
         'deberta_v2': ['DebertaV2ForMaskedLM', 'DebertaV2Model'],
+        'chatglm': [
+            'ChatGLMForConditionalGeneration', 'ChatGLMTokenizer',
+            'ChatGLMConfig'
+        ],
+        'chatglm2': [
+            'ChatGLM2ForConditionalGeneration', 'ChatGLM2Tokenizer',
+            'ChatGLM2Config'
+        ],
         'heads': ['TextClassificationHead'],
         'hf_transformers': ['TransformersModel'],
         'gpt2': ['GPT2Model'],
         'gpt3': ['GPT3ForTextGeneration', 'DistributedGPT3'],
         'gpt_moe': ['GPTMoEForTextGeneration', 'DistributedGPTMoE'],
         'gpt_neo': ['GPTNeoModel'],
         'structbert': [
```

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bart/text_error_correction.py` & `modelscope-1.7.0/modelscope/models/nlp/bart/text_error_correction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/document_segmentation.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/document_segmentation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/fill_mask.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/sentence_embedding.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/sentence_embedding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/siamese_uie.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/siamese_uie.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/text_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/text_ranking.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/text_ranking.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/token_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/bert/word_alignment.py` & `modelscope-1.7.0/modelscope/models/nlp/bert/word_alignment.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/canmt/canmt_model.py` & `modelscope-1.7.0/modelscope/models/nlp/canmt/canmt_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/canmt/canmt_translation.py` & `modelscope-1.7.0/modelscope/models/nlp/canmt/canmt_translation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/canmt/sequence_generator.py` & `modelscope-1.7.0/modelscope/models/nlp/canmt/sequence_generator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/codegeex/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/codegeex/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/codegeex/codegeex.py` & `modelscope-1.7.0/modelscope/models/nlp/codegeex/codegeex.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/codegeex/codegeex_for_code_generation.py` & `modelscope-1.7.0/modelscope/models/nlp/codegeex/codegeex_for_code_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/codegeex/codegeex_for_code_translation.py` & `modelscope-1.7.0/modelscope/models/nlp/codegeex/codegeex_for_code_translation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/codegeex/inference.py` & `modelscope-1.7.0/modelscope/models/nlp/codegeex/inference.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/codegeex/tokenizer.py` & `modelscope-1.7.0/modelscope/models/nlp/codegeex/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/csanmt/translation.py` & `modelscope-1.7.0/modelscope/models/nlp/csanmt/translation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/deberta_v2/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/deberta_v2/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/deberta_v2/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/deberta_v2/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/deberta_v2/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/deberta_v2/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/deberta_v2/fill_mask.py` & `modelscope-1.7.0/modelscope/models/nlp/deberta_v2/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/deberta_v2/tokenization.py` & `modelscope-1.7.0/modelscope/models/nlp/deberta_v2/tokenization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/deberta_v2/tokenization_fast.py` & `modelscope-1.7.0/modelscope/models/nlp/deberta_v2/tokenization_fast.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/dgds/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/dgds/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/dgds/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/dgds/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/dgds/document_grounded_dialog_generate.py` & `modelscope-1.7.0/modelscope/models/nlp/dgds/document_grounded_dialog_generate.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/dgds/document_grounded_dialog_rerank.py` & `modelscope-1.7.0/modelscope/models/nlp/dgds/document_grounded_dialog_rerank.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/dgds/document_grounded_dialog_retrieval.py` & `modelscope-1.7.0/modelscope/models/nlp/dgds/document_grounded_dialog_retrieval.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/fid_T5/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/fid_T5/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/fid_T5/text_generation.py` & `modelscope-1.7.0/modelscope/models/nlp/fid_T5/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/fid_plug/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/fid_plug/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/fid_plug/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/fid_plug/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/fid_plug/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/fid_plug/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/fid_plug/text_generation.py` & `modelscope-1.7.0/modelscope/models/nlp/fid_plug/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/glm_130b/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/glm_130b/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/glm_130b/generation/strategies.py` & `modelscope-1.7.0/modelscope/models/nlp/glm_130b/generation/strategies.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/glm_130b/initialize.py` & `modelscope-1.7.0/modelscope/models/nlp/glm_130b/initialize.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/glm_130b/kernels/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/glm_130b/kernels/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/glm_130b/quantization/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/glm_130b/quantization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/glm_130b/quantization/functional.py` & `modelscope-1.7.0/modelscope/models/nlp/glm_130b/quantization/functional.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/glm_130b/quantization/layers.py` & `modelscope-1.7.0/modelscope/models/nlp/glm_130b/quantization/layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/glm_130b/text_generation.py` & `modelscope-1.7.0/modelscope/models/nlp/glm_130b/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt3/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt3/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt3/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt3/backbone.py`

 * *Files 2% similar despite different names*

```diff
@@ -349,15 +349,15 @@
         state_dict = {
             k.replace('model.language_model', 'language_model'): v
             for k, v in state_dict.items()
         }
         model.load_state_dict(state_dict)
         return model
 
-    def generate(self, tokens, temperature=1.0, **kwargs):
+    def streaming_generate(self, tokens, temperature=1.0, **kwargs):
         top_k = kwargs.pop('top_k', self.config.top_k)
         top_p = kwargs.pop('top_p', self.config.top_p)
         max_length = kwargs.pop('max_length', tokens.size(1) + 100)
 
         batch_size = tokens.size(0)
         lengths = kwargs.pop(
             'prompt_length',
@@ -406,18 +406,24 @@
 
                 # If a prompt length is smaller or equal th current context
                 # length, it means we have started generating tokens
                 started = lengths <= context_length
                 # Update the tokens.
                 tokens[started, context_length] = new_sample[started]
 
+                yield TokenGeneratorOutput(sequences=tokens[:, :(context_length
+                                                                 + 1)])
+
                 done_token = (new_sample == termination_id).byte() & \
                     started.byte()
 
                 is_generation_done = is_generation_done | done_token
                 done = torch.all(is_generation_done)
 
                 if done:
                     break
 
-        tokens = tokens[:, :(context_length + 1)]
-        return TokenGeneratorOutput(sequences=tokens)
+    def generate(self, tokens, temperature=1.0, **kwargs):
+        last_output = None
+        for output in self.streaming_generate(tokens, temperature, **kwargs):
+            last_output = output
+        return last_output
```

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt3/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt3/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt3/distributed_gpt3.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt3/distributed_gpt3.py`

 * *Files 1% similar despite different names*

```diff
@@ -29,14 +29,15 @@
 from transformers.modeling_utils import PreTrainedModel
 
 from modelscope.models import TorchModel
 from modelscope.models.nlp.gpt3 import GPT3Config
 from modelscope.outputs import TextGenerationModelOutput, TokenGeneratorOutput
 from modelscope.utils.megatron_utils import init_megatron_util
 from modelscope.utils.nlp.load_checkpoint import pre_load
+from modelscope.utils.streaming_output import StreamingOutputMixin
 
 
 class GPT3ParallelMLP(nn.Module):
     """MLP.
 
     MLP will take the input with h hidden state, project it to 4*h
     hidden dimension, perform nonlinear transformation, and project the
@@ -941,15 +942,15 @@
         dim = max(parameters.partition_dim, 0)
         stride = parameters.partition_stride
         state_dict[name] = split_into_partitions(state_dict[name], partitions,
                                                  dim, stride)[rank]
     return state_dict
 
 
-class DistributedGPT3(TorchModel):
+class DistributedGPT3(TorchModel, StreamingOutputMixin):
 
     def __init__(self,
                  model_dir,
                  rank,
                  path_load_tag='model',
                  *args,
                  megatron_cfg=None,
@@ -1018,15 +1019,19 @@
                 for i, l in enumerate(inputs_len):
                     loss_mask[i, l - 1:] = 0
                 for i, l in enumerate(prompts_len):
                     loss_mask[i, :l - 1] = 0
 
             losses = losses.float()
             loss_mask = loss_mask.view(-1).float()
-            loss = torch.sum(losses.view(-1) * loss_mask) / loss_mask.sum()
+            mask_sum = loss_mask.sum()
+            if mask_sum == 0:
+                loss = torch.sum(losses.view(-1)).zero_()
+            else:
+                loss = torch.sum(losses.view(-1) * loss_mask) / mask_sum
 
         return TextGenerationModelOutput(logits=logits, loss=loss)
 
     def sample(self,
                tokens,
                prompts_len=None,
                use_eod_token_for_early_termination=True,
@@ -1100,14 +1105,18 @@
 
             # If a prompt length is smaller or equal th current context
             # length, it means we have started generating tokens
             started = lengths <= context_length
             # Update the tokens.
             tokens[started, context_length] = new_sample[started]
 
+            # streaming output
+            yield TokenGeneratorOutput(sequences=tokens[:, :(context_length
+                                                             + 1)])
+
             # Update the context length for the next token generation.
             prev_context_length = context_length
 
             # instead tokenization should be in the inference loop so stop sequences can be used
             if stop_on_double_eol:
                 hit_double_eol = (new_sample == 628).byte() & started.byte()
                 hit_two_eols = (new_sample == 198).byte() & (
@@ -1124,17 +1133,14 @@
 
             is_generation_done = is_generation_done | done_token
             done = torch.all(is_generation_done)
 
             if use_eod_token_for_early_termination and done:
                 break
 
-        tokens = tokens[:, :(context_length + 1)]
-        return TokenGeneratorOutput(sequences=tokens)
-
     def beam_search(self, tokens, beam_size=5, num_return_gen=1, **kwargs):
         batch_size = tokens.size(0)
         assert (batch_size == 1)
         prompt_length = kwargs.pop(
             'prompt_length',
             torch.tensor([tokens.size(1)], device=tokens.device)).item()
         stop_token = self.config.eod_id
@@ -1243,18 +1249,25 @@
         tokens = torch.stack(tokens, dim=0)
 
         return TokenGeneratorOutput(sequences=tokens, scores=scores)
 
     @torch.no_grad()
     def generate(self, tokens, do_sample=True, *args, **kwargs):
         if do_sample:
-            return self.sample(tokens, *args, **kwargs)
+            last_output = None
+            for output in self.sample(tokens, *args, **kwargs):
+                last_output = output
+            return last_output
         else:
             return self.beam_search(tokens, *args, **kwargs)
 
+    @torch.no_grad()
+    def stream(self, tokens, *args, **kwargs):
+        return self.sample(tokens, *args, **kwargs)
+
     def state_dict(self, destination=None, prefix='', keep_vars=False):
         return self.dist_model.state_dict(destination, prefix, keep_vars)
 
     def load_state_dict(self,
                         state_dict: 'OrderedDict[str, torch.Tensor]',
                         strict: bool = True):
         return self.dist_model.load_state_dict(state_dict, strict)
```

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt3/text_generation.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt3/text_generation.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,26 +1,27 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 from collections import OrderedDict
-from typing import Dict
+from typing import Dict, Generator
 
 import torch
 from transformers import BertTokenizer
 
 from modelscope.metainfo import Models
 from modelscope.models.base import Tensor, TorchModel
 from modelscope.models.builder import MODELS
 from modelscope.models.nlp.gpt3 import GPT3Model
 from modelscope.utils.constant import Tasks
 from modelscope.utils.hub import read_config
+from modelscope.utils.streaming_output import StreamingOutputMixin
 
 __all__ = ['GPT3ForTextGeneration']
 
 
 @MODELS.register_module(Tasks.text_generation, module_name=Models.gpt3)
-class GPT3ForTextGeneration(TorchModel):
+class GPT3ForTextGeneration(TorchModel, StreamingOutputMixin):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the text generation model from the `model_dir` path.
 
         Args:
             model_dir (str): the model path.
         """
@@ -73,7 +74,13 @@
     def state_dict(self, destination=None, prefix='', keep_vars=False):
         return self.model.state_dict(destination, prefix, keep_vars)
 
     def load_state_dict(self,
                         state_dict: 'OrderedDict[str, Tensor]',
                         strict: bool = True):
         return self.model.load_state_dict(state_dict, strict)
+
+    def stream(self, inputs, **kwargs) -> Generator:
+        tokens = inputs['input_ids']
+        lengths = self._get_length(inputs['attention_mask'])
+        return self.model.streaming_generate(
+            tokens, prompt_length=lengths, **kwargs)
```

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt3/tokenizer.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt3/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/checkpointing.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/checkpointing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/distributed_gpt_moe.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/distributed_gpt_moe.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/experts.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/experts.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/layer.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/layer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/mappings.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/mappings.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/sharded_moe.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/sharded_moe.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/moe/utils.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/moe/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/text_generation.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_moe/tokenizer.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_moe/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/gpt_neo/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/gpt_neo/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/heads/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/heads/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/heads/crf_head.py` & `modelscope-1.7.0/modelscope/models/nlp/heads/crf_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/heads/fill_mask_head.py` & `modelscope-1.7.0/modelscope/models/nlp/heads/fill_mask_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/heads/infromation_extraction_head.py` & `modelscope-1.7.0/modelscope/models/nlp/heads/infromation_extraction_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/heads/text_classification_head.py` & `modelscope-1.7.0/modelscope/models/nlp/heads/text_classification_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/heads/text_generation_head.py` & `modelscope-1.7.0/modelscope/models/nlp/heads/text_generation_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/heads/text_ranking_head.py` & `modelscope-1.7.0/modelscope/models/nlp/heads/text_ranking_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/heads/token_classification_head.py` & `modelscope-1.7.0/modelscope/models/nlp/heads/token_classification_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/heads/torch_pretrain_head.py` & `modelscope-1.7.0/modelscope/models/nlp/heads/torch_pretrain_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/hf_transformers/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/hf_transformers/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/llama/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/llama/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/llama/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/llama/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/llama/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/llama/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/llama/convert_llama_weights_to_hf.py` & `modelscope-1.7.0/modelscope/models/nlp/llama/convert_llama_weights_to_hf.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/llama/text_generation.py` & `modelscope-1.7.0/modelscope/models/nlp/llama/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/llama/tokenization.py` & `modelscope-1.7.0/modelscope/models/nlp/llama/tokenization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/llama/tokenization_fast.py` & `modelscope-1.7.0/modelscope/models/nlp/llama/tokenization_fast.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/lstm/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/lstm/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/lstm/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/lstm/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/lstm/token_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/lstm/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/megatron_bert/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/megatron_bert/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/megatron_bert/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/megatron_bert/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/megatron_bert/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/megatron_bert/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/megatron_bert/fill_mask.py` & `modelscope-1.7.0/modelscope/models/nlp/megatron_bert/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/arguments.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/arguments.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/blocklm_utils.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/blocklm_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/configure_data.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/configure_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/corpora.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/corpora.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/datasets.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/datasets.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/extraction.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/extraction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/file_utils.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/file_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/lazy_loader.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/lazy_loader.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/samplers.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/samplers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/sp_tokenizer.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/sp_tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/tokenization.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/tokenization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/tokenization_gpt2.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/tokenization_gpt2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/data_utils/wordpiece.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/data_utils/wordpiece.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/generation_utils.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/generation_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/mglm_for_text_summarization.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/mglm_for_text_summarization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/model/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/model/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/model/distributed.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/model/distributed.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/model/downstream.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/model/downstream.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/model/modeling_bert.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/model/modeling_bert.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/model/modeling_glm.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/model/modeling_glm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/model/prompt.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/model/prompt.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/model/transformer.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/model/transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/process_grid.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/process_grid.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/test/test_block.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/test/test_block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/test/test_rel_shift.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/test/test_rel_shift.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/train_utils.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/train_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/mglm/utils.py` & `modelscope-1.7.0/modelscope/models/nlp/mglm/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/palm_v2/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/palm_v2/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/palm_v2/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/palm_v2/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/palm_v2/dureader_eval.py` & `modelscope-1.7.0/modelscope/models/nlp/palm_v2/dureader_eval.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/palm_v2/text_generation.py` & `modelscope-1.7.0/modelscope/models/nlp/palm_v2/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/peer/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/peer/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/peer/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/peer/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/peer/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/peer/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/peer/sas_utils.py` & `modelscope-1.7.0/modelscope/models/nlp/peer/sas_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/peer/text_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/peer/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug/AnnealingLR.py` & `modelscope-1.7.0/modelscope/models/nlp/plug/AnnealingLR.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/plug/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/plug/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/plug/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug/distributed_plug.py` & `modelscope-1.7.0/modelscope/models/nlp/plug/distributed_plug.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug/generator.py` & `modelscope-1.7.0/modelscope/models/nlp/plug/generator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug_mental/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/plug_mental/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug_mental/adv_utils.py` & `modelscope-1.7.0/modelscope/models/nlp/plug_mental/adv_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug_mental/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/plug_mental/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug_mental/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/plug_mental/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/plug_mental/text_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/plug_mental/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/ponet/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/ponet/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/ponet/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/ponet/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/ponet/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/ponet/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/ponet/document_segmentation.py` & `modelscope-1.7.0/modelscope/models/nlp/ponet/document_segmentation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/ponet/fill_mask.py` & `modelscope-1.7.0/modelscope/models/nlp/ponet/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/ponet/tokenization.py` & `modelscope-1.7.0/modelscope/models/nlp/ponet/tokenization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/space/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/space/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/dialog_intent_prediction.py` & `modelscope-1.7.0/modelscope/models/nlp/space/dialog_intent_prediction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/dialog_modeling.py` & `modelscope-1.7.0/modelscope/models/nlp/space/dialog_modeling.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/dialog_state_tracking.py` & `modelscope-1.7.0/modelscope/models/nlp/space/dialog_state_tracking.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/model/gen_unified_transformer.py` & `modelscope-1.7.0/modelscope/models/nlp/space/model/gen_unified_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/model/generator.py` & `modelscope-1.7.0/modelscope/models/nlp/space/model/generator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/model/intent_unified_transformer.py` & `modelscope-1.7.0/modelscope/models/nlp/space/model/intent_unified_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/model/model_base.py` & `modelscope-1.7.0/modelscope/models/nlp/space/model/model_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/model/tokenization_space.py` & `modelscope-1.7.0/modelscope/models/nlp/space/model/tokenization_space.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/model/unified_transformer.py` & `modelscope-1.7.0/modelscope/models/nlp/space/model/unified_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/modules/embedder.py` & `modelscope-1.7.0/modelscope/models/nlp/space/modules/embedder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/modules/feedforward.py` & `modelscope-1.7.0/modelscope/models/nlp/space/modules/feedforward.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/modules/functions.py` & `modelscope-1.7.0/modelscope/models/nlp/space/modules/functions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/modules/multihead_attention.py` & `modelscope-1.7.0/modelscope/models/nlp/space/modules/multihead_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space/modules/transformer_block.py` & `modelscope-1.7.0/modelscope/models/nlp/space/modules/transformer_block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space_T_cn/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/space_T_cn/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space_T_cn/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/space_T_cn/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space_T_cn/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/space_T_cn/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space_T_cn/table_question_answering.py` & `modelscope-1.7.0/modelscope/models/nlp/space_T_cn/table_question_answering.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/space_T_en/text_to_sql.py` & `modelscope-1.7.0/modelscope/models/nlp/space_T_en/text_to_sql.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/structbert/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/structbert/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/structbert/adv_utils.py` & `modelscope-1.7.0/modelscope/models/nlp/structbert/adv_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/structbert/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/structbert/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/structbert/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/structbert/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/structbert/faq_question_answering.py` & `modelscope-1.7.0/modelscope/models/nlp/structbert/faq_question_answering.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/structbert/fill_mask.py` & `modelscope-1.7.0/modelscope/models/nlp/structbert/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/structbert/text_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/structbert/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/structbert/token_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/structbert/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/task_models/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/task_models/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/task_models/feature_extraction.py` & `modelscope-1.7.0/modelscope/models/nlp/task_models/feature_extraction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/task_models/fill_mask.py` & `modelscope-1.7.0/modelscope/models/nlp/task_models/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/task_models/information_extraction.py` & `modelscope-1.7.0/modelscope/models/nlp/task_models/information_extraction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/task_models/task_model.py` & `modelscope-1.7.0/modelscope/models/nlp/task_models/task_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/task_models/text_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/task_models/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/task_models/text_generation.py` & `modelscope-1.7.0/modelscope/models/nlp/task_models/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/task_models/text_ranking.py` & `modelscope-1.7.0/modelscope/models/nlp/task_models/text_ranking.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/task_models/token_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/task_models/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/unite/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/unite/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/unite/translation_evaluation.py` & `modelscope-1.7.0/modelscope/models/nlp/unite/translation_evaluation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/use/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/use/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/use/transformer.py` & `modelscope-1.7.0/modelscope/models/nlp/use/transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/use/user_satisfaction_estimation.py` & `modelscope-1.7.0/modelscope/models/nlp/use/user_satisfaction_estimation.py`

 * *Files 4% similar despite different names*

```diff
@@ -23,24 +23,25 @@
 
 @MODELS.register_module(Tasks.text_classification, module_name=Models.use)
 class UserSatisfactionEstimation(TorchModel):
 
     def __init__(self,
                  model_dir: str,
                  bert_name: str = None,
-                 device: str = None):
+                 device: str = None,
+                 **kwargs):
         """initialize the user satisfaction estimation model from the `model_dir` path. The default preprocessor
         for this task is DialogueClassificationUsePreprocessor.
 
         Args:
             model_dir: The model dir containing the model.
             bert_name: The pretrained model, default bert-base-chinese
             device: The device of running model, default cpu
         """
-        super().__init__(model_dir)
+        super().__init__(model_dir, **kwargs)
         self.model_dir = model_dir
         self.bert_name = bert_name if bert_name is not None else 'bert-base-chinese'
         self.device = 'cpu'
         if device is not None and torch.cuda.is_available():
             self.device = device
         self.model = self.init_model()
         model_ckpt = os.path.join(model_dir, ModelFile.TORCH_MODEL_FILE)
```

### Comparing `modelscope-1.6.1/modelscope/models/nlp/veco/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/veco/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/veco/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/veco/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/veco/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/veco/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/veco/fill_mask.py` & `modelscope-1.7.0/modelscope/models/nlp/veco/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/veco/text_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/veco/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/veco/token_classification.py` & `modelscope-1.7.0/modelscope/models/nlp/veco/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/xlm_roberta/__init__.py` & `modelscope-1.7.0/modelscope/models/nlp/xlm_roberta/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/xlm_roberta/backbone.py` & `modelscope-1.7.0/modelscope/models/nlp/xlm_roberta/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/nlp/xlm_roberta/configuration.py` & `modelscope-1.7.0/modelscope/models/nlp/xlm_roberta/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/config.py` & `modelscope-1.7.0/modelscope/models/science/unifold/config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/data/__init__.py` & `modelscope-1.7.0/modelscope/models/science/unifold/data/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/data/data_ops.py` & `modelscope-1.7.0/modelscope/models/science/unifold/data/data_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/data/msa_pairing.py` & `modelscope-1.7.0/modelscope/models/science/unifold/data/msa_pairing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/data/process.py` & `modelscope-1.7.0/modelscope/models/science/unifold/data/process.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/data/process_multimer.py` & `modelscope-1.7.0/modelscope/models/science/unifold/data/process_multimer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/data/protein.py` & `modelscope-1.7.0/modelscope/models/science/unifold/data/protein.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/data/residue_constants.py` & `modelscope-1.7.0/modelscope/models/science/unifold/data/residue_constants.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/data/utils.py` & `modelscope-1.7.0/modelscope/models/science/unifold/data/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/dataset.py` & `modelscope-1.7.0/modelscope/models/science/unifold/dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/model.py` & `modelscope-1.7.0/modelscope/models/science/unifold/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/alphafold.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/alphafold.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/attentions.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/attentions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/auxillary_heads.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/auxillary_heads.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/common.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/confidence.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/confidence.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/embedders.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/embedders.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/evoformer.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/evoformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/featurization.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/featurization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/frame.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/frame.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/structure_module.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/structure_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/template.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/template.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/modules/triangle_multiplication.py` & `modelscope-1.7.0/modelscope/models/science/unifold/modules/triangle_multiplication.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/mmcif.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/mmcif.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/msa_identifiers.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/msa_identifiers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/parsers.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/parsers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/pipeline.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/templates.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/templates.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/__init__.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/hhblits.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/hhblits.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/hhsearch.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/hhsearch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/hmmbuild.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/hmmbuild.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/hmmsearch.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/hmmsearch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/jackhmmer.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/jackhmmer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/kalign.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/kalign.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/tools/utils.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/tools/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/models/science/unifold/msa/utils.py` & `modelscope-1.7.0/modelscope/models/science/unifold/msa/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/auth/auth_config.py` & `modelscope-1.7.0/modelscope/msdatasets/auth/auth_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/context/dataset_context_config.py` & `modelscope-1.7.0/modelscope/msdatasets/context/dataset_context_config.py`

 * *Files 3% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 
     def __init__(self, dataset_name: Union[str, list], namespace: str,
                  version: str, subset_name: str, split: Union[str, list],
                  target: str, hub: Hubs, data_dir: str,
                  data_files: Union[str, Sequence[str],
                                    Mapping[str, Union[str, Sequence[str]]]],
                  download_mode: DownloadMode, cache_root_dir: str,
-                 use_streaming: bool, **kwargs):
+                 use_streaming: bool, stream_batch_size: int, **kwargs):
 
         self._download_config = None
         self._data_meta_config = None
         self._config_kwargs = kwargs
         self._dataset_version_cache_root_dir = None
         self._auth_config = None
 
@@ -38,14 +38,15 @@
         self.subset_name = subset_name
         self.split = split
         self.target = target
         self.data_dir = data_dir
         self.data_files = data_files
         self.cache_root_dir = cache_root_dir
         self.use_streaming = use_streaming
+        self.stream_batch_size = stream_batch_size
         self.download_virgo_files: bool = False
 
     @property
     def config_kwargs(self) -> dict:
         return self._config_kwargs
 
     @config_kwargs.setter
```

### Comparing `modelscope-1.6.1/modelscope/msdatasets/data_files/data_files_manager.py` & `modelscope-1.7.0/modelscope/msdatasets/data_files/data_files_manager.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,16 +9,16 @@
 from modelscope.msdatasets.context.dataset_context_config import \
     DatasetContextConfig
 from modelscope.msdatasets.download.dataset_builder import (
     CsvDatasetBuilder, IterableDatasetBuilder, TaskSpecificDatasetBuilder)
 from modelscope.msdatasets.download.download_config import DataDownloadConfig
 from modelscope.msdatasets.download.download_manager import (
     DataDownloadManager, DataStreamingDownloadManager)
-from modelscope.utils.constant import (DatasetPathName, DownloadMode,
-                                       MetaDataFields)
+from modelscope.utils.constant import (META_FILES_FORMAT, DatasetPathName,
+                                       DownloadMode, MetaDataFields)
 
 
 class DataFilesManager(object):
     """The modelscope data-files manager."""
 
     def __init__(self, dataset_context_config: DatasetContextConfig):
 
@@ -54,14 +54,15 @@
         # Get oss config
         api = HubApi()
         self.oss_config = api.get_dataset_access_config(
             self.dataset_name, self.namespace, self.version)
 
         # Set context. Note: no need to update context_config.
         download_config.oss_config = self.oss_config
+        download_config.num_proc = self.input_config_kwargs.get('num_proc', 4)
         dataset_context_config.download_config = download_config
         self.dataset_context_config = dataset_context_config
         os.makedirs(download_config.cache_dir, exist_ok=True)
 
     def get_data_files_builder(self) -> Union[DatasetBuilder, None]:
         """ Build download manager. """
 
@@ -80,15 +81,16 @@
         if not meta_data_file or meta_args_map_file.get(
                 MetaDataFields.ARGS_BIG_DATA):
             meta_args_map_file.update(self.input_config_kwargs)
             self.dataset_context_config.data_meta_config.meta_args_map = meta_args_map_file
 
             builder = TaskSpecificDatasetBuilder(
                 dataset_context_config=self.dataset_context_config)
-        elif meta_data_file.endswith('.csv'):
+        elif meta_data_file and os.path.splitext(
+                meta_data_file)[-1] in META_FILES_FORMAT:
             builder = CsvDatasetBuilder(
                 dataset_context_config=self.dataset_context_config)
         else:
             raise NotImplementedError(
                 f'Dataset meta file extensions "{os.path.splitext(meta_data_file)[-1]}" is not implemented yet'
             )
         return builder
```

### Comparing `modelscope-1.6.1/modelscope/msdatasets/data_loader/data_loader.py` & `modelscope-1.7.0/modelscope/msdatasets/data_loader/data_loader.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/data_loader/data_loader_manager.py` & `modelscope-1.7.0/modelscope/msdatasets/data_loader/data_loader_manager.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/builder.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/easycv_base.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/easycv_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py`

 * *Files 1% similar despite different names*

```diff
@@ -64,14 +64,14 @@
         with self.env.begin(write=False) as txn:
             imgbuf = txn.get(img_key.encode())
             buf = six.BytesIO()
             buf.write(imgbuf)
             buf.seek(0)
             img = Image.open(buf).convert('L')
             if self.reco_preprocess is not None:
-                img = self.reco_preprocess(img)
+                img = self.reco_preprocess(img)['image']
 
             label_key = 'label-%09d' % index
             label = txn.get(label_key.encode()).decode('utf-8')
             label = ''.join([Q2B(c) for c in label])
 
         return {'images': img, 'labels': label}
```

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/veco_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/veco_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/dataset_cls/dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/dataset_cls/dataset.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 
 import copy
 import os
 
 import datasets
 import pandas as pd
 from datasets import IterableDataset
+from tqdm import tqdm
 
 from modelscope.msdatasets.utils.maxcompute_utils import MaxComputeUtil
 from modelscope.utils.constant import (DEFAULT_MAXCOMPUTE_ENDPOINT,
                                        EXTENSIONS_TO_LOAD, MaxComputeEnvs,
                                        VirgoDatasetConfig)
 from modelscope.utils.logger import get_logger
 from modelscope.utils.url_utils import fetch_csv_with_url, valid_url
@@ -19,23 +20,26 @@
 
 class ExternalDataset(object):
     """Dataset class for custom datasets."""
 
     def __init__(self, split_path_dict, config_kwargs):
         self.split_path_dict = split_path_dict
         self.config_kwargs = copy.deepcopy(config_kwargs)
-        self.config_kwargs.update({'split_config': split_path_dict})
+        self.config_kwargs.update({'split_config': self.split_path_dict})
         # dataset for specific extensions
         self.spec_extension_dataset = None
-        self.split_data_files = {k: [] for k, _ in split_path_dict.items()}
+        self.split_data_files = {
+            k: []
+            for k, _ in self.split_path_dict.items()
+        }
         self.custom_map = {}
 
         # the extension of file
         file_ext = ''
-        for split_name, split_dir in split_path_dict.items():
+        for split_name, split_dir in self.split_path_dict.items():
             if isinstance(split_dir, str) and os.path.isdir(split_dir):
                 split_file_names = os.listdir(split_dir)
                 set_files_exts = set([
                     os.path.splitext(file_name)[-1].strip('.')
                     for file_name in split_file_names
                 ])
                 if '' in set_files_exts:
@@ -83,40 +87,70 @@
             for k, v in self.spec_extension_dataset.items():
                 yield k, v
 
 
 class NativeIterableDataset(IterableDataset):
     """The modelscope iterable dataset class."""
 
-    def __init__(self, ex_iterable, info, split):
+    def __init__(self, ex_iterable, info, split, stream_batch_size=1):
         super().__init__(ex_iterable=ex_iterable, info=info, split=split)
+        self.stream_batch_size = stream_batch_size
 
     def __iter__(self):
-        for key, entity in self._iter():
-            if isinstance(entity, dict):
-                ret = {}
-                for k, v in entity.items():
-                    ret[k] = v
-                    if k.endswith(':FILE'):
-                        dl_manager = self._ex_iterable.kwargs.get('dl_manager')
-                        ex_cache_path = dl_manager.download_and_extract(v)
-                        ret[k] = ex_cache_path
-                        if k.endswith('Image:FILE'):
-                            from PIL import Image
-                            ret[k + ':Object'] = Image.open(fp=ex_cache_path)
-                        if k.endswith('Audio:FILE'):
-                            import torchaudio
-                            waveform_and_rate = torchaudio.load(ex_cache_path)
-                            ret[k + ':Object'] = waveform_and_rate
-                entity = ret
+        for item in tqdm(
+                self.iter(
+                    batch_size=self.stream_batch_size, drop_last_batch=False),
+                desc='Overall progress',
+                total=self.n_shards,
+                dynamic_ncols=True):
+            ret = {}
+            if isinstance(item, dict):
+                try:
+                    for k, v in item.items():
+                        ret[k] = v
+                        if k.endswith(':FILE'):
+                            dl_manager = self._ex_iterable.kwargs.get(
+                                'dl_manager')
+                            ex_cache_path = dl_manager.download_and_extract(v)
+                            if isinstance(ex_cache_path, str):
+                                ex_cache_path = [ex_cache_path]
+                            ret[k] = ex_cache_path
+
+                except Exception as e:
+                    logger.error(e)
+                    ret = item
+            else:
+                ret = item
 
-            yield entity
+            yield ret
 
     def __len__(self):
-        return 1
+        return self.n_shards
+
+    def head(self, n=5):
+        """
+        Returns the first n rows of the dataset.
+
+        Args:
+            n (int): Number of rows to return.
+
+        Returns:
+            list: The list of results, e.g. [{'id': 'abc123', 'text': 'hello world'}, ...]
+        """
+        # return self._head(n=n)
+        res = []
+        if n <= 0:
+            return res
+        iter_num = 0
+        for item in self.__iter__():
+            if iter_num >= n:
+                break
+            res.append(item)
+            iter_num += 1
+        return res
 
 
 class VirgoDataset(object):
     """Dataset class for Virgo.
 
     Attributes:
         _meta_content (str): Virgo meta data content, could be a url that contains csv file.
```

### Comparing `modelscope-1.6.1/modelscope/msdatasets/download/dataset_builder.py` & `modelscope-1.7.0/modelscope/msdatasets/download/dataset_builder.py`

 * *Files 2% similar despite different names*

```diff
@@ -202,15 +202,15 @@
 
         target_cache_dir = dl_manager.download_config.cache_dir
         if download_mode == DownloadMode.FORCE_REDOWNLOAD.value:
             shutil.rmtree(target_cache_dir, ignore_errors=True)
             os.makedirs(target_cache_dir, exist_ok=True)
 
         self.local_meta_csv_paths = {
-            k: HubApi.fetch_csv_from_url(v, target_cache_dir)
+            k: HubApi.fetch_meta_files_from_url(v, target_cache_dir)
             for k, v in self.meta_data_files.items()
         }
 
         self.split_path_dict = dl_manager.download_and_extract(
             self.zip_data_files)
 
     def _convert_csv_to_dataset(self, split_name, csv_file_path):
@@ -297,14 +297,15 @@
         self.namespace = dataset_context_config.namespace
         self.version = dataset_context_config.version
         self.subset_name = dataset_context_config.subset_name
         self.split = dataset_context_config.split
         self.meta_data_files = dataset_context_config.data_meta_config.meta_data_files
         self.zip_data_files = dataset_context_config.data_meta_config.zip_data_files
         self.input_config_kwargs = dataset_context_config.config_kwargs
+        self.stream_batch_size = dataset_context_config.stream_batch_size
 
         self.cache_build_dir = os.path.join(self.cache_root_dir,
                                             self.namespace, self.dataset_name,
                                             self.version,
                                             DatasetPathName.META_NAME)
         self.csv_delimiter = DEFAULT_CSV_DELIMITER
         if DELIMITER_NAME in self.input_config_kwargs:
@@ -321,14 +322,17 @@
             hash=sub_dir_hash,
             data_files=None,  # TODO: self.meta_data_files,
             **self.input_config_kwargs)
 
         self.info.builder_name = self.dataset_name
         self.name = camelcase_to_snakecase(self.dataset_name)
 
+        self.meta_csv_df = None
+        self.meta_cache_dir = dataset_context_config.data_meta_config.meta_cache_dir
+
     @staticmethod
     def get_builder_instance(
             dataset_context_config: DatasetContextConfig) -> csv.Csv:
         builder_instance = IterableDatasetBuilder(
             dataset_context_config=dataset_context_config)
         return builder_instance
 
@@ -426,15 +430,18 @@
     def _as_streaming_dataset_single(
         self,
         splits_generator,
     ) -> NativeIterableDataset:
 
         ex_iterable = self._get_examples_iterable_for_split(splits_generator)
         return NativeIterableDataset(
-            ex_iterable, info=self.info, split=splits_generator.name)
+            ex_iterable,
+            info=self.info,
+            split=splits_generator.name,
+            stream_batch_size=self.stream_batch_size)
 
     def _generate_tables(self, **gen_kwargs):
 
         meta_file_url = gen_kwargs.get('meta')
         files = gen_kwargs.get('files')
         dl_manager = gen_kwargs.get('dl_manager')
 
@@ -445,42 +452,47 @@
         if files:
             zip_file = str(next(iter(files)))
             if zip_file.endswith('.zip'):
                 is_zip = True
                 zip_file_name = os.path.splitext(zip_file)[0]
 
         if meta_file_url and not files:
-            headers, texts = hub_api.fetch_single_csv_script(meta_file_url)
-            meta_csv_mapping = IterableDatasetBuilder.trans_data_to_mapping(
-                headers, texts, self.csv_delimiter)
-            pa_table = pa.Table.from_pydict(meta_csv_mapping)
+            self._get_meta_csv_df(meta_file_url)
+            pa_table = pa.Table.from_pandas(self.meta_csv_df)
             yield 0, pa_table
 
         elif meta_file_url and files:
             # Get meta file
-            headers, texts = hub_api.fetch_single_csv_script(meta_file_url)
-            meta_csv_mapping = IterableDatasetBuilder.trans_data_to_mapping(
-                headers, texts, self.csv_delimiter)
+            self._get_meta_csv_df(meta_file_url)
 
             if is_zip:
                 oss_config_for_unzipped = hub_api.get_dataset_access_config_for_unzipped(
                     self.dataset_name, self.namespace, self.version,
                     zip_file_name)
                 dl_manager.download_config.oss_config = oss_config_for_unzipped
 
-            pa_table = pa.Table.from_pydict(meta_csv_mapping)
+            pa_table = pa.Table.from_pandas(self.meta_csv_df)
             yield 0, pa_table
 
         elif not meta_file_url and files:
             pa_table = pa.Table.from_pydict({'Input:FILE': files})
             yield 0, pa_table
 
         else:
             raise f'Neither column meta nor data file found in {self.dataset_name}.json .'
 
+    def _get_meta_csv_df(self, meta_file_url: str) -> None:
+        if self.meta_csv_df is None or self.meta_csv_df.empty:
+            meta_csv_file_path = HubApi.fetch_meta_files_from_url(
+                meta_file_url, self.meta_cache_dir)
+            self.meta_csv_df = pd.read_csv(
+                meta_csv_file_path,
+                iterator=False,
+                delimiter=self.csv_delimiter)
+
     @staticmethod
     def trans_data_to_mapping(headers: str, texts: list, delimiter: str):
         res = {}
         headers = headers.split(delimiter)
         for idx in range(0, len(headers)):
             col_list = []
             for line in texts:
```

### Comparing `modelscope-1.6.1/modelscope/msdatasets/download/download_config.py` & `modelscope-1.7.0/modelscope/msdatasets/download/download_config.py`

 * *Files 4% similar despite different names*

```diff
@@ -11,10 +11,11 @@
         self.dataset_name: Optional[str] = None
         self.namespace: Optional[str] = None
         self.version: Optional[str] = None
         self.split: Optional[Union[str, list]] = None
         self.data_dir: Optional[str] = None
         self.oss_config: Optional[dict] = {}
         self.meta_args_map: Optional[dict] = {}
+        self.num_proc: int = 4
 
     def copy(self) -> 'DataDownloadConfig':
         return self
```

### Comparing `modelscope-1.6.1/modelscope/msdatasets/download/download_manager.py` & `modelscope-1.7.0/modelscope/msdatasets/download/download_manager.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/meta/data_meta_config.py` & `modelscope-1.7.0/modelscope/msdatasets/meta/data_meta_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/meta/data_meta_manager.py` & `modelscope-1.7.0/modelscope/msdatasets/meta/data_meta_manager.py`

 * *Files 1% similar despite different names*

```diff
@@ -126,15 +126,16 @@
         # Parse meta and get dataset structure
         if dataset_py_script:
             data_meta_config.dataset_py_script = dataset_py_script
         else:
             target_subset_name, target_dataset_structure = get_target_dataset_structure(
                 dataset_json, subset_name, split)
             meta_map, file_map, args_map, type_map = get_dataset_files(
-                target_dataset_structure, dataset_name, namespace, version)
+                target_dataset_structure, dataset_name, namespace,
+                self.dataset_context_config, version)
 
             data_meta_config.meta_data_files = meta_map
             data_meta_config.zip_data_files = file_map
             data_meta_config.meta_args_map = args_map
             data_meta_config.meta_type_map = type_map
             data_meta_config.target_dataset_structure = target_dataset_structure
```

### Comparing `modelscope-1.6.1/modelscope/msdatasets/ms_dataset.py` & `modelscope-1.7.0/modelscope/msdatasets/ms_dataset.py`

 * *Files 1% similar despite different names*

```diff
@@ -56,15 +56,16 @@
     general external web-hosted data and cloud storage such as OSS.
     """
     # the underlying huggingface Dataset
     _hf_ds = None
     _dataset_context_config: DatasetContextConfig = None
 
     def __init__(self,
-                 ds_instance: Union[Dataset, IterableDataset, ExternalDataset],
+                 ds_instance: Union[Dataset, IterableDataset, ExternalDataset,
+                                    NativeIterableDataset],
                  target: Optional[str] = None):
         self._hf_ds = ds_instance
         if target is not None and target not in self._hf_ds.features:
             raise TypeError(
                 f'"target" must be a column of the dataset({list(self._hf_ds.features.keys())}, but got {target}'
             )
         self.target = target
@@ -77,20 +78,14 @@
             else:
                 yield item
 
     def __getitem__(self, key):
         return self._hf_ds[key]
 
     def __len__(self):
-        if isinstance(self._hf_ds, IterableDataset) or isinstance(
-                self._hf_ds, NativeIterableDataset):
-            logger.warning(
-                f'object of type `{self._hf_ds.__class__.__name__}` has default length 1'
-            )
-            return 1
         return len(self._hf_ds)
 
     @property
     def ds_instance(self):
         return self._hf_ds
 
     @property
@@ -165,14 +160,15 @@
         data_files: Optional[Union[str, Sequence[str],
                                    Mapping[str, Union[str,
                                                       Sequence[str]]]]] = None,
         download_mode: Optional[DownloadMode] = DownloadMode.
         REUSE_DATASET_IF_EXISTS,
         cache_dir: Optional[str] = MS_DATASETS_CACHE,
         use_streaming: Optional[bool] = False,
+        stream_batch_size: Optional[int] = 1,
         custom_cfg: Optional[Config] = Config(),
         token: Optional[str] = None,
         **config_kwargs,
     ) -> Union[dict, 'MsDataset', NativeIterableDataset]:
         """Load a MsDataset from the ModelScope Hub, Hugging Face Hub, urls, or a local dataset.
 
             Args:
@@ -192,14 +188,15 @@
                 hub (Hubs or str, optional): When loading from a remote hub, where it is from. default Hubs.modelscope
                 download_mode (DownloadMode or str, optional): How to treat existing datasets. default
                                                                DownloadMode.REUSE_DATASET_IF_EXISTS
                 cache_dir (str, Optional): User-define local cache directory.
                 use_streaming (bool, Optional): If set to True, no need to download all data files.
                                                 Instead, it streams the data progressively, and returns
                                                 NativeIterableDataset or a dict of NativeIterableDataset.
+                stream_batch_size (int, Optional): The batch size of the streaming data.
                 custom_cfg (str, Optional): Model configuration, this can be used for custom datasets.
                                            see https://modelscope.cn/docs/Configuration%E8%AF%A6%E8%A7%A3
                 token (str, Optional): SDK token of ModelScope.
                 **config_kwargs (additional keyword arguments): Keyword arguments to be passed
 
             Returns:
                 MsDataset (MsDataset): MsDataset object for a certain dataset.
@@ -246,14 +243,15 @@
             target=target,
             hub=hub,
             data_dir=data_dir,
             data_files=data_files,
             download_mode=download_mode,
             cache_root_dir=cache_dir,
             use_streaming=use_streaming,
+            stream_batch_size=stream_batch_size,
             **config_kwargs)
 
         # Load from local disk
         if dataset_name in _PACKAGED_DATASETS_MODULES or os.path.isdir(
                 dataset_name) or os.path.isfile(dataset_name):
             dataset_inst = LocalDataLoaderManager(
                 dataset_context_config).load_dataset(
@@ -268,19 +266,20 @@
             return dataset_inst
         # Load from the huggingface hub
         elif hub == Hubs.huggingface:
             dataset_inst = RemoteDataLoaderManager(
                 dataset_context_config).load_dataset(
                     RemoteDataLoaderType.HF_DATA_LOADER)
             dataset_inst = MsDataset.to_ms_dataset(dataset_inst, target=target)
-            dataset_inst._dataset_context_config = dataset_context_config
-            if custom_cfg:
-                dataset_inst.to_custom_dataset(
-                    custom_cfg=custom_cfg, **config_kwargs)
-                dataset_inst.is_custom = True
+            if isinstance(dataset_inst, MsDataset):
+                dataset_inst._dataset_context_config = dataset_context_config
+                if custom_cfg:
+                    dataset_inst.to_custom_dataset(
+                        custom_cfg=custom_cfg, **config_kwargs)
+                    dataset_inst.is_custom = True
             return dataset_inst
         # Load from the modelscope hub
         elif hub == Hubs.modelscope:
             remote_dataloader_manager = RemoteDataLoaderManager(
                 dataset_context_config)
             dataset_inst = remote_dataloader_manager.load_dataset(
                 RemoteDataLoaderType.MS_DATA_LOADER)
@@ -650,15 +649,15 @@
                 self.columns = columns
 
             def __len__(self):
                 return len(self.dataset)
 
             def type_converter(self, x):
                 if self.to_tensor:
-                    return torch.tensor(x)
+                    return torch.as_tensor(x)
                 else:
                     return x
 
             def __getitem__(self, index):
                 item_dict = self.dataset[index]
                 res = {
                     k: self.type_converter(item_dict[k])
```

### Comparing `modelscope-1.6.1/modelscope/msdatasets/task_datasets/__init__.py` & `modelscope-1.7.0/modelscope/msdatasets/task_datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/utils/dataset_utils.py` & `modelscope-1.7.0/modelscope/msdatasets/utils/dataset_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,18 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
 import os
 from collections import defaultdict
 from typing import Optional, Union
 
+import pandas as pd
+
 from modelscope.hub.api import HubApi
+from modelscope.msdatasets.context.dataset_context_config import \
+    DatasetContextConfig
 from modelscope.utils.constant import DEFAULT_DATASET_REVISION, MetaDataFields
 from modelscope.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def format_dataset_structure(dataset_structure):
@@ -165,14 +169,15 @@
 
     return res
 
 
 def get_dataset_files(subset_split_into: dict,
                       dataset_name: str,
                       namespace: str,
+                      context_config: DatasetContextConfig,
                       revision: Optional[str] = DEFAULT_DATASET_REVISION):
     """
     Return:
         meta_map: Structure of meta files (.csv), the meta file name will be replaced by url, like
         {
            "test": "https://xxx/mytest.csv"
         }
@@ -182,38 +187,46 @@
         }
     """
     meta_map = defaultdict(dict)
     file_map = defaultdict(dict)
     args_map = defaultdict(dict)
     custom_type_map = defaultdict(dict)
     modelscope_api = HubApi()
+    meta_cache_dir = context_config.data_meta_config.meta_cache_dir
 
     for split, info in subset_split_into.items():
         custom_type_map[split] = info.get('custom', '')
         meta_map[split] = modelscope_api.get_dataset_file_url(
             info.get('meta', ''), dataset_name, namespace, revision)
         if info.get('file'):
             file_map[split] = info['file']
         args_map[split] = info.get('args')
 
     objects = []
     # If `big_data` is true, then fetch objects from meta-csv file directly.
     for split, args_dict in args_map.items():
         if args_dict and args_dict.get(MetaDataFields.ARGS_BIG_DATA):
             meta_csv_file_url = meta_map[split]
-            _, script_content = modelscope_api.fetch_single_csv_script(
-                meta_csv_file_url)
-            if not script_content:
-                raise 'Meta-csv file cannot be empty when meta-args `big_data` is true.'
-            for item in script_content:
-                if not item:
-                    continue
-                item = item.strip().split(',')[0]
-                if item:
-                    objects.append(item)
+
+            meta_csv_file_path = HubApi.fetch_meta_files_from_url(
+                meta_csv_file_url, meta_cache_dir)
+
+            csv_delimiter = context_config.config_kwargs.get('delimiter', ',')
+            csv_df = pd.read_csv(
+                meta_csv_file_path, iterator=False, delimiter=csv_delimiter)
+            target_col = csv_df.columns[csv_df.columns.str.contains(
+                ':FILE')].to_list()
+            if len(target_col) == 0:
+                logger.error(
+                    f'No column contains ":FILE" in {meta_csv_file_path}.')
+                target_col = csv_df.columns[0]
+            else:
+                target_col = target_col[0]
+            objects = csv_df[target_col].to_list()
+
             file_map[split] = objects
     # More general but low-efficiency.
     if not objects:
         objects = list_dataset_objects(
             hub_api=modelscope_api,
             max_limit=-1,
             is_recursive=True,
```

### Comparing `modelscope-1.6.1/modelscope/msdatasets/utils/delete_utils.py` & `modelscope-1.7.0/modelscope/msdatasets/utils/delete_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/utils/maxcompute_utils.py` & `modelscope-1.7.0/modelscope/msdatasets/utils/maxcompute_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/msdatasets/utils/oss_utils.py` & `modelscope-1.7.0/modelscope/msdatasets/utils/oss_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -113,15 +113,16 @@
                         progress_callback=self._percentage,
                         num_threads=self.num_threads)
                 break
             except Exception as e:
                 if e.__dict__.get('status') == 403:
                     self._reload_sts()
                 if retry_count >= self.max_retries:
-                    raise
+                    logger.warning(f'Failed to download {oss_file_name}')
+                    raise e
 
         return local_path
 
     def upload(self, oss_object_name: str, local_file_path: str,
                indicate_individual_progress: bool,
                upload_mode: UploadMode) -> str:
         retry_count = 0
```

### Comparing `modelscope-1.6.1/modelscope/msdatasets/utils/upload_utils.py` & `modelscope-1.7.0/modelscope/msdatasets/utils/upload_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/ops/ailut/pyinterfaces.py` & `modelscope-1.7.0/modelscope/ops/ailut/pyinterfaces.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/ops/quadtree_attention/functions/quadtree_attention.py` & `modelscope-1.7.0/modelscope/ops/quadtree_attention/functions/quadtree_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/ops/quadtree_attention/modules/quadtree_attention.py` & `modelscope-1.7.0/modelscope/ops/quadtree_attention/modules/quadtree_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/outputs/cv_outputs.py` & `modelscope-1.7.0/modelscope/outputs/cv_outputs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/outputs/nlp_outputs.py` & `modelscope-1.7.0/modelscope/outputs/nlp_outputs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/outputs/outputs.py` & `modelscope-1.7.0/modelscope/outputs/outputs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipeline_inputs.py` & `modelscope-1.7.0/modelscope/pipeline_inputs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/__init__.py` & `modelscope-1.7.0/modelscope/pipelines/audio/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/ans_dfsmn_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/ans_dfsmn_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -66,15 +66,16 @@
         def stft(x):
             return torch.stft(
                 x,
                 N_FFT,
                 HOP_LENGTH,
                 STFT_WIN_LEN,
                 center=False,
-                window=window)
+                window=window,
+                return_complex=False)
 
         def istft(x, slen):
             return librosa.istft(
                 x,
                 hop_length=HOP_LENGTH,
                 win_length=STFT_WIN_LEN,
                 window=WINDOW_NAME_HAM,
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/ans_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/ans_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/asr_inference_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/asr_inference_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -123,15 +123,15 @@
         from funasr.bin import asr_inference_launch
         self.funasr_infer_modelscope = asr_inference_launch.inference_launch(
             mode=self.cmd['mode'],
             maxlenratio=self.cmd['maxlenratio'],
             minlenratio=self.cmd['minlenratio'],
             batch_size=self.cmd['batch_size'],
             beam_size=self.cmd['beam_size'],
-            ngpu=self.cmd['ngpu'],
+            ngpu=ngpu,
             ctc_weight=self.cmd['ctc_weight'],
             lm_weight=self.cmd['lm_weight'],
             penalty=self.cmd['penalty'],
             log_level=self.cmd['log_level'],
             asr_train_config=self.cmd['asr_train_config'],
             asr_model_file=self.cmd['asr_model_file'],
             cmvn_file=self.cmd['cmvn_file'],
@@ -383,16 +383,17 @@
             'vad_cmvn_file',
             'punc_model_file',
             'punc_infer_config',
             'param_dict',
         ]
 
         for user_args in user_args_dict:
-            if user_args in extra_args and extra_args[user_args] is not None:
-                cmd[user_args] = extra_args[user_args]
+            if user_args in extra_args:
+                if extra_args.get(user_args) is not None:
+                    cmd[user_args] = extra_args[user_args]
                 del extra_args[user_args]
 
         return cmd
 
     def load_vad_model(self, cmd):
         if self.vad_model is not None and self.vad_model != '':
             if os.path.exists(self.vad_model):
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/asr_wenet_inference_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/asr_wenet_inference_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/inverse_text_processing_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/inverse_text_processing_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/kws_farfield_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/kws_farfield_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/kws_kwsbp_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/kws_kwsbp_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/linear_aec_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/linear_aec_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -78,26 +78,27 @@
 
         n_fft = self.config['loss']['args']['n_fft']
         hop_length = self.config['loss']['args']['hop_length']
         winlen = n_fft
         window = torch.hamming_window(winlen, periodic=False)
 
         def stft(x):
-            return torch.stft(
-                x,
-                n_fft,
-                hop_length,
-                winlen,
-                center=False,
-                window=window.to(x.device),
-                return_complex=False)
+            return torch.view_as_real(
+                torch.stft(
+                    x,
+                    n_fft,
+                    hop_length,
+                    winlen,
+                    center=False,
+                    window=window.to(x.device),
+                    return_complex=True))
 
         def istft(x, slen):
             return torch.istft(
-                x,
+                torch.view_as_complex(x),
                 n_fft,
                 hop_length,
                 winlen,
                 window=window.to(x.device),
                 center=False,
                 length=slen)
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/lm_infer_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/lm_infer_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -76,15 +76,15 @@
         self.cmd = self.get_cmd(config_path, kwargs, model)
 
         from funasr.bin import lm_inference_launch
         self.funasr_infer_modelscope = lm_inference_launch.inference_launch(
             mode=self.cmd['mode'],
             batch_size=self.cmd['batch_size'],
             dtype=self.cmd['dtype'],
-            ngpu=self.cmd['ngpu'],
+            ngpu=ngpu,
             seed=self.cmd['seed'],
             num_workers=self.cmd['num_workers'],
             log_level=self.cmd['log_level'],
             key_file=self.cmd['key_file'],
             train_config=self.cmd['train_config'],
             model_file=self.cmd['model_file'],
             log_base=self.cmd['log_base'],
@@ -188,16 +188,17 @@
             'split_with_space',
             'seg_dict_file',
             'output_dir',
             'param_dict',
         ]
 
         for user_args in user_args_dict:
-            if user_args in extra_args and extra_args[user_args] is not None:
-                cmd[user_args] = extra_args[user_args]
+            if user_args in extra_args:
+                if extra_args.get(user_args) is not None:
+                    cmd[user_args] = extra_args[user_args]
                 del extra_args[user_args]
 
         return cmd
 
     def forward(self, text_in: str = None) -> list:
         """Decoding
         """
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/punctuation_processing_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/punctuation_processing_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -50,15 +50,15 @@
         self.cmd = self.get_cmd(kwargs, model)
 
         from funasr.bin import punc_inference_launch
         self.funasr_infer_modelscope = punc_inference_launch.inference_launch(
             mode=self.cmd['mode'],
             batch_size=self.cmd['batch_size'],
             dtype=self.cmd['dtype'],
-            ngpu=self.cmd['ngpu'],
+            ngpu=ngpu,
             seed=self.cmd['seed'],
             num_workers=self.cmd['num_workers'],
             log_level=self.cmd['log_level'],
             key_file=self.cmd['key_file'],
             train_config=self.cmd['train_config'],
             model_file=self.cmd['model_file'],
             output_dir=self.cmd['output_dir'],
@@ -140,16 +140,17 @@
             'model_file',
             'output_dir',
             'lang',
             'param_dict',
         ]
 
         for user_args in user_args_dict:
-            if user_args in extra_args and extra_args[user_args] is not None:
-                cmd[user_args] = extra_args[user_args]
+            if user_args in extra_args:
+                if extra_args.get(user_args) is not None:
+                    cmd[user_args] = extra_args[user_args]
                 del extra_args[user_args]
 
         return cmd
 
     def forward(self, text_in: str = None) -> list:
         """Decoding
         """
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/separation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/separation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/speaker_change_locating_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/speaker_change_locating_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 
 import io
 from typing import Any, Dict, List, Union
 
 import numpy as np
 import soundfile as sf
 import torch
+import torchaudio
 
 from modelscope.fileio import File
 from modelscope.metainfo import Pipelines
 from modelscope.outputs import OutputKeys
 from modelscope.pipelines.base import InputModel, Pipeline
 from modelscope.pipelines.builder import PIPELINES
 from modelscope.utils.constant import Tasks
@@ -42,18 +43,22 @@
     def __init__(self, model: InputModel, **kwargs):
         """use `model` to create a speaker change Locating pipeline for prediction
         Args:
             model (str): a valid offical model id
         """
         super().__init__(model=model, **kwargs)
         self.model_config = self.model.model_config
-        self.config = self.model.model_config
-        self.anchor_size = self.config['anchor_size']
+        self.anchor_size = self.model_config['anchor_size']
 
-    def __call__(self, audio: str, embds: List = None) -> Dict[str, Any]:
+    def __call__(
+        self,
+        audio: Union[str, np.ndarray],
+        embds: Union[list, np.ndarray] = None,
+        output_res=False,
+    ):
         if embds is not None:
             assert len(embds) == 2
             assert isinstance(embds[0], np.ndarray) and isinstance(
                 embds[1], np.ndarray)
             assert embds[0].shape == (
                 self.anchor_size, ) and embds[1].shape == (self.anchor_size, )
         else:
@@ -61,45 +66,62 @@
             embd2 = np.ones(self.anchor_size - self.anchor_size // 2)
             embd3 = np.ones(self.anchor_size // 2)
             embd4 = np.zeros(self.anchor_size - self.anchor_size // 2)
             embds = [
                 np.stack([embd1, embd2], axis=1).flatten(),
                 np.stack([embd3, embd4], axis=1).flatten(),
             ]
-        anchors = torch.from_numpy(np.stack(embds,
-                                            axis=0)).float().unsqueeze(0)
+        if isinstance(embds, list):
+            anchors = np.stack(embds, axis=0)
+        anchors = torch.from_numpy(anchors).unsqueeze(0).float()
 
         output = self.preprocess(audio)
         output = self.forward(output, anchors)
-        output = self.postprocess(output)
+        output, p = self.postprocess(output)
 
-        return output
+        if output_res:
+            return output, p
+        else:
+            return output
 
     def forward(self, input: torch.Tensor, anchors: torch.Tensor):
         output = self.model(input, anchors)
         return output
 
-    def postprocess(self, input: torch.Tensor) -> Dict[str, Any]:
+    def postprocess(self, input: torch.Tensor):
         predict = np.where(np.diff(input.argmax(-1).numpy()))
         try:
             predict = predict[0][0] * 0.01 + 0.02
             predict = round(predict, 2)
-            return {OutputKeys.TEXT: f'The change point is at {predict}s.'}
+            return {
+                OutputKeys.TEXT: f'The change point is at {predict}s.'
+            }, predict
         except Exception:
-            return {OutputKeys.TEXT: 'No change point is found.'}
+            return {OutputKeys.TEXT: 'No change point is found.'}, None
 
-    def preprocess(self, input: str) -> torch.Tensor:
+    def preprocess(self, input: Union[str, np.ndarray]) -> torch.Tensor:
         if isinstance(input, str):
             file_bytes = File.read(input)
             data, fs = sf.read(io.BytesIO(file_bytes), dtype='float32')
             if len(data.shape) == 2:
                 data = data[:, 0]
-            if fs != self.model_config['sample_rate']:
-                raise ValueError(
-                    'modelscope error: Only support %d sample rate files'
-                    % self.model_cfg['sample_rate'])
             data = torch.from_numpy(data).unsqueeze(0)
+            if fs != self.model_config['sample_rate']:
+                logger.warning(
+                    'The sample rate of audio is not %d, resample it.'
+                    % self.model_config['sample_rate'])
+                data, fs = torchaudio.sox_effects.apply_effects_tensor(
+                    data,
+                    fs,
+                    effects=[['rate',
+                              str(self.model_config['sample_rate'])]])
+        elif isinstance(input, np.ndarray):
+            if input.dtype in ['int16', 'int32', 'int64']:
+                input = (input / (1 << 15)).astype('float32')
+            data = torch.from_numpy(input)
+            if len(data.shape) == 1:
+                data = data.unsqueeze(0)
         else:
             raise ValueError(
-                'modelscope error: The input type is restricted to audio file address'
-                % i)
+                'modelscope error: The input type is restricted to audio file address and numpy array.'
+            )
         return data
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/speaker_diarization_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/speaker_diarization_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -73,15 +73,15 @@
 
         from funasr.bin import diar_inference_launch
         self.funasr_infer_modelscope = diar_inference_launch.inference_launch(
             mode=self.cmd['mode'],
             output_dir=self.cmd['output_dir'],
             batch_size=self.cmd['batch_size'],
             dtype=self.cmd['dtype'],
-            ngpu=self.cmd['ngpu'],
+            ngpu=ngpu,
             seed=self.cmd['seed'],
             num_workers=self.cmd['num_workers'],
             log_level=self.cmd['log_level'],
             key_file=self.cmd['key_file'],
             diar_train_config=self.cmd['diar_train_config'],
             diar_model_file=self.cmd['diar_model_file'],
             model_tag=self.cmd['model_tag'],
@@ -195,20 +195,21 @@
             self.sv_model = model_config['sv_model']
         if model_config.__contains__('sv_model_revision'):
             self.sv_model_revision = model_config['sv_model_revision']
         self.load_sv_model(cmd)
 
         # rewrite the config with user args
         for user_args in user_args_dict:
-            if user_args in extra_args and extra_args[user_args] is not None:
-                if isinstance(cmd[user_args], dict) and isinstance(
-                        extra_args[user_args], dict):
-                    cmd[user_args].update(extra_args[user_args])
-                else:
-                    cmd[user_args] = extra_args[user_args]
+            if user_args in extra_args:
+                if extra_args.get(user_args) is not None:
+                    if isinstance(cmd[user_args], dict) and isinstance(
+                            extra_args[user_args], dict):
+                        cmd[user_args].update(extra_args[user_args])
+                    else:
+                        cmd[user_args] = extra_args[user_args]
                 del extra_args[user_args]
 
         return cmd
 
     def load_sv_model(self, cmd):
         if self.sv_model is not None and self.sv_model != '':
             if os.path.exists(self.sv_model):
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/speaker_verification_light_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py`

 * *Files 3% similar despite different names*

```diff
@@ -12,20 +12,19 @@
 from modelscope.pipelines.base import InputModel, Pipeline
 from modelscope.pipelines.builder import PIPELINES
 from modelscope.utils.constant import Tasks
 from modelscope.utils.logger import get_logger
 
 logger = get_logger()
 
-__all__ = ['SpeakerVerificationPipeline']
-
 
 @PIPELINES.register_module(
-    Tasks.speaker_verification, module_name=Pipelines.speaker_verification)
-class SpeakerVerificationPipeline(Pipeline):
+    Tasks.speaker_verification,
+    module_name=Pipelines.speaker_verification_rdino)
+class RDINO_Pipeline(Pipeline):
     """Speaker Verification Inference Pipeline
     use `model` to create a Speaker Verification pipeline.
 
     Args:
         model (SpeakerVerificationPipeline): A model instance, or a model local dir, or a model id in the model hub.
         kwargs (dict, `optional`):
             Extra kwargs passed into the pipeline's constructor.
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/speaker_verification_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/speaker_verification_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -53,15 +53,15 @@
 
         from funasr.bin import sv_inference_launch
         self.funasr_infer_modelscope = sv_inference_launch.inference_launch(
             mode=self.cmd['mode'],
             output_dir=self.cmd['output_dir'],
             batch_size=self.cmd['batch_size'],
             dtype=self.cmd['dtype'],
-            ngpu=self.cmd['ngpu'],
+            ngpu=ngpu,
             seed=self.cmd['seed'],
             num_workers=self.cmd['num_workers'],
             log_level=self.cmd['log_level'],
             key_file=self.cmd['key_file'],
             sv_train_config=self.cmd['sv_train_config'],
             sv_model_file=self.cmd['sv_model_file'],
             model_tag=self.cmd['model_tag'],
@@ -162,20 +162,21 @@
                     cmd[user_args].update(
                         self.model_cfg['model_config'][user_args])
                 else:
                     cmd[user_args] = self.model_cfg['model_config'][user_args]
 
         # rewrite the config with user args
         for user_args in user_args_dict:
-            if user_args in extra_args and extra_args[user_args] is not None:
-                if isinstance(cmd[user_args], dict) and isinstance(
-                        extra_args[user_args], dict):
-                    cmd[user_args].update(extra_args[user_args])
-                else:
-                    cmd[user_args] = extra_args[user_args]
+            if user_args in extra_args:
+                if extra_args.get(user_args) is not None:
+                    if isinstance(cmd[user_args], dict) and isinstance(
+                            extra_args[user_args], dict):
+                        cmd[user_args].update(extra_args[user_args])
+                    else:
+                        cmd[user_args] = extra_args[user_args]
                 del extra_args[user_args]
 
         return cmd
 
     def forward(self, audio_in: Union[tuple, str, Any] = None) -> list:
         """Decoding
         """
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_quality_assessment_degradation_pipeline.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,110 +1,95 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
+import math
+import tempfile
+from typing import Any, Dict, Optional, Union
 
-import io
-from typing import Any, Dict, List, Union
-
-import soundfile as sf
+import cv2
+import numpy as np
 import torch
+from torchvision import transforms
 
-from modelscope.fileio import File
 from modelscope.metainfo import Pipelines
+from modelscope.models.cv.image_quality_assessment_degradation import \
+    ImageQualityAssessmentDegradation
 from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import InputModel, Pipeline
+from modelscope.pipelines.base import Input, Pipeline
 from modelscope.pipelines.builder import PIPELINES
+from modelscope.preprocessors import LoadImage
 from modelscope.utils.constant import Tasks
 from modelscope.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.speaker_verification,
-    module_name=Pipelines.speaker_verification_rdino)
-class RDINO_Pipeline(Pipeline):
-    """Speaker Verification Inference Pipeline
-    use `model` to create a Speaker Verification pipeline.
-
-    Args:
-        model (SpeakerVerificationPipeline): A model instance, or a model local dir, or a model id in the model hub.
-        kwargs (dict, `optional`):
-            Extra kwargs passed into the pipeline's constructor.
-    Example:
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
-    >>> p = pipeline(
-    >>>    task=Tasks.speaker_verification, model='damo/speech_ecapa-tdnn_sv_en_voxceleb_16k')
-    >>> print(p([audio_1, audio_2]))
+    Tasks.image_quality_assessment_degradation,
+    module_name=Pipelines.image_quality_assessment_degradation)
+class ImageQualityAssessmentDegradationPipeline(Pipeline):
+    """ Image Quality Assessment Degradation Pipeline which will return mean option score for the input image.
+
+        Example:
+
+        ```python
+        >>> from modelscope.pipelines import pipeline
+        >>> from modelscope.outputs import OutputKeys
+        >>> from modelscope.utils.constant import Tasks
+
+        >>> test_image = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/dogs.jpg'
+        >>> assessment_predictor = pipeline(Tasks.image_quality_assessment_degradation, \
+            model='damo/cv_resnet50_image-quality-assessment_degradation')
+        >>> out_res = assessment_predictor(test_image)[OutputKeys.SCORES]
+        >>> print('Pipeline: the output noise degree is {}, the output blur degree is {}, \
+                the output compression degree is {}'.format(out_res[0], out_res[1], out_res[2]))
 
-    """
+        ```
+        """
 
-    def __init__(self, model: InputModel, **kwargs):
-        """use `model` to create a speaker verification pipeline for prediction
+    def __init__(self, model: Union[ImageQualityAssessmentDegradation, str],
+                 **kwargs):
+        """
+        use `model` to create image quality assessment degradation pipeline for prediction
         Args:
-            model (str): a valid offical model id
+            model: model id on modelscope hub or `ImageQualityAssessmentDegradation` Model.
+            preprocessor: preprocessor for input image
+
         """
         super().__init__(model=model, **kwargs)
-        self.model_config = self.model.model_config
-        self.config = self.model.other_config
-        self.thr = self.config['yesOrno_thr']
-
-    def __call__(self,
-                 in_audios: List[str],
-                 thr: float = None) -> Dict[str, Any]:
-        if thr is not None:
-            self.thr = thr
-        if self.thr < -1 or self.thr > 1:
-            raise ValueError(
-                'modelscope error: the thr value should be in [-1, 1], but found to be %f.'
-                % self.thr)
-        outputs = self.preprocess(in_audios)
-        outputs = self.forward(outputs)
-        outputs = self.postprocess(outputs)
-
-        return outputs
-
-    def forward(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        emb1 = self.model(inputs['data1'])
-        emb2 = self.model(inputs['data2'])
 
-        return {'emb1': emb1, 'emb2': emb2}
-
-    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        score = self.compute_cos_similarity(inputs['emb1'], inputs['emb2'])
-        score = round(score, 5)
-        if score >= self.thr:
-            ans = 'yes'
+        if torch.cuda.is_available():
+            self._device = torch.device('cuda')
         else:
-            ans = 'no'
+            self._device = torch.device('cpu')
+
+        logger.info('load vqa-degradation model done')
 
-        return {OutputKeys.SCORE: score, OutputKeys.TEXT: ans}
+    def preprocess(self, input: Input) -> Dict[str, Any]:
+        img = LoadImage.convert_to_img(input)
+        w, h = img.size
+        if h * w < 1280 * 720:
+            img = transforms.functional.resize(img, 720)
+        test_transforms = transforms.Compose([transforms.ToTensor()])
+        img = test_transforms(img).unsqueeze(0)
+        result = {'src': img.to(self._device)}
+        return result
 
-    def preprocess(self, inputs: List[str],
-                   **preprocess_params) -> Dict[str, Any]:
-        if len(inputs) != 2:
-            raise ValueError(
-                'modelscope error: Two input audio files are required.')
-        output = {}
-        for i in range(len(inputs)):
-            if isinstance(inputs[i], str):
-                file_bytes = File.read(inputs[i])
-                data, fs = sf.read(io.BytesIO(file_bytes), dtype='float32')
-                if len(data.shape) == 2:
-                    data = data[:, 0]
-                if fs != self.model_config['sample_rate']:
-                    raise ValueError(
-                        'modelscope error: Only support %d sample rate files'
-                        % self.model_cfg['sample_rate'])
-                output['data%d' %
-                       (i + 1)] = torch.from_numpy(data).unsqueeze(0)
-            else:
-                raise ValueError(
-                    'modelscope error: The input type is temporarily restricted to audio file address'
-                    % i)
-        return output
-
-    def compute_cos_similarity(self, emb1: torch.Tensor,
-                               emb2: torch.Tensor) -> float:
-        assert len(emb1.shape) == 2 and len(emb2.shape) == 2
-        cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)
-        cosine = cos(emb1, emb2)
-        return cosine.item()
+    @torch.no_grad()
+    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
+        """
+        inference for image quality assessment degradation prediction
+        Args:
+            input: dict including torch tensor.
+
+        """
+        outputs = self.model._inference_forward(input['src'])
+        noise_degree, blur_degree, comp_degree = outputs['noise_degree'].cpu(
+        ), outputs['blur_degree'].cpu(), outputs['comp_degree'].cpu()
+        return {
+            OutputKeys.SCORES:
+            [noise_degree.item(),
+             blur_degree.item(),
+             comp_degree.item()],
+            OutputKeys.LABELS: ['噪声强度', '模糊程度', '压缩强度']
+        }
+
+    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
+        return inputs
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/text_to_speech_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/text_to_speech_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/timestamp_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/timestamp_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -71,15 +71,15 @@
         self.cmd = self.get_cmd(config_path, kwargs, model)
 
         from funasr.bin import tp_inference_launch
         self.funasr_infer_modelscope = tp_inference_launch.inference_launch(
             mode=self.cmd['mode'],
             batch_size=self.cmd['batch_size'],
             dtype=self.cmd['dtype'],
-            ngpu=self.cmd['ngpu'],
+            ngpu=ngpu,
             seed=self.cmd['seed'],
             num_workers=self.cmd['num_workers'],
             log_level=self.cmd['log_level'],
             key_file=self.cmd['key_file'],
             timestamp_infer_config=self.cmd['timestamp_infer_config'],
             timestamp_model_file=self.cmd['timestamp_model_file'],
             timestamp_cmvn_file=self.cmd['timestamp_cmvn_file'],
@@ -263,16 +263,17 @@
             'num_workers',
             'log_level',
             'split_with_space',
             'seg_dict_file',
         ]
 
         for user_args in user_args_dict:
-            if user_args in extra_args and extra_args[user_args] is not None:
-                cmd[user_args] = extra_args[user_args]
+            if user_args in extra_args:
+                if extra_args.get(user_args) is not None:
+                    cmd[user_args] = extra_args[user_args]
                 del extra_args[user_args]
 
         return cmd
 
     def forward(self, audio_in: Dict[str, Any], text_in: Dict[str, Any],
                 **kwargs) -> Dict[str, Any]:
         """Decoding
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/audio/voice_activity_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/audio/voice_activity_detection_pipeline.py`

 * *Files 0% similar despite different names*

```diff
@@ -52,15 +52,15 @@
         self.cmd = self.get_cmd(config_path, kwargs, model)
 
         from funasr.bin import vad_inference_launch
         self.funasr_infer_modelscope = vad_inference_launch.inference_launch(
             mode=self.cmd['mode'],
             batch_size=self.cmd['batch_size'],
             dtype=self.cmd['dtype'],
-            ngpu=self.cmd['ngpu'],
+            ngpu=ngpu,
             seed=self.cmd['seed'],
             num_workers=self.cmd['num_workers'],
             log_level=self.cmd['log_level'],
             key_file=self.cmd['key_file'],
             vad_infer_config=self.cmd['vad_infer_config'],
             vad_model_file=self.cmd['vad_model_file'],
             vad_cmvn_file=self.cmd['vad_cmvn_file'],
@@ -208,16 +208,17 @@
 
         user_args_dict = [
             'output_dir', 'batch_size', 'mode', 'ngpu', 'param_dict',
             'num_workers', 'fs'
         ]
 
         for user_args in user_args_dict:
-            if user_args in extra_args and extra_args[user_args] is not None:
-                cmd[user_args] = extra_args[user_args]
+            if user_args in extra_args:
+                if extra_args.get(user_args) is not None:
+                    cmd[user_args] = extra_args[user_args]
                 del extra_args[user_args]
 
         return cmd
 
     def forward(self, audio_in: Dict[str, Any], **kwargs) -> Dict[str, Any]:
         """Decoding
         """
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/base.py` & `modelscope-1.7.0/modelscope/pipelines/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -50,15 +50,16 @@
         if isinstance(model, str) and is_official_hub_path(model):
             logger.info(f'initiate model from location {model}.')
             # expecting model has been prefetched to local cache beforehand
             return Model.from_pretrained(
                 model,
                 device=self.device_name,
                 model_prefetched=True,
-                invoked_by=Invoke.PIPELINE) if is_model(model) else model
+                invoked_by=Invoke.PIPELINE,
+                device_map=self.device_map) if is_model(model) else model
         else:
             return model
 
     def initiate_multiple_models(self, input_models: List[InputModel]):
         models = []
         for model in input_models:
             models.append(self.initiate_single_model(model))
@@ -66,14 +67,15 @@
 
     def __init__(self,
                  config_file: str = None,
                  model: Union[InputModel, List[InputModel]] = None,
                  preprocessor: Union[Preprocessor, List[Preprocessor]] = None,
                  device: str = 'gpu',
                  auto_collate=True,
+                 device_map=None,
                  **kwargs):
         """ Base class for pipeline.
 
         If config_file is provided, model and preprocessor will be
         instantiated from corresponding config. Otherwise, model
         and preprocessor will be constructed separately.
 
@@ -83,14 +85,17 @@
             preprocessor: (list of) Preprocessor object
             device (str): device str, should be either cpu, cuda, gpu, gpu:X or cuda:X
             auto_collate (bool): automatically to convert data to tensor or not.
             compile (bool, optional): Compile the model with torch 2.0, default False
             compile_options (dict, optional): The compile options if compile=True,
                 default None to use the default params of 'TorchModel.compile'.
         """
+        if device_map is not None:
+            assert device == 'gpu', '`device` and `device_map` cannot be input at the same time!'
+        self.device_map = device_map
         verify_device(device)
         self.device_name = device
 
         if not isinstance(model, List):
             self.model = self.initiate_single_model(model)
             self.models = [self.model]
         else:
@@ -129,21 +134,22 @@
 
     def prepare_model(self):
         """ Place model on certain device for pytorch models before first inference
         """
         self._model_prepare_lock.acquire(timeout=600)
 
         def _prepare_single(model):
-            if isinstance(model, torch.nn.Module):
+            if not isinstance(model, torch.nn.Module) and hasattr(
+                    model, 'model'):
+                model = model.model
+            if not isinstance(model, torch.nn.Module):
+                return
+            model.eval()
+            if self.device_map is None:
                 model.to(self.device)
-                model.eval()
-            elif hasattr(model, 'model') and isinstance(
-                    model.model, torch.nn.Module):
-                model.model.to(self.device)
-                model.model.eval()
 
         if not self._model_prepare:
             # prepare model for pytorch
             if self.framework == Frameworks.torch:
                 if self.has_multiple_models:
                     for m in self.models:
                         _prepare_single(m)
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/builder.py` & `modelscope-1.7.0/modelscope/pipelines/builder.py`

 * *Files 14% similar despite different names*

```diff
@@ -3,46 +3,49 @@
 import os
 from typing import List, Optional, Union
 
 from modelscope.hub.snapshot_download import snapshot_download
 from modelscope.metainfo import DEFAULT_MODEL_FOR_PIPELINE, Pipelines
 from modelscope.models.base import Model
 from modelscope.utils.config import ConfigDict, check_config
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION, Invoke
+from modelscope.utils.constant import (DEFAULT_MODEL_REVISION, Invoke,
+                                       ThirdParty)
 from modelscope.utils.hub import read_config
 from modelscope.utils.plugins import (register_modelhub_repo,
                                       register_plugins_repo)
 from modelscope.utils.registry import Registry, build_from_cfg
 from .base import Pipeline
 from .util import is_official_hub_path
 
 PIPELINES = Registry('pipelines')
 
 
-def normalize_model_input(model, model_revision):
+def normalize_model_input(model, model_revision, third_party=None):
     """ normalize the input model, to ensure that a model str is a valid local path: in other words,
     for model represented by a model id, the model shall be downloaded locally
     """
     if isinstance(model, str) and is_official_hub_path(model, model_revision):
         # skip revision download if model is a local directory
         if not os.path.exists(model):
             # note that if there is already a local copy, snapshot_download will check and skip downloading
+            user_agent = {Invoke.KEY: Invoke.PIPELINE}
+            if third_party is not None:
+                user_agent[ThirdParty.KEY] = third_party
             model = snapshot_download(
-                model,
-                revision=model_revision,
-                user_agent={Invoke.KEY: Invoke.PIPELINE})
+                model, revision=model_revision, user_agent=user_agent)
     elif isinstance(model, list) and isinstance(model[0], str):
         for idx in range(len(model)):
             if is_official_hub_path(
                     model[idx],
                     model_revision) and not os.path.exists(model[idx]):
+                user_agent = {Invoke.KEY: Invoke.PIPELINE}
+                if third_party is not None:
+                    user_agent[ThirdParty.KEY] = third_party
                 model[idx] = snapshot_download(
-                    model[idx],
-                    revision=model_revision,
-                    user_agent={Invoke.KEY: Invoke.PIPELINE})
+                    model[idx], revision=model_revision, user_agent=user_agent)
     return model
 
 
 def build_pipeline(cfg: ConfigDict,
                    task_name: str = None,
                    default_args: dict = None):
     """ build pipeline given model config dict.
@@ -93,15 +96,19 @@
         >>> p = pipeline('image-classification', model=resnet)
         >>> # Using pipeline with a list of model names
         >>> p = pipeline('audio-kws', model=['damo/audio-tts', 'damo/auto-tts2'])
     """
     if task is None and pipeline_name is None:
         raise ValueError('task or pipeline_name is required')
 
-    model = normalize_model_input(model, model_revision)
+    third_party = kwargs.get(ThirdParty.KEY)
+    if third_party is not None:
+        kwargs.pop(ThirdParty.KEY)
+    model = normalize_model_input(
+        model, model_revision, third_party=third_party)
     pipeline_props = {'type': pipeline_name}
     if pipeline_name is None:
         # get default pipeline for this task
         if isinstance(model, str) \
            or (isinstance(model, list) and isinstance(model[0], str)):
             if is_official_hub_path(model, revision=model_revision):
                 # read config file from hub and parse
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/__init__.py` & `modelscope-1.7.0/modelscope/pipelines/cv/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -102,15 +102,15 @@
     from .bad_image_detecting_pipeline import BadImageDetecingPipeline
     from .mobile_image_super_resolution_pipeline import MobileImageSuperResolutionPipeline
     from .image_human_parsing_pipeline import ImageHumanParsingPipeline
     from .nerf_recon_acc_pipeline import NeRFReconAccPipeline
     from .controllable_image_generation_pipeline import ControllableImageGenerationPipeline
     from .image_bts_depth_estimation_pipeline import ImageBTSDepthEstimationPipeline
     from .pedestrian_attribute_recognition_pipeline import PedestrainAttributeRecognitionPipeline
-
+    from .image_panoptic_segmentation_pipeline import ImagePanopticSegmentationPipeline
 else:
     _import_structure = {
         'action_recognition_pipeline': ['ActionRecognitionPipeline'],
         'action_detection_pipeline': ['ActionDetectionPipeline'],
         'animal_recognition_pipeline': ['AnimalRecognitionPipeline'],
         'body_2d_keypoints_pipeline': ['Body2DKeypointsPipeline'],
         'body_3d_keypoints_pipeline': ['Body3DKeypointsPipeline'],
@@ -257,15 +257,18 @@
             'ControllableImageGenerationPipeline'
         ],
         'image_bts_depth_estimation_pipeline': [
             'ImageBTSDepthEstimationPipeline'
         ],
         'pedestrian_attribute_recognition_pipeline': [
             'PedestrainAttributeRecognitionPipeline'
-        ]
+        ],
+        'image_panoptic_segmentation_pipeline': [
+            'ImagePanopticSegmentationPipeline',
+        ],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/action_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/action_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/action_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/action_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/animal_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/animal_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/arc_face_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/arc_face_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/bad_image_detecting_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/bad_image_detecting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/body_2d_keypoints_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/body_2d_keypoints_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/body_3d_keypoints_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/body_3d_keypoints_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/card_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/card_detection_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 from typing import Any, Dict, List, Union
 
 from modelscope.metainfo import Pipelines
 from modelscope.models.base.base_model import Model
 from modelscope.pipelines.base import Pipeline
 from modelscope.pipelines.builder import PIPELINES
 from modelscope.utils.constant import Tasks
+from modelscope.utils.input_output_typing import Image
 from modelscope.utils.logger import get_logger
-from modelscope.utils.typing import Image
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.card_detection, module_name=Pipelines.card_detection)
 class CardDetectionPipeline(Pipeline):
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/cmdssl_video_embedding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/cmdssl_video_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/content_check_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/content_check_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/controllable_image_generation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/controllable_image_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/crowd_counting_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/crowd_counting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ddcolor_image_colorization_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ddcolor_image_colorization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ddpm_semantic_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ddpm_semantic_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_attribute_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_attribute_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_detection_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,16 +12,16 @@
 from modelscope.models.cv.face_detection import ScrfdDetect, SCRFDPreprocessor
 from modelscope.outputs import OutputKeys
 from modelscope.pipelines.base import Input, Pipeline
 from modelscope.pipelines.builder import PIPELINES
 from modelscope.preprocessors import LoadImage
 from modelscope.utils.config import Config
 from modelscope.utils.constant import ModelFile, Tasks
+from modelscope.utils.input_output_typing import Image
 from modelscope.utils.logger import get_logger
-from modelscope.utils.typing import Image
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.face_detection, module_name=Pipelines.face_detection)
 class FaceDetectionPipeline(Pipeline):
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_emotion_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_emotion_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_human_hand_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_human_hand_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_image_generation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_image_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_liveness_ir_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_liveness_ir_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_liveness_xc_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_liveness_xc_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_processing_base_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_processing_base_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_quality_assessment_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_quality_assessment_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_recognition_onnx_fm_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_recognition_onnx_fm_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_recognition_onnx_ir_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_recognition_onnx_ir_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_recognition_ood_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_recognition_ood_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/face_reconstruction_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/face_reconstruction_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -99,15 +99,15 @@
         shutil.copy(
             os.path.join(model_root, 'face_alignment',
                          '3DFAN4-4a694010b9.zip'), save_ckpt_dir)
         shutil.copy(
             os.path.join(model_root, 'face_alignment', 'depth-6c4283c0e0.zip'),
             save_ckpt_dir)
         self.lm_sess = face_alignment.FaceAlignment(
-            face_alignment.LandmarksType._3D, flip_input=False)
+            face_alignment.LandmarksType.THREE_D, flip_input=False)
 
         config = tf.ConfigProto(allow_soft_placement=True)
         config.gpu_options.per_process_gpu_memory_fraction = 0.2
         config.gpu_options.allow_growth = True
         g1 = tf.Graph()
         self.face_sess = tf.Session(graph=g1, config=config)
         with self.face_sess.as_default():
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/facial_expression_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/facial_expression_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/facial_landmark_confidence_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/facial_landmark_confidence_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/fast_instance_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/fast_instance_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/general_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/general_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/hand_static_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/hand_static_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/hicossl_video_embedding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/hicossl_video_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/human_reconstruction_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/human_reconstruction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_body_reshaping_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_body_reshaping_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_bts_depth_estimation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_bts_depth_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_cartoon_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_cartoon_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_classification_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_color_enhance_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_color_enhance_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_colorization_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_colorization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_debanding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_debanding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_deblur_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_deblur_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_defrcn_fewshot_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_defrcn_fewshot_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_denoise_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_denoise_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_depth_estimation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_depth_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_driving_perception_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_driving_perception_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_face_fusion_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_face_fusion_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_human_parsing_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_human_parsing_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_inpainting_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_inpainting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_inpainting_sdv2_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_inpainting_sdv2_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_instance_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_instance_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_matching_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_matching_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_matting_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_matting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_mvs_depth_estimation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_mvs_depth_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_open_vocabulary_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_open_vocabulary_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_paintbyexample_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_paintbyexample_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_portrait_enhancement_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_portrait_enhancement_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_quality_assessment_man_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_quality_assessment_man_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_quality_assessment_mos_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_quality_assessment_mos_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_reid_person_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_reid_person_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_restoration_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_restoration_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_salient_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_salient_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_semantic_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_semantic_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_skychange_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_skychange_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_structured_model_probing_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_structured_model_probing_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_style_transfer_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_style_transfer_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_super_resolution_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_super_resolution_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_to_image_generate_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_to_image_generate_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/image_to_image_translation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/image_to_image_translation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/indoor_layout_estimation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/indoor_layout_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/language_guided_video_summarization_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/language_guided_video_summarization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/license_plate_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/license_plate_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/lineless_table_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/lineless_table_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/live_category_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/live_category_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/mask_face_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/mask_face_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/maskdino_instance_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/maskdino_instance_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/mobile_image_super_resolution_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/mobile_image_super_resolution_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/mog_face_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/mog_face_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/motion_generation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/motion_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/movie_scene_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/movie_scene_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/mtcnn_face_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/mtcnn_face_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/nerf_recon_acc_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/nerf_recon_acc_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/object_detection_3d_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/object_detection_3d_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_recognition_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -62,13 +62,13 @@
         return super().__call__(input, **kwargs)
 
     def preprocess(self, inputs):
         outputs = self.preprocessor(inputs)
         return outputs
 
     def forward(self, inputs):
-        outputs = self.ocr_recognizer(inputs)
+        outputs = self.ocr_recognizer(inputs['image'])
         return outputs
 
     def postprocess(self, inputs):
         outputs = {OutputKeys.TEXT: inputs['preds']}
         return outputs
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/__init__.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/model_convnext_transformer.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/model_convnext_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/model_dla34.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/model_dla34.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/model_resnet18_half.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/model_resnet18_half.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/model_vlpt.py` & `modelscope-1.7.0/modelscope/models/cv/ocr_detection/modules/dbnet.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,19 +1,21 @@
 # ------------------------------------------------------------------------------
 # Part of implementation is adopted from ViLT,
 # made publicly available under the Apache License 2.0 at https://github.com/dandelin/ViLT.
 # ------------------------------------------------------------------------------
-
 import math
 import os
 import sys
+from collections import OrderedDict
 
 import torch
 import torch.nn as nn
 
+from .proxyless import CompactDetBackbone
+
 BatchNorm2d = nn.BatchNorm2d
 
 
 def constant_init(module, constant, bias=0):
     nn.init.constant_(module.weight, constant)
     if hasattr(module, 'bias'):
         nn.init.constant_(module.bias, bias)
@@ -26,14 +28,81 @@
         out_planes,
         kernel_size=3,
         stride=stride,
         padding=1,
         bias=False)
 
 
+class DwPwConv(nn.Module):
+
+    def __init__(self,
+                 in_planes,
+                 out_planes,
+                 kernel_size,
+                 stride=1,
+                 padding=1,
+                 bias=False):
+        super(DwPwConv, self).__init__()
+        self.depthwise = nn.Conv2d(
+            in_planes,
+            in_planes,
+            kernel_size,
+            stride,
+            padding,
+            groups=in_planes,
+            bias=bias)
+        self.bn1 = nn.BatchNorm2d(in_planes)
+        self.relu1 = nn.ReLU(inplace=True)
+
+        self.pointwise = nn.Conv2d(
+            in_planes,
+            out_planes,
+            kernel_size=1,
+            stride=1,
+            padding=0,
+            groups=1,
+            bias=bias)
+
+    def forward(self, x):
+        out = self.depthwise(x)
+        out = self.bn1(out)
+        out = self.relu1(out)
+
+        out = self.pointwise(out)
+
+        return out
+
+
+class DwPwConvTranspose(nn.Module):
+
+    def __init__(self, in_planes, out_planes, kernel_size, stride):
+        super(DwPwConvTranspose, self).__init__()
+        self.depthwise = nn.ConvTranspose2d(
+            in_planes, in_planes, kernel_size, stride, groups=in_planes)
+        self.bn1 = nn.BatchNorm2d(in_planes)
+        self.relu1 = nn.ReLU(inplace=True)
+
+        self.pointwise = nn.Conv2d(
+            in_planes,
+            out_planes,
+            kernel_size=1,
+            stride=1,
+            padding=0,
+            groups=1)
+
+    def forward(self, x):
+        out = self.depthwise(x)
+        out = self.bn1(out)
+        out = self.relu1(out)
+
+        out = self.pointwise(out)
+
+        return out
+
+
 class BasicBlock(nn.Module):
     expansion = 1
 
     def __init__(self, inplanes, planes, stride=1, downsample=None, dcn=None):
         super(BasicBlock, self).__init__()
         self.with_dcn = dcn is not None
         self.conv1 = conv3x3(inplanes, planes, stride)
@@ -262,14 +331,164 @@
         x3 = self.layer2(x2)
         x4 = self.layer3(x3)
         x5 = self.layer4(x4)
 
         return x2, x3, x4, x5
 
 
+class LightSegDetector(nn.Module):
+
+    def __init__(self,
+                 in_channels=[64, 128, 256, 512],
+                 inner_channels=256,
+                 k=10,
+                 bias=False,
+                 adaptive=False,
+                 smooth=False,
+                 serial=False,
+                 dw_kernel_size=3,
+                 dw_padding=1,
+                 *args,
+                 **kwargs):
+        '''
+        bias: Whether conv layers have bias or not.
+        adaptive: Whether to use adaptive threshold training or not.
+        smooth: If true, use bilinear instead of deconv.
+        serial: If true, thresh prediction will combine segmentation result as input.
+        '''
+        super(LightSegDetector, self).__init__()
+        self.k = k
+        self.serial = serial
+        self.inner_channels = inner_channels
+        self.bias = bias
+        self.dw_kernel_size = dw_kernel_size
+        self.dw_padding = dw_padding
+
+        self.up5 = nn.Upsample(scale_factor=8, mode='nearest')
+        self.up4 = nn.Upsample(scale_factor=4, mode='nearest')
+        self.up3 = nn.Upsample(scale_factor=2, mode='nearest')
+
+        self.in5 = nn.Conv2d(in_channels[-1], inner_channels, 1, bias=bias)
+        self.in4 = nn.Conv2d(in_channels[-2], inner_channels, 1, bias=bias)
+        self.in3 = nn.Conv2d(in_channels[-3], inner_channels, 1, bias=bias)
+        self.in2 = nn.Conv2d(in_channels[-4], inner_channels, 1, bias=bias)
+
+        # DwPM
+        self.binarize = nn.Sequential(
+            DwPwConv(
+                inner_channels,
+                inner_channels // 4,
+                kernel_size=self.dw_kernel_size,
+                padding=self.dw_padding,
+                bias=bias), BatchNorm2d(inner_channels // 4),
+            nn.ReLU(inplace=True),
+            DwPwConvTranspose(inner_channels // 4, inner_channels // 4, 2, 2),
+            BatchNorm2d(inner_channels // 4), nn.ReLU(inplace=True),
+            DwPwConvTranspose(inner_channels // 4, 1, 2, 2), nn.Sigmoid())
+
+        self.adaptive = adaptive
+        if adaptive:
+            self.thresh = self._init_thresh(
+                inner_channels, serial=serial, smooth=smooth, bias=bias)
+
+        # weight initialization
+        for m in self.modules():
+            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):
+                nn.init.kaiming_normal_(m.weight)
+                if m.bias is not None:
+                    nn.init.zeros_(m.bias)
+            elif isinstance(m, nn.BatchNorm2d):
+                m.weight.data.fill_(1.)
+                m.bias.data.fill_(1e-4)
+
+    def _init_thresh(self,
+                     inner_channels,
+                     serial=False,
+                     smooth=False,
+                     bias=False):
+        in_channels = inner_channels
+        if serial:
+            in_channels += 1
+        self.thresh = nn.Sequential(
+            nn.Conv2d(
+                inner_channels,
+                inner_channels // 4,
+                self.dw_kernel_size,
+                padding=self.dw_padding,
+                bias=bias), BatchNorm2d(inner_channels // 4),
+            nn.ReLU(inplace=True),
+            self._init_upsample(
+                inner_channels // 4,
+                inner_channels // 4,
+                smooth=smooth,
+                bias=bias), BatchNorm2d(inner_channels // 4),
+            nn.ReLU(inplace=True),
+            self._init_upsample(
+                inner_channels // 4, 1, smooth=smooth, bias=bias),
+            nn.Sigmoid())
+
+        return self.thresh
+
+    def _init_upsample(self,
+                       in_channels,
+                       out_channels,
+                       smooth=False,
+                       bias=False):
+        if smooth:
+            inter_out_channels = out_channels
+            if out_channels == 1:
+                inter_out_channels = in_channels
+            module_list = [
+                nn.Upsample(scale_factor=2, mode='nearest'),
+                nn.Conv2d(in_channels, inter_out_channels, 3, 1, 1, bias=bias)
+            ]
+            if out_channels == 1:
+                module_list.append(
+                    nn.Conv2d(
+                        in_channels,
+                        out_channels,
+                        kernel_size=1,
+                        stride=1,
+                        padding=1,
+                        bias=True))
+
+            return nn.Sequential(module_list)
+        else:
+            return nn.ConvTranspose2d(in_channels, out_channels, 2, 2)
+
+    def forward(self, features, gt=None, masks=None, training=False):
+        c2, c3, c4, c5 = features
+        p5 = self.up5(self.in5(c5))
+        p4 = self.up4(self.in4(c4))
+        p3 = self.up3(self.in3(c3))
+        p2 = self.in2(c2)
+
+        fuse = p5 + p4 + p3 + p2
+
+        # this is the pred module, not binarization module;
+        # We do not correct the name due to the trained model.
+        binary = self.binarize(fuse)
+        if self.training:
+            result = OrderedDict(binary=binary)
+        else:
+            return binary
+        if self.adaptive and self.training:
+            if self.serial:
+                fuse = torch.cat(
+                    (fuse, nn.functional.interpolate(binary, fuse.shape[2:])),
+                    1)
+            thresh = self.thresh(fuse)
+            thresh_binary = self.step_function(binary, thresh)
+            result.update(thresh=thresh, thresh_binary=thresh_binary)
+        return result
+
+    def step_function(self, x, y):
+        return torch.reciprocal(1 + torch.exp(-self.k * (x - y)))
+
+
 class SegDetector(nn.Module):
 
     def __init__(self,
                  in_channels=[64, 128, 256, 512],
                  inner_channels=256,
                  k=10,
                  bias=False,
@@ -409,35 +628,142 @@
         p3 = self.out3(out3)
         p2 = self.out2(out2)
 
         fuse = torch.cat((p5, p4, p3, p2), 1)
         # this is the pred module, not binarization module;
         # We do not correct the name due to the trained model.
         binary = self.binarize(fuse)
-        return binary
+        if self.training:
+            result = OrderedDict(binary=binary)
+        else:
+            return binary
+        if self.adaptive and self.training:
+            if self.serial:
+                fuse = torch.cat(
+                    (fuse, nn.functional.interpolate(binary, fuse.shape[2:])),
+                    1)
+            thresh = self.thresh(fuse)
+            thresh_binary = self.step_function(binary, thresh)
+            result.update(thresh=thresh, thresh_binary=thresh_binary)
+        return result
 
     def step_function(self, x, y):
         return torch.reciprocal(1 + torch.exp(-self.k * (x - y)))
 
 
+class BasicModel(nn.Module):
+
+    def __init__(self, *args, **kwargs):
+        nn.Module.__init__(self)
+
+        self.backbone = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
+        self.decoder = SegDetector(
+            in_channels=[64, 128, 256, 512], adaptive=True, k=50, **kwargs)
+
+    def forward(self, data, *args, **kwargs):
+        return self.decoder(self.backbone(data), *args, **kwargs)
+
+
+def parallelize(model, distributed, local_rank):
+    if distributed:
+        return nn.parallel.DistributedDataParallel(
+            model,
+            device_ids=[local_rank],
+            output_device=[local_rank],
+            find_unused_parameters=True)
+    else:
+        return nn.DataParallel(model)
+
+
 class VLPTModel(nn.Module):
 
     def __init__(self, *args, **kwargs):
+        """
+        VLPT-STD pretrained DBNet-resnet50 model,
+        paper reference: https://arxiv.org/pdf/2204.13867.pdf
+        """
         super(VLPTModel, self).__init__()
         self.backbone = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
         self.decoder = SegDetector(
             in_channels=[256, 512, 1024, 2048], adaptive=True, k=50, **kwargs)
 
     def forward(self, x):
         return self.decoder(self.backbone(x))
 
 
+class DBNasModel(nn.Module):
+
+    def __init__(self, *args, **kwargs):
+        """
+        DB-NAS model
+        """
+        super(DBNasModel, self).__init__()
+        self.backbone = CompactDetBackbone(
+            width_stages=[32, 64, 96, 128], input_channel=32, **kwargs)
+        self.decoder = LightSegDetector(
+            in_channels=[32, 64, 96, 128],
+            adaptive=True,
+            k=50,
+            inner_channels=64,
+            dw_kernel_size=5,
+            dw_padding=2,
+            **kwargs)
+
+    def forward(self, x):
+        return self.decoder(self.backbone(x))
+
+
 class DBModel(nn.Module):
 
     def __init__(self, *args, **kwargs):
+        """
+        DBNet-resnet18 model without deformable conv,
+        paper reference: https://arxiv.org/pdf/1911.08947.pdf
+        """
         super(DBModel, self).__init__()
         self.backbone = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
         self.decoder = SegDetector(
             in_channels=[64, 128, 256, 512], adaptive=True, k=50, **kwargs)
 
     def forward(self, x):
         return self.decoder(self.backbone(x))
+
+
+class DBModel_v2(nn.Module):
+
+    def __init__(self,
+                 device,
+                 distributed: bool = False,
+                 local_rank: int = 0,
+                 *args,
+                 **kwargs):
+        """
+        DBNet-resnet18 model without deformable conv,
+        paper reference: https://arxiv.org/pdf/1911.08947.pdf
+        """
+        super(DBModel_v2, self).__init__()
+        from .seg_detector_loss import L1BalanceCELoss
+
+        self.model = BasicModel(*args, **kwargs)
+        self.model = parallelize(self.model, distributed, local_rank)
+        self.criterion = L1BalanceCELoss()
+        self.criterion = parallelize(self.criterion, distributed, local_rank)
+        self.device = device
+        self.to(self.device)
+
+    def forward(self, batch, training=False):
+        if isinstance(batch, dict):
+            data = batch['image'].to(self.device)
+        else:
+            data = batch.to(self.device)
+        data = data.float()
+        pred = self.model(data, training=self.training)
+
+        if self.training:
+            for key, value in batch.items():
+                if value is not None:
+                    if hasattr(value, 'to'):
+                        batch[key] = value.to(self.device)
+            loss_with_metrics = self.criterion(pred, batch)
+            loss, metrics = loss_with_metrics
+            return loss, pred, metrics
+        return pred
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/__init__.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ocr_modules/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/convnext.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ocr_modules/convnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/vitstr.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ocr_modules/vitstr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/ops.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/resnet18_v1.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/resnet18_v1.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/resnet_utils.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/resnet_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/table_process.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/table_process.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ocr_utils/utils.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ocr_utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/panorama_depth_estimation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/panorama_depth_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/pedestrian_attribute_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/pedestrian_attribute_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/product_retrieval_embedding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/product_retrieval_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/product_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/product_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/realtime_video_object_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/realtime_video_object_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/referring_video_object_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/referring_video_object_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/retina_face_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/retina_face_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/shop_segmentation_pipleline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/shop_segmentation_pipleline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/skin_retouching_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/skin_retouching_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/table_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/table_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/tbs_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/tbs_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/tbs_detection_utils/utils.py` & `modelscope-1.7.0/modelscope/pipelines/cv/tbs_detection_utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/text_driven_segmentation_pipleline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/text_driven_segmentation_pipleline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/tinynas_classification_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/tinynas_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/tinynas_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/tinynas_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/ulfd_face_detection_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/ulfd_face_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_category_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_category_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_colorization_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_colorization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_deinterlace_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_deinterlace_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_depth_estimation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_depth_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_frame_interpolation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_frame_interpolation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_human_matting_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_human_matting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_inpainting_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_inpainting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_instance_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_instance_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_multi_object_tracking_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_multi_object_tracking_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_object_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_object_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_panoptic_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_panoptic_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_single_object_tracking_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_single_object_tracking_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_stabilization_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_stabilization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_summarization_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_summarization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/video_super_resolution_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/video_super_resolution_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/vidt_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/vidt_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/virtual_try_on_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/virtual_try_on_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/vision_efficient_tuning_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/vision_efficient_tuning_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/vision_middleware_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/vision_middleware_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/vop_retrieval_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/vop_retrieval_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/cv/vop_retrieval_se_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/cv/vop_retrieval_se_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/__init__.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
         VideoMultiModalEmbeddingPipeline
     from .visual_question_answering_pipeline import VisualQuestionAnsweringPipeline
     from .asr_pipeline import AutomaticSpeechRecognitionPipeline
     from .mgeo_ranking_pipeline import MGeoRankingPipeline
     from .document_vl_embedding_pipeline import DocumentVLEmbeddingPipeline
     from .video_captioning_pipeline import VideoCaptioningPipeline
     from .video_question_answering_pipeline import VideoQuestionAnsweringPipeline
-    from .diffusers_wrapped import StableDiffusionWrapperPipeline, ChineseStableDiffusionPipeline
+    from .diffusers_wrapped import StableDiffusionPipeline, ChineseStableDiffusionPipeline
     from .soonet_video_temporal_grounding_pipeline import SOONetVideoTemporalGroundingPipeline
     from .text_to_video_synthesis_pipeline import TextToVideoSynthesisPipeline
     from .multimodal_dialogue_pipeline import MultimodalDialoguePipeline
 else:
     _import_structure = {
         'image_captioning_pipeline': ['ImageCaptioningPipeline'],
         'visual_entailment_pipeline': ['VisualEntailmentPipeline'],
@@ -38,15 +38,15 @@
         'asr_pipeline': ['AutomaticSpeechRecognitionPipeline'],
         'mgeo_ranking_pipeline': ['MGeoRankingPipeline'],
         'document_vl_embedding_pipeline': ['DocumentVLEmbeddingPipeline'],
         'video_captioning_pipeline': ['VideoCaptioningPipeline'],
         'video_question_answering_pipeline':
         ['VideoQuestionAnsweringPipeline'],
         'diffusers_wrapped':
-        ['StableDiffusionWrapperPipeline', 'ChineseStableDiffusionPipeline'],
+        ['StableDiffusionPipeline', 'ChineseStableDiffusionPipeline'],
         'soonet_video_temporal_grounding_pipeline':
         ['SOONetVideoTemporalGroundingPipeline'],
         'text_to_video_synthesis_pipeline': ['TextToVideoSynthesisPipeline'],
         'multimodal_dialogue_pipeline': ['MultimodalDialoguePipeline']
     }
 
     import sys
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/asr_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/asr_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/__init__.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
 from modelscope.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .stable_diffusion import StableDiffusionWrapperPipeline
+    from .stable_diffusion import StableDiffusionPipeline
     from .stable_diffusion import ChineseStableDiffusionPipeline
 else:
     _import_structure = {
         'stable_diffusion':
-        ['StableDiffusionWrapperPipeline', 'ChineseStableDiffusionPipeline']
+        ['StableDiffusionPipeline', 'ChineseStableDiffusionPipeline']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
 from modelscope.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .stable_diffusion_pipeline import StableDiffusionWrapperPipeline
+    from .stable_diffusion_pipeline import StableDiffusionPipeline
     from .chinese_stable_diffusion_pipeline import ChineseStableDiffusionPipeline
 else:
     _import_structure = {
-        'stable_diffusion_pipeline': ['StableDiffusionWrapperPipeline'],
+        'stable_diffusion_pipeline': ['StableDiffusionPipeline'],
         'chinese_stable_diffusion_pipeline':
         ['ChineseStableDiffusionPipeline']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/document_vl_embedding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/document_vl_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/gridvlp_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/gridvlp_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/image_captioning_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/image_captioning_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/image_text_retrieval_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/image_text_retrieval_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/mgeo_ranking_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/mgeo_ranking_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/multi_modal_embedding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/multi_modal_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/multimodal_dialogue_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/multimodal_dialogue_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/ocr_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/ocr_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/sudoku_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/sudoku_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/text2sql_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/text2sql_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/text_to_image_synthesis_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/text_to_image_synthesis_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/text_to_video_synthesis_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/text_to_video_synthesis_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/video_captioning_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/video_captioning_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/video_question_answering_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/video_question_answering_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/visual_entailment_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/visual_entailment_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/visual_grounding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/visual_grounding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/multi_modal/visual_question_answering_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/visual_question_answering_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/__init__.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/automatic_post_editing_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/automatic_post_editing_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/canmt_translation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/canmt_translation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/codegeex_code_generation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/codegeex_code_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/codegeex_code_translation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/codegeex_code_translation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/conversational_text_to_sql_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/conversational_text_to_sql_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/dialog_intent_prediction_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/dialog_intent_prediction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/dialog_modeling_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/dialog_modeling_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/dialog_state_tracking_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/dialog_state_tracking_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/distributed_gpt3_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/text_ranking_pipeline.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,66 +1,77 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
-from typing import Any, Dict
+from typing import Any, Dict, Optional, Union
 
-import torch
+import numpy as np
 
 from modelscope.metainfo import Pipelines
-from modelscope.models.nlp import DistributedGPT3
-from modelscope.pipelines.base import DistributedPipeline
+from modelscope.models import Model
+from modelscope.outputs import OutputKeys
+from modelscope.pipelines.base import Pipeline
 from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import TextGenerationJiebaPreprocessor
-from modelscope.utils.constant import Tasks
+from modelscope.preprocessors import (Preprocessor,
+                                      TextRankingTransformersPreprocessor)
+from modelscope.utils.constant import ModelFile, Tasks
 
+__all__ = ['TextRankingPipeline']
 
-@PIPELINES.register_module(
-    Tasks.text_generation, module_name=Pipelines.gpt3_generation)
-class DistributedGPT3Pipeline(DistributedPipeline):
-    """This class is used to instantiate the gpt3 model.
-    """
 
-    model = None
+@PIPELINES.register_module(
+    Tasks.text_ranking, module_name=Pipelines.text_ranking)
+class TextRankingPipeline(Pipeline):
 
-    def __init__(self, model, preprocessor=None, **kwargs):
-        """
+    def __init__(self,
+                 model: Union[Model, str],
+                 preprocessor: Optional[Preprocessor] = None,
+                 config_file: str = None,
+                 device: str = 'gpu',
+                 auto_collate=True,
+                 sequence_length=128,
+                 **kwargs):
+        """Use `model` and `preprocessor` to create a nlp word segment pipeline for prediction.
 
         Args:
-            model: The model piece, str is not supported.
-            preprocessor: The preprocessor matched with the model.
+            model (str or Model): Supply either a local model dir which supported the WS task,
+            or a model id from the model hub, or a torch model instance.
+            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            the model if supplied.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
         """
+        super().__init__(
+            model=model,
+            preprocessor=preprocessor,
+            config_file=config_file,
+            device=device,
+            auto_collate=auto_collate,
+            compile=kwargs.pop('compile', False),
+            compile_options=kwargs.pop('compile_options', {}))
+
+        assert isinstance(self.model, Model), \
+            f'please check whether model config exists in {ModelFile.CONFIGURATION}'
+
         if preprocessor is None:
-            preprocessor = TextGenerationJiebaPreprocessor(model)
-        super().__init__(model, preprocessor=preprocessor, **kwargs)
-        assert hasattr(preprocessor, 'tokenizer')
-
-    @classmethod
-    def _instantiate_one(cls, rank, model_dir, **kwargs):
-        cls.model = DistributedGPT3(model_dir, rank, **kwargs)
-        cls.model.eval()
-
-    @classmethod
-    def _forward_one(cls, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        tokens = inputs['inputs']['input_ids'].cuda(
-            torch.cuda.current_device())
-        return cls.model.generate(tokens, **inputs['forward_params'])
+            self.preprocessor = Preprocessor.from_pretrained(
+                self.model.model_dir,
+                sequence_length=sequence_length,
+                **kwargs)
+
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        return self.model(**inputs, **forward_params)
 
-    def postprocess(self, inputs: Dict[str, Any],
-                    **postprocess_params) -> Dict[str, str]:
+    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         """process the prediction results
-
         Args:
             inputs (Dict[str, Any]): _description_
 
         Returns:
-            Dict[str, str]: the prediction results
+            Dict[str, Any]: the predicted text representation
         """
-        from modelscope.outputs import OutputKeys
-        return {
-            OutputKeys.TEXT:
-            self.preprocessor.tokenizer.detokenize(
-                inputs.sequences[0].tolist())
-        }
 
-    def _sanitize_parameters(self, **pipeline_parameters):
-        return {}, pipeline_parameters, {}
+        def sigmoid(logits):
+            return np.exp(logits) / (1 + np.exp(logits))
+
+        logits = inputs[OutputKeys.LOGITS].squeeze(-1).detach().cpu().numpy()
+        pred_list = sigmoid(logits).tolist()
+        return {OutputKeys.SCORES: pred_list}
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/distributed_gpt_moe_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/distributed_gpt_moe_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/distributed_plug_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/distributed_plug_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/document_grounded_dialog_generate_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/document_grounded_dialog_generate_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/document_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/document_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/extractive_summarization_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/extractive_summarization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/faq_question_answering_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/faq_question_answering_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/fasttext_text_classification_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/fasttext_text_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/feature_extraction_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/feature_extraction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/fid_dialogue_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/fid_dialogue_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/fill_mask_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/fill_mask_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/glm130b_text_generation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/glm130b_text_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/information_extraction_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/information_extraction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/interactive_translation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/interactive_translation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/language_identification_pipline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/language_identification_pipline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/mglm_text_summarization_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/mglm_text_summarization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/named_entity_recognition_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/named_entity_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/sentence_embedding_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/sentence_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/siamese_uie_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/siamese_uie_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/summarization_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/summarization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/table_question_answering_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/table_question_answering_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/text_classification_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/text_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/text_error_correction_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/text_error_correction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/text_generation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/text_generation_pipeline.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
+# Copyright (c) 2022 Zhipu.AI
 import os
 from typing import Any, Dict, Optional, Union
 
 import torch
 
 from modelscope.metainfo import Pipelines
 from modelscope.models.base import Model
@@ -11,21 +12,25 @@
                                 TokenGeneratorOutput)
 from modelscope.pipelines.base import Pipeline, Tensor
 from modelscope.pipelines.builder import PIPELINES
 from modelscope.preprocessors import Preprocessor
 from modelscope.utils.chinese_utils import remove_space_between_chinese_chars
 from modelscope.utils.constant import ModelFile, Tasks
 from modelscope.utils.hub import Config, read_config
+from modelscope.utils.streaming_output import PipelineStreamingOutputMixin
 
-__all__ = ['TextGenerationPipeline', 'TextGenerationT5Pipeline']
+__all__ = [
+    'TextGenerationPipeline', 'TextGenerationT5Pipeline',
+    'ChatGLM6bTextGenerationPipeline', 'ChatGLM6bV2TextGenerationPipeline'
+]
 
 
 @PIPELINES.register_module(
     Tasks.text_generation, module_name=Pipelines.text_generation)
-class TextGenerationPipeline(Pipeline):
+class TextGenerationPipeline(Pipeline, PipelineStreamingOutputMixin):
 
     def __init__(self,
                  model: Union[Model, str],
                  preprocessor: Optional[Preprocessor] = None,
                  config_file: str = None,
                  device: str = 'gpu',
                  auto_collate=True,
@@ -172,7 +177,75 @@
         if min_length is not None:
             forward_params['min_length'] = min_length
         if max_length is not None:
             forward_params['max_length'] = max_length
 
         with torch.no_grad():
             return self.model.generate(**inputs, **forward_params)
+
+
+@PIPELINES.register_module(
+    group_key=Tasks.chat, module_name='chatglm6b-text-generation')
+class ChatGLM6bTextGenerationPipeline(Pipeline):
+
+    def __init__(self,
+                 model: Union[Model, str],
+                 quantization_bit=None,
+                 use_bf16=False,
+                 **kwargs):
+        from modelscope.models.nlp.chatglm.text_generation import ChatGLMForConditionalGeneration
+        model = ChatGLMForConditionalGeneration(model) if isinstance(
+            model, str) else model
+        if quantization_bit is not None:
+            model = model.quantize(quantization_bit)
+        if use_bf16:
+            model = model.bfloat16()
+        self.model = model
+        self.model.eval()
+
+        super().__init__(model=model, **kwargs)
+
+    def preprocess(self, inputs, **preprocess_params) -> Dict[str, Any]:
+        return inputs
+
+    # define the forward pass
+    def forward(self, inputs: Dict, **forward_params) -> Dict[str, Any]:
+        return self.model.chat(inputs)
+
+    # format the outputs from pipeline
+    def postprocess(self, input, **kwargs) -> Dict[str, Any]:
+        return input
+
+
+@PIPELINES.register_module(
+    group_key=Tasks.chat, module_name='chatglm2_6b-text-generation')
+class ChatGLM6bV2TextGenerationPipeline(Pipeline):
+
+    def __init__(self,
+                 model: Union[Model, str],
+                 quantization_bit=None,
+                 use_bf16=False,
+                 **kwargs):
+        from modelscope.models.nlp import ChatGLM2ForConditionalGeneration, ChatGLM2Tokenizer
+        model = ChatGLM2ForConditionalGeneration(model) if isinstance(
+            model, str) else model
+        if quantization_bit is not None:
+            model = model.quantize(quantization_bit)
+        if use_bf16:
+            model = model.bfloat16()
+        self.model = model
+        self.model.eval()
+        self.tokenizer = ChatGLM2Tokenizer.from_pretrained(
+            self.model.model_dir)
+
+        super().__init__(model=model, **kwargs)
+
+    def preprocess(self, inputs, **preprocess_params) -> Dict[str, Any]:
+        return inputs
+
+    # define the forward pass
+    def forward(self, inputs: Dict, **forward_params) -> Dict[str, Any]:
+        return self.model.chat(self.tokenizer, inputs['text'])
+
+    # format the outputs from pipeline
+    def postprocess(self, input, **kwargs) -> Dict[str, Any]:
+        return input
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/text_ranking_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/word_alignment_pipeline.py`

 * *Files 20% similar despite different names*

```diff
@@ -5,73 +5,64 @@
 import numpy as np
 
 from modelscope.metainfo import Pipelines
 from modelscope.models import Model
 from modelscope.outputs import OutputKeys
 from modelscope.pipelines.base import Pipeline
 from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import (Preprocessor,
-                                      TextRankingTransformersPreprocessor)
-from modelscope.utils.constant import ModelFile, Tasks
+from modelscope.preprocessors import WordAlignmentPreprocessor
+from modelscope.utils.constant import Tasks
 
-__all__ = ['TextRankingPipeline']
+__all__ = ['WordAlignmentPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.text_ranking, module_name=Pipelines.text_ranking)
-class TextRankingPipeline(Pipeline):
+    Tasks.word_alignment, module_name=Pipelines.word_alignment)
+class WordAlignmentPipeline(Pipeline):
 
     def __init__(self,
                  model: Union[Model, str],
-                 preprocessor: Optional[Preprocessor] = None,
+                 preprocessor: WordAlignmentPreprocessor = None,
                  config_file: str = None,
                  device: str = 'gpu',
                  auto_collate=True,
                  sequence_length=128,
                  **kwargs):
-        """Use `model` and `preprocessor` to create a nlp word segment pipeline for prediction.
-
+        """Use `model` and `preprocessor` to create a nlp text dual encoder then generates the text representation.
         Args:
             model (str or Model): Supply either a local model dir which supported the WS task,
             or a model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
-            the model if supplied.
+            preprocessor (Preprocessor): A WordAlignmentPreprocessor.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
+         Example:
+            >>> from modelscope.pipelines import pipeline
+            >>> from modelscope.utils.constant import Tasks
+            >>> model_id = 'damo/Third-Party-Supervised-Word-Aligner-mBERT-base-zhen'
+            >>> input = {"sentence_pair": '贝利 在 墨西哥 推出 自传 。||| pele promotes autobiography in mexico .'}
+            >>> pipeline_ins = pipeline(Tasks.word_alignment, model=model_id)
+            >>> print(pipeline_ins(input)['output'])
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
             config_file=config_file,
             device=device,
-            auto_collate=auto_collate,
-            compile=kwargs.pop('compile', False),
-            compile_options=kwargs.pop('compile_options', {}))
-
-        assert isinstance(self.model, Model), \
-            f'please check whether model config exists in {ModelFile.CONFIGURATION}'
-
+            auto_collate=auto_collate)
         if preprocessor is None:
-            self.preprocessor = Preprocessor.from_pretrained(
+            self.preprocessor = WordAlignmentPreprocessor.from_pretrained(
                 self.model.model_dir,
                 sequence_length=sequence_length,
                 **kwargs)
 
     def forward(self, inputs: Dict[str, Any],
                 **forward_params) -> Dict[str, Any]:
         return self.model(**inputs, **forward_params)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        """process the prediction results
-        Args:
-            inputs (Dict[str, Any]): _description_
-
-        Returns:
-            Dict[str, Any]: the predicted text representation
-        """
 
-        def sigmoid(logits):
-            return np.exp(logits) / (1 + np.exp(logits))
+        align = []
+        for k in inputs[0][0].keys():
+            align.append(f'{k[0]}-{k[1]}')
+        align = ' '.join(align)
 
-        logits = inputs[OutputKeys.LOGITS].squeeze(-1).detach().cpu().numpy()
-        pred_list = sigmoid(logits).tolist()
-        return {OutputKeys.SCORES: pred_list}
+        return {OutputKeys.OUTPUT: align}
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/token_classification_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/token_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/translation_evaluation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/translation_evaluation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/translation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/translation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/translation_quality_estimation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/translation_quality_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/user_satisfaction_estimation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/user_satisfaction_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/word_alignment_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,68 +1,70 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from typing import Any, Dict, Optional, Union
+# Copyright © Alibaba, Inc. and its affiliates.
+import os
+from typing import Any, Dict, Optional
 
+import cv2
 import numpy as np
+import torch
+import torchvision.transforms as transforms
+from diffusers import \
+    StableDiffusionPipeline as DiffuserStableDiffusionPipeline
+from PIL import Image
 
 from modelscope.metainfo import Pipelines
 from modelscope.models import Model
 from modelscope.outputs import OutputKeys
 from modelscope.pipelines.base import Pipeline
 from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import WordAlignmentPreprocessor
+from modelscope.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline import \
+    DiffusersPipeline
 from modelscope.utils.constant import Tasks
 
-__all__ = ['WordAlignmentPipeline']
-
 
 @PIPELINES.register_module(
-    Tasks.word_alignment, module_name=Pipelines.word_alignment)
-class WordAlignmentPipeline(Pipeline):
+    Tasks.text_to_image_synthesis,
+    module_name=Pipelines.diffusers_stable_diffusion)
+class StableDiffusionPipeline(DiffusersPipeline):
 
-    def __init__(self,
-                 model: Union[Model, str],
-                 preprocessor: WordAlignmentPreprocessor = None,
-                 config_file: str = None,
-                 device: str = 'gpu',
-                 auto_collate=True,
-                 sequence_length=128,
-                 **kwargs):
-        """Use `model` and `preprocessor` to create a nlp text dual encoder then generates the text representation.
+    def __init__(self, model: str, lora_dir: str = None, **kwargs):
+        """
+        use `model` to create a stable diffusion pipeline
         Args:
-            model (str or Model): Supply either a local model dir which supported the WS task,
-            or a model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): A WordAlignmentPreprocessor.
-            kwargs (dict, `optional`):
-                Extra kwargs passed into the preprocessor's constructor.
-         Example:
-            >>> from modelscope.pipelines import pipeline
-            >>> from modelscope.utils.constant import Tasks
-            >>> model_id = 'damo/Third-Party-Supervised-Word-Aligner-mBERT-base-zhen'
-            >>> input = {"sentence_pair": '贝利 在 墨西哥 推出 自传 。||| pele promotes autobiography in mexico .'}
-            >>> pipeline_ins = pipeline(Tasks.word_alignment, model=model_id)
-            >>> print(pipeline_ins(input)['output'])
+            model: model id on modelscope hub or local model dir.
         """
-        super().__init__(
-            model=model,
-            preprocessor=preprocessor,
-            config_file=config_file,
-            device=device,
-            auto_collate=auto_collate)
-        if preprocessor is None:
-            self.preprocessor = WordAlignmentPreprocessor.from_pretrained(
-                self.model.model_dir,
-                sequence_length=sequence_length,
-                **kwargs)
-
-    def forward(self, inputs: Dict[str, Any],
-                **forward_params) -> Dict[str, Any]:
-        return self.model(**inputs, **forward_params)
 
-    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
+        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
+        # load pipeline
+        torch_type = torch.float16 if self.device == 'cuda' else torch.float32
+        self.pipeline = DiffuserStableDiffusionPipeline.from_pretrained(
+            model, torch_dtype=torch_type)
+        self.pipeline = self.pipeline.to(self.device)
+        # load lora moudle to unet
+        if lora_dir is not None:
+            assert os.path.exists(lora_dir), f"{lora_dir} isn't exist"
+            self.pipeline.unet.load_attn_procs(lora_dir)
 
-        align = []
-        for k in inputs[0][0].keys():
-            align.append(f'{k[0]}-{k[1]}')
-        align = ' '.join(align)
+    def preprocess(self, inputs: Dict[str, Any], **kwargs) -> Dict[str, Any]:
+        return inputs
 
-        return {OutputKeys.OUTPUT: align}
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        if not isinstance(inputs, dict):
+            raise ValueError(
+                f'Expected the input to be a dictionary, but got {type(input)}'
+            )
+
+        if 'text' not in inputs:
+            raise ValueError('input should contain "text", but not found')
+
+        images = self.pipeline(
+            inputs['text'], num_inference_steps=30, guidance_scale=7.5)
+
+        return images
+
+    def postprocess(self, inputs: Dict[str, Any], **kwargs) -> Dict[str, Any]:
+        images = []
+        for img in inputs.images:
+            if isinstance(img, Image.Image):
+                img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
+                images.append(img)
+        return {OutputKeys.OUTPUT_IMGS: images}
```

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/word_segmentation_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/word_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/nlp/zero_shot_classification_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/nlp/zero_shot_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/pipeline_template.py` & `modelscope-1.7.0/modelscope/pipelines/pipeline_template.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/science/__init__.py` & `modelscope-1.7.0/modelscope/pipelines/science/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/science/protein_structure_pipeline.py` & `modelscope-1.7.0/modelscope/pipelines/science/protein_structure_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/pipelines/util.py` & `modelscope-1.7.0/modelscope/pipelines/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/__init__.py` & `modelscope-1.7.0/modelscope/preprocessors/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/asr.py` & `modelscope-1.7.0/modelscope/preprocessors/asr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/audio.py` & `modelscope-1.7.0/modelscope/preprocessors/audio.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/base.py` & `modelscope-1.7.0/modelscope/preprocessors/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/builder.py` & `modelscope-1.7.0/modelscope/preprocessors/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/common.py` & `modelscope-1.7.0/modelscope/preprocessors/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/__init__.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/action_detection_mapper.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/action_detection_mapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/bad_image_detecting_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/bad_image_detecting_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/controllable_image_generation.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/controllable_image_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/cv2_transforms.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/cv2_transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/image_classification_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/image_classification_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/image_quality_assessment_man.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/image_quality_assessment_man.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/image_quality_assessment_mos.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/image_quality_assessment_mos.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/image_restoration_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/image_restoration_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/mmcls_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/mmcls_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/timer.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/timer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/util.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/video_stabilization.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/video_stabilization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/cv/video_super_resolution.py` & `modelscope-1.7.0/modelscope/preprocessors/cv/video_super_resolution.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/image.py` & `modelscope-1.7.0/modelscope/preprocessors/image.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/kws.py` & `modelscope-1.7.0/modelscope/preprocessors/kws.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/movie_scene_segmentation/transforms.py` & `modelscope-1.7.0/modelscope/preprocessors/movie_scene_segmentation/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/multi_modal.py` & `modelscope-1.7.0/modelscope/preprocessors/multi_modal.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 import decord
 import json
 import numpy as np
 import torch
 from PIL import Image
 from timm.data import create_transform
 from torchvision import transforms
+from torchvision.datasets import ImageFolder
 from torchvision.transforms import Compose, Normalize, Resize, ToTensor
 
 from modelscope.hub.snapshot_download import snapshot_download
 from modelscope.metainfo import Preprocessors
 from modelscope.pipelines.base import Input
 from modelscope.pipelines.cv.cmdssl_video_embedding_pipeline import (
     VCenterCrop, VCompose, VNormalize, VRescale, VToTensor)
@@ -44,16 +45,16 @@
                 or existing in preprocessor_image_keys and pass-through the values of other keys.
 
     """
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.preprocessor_resolution = kwargs.pop('resolution', 512)
-        self.preprocessor_mean = kwargs.pop('mean', [0.5, 0.5, 0.5])
-        self.preprocessor_std = kwargs.pop('std', [0.5, 0.5, 0.5])
+        self.preprocessor_mean = kwargs.pop('mean', [0.5])
+        self.preprocessor_std = kwargs.pop('std', [0.5])
         self.preprocessor_image_keys = set(kwargs.pop('image_keys', []))
         self.transform_input = transforms.Compose([
             transforms.Resize(
                 self.preprocessor_resolution,
                 interpolation=transforms.InterpolationMode.BILINEAR),
             transforms.ToTensor(),
             transforms.Normalize(self.preprocessor_mean,
```

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/__init__.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/bert_seq_cls_tokenizer.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/bert_seq_cls_tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/canmt_translation.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/canmt_translation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/dialog_classification_use_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/dialog_classification_use_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/document_segmentation_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/document_segmentation_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/faq_question_answering_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/faq_question_answering_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/feature_extraction_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/feature_extraction_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/fill_mask_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/fill_mask_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/mgeo_ranking_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/mgeo_ranking_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/mglm_summarization_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/mglm_summarization_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/relation_extraction_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/relation_extraction_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/sentence_embedding_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/sentence_embedding_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/siamese_uie_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/siamese_uie_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/__init__.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/args.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/args.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/batch.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/batch.py`

 * *Files 1% similar despite different names*

```diff
@@ -46,11 +46,11 @@
                 b = []
         if drop_last is False and len(b) != 0:
             yield b
 
     # Batch size check
     batch_size = int(batch_size)
     if batch_size <= 0:
-        raise ValueError('batch_size should be a positive integeral value, '
+        raise ValueError('batch_size should be a positive integer value, '
                          'but got batch_size={}'.format(batch_size))
 
     return batch_reader
```

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/data_loader.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/data_loader.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/dialog_modeling_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/dialog_modeling_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/dst_processors.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/dst_processors.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/fields/__init__.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/fields/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/fields/gen_field.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/fields/gen_field.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/fields/intent_field.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/fields/intent_field.py`

 * *Files 0% similar despite different names*

```diff
@@ -340,15 +340,15 @@
             with open(filename, 'w', encoding='utf-8') as fp:
                 for ex in examples:
                     fp.write(json.dumps(ex) + '\n')
             elapsed = time.time() - start
             print(f'Saved {len(examples)} examples (elapsed {elapsed:.2f}s)')
         else:
             print(f"Saving examples to '{filename}' ...")
-            raise ValueError(f'Unsport file format: {filename}')
+            raise ValueError(f'Unsupport file format: {filename}')
 
     def load_examples(self, filename):
         start = time.time()
         if filename.endswith('npy'):
             print(f"Loading 1 object from '{filename}' ...")
             fp = np.memmap(filename, dtype='float32', mode='r')
             assert len(fp.shape) == 1
```

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/lazy_dataset.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/lazy_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/preprocess.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/preprocess.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/sampler.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/sampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/tensorlistdataset.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/tensorlistdataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space/tokenizer.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/__init__.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/fields/database.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/fields/database.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/fields/schema_link.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/fields/schema_link.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/fields/struct.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/fields/struct.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/__init__.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/__init__.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/common_utils.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/common_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/parse.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/parse.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/space_T_en/fields/process_dataset.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/space_T_en/fields/process_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/text_classification_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/text_classification_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/text_clean.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/text_clean.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/text_error_correction.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/text_error_correction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/text_generation_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/text_generation_preprocessor.py`

 * *Files 2% similar despite different names*

```diff
@@ -135,16 +135,23 @@
             else kwargs.get('max_length', 128)
 
         self.src_length = kwargs['max_length']
         self.tgt_length = kwargs.pop('target_max_length', kwargs['max_length'])
         model_type = None
         if model_dir is not None:
             model_type = get_model_type(model_dir)
-        self.nlp_tokenizer = NLPTokenizerForRoberta(
-            model_dir, model_type, use_fast=use_fast, tokenize_kwargs=kwargs)
+        if tokenizer is not None:
+            self.nlp_tokenizer = NLPTokenizer(tokenize_kwargs=kwargs)
+            self.nlp_tokenizer._tokenizer = tokenizer
+        else:
+            self.nlp_tokenizer = NLPTokenizerForRoberta(
+                model_dir,
+                model_type,
+                use_fast=use_fast,
+                tokenize_kwargs=kwargs)
 
     def decode(self, tokens, **kwargs):
         """Decode the tokens to real text.
 
         Args:
             tokens: The output tokens from model's `forward` and `generate`
```

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/text_ranking_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/text_ranking_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/token_classification_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/token_classification_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/token_classification_thai_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/token_classification_thai_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/token_classification_viet_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/token_classification_viet_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/transformers_tokenizer.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/transformers_tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/translation_evaluation_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/translation_evaluation_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/utils.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/word_alignment_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/word_alignment_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/nlp/zero_shot_classification_preprocessor.py` & `modelscope-1.7.0/modelscope/preprocessors/nlp/zero_shot_classification_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/__init__.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/asr.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/asr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/base.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/image_captioning.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/image_captioning.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/image_classification.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/image_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/ocr_recognition.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/ocr_recognition.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/sudoku.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/sudoku.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/summarization.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/summarization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/text2sql.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/text2sql.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/text_classification.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/text_to_image_synthesis.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/text_to_image_synthesis.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/utils/audio_helper.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/utils/audio_helper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/utils/bridge_content_encoder.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/utils/bridge_content_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/utils/collate.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/utils/collate.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/utils/constant.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/utils/constant.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/utils/get_tables.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/utils/get_tables.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/utils/random_help.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/utils/random_help.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/utils/text2phone.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/utils/text2phone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/utils/transforms.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/utils/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/utils/vision_helper.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/utils/vision_helper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/visual_entailment.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/visual_entailment.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/visual_grounding.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/visual_grounding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/ofa/visual_question_answering.py` & `modelscope-1.7.0/modelscope/preprocessors/ofa/visual_question_answering.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/science/uni_fold.py` & `modelscope-1.7.0/modelscope/preprocessors/science/uni_fold.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/tts.py` & `modelscope-1.7.0/modelscope/preprocessors/tts.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/preprocessors/video.py` & `modelscope-1.7.0/modelscope/preprocessors/video.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/tools/eval.py` & `modelscope-1.7.0/modelscope/tools/eval.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/tools/speech_tts_autolabel.py` & `modelscope-1.7.0/modelscope/tools/speech_tts_autolabel.py`

 * *Files 8% similar despite different names*

```diff
@@ -35,38 +35,38 @@
                    has_para=False,
                    enable_enh=False):
     if not os.path.exists(input_wav):
         raise ValueError(f'input_wav: {input_wav} not exists')
     if not os.path.exists(work_dir):
         raise ValueError(f'work_dir: {work_dir} not exists')
 
-    def _download_and_unzip_resousrce(model, model_revision=None):
+    def _download_and_unzip_resource(model, model_revision=None):
         if os.path.exists(model):
             model_cache_dir = model if os.path.isdir(
                 model) else os.path.dirname(model)
             check_local_model_is_latest(
                 model_cache_dir,
                 user_agent={ThirdParty.KEY: 'speech_tts_autolabel'})
         else:
             model_cache_dir = snapshot_download(
                 model,
                 revision=model_revision,
                 user_agent={ThirdParty.KEY: 'speech_tts_autolabel'})
         if not os.path.exists(model_cache_dir):
-            raise ValueError(f'mdoel_cache_dir: {model_cache_dir} not exists')
+            raise ValueError(f'model_cache_dir: {model_cache_dir} not exists')
         zip_file = os.path.join(model_cache_dir, 'model.zip')
         if not os.path.exists(zip_file):
             raise ValueError(f'zip_file: {zip_file} not exists')
         z = zipfile.ZipFile(zip_file)
         z.extractall(model_cache_dir)
         target_resource = os.path.join(model_cache_dir, 'model')
         return target_resource
 
-    model_resource = _download_and_unzip_resousrce(resource_model_id,
-                                                   resource_revision)
+    model_resource = _download_and_unzip_resource(resource_model_id,
+                                                  resource_revision)
     auto_labeling = AutoLabeling(
         os.path.abspath(input_wav),
         model_resource,
         False,
         os.path.abspath(work_dir),
         gender,
         develop_mode,
```

### Comparing `modelscope-1.6.1/modelscope/tools/train.py` & `modelscope-1.7.0/modelscope/tools/train.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/__init__.py` & `modelscope-1.7.0/modelscope/trainers/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/__init__.py` & `modelscope-1.7.0/modelscope/trainers/audio/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/ans_trainer.py` & `modelscope-1.7.0/modelscope/trainers/audio/ans_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/asr_trainer.py` & `modelscope-1.7.0/modelscope/trainers/audio/asr_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/kws_farfield_trainer.py` & `modelscope-1.7.0/modelscope/trainers/audio/kws_farfield_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/kws_nearfield_trainer.py` & `modelscope-1.7.0/modelscope/trainers/audio/kws_nearfield_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/kws_utils/__init__.py` & `modelscope-1.7.0/modelscope/trainers/audio/kws_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/kws_utils/batch_utils.py` & `modelscope-1.7.0/modelscope/trainers/audio/kws_utils/batch_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/kws_utils/det_utils.py` & `modelscope-1.7.0/modelscope/trainers/audio/kws_utils/det_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/kws_utils/file_utils.py` & `modelscope-1.7.0/modelscope/trainers/audio/kws_utils/file_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/kws_utils/model_utils.py` & `modelscope-1.7.0/modelscope/trainers/audio/kws_utils/model_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/kws_utils/runtime_utils.py` & `modelscope-1.7.0/modelscope/trainers/audio/kws_utils/runtime_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/separation_trainer.py` & `modelscope-1.7.0/modelscope/trainers/audio/separation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/audio/tts_trainer.py` & `modelscope-1.7.0/modelscope/trainers/audio/tts_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/base.py` & `modelscope-1.7.0/modelscope/trainers/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/builder.py` & `modelscope-1.7.0/modelscope/trainers/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cli_argument_parser.py` & `modelscope-1.7.0/modelscope/trainers/cli_argument_parser.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/__init__.py` & `modelscope-1.7.0/modelscope/trainers/cv/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/action_detection_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/action_detection_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/card_detection_scrfd_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/card_detection_scrfd_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/cartoon_translation_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/cartoon_translation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/face_detection_scrfd_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/face_detection_scrfd_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/image_classifition_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/image_classifition_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/image_defrcn_fewshot_detection_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/image_defrcn_fewshot_detection_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/image_detection_damoyolo_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/image_detection_damoyolo_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/image_inpainting_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/image_inpainting_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/image_instance_segmentation_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/image_instance_segmentation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/image_portrait_enhancement_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/image_portrait_enhancement_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/movie_scene_segmentation_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/movie_scene_segmentation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/nerf_recon_acc_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/nerf_recon_acc_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/ocr_detection_db_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/ocr_detection_db_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/ocr_recognition_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/ocr_recognition_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/referring_video_object_segmentation_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/referring_video_object_segmentation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/cv/vision_efficient_tuning_trainer.py` & `modelscope-1.7.0/modelscope/trainers/cv/vision_efficient_tuning_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/default_config.py` & `modelscope-1.7.0/modelscope/trainers/default_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/__init__.py` & `modelscope-1.7.0/modelscope/trainers/hooks/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/checkpoint/checkpoint_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/checkpoint/checkpoint_hook.py`

 * *Files 1% similar despite different names*

```diff
@@ -183,15 +183,16 @@
     def after_run(self, trainer):
         self.logger.info('Train finished. Uploading models, waiting...')
         push_to_hub_in_queue(
             self.PUSH_TO_HUB_QUEUE_NAME,
             strategy=self.upload_strategy,
             done=True)
         wait_for_done(self.PUSH_TO_HUB_QUEUE_NAME)
-        self.logger.info('Uploading models done.')
+        if self.push_to_hub:
+            self.logger.info('Uploading models done.')
 
     def _push_to_hub(self, trainer, prefix, output_dir, delete_dir=False):
         if self.is_model_id is None:
             self.is_model_id = check_model_is_id(trainer.input_model_id,
                                                  self.hub_token)
         self.tag += 1
         return push_to_hub_in_queue(
```

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/checkpoint/checkpoint_processor.py` & `modelscope-1.7.0/modelscope/trainers/hooks/checkpoint/checkpoint_processor.py`

 * *Files 1% similar despite different names*

```diff
@@ -22,28 +22,26 @@
 
         This is a strategic function which can be registered by other hook's function.
 
         Args:
             trainer: The trainer instance.
             output_dir: The target folder used in inference.
         """
-        model = trainer.unwrap_module(trainer.model)
         config = trainer.cfg
 
         # override pipeline by tasks name after finetune done,
         # avoid case like fill mask pipeline with a text cls task
         if config['task'] in [
                 getattr(Pipelines, attr) for attr in dir(Pipelines)
                 if not attr.startswith('__')
         ]:
             # TODO a temp fix to avoid pipeline_name and task mismatch
             config['pipeline'] = {'type': config['task']}
 
-        self.copy_files_and_dump_config(trainer, output_dir, config,
-                                        self._bin_file(model))
+        self.copy_files_and_dump_config(trainer, output_dir, config, '*.bin')
 
     @staticmethod
     def copy_files_and_dump_config(trainer, output_dir, config, bin_file):
         """Copy useful files to target output folder and dumps the target configuration.json.
         """
         model = trainer.unwrap_module(trainer.model)
```

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/checkpoint/load_checkpoint_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/checkpoint/load_checkpoint_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/clip_clamp_logit_scale_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/clip_clamp_logit_scale_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/compression/__init__.py` & `modelscope-1.7.0/modelscope/trainers/hooks/compression/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/compression/sparsity_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/compression/sparsity_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/compression/utils.py` & `modelscope-1.7.0/modelscope/trainers/hooks/compression/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/distributed/ddp_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/distributed/ddp_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/distributed/megatron_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/distributed/megatron_hook.py`

 * *Files 2% similar despite different names*

```diff
@@ -31,15 +31,15 @@
             if tp_world_size == 1:
                 return ''
             mp_rank = mpu.get_tensor_model_parallel_rank()
             return '_mp_rank_{:02d}'.format(mp_rank)
         except (ImportError, AssertionError):
             return ''
 
-    def get_bin_file(self):
+    def get_bin_filename(self):
         mp_rank = mpu.get_tensor_model_parallel_rank()
         rank = '{:02d}'.format(mp_rank)
         return f'mp_rank_{rank}_model_states.pt'
 
     def should_save_on_rank(self, trainer):
         # TODO
         return (not torch.distributed.is_initialized()
@@ -68,15 +68,15 @@
             trainer.optimizer,
             trainer.lr_scheduler,
             meta=meta,
             with_model=False)
 
         save_dir = os.path.dirname(checkpoint_path_prefix)
         prefix = os.path.basename(checkpoint_path_prefix)
-        bin_file = self.get_bin_file()
+        bin_file = self.get_bin_filename()
         prefix_bin_file = os.path.join(save_dir, prefix + '_' + bin_file)
         save_checkpoint(model, prefix_bin_file, with_meta=False)
 
         src_file = prefix_bin_file
         dest_file = os.path.join(output_dir, self._BIN_FILE_DIR, bin_file)
         if os.path.isfile(dest_file):
             os.unlink(dest_file)
@@ -94,36 +94,36 @@
         _train_state_file = checkpoint_path_prefix + self.rank_name(
         ) + CheckpointProcessor.TRAINER_STATE_SUFFIX
         if os.path.isfile(_train_state_file):
             os.remove(_train_state_file)
 
         save_dir = os.path.dirname(checkpoint_path_prefix)
         prefix = os.path.basename(checkpoint_path_prefix)
-        bin_file = self.get_bin_file()
+        bin_file = self.get_bin_filename()
         absolute_file = os.path.join(save_dir, prefix + '_' + bin_file)
         if os.path.isfile(absolute_file):
             os.remove(absolute_file)
 
     def load_checkpoints(self, checkpoint_path_prefix, trainer, load_all_state,
                          strict):
         model = trainer.unwrap_module(trainer.model)
         if os.path.isdir(checkpoint_path_prefix):
             save_dir = checkpoint_path_prefix
-            bin_file = self.get_bin_file()
+            bin_file = self.get_bin_filename()
             model_file = os.path.join(save_dir, bin_file)
             load_checkpoint(model_file, model, None, None)
         else:
             _train_state_file = checkpoint_path_prefix + self.rank_name(
             ) + CheckpointProcessor.TRAINER_STATE_SUFFIX
             meta = LoadCheckpointHook.load_trainer_state(
                 trainer, _train_state_file, load_all_state)
 
             save_dir = os.path.dirname(checkpoint_path_prefix)
             prefix = os.path.basename(checkpoint_path_prefix)
-            bin_file = self.get_bin_file()
+            bin_file = self.get_bin_filename()
 
             model_file = os.path.join(save_dir, prefix + '_' + bin_file)
             load_checkpoint(model_file, model, None, None)
             return meta
 
 
 @HOOKS.register_module(module_name=Hooks.MegatronHook)
```

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/early_stop_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/early_stop_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/evaluation_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/evaluation_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/iter_timer_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/iter_timer_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/logger/__init__.py` & `modelscope-1.7.0/modelscope/trainers/hooks/logger/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/logger/base.py` & `modelscope-1.7.0/modelscope/trainers/hooks/logger/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/logger/tensorboard_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/logger/tensorboard_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/logger/text_logger_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/logger/text_logger_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/lr_scheduler_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/lr_scheduler_hook.py`

 * *Files 2% similar despite different names*

```diff
@@ -35,14 +35,28 @@
         This is a strategic function which can be registered by other hook's function.
         """
         if self.warmup_lr_scheduler is not None:
             self.warmup_lr_scheduler.step()
         else:
             trainer.lr_scheduler.step()
 
+    def get_current_lr(self, trainer):
+        import torch
+
+        if isinstance(trainer.optimizer, torch.optim.Optimizer):
+            lr = [group['lr'] for group in trainer.optimizer.param_groups]
+        elif isinstance(trainer.optimizer, dict):
+            lr = dict()
+            for name, optim in trainer.optimizer.items():
+                lr[name] = [group['lr'] for group in optim.param_groups]
+        else:
+            raise RuntimeError(
+                'lr is not applicable because optimizer does not exist.')
+        return lr
+
 
 class LrStrategy:
     by_epoch = 'by_epoch'
     by_step = 'by_step'
     no = 'no'
 
 
@@ -80,43 +94,32 @@
             self.warmup_lr_scheduler = build_lr_scheduler(
                 cfg=self.warmup,
                 default_args={'base_scheduler': trainer.lr_scheduler})
             self.processor.set_warmup_lr_scheduler(self.warmup_lr_scheduler)
 
         self.processor.initialize_lr_scheduler(trainer)
 
-    def get_current_lr(self, trainer):
-        import torch
-
-        if isinstance(trainer.optimizer, torch.optim.Optimizer):
-            lr = [group['lr'] for group in trainer.optimizer.param_groups]
-        elif isinstance(trainer.optimizer, dict):
-            lr = dict()
-            for name, optim in trainer.optimizer.items():
-                lr[name] = [group['lr'] for group in optim.param_groups]
-        else:
-            raise RuntimeError(
-                'lr is not applicable because optimizer does not exist.')
-        return lr
-
     def after_train_iter(self, trainer):
         if self.lr_strategy == LrStrategy.by_step and trainer.iter >= getattr(
                 trainer, 'cumulative_iters', 1) - 1:
             self.processor.step(trainer)
         trainer.log_buffer.output[LogKeys.LR] = self._get_log_lr(trainer)
 
     def before_train_epoch(self, trainer):
         trainer.log_buffer.output[LogKeys.LR] = self._get_log_lr(trainer)
 
     def after_train_epoch(self, trainer):
         if self.lr_strategy == LrStrategy.by_epoch:
             self.processor.step(trainer)
 
     def _get_log_lr(self, trainer):
-        cur_lr = self.get_current_lr(trainer)
+        # forward compatibility with AddLrLogHook in EasyCV
+        if not hasattr(self, 'processor'):
+            self.processor = LrSchedulerProcessor()
+        cur_lr = self.processor.get_current_lr(trainer)
         # only record lr of the first param group
         if isinstance(cur_lr, list):
             lr = cur_lr[0]
         else:
             assert isinstance(cur_lr, dict)
             lr = {}
             for k, lr_ in cur_lr.items():
```

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/optimizer/__init__.py` & `modelscope-1.7.0/modelscope/trainers/hooks/optimizer/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/optimizer/apex_optimizer_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/optimizer/apex_optimizer_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/optimizer/base.py` & `modelscope-1.7.0/modelscope/trainers/hooks/optimizer/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/optimizer/torch_optimizer_hook.py` & `modelscope-1.7.0/modelscope/trainers/hooks/optimizer/torch_optimizer_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/hooks/priority.py` & `modelscope-1.7.0/modelscope/trainers/hooks/priority.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/lrscheduler/__init__.py` & `modelscope-1.7.0/modelscope/trainers/lrscheduler/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/lrscheduler/builder.py` & `modelscope-1.7.0/modelscope/trainers/lrscheduler/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/lrscheduler/warmup/__init__.py` & `modelscope-1.7.0/modelscope/trainers/lrscheduler/warmup/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/lrscheduler/warmup/base.py` & `modelscope-1.7.0/modelscope/trainers/lrscheduler/warmup/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/lrscheduler/warmup/warmup.py` & `modelscope-1.7.0/modelscope/trainers/lrscheduler/warmup/warmup.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/multi_modal/__init__.py` & `modelscope-1.7.0/modelscope/trainers/multi_modal/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/multi_modal/clip/clip_trainer.py` & `modelscope-1.7.0/modelscope/trainers/multi_modal/clip/clip_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/multi_modal/clip/clip_trainer_utils.py` & `modelscope-1.7.0/modelscope/trainers/multi_modal/clip/clip_trainer_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py` & `modelscope-1.7.0/modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/multi_modal/mgeo_ranking_trainer.py` & `modelscope-1.7.0/modelscope/trainers/multi_modal/mgeo_ranking_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/multi_modal/mplug/mplug_trainer.py` & `modelscope-1.7.0/modelscope/trainers/multi_modal/mplug/mplug_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/multi_modal/ofa/ofa_trainer.py` & `modelscope-1.7.0/modelscope/trainers/multi_modal/ofa/ofa_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/multi_modal/ofa/ofa_trainer_utils.py` & `modelscope-1.7.0/modelscope/trainers/multi_modal/ofa/ofa_trainer_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/multi_modal/team/team_trainer.py` & `modelscope-1.7.0/modelscope/trainers/multi_modal/team/team_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/multi_modal/team/team_trainer_utils.py` & `modelscope-1.7.0/modelscope/trainers/multi_modal/team/team_trainer_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/__init__.py` & `modelscope-1.7.0/modelscope/trainers/nlp/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/csanmt_translation_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/csanmt_translation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/document_grounded_dialog_generate_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/document_grounded_dialog_generate_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/document_grounded_dialog_rerank_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/document_grounded_dialog_rerank_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/document_grounded_dialog_retrieval_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/document_grounded_dialog_retrieval_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/faq_question_answering_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/faq_question_answering_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/gpt3_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/gpt3_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/gpt_moe_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/gpt_moe_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/plug_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/plug_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/sentence_embedding_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/sentence_embedding_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/sequence_classification_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/sequence_classification_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/siamese_uie_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/siamese_uie_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/space/dialog_intent_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/space/dialog_intent_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/space/dialog_modeling_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/space/dialog_modeling_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/space/eval.py` & `modelscope-1.7.0/modelscope/trainers/nlp/space/eval.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/space/metrics/metrics_tracker.py` & `modelscope-1.7.0/modelscope/trainers/nlp/space/metrics/metrics_tracker.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/space/trainer/gen_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/space/trainer/gen_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/space/trainer/intent_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/space/trainer/intent_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/table_question_answering_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/table_question_answering_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/text_generation_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/text_generation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/text_ranking_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/text_ranking_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp/translation_evaluation_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp/translation_evaluation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/nlp_trainer.py` & `modelscope-1.7.0/modelscope/trainers/nlp_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/optimizer/builder.py` & `modelscope-1.7.0/modelscope/trainers/optimizer/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/optimizer/child_tuning_adamw_optimizer.py` & `modelscope-1.7.0/modelscope/swift/optimizers/child_tuning_adamw_optimizer.py`

 * *Files 3% similar despite different names*

```diff
@@ -9,24 +9,22 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import math
-import types
 from typing import Callable, Iterable, Tuple
 
 import numpy as np
 import torch
 from torch.distributions.bernoulli import Bernoulli
 from torch.optim import Optimizer
 
 from modelscope.utils.logger import get_logger
-from .builder import OPTIMIZERS, default_group
 
 logger = get_logger()
 
 __all__ = ['calculate_fisher', 'ChildTuningAdamW']
 
 
 def calculate_fisher(model: torch.nn.Module,
@@ -68,16 +66,14 @@
     print('Polar => {}'.format(polar))
 
     # TODO: pytorch: torch.kthvalue
 
     return gradient_mask
 
 
-@OPTIMIZERS.register_module(
-    group_key=default_group, module_name='ChildTuningAdamW')
 class ChildTuningAdamW(Optimizer):
 
     def __init__(self,
                  params: Iterable[torch.nn.parameter.Parameter],
                  lr: float = 1e-3,
                  betas: Tuple[float, float] = (0.9, 0.999),
                  eps: float = 1e-6,
```

### Comparing `modelscope-1.6.1/modelscope/trainers/parallel/builder.py` & `modelscope-1.7.0/modelscope/trainers/parallel/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/parallel/utils.py` & `modelscope-1.7.0/modelscope/trainers/parallel/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/trainer.py` & `modelscope-1.7.0/modelscope/trainers/trainer.py`

 * *Files 1% similar despite different names*

```diff
@@ -40,14 +40,15 @@
 from modelscope.utils.device import create_device
 from modelscope.utils.file_utils import func_receive_dict_inputs
 from modelscope.utils.logger import get_logger
 from modelscope.utils.registry import build_from_cfg
 from modelscope.utils.torch_utils import (compile_model, get_dist_info,
                                           get_local_rank, init_dist, is_dist,
                                           is_master, set_random_seed)
+from ..swift import Swift
 from .base import BaseTrainer
 from .builder import TRAINERS
 from .default_config import merge_cfg, merge_hooks, update_cfg
 from .hooks.hook import Hook
 from .parallel.builder import build_parallel
 from .parallel.utils import is_parallel
 
@@ -227,15 +228,15 @@
         self.parallel_groups = {}
 
         if self.launcher is not None and not self.cfg.safe_get(
                 'train.hooks.DDPHook'):
             # A logic to fit the current code
             # Put a DDPHook in if launcher is provided.
             if 'hooks' not in self.cfg.train:
-                self.cfg.train['hooks'] = ConfigDict([])
+                self.cfg.train['hooks'] = []
             self.cfg.train['hooks'].append({
                 'type': 'DDPHook',
                 'launcher': self.launcher
             })
 
         hooks = merge_hooks(self.cfg)
         self.register_hook_from_cfg(hooks)
@@ -260,18 +261,15 @@
                 self.model.to(self.device)
 
         self.print_cfg()
 
     def tune_module(self, efficient_tuners):
         if efficient_tuners is not None:
             for tuner in efficient_tuners:
-                type = tuner.pop('type')
-                if type == 'lora':
-                    from modelscope.tuners.lora import LoRATuner
-                    LoRATuner.tune(self.model, **tuner)
+                self.model = Swift.prepare_model(self.model, tuner)
 
     def place_model(self):
         """Place model to device, or to DDP
         """
         if self.device.type == 'cuda':
             self.model.to(self.device)
             if not is_parallel(self.model) and self._dist:
@@ -997,25 +995,26 @@
 
         We provide a default implementation, if you want to customize your own optimizer
         and lr scheduler, you can either pass a tuple through trainer init function or
         subclass this class and override this method.
         """
         optimizer, lr_scheduler = self.optimizers
         if optimizer is None:
-            optimizer_cfg = self.cfg.train.get('optimizer', None)
+            optimizer_cfg = deepcopy(self.cfg.train.get('optimizer', None))
         else:
             optimizer_cfg = None
 
         optim_options = {}
         if optimizer_cfg is not None:
             optim_options = optimizer_cfg.pop('options', {})
             optimizer = self.build_optimizer(cfg=optimizer_cfg)
 
         if lr_scheduler is None:
-            lr_scheduler_cfg = self.cfg.train.get('lr_scheduler', None)
+            lr_scheduler_cfg = deepcopy(
+                self.cfg.train.get('lr_scheduler', None))
         else:
             lr_scheduler_cfg = None
 
         lr_options = {}
         if lr_scheduler_cfg is not None:
             assert optimizer is not None
             lr_options = lr_scheduler_cfg.pop('options', {})
```

### Comparing `modelscope-1.6.1/modelscope/trainers/training_args.py` & `modelscope-1.7.0/modelscope/trainers/training_args.py`

 * *Files 2% similar despite different names*

```diff
@@ -113,14 +113,19 @@
         })
 
     model: str = field(
         default=None, metadata={
             'help': 'A model id or model dir',
         })
 
+    model_revision: str = field(
+        default=None, metadata={
+            'help': 'the revision of model',
+        })
+
     model_type: str = field(
         default=None,
         metadata={
             'help':
             'The mode type, if load_model_config is False, user need to fill this field',
             'cfg_node': 'model.type'
         })
```

### Comparing `modelscope-1.6.1/modelscope/trainers/utils/inference.py` & `modelscope-1.7.0/modelscope/trainers/utils/inference.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/trainers/utils/log_buffer.py` & `modelscope-1.7.0/modelscope/trainers/utils/log_buffer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/tuners/control_sd_lora.py` & `modelscope-1.7.0/modelscope/swift/control_sd_lora.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from diffusers.configuration_utils import ConfigMixin, register_to_config
 from diffusers.models.cross_attention import CrossAttention, LoRALinearLayer
 from diffusers.models.modeling_utils import ModelMixin
-from diffusers.models.resnet import (Downsample2D, Mish, Upsample2D,
-                                     downsample_2d, partial, upsample_2d)
+from diffusers.models.resnet import (Downsample2D, Upsample2D, downsample_2d,
+                                     partial, upsample_2d)
 from diffusers.models.unet_2d_blocks import \
     get_down_block as get_down_block_default
 from diffusers.utils.outputs import BaseOutput
 
 from .sd_lora import LoRACrossAttnProcessor
 
 
@@ -473,16 +473,18 @@
                  attention_mask=None,
                  scale=1.0):
         pre_lora: LoRACrossAttnProcessor
         post_lora: LoRACrossAttnProcessor
         assert self.control_states is not None
 
         batch_size, sequence_length, _ = hidden_states.shape
-        attention_mask = attn.prepare_attention_mask(attention_mask,
-                                                     sequence_length)
+        attention_mask = attn.prepare_attention_mask(
+            attention_mask=attention_mask,
+            target_length=sequence_length,
+            batch_size=batch_size)
         query = attn.to_q(hidden_states)
         for pre_lora in self.pre_loras:
             lora_in = query if pre_lora.post_add else hidden_states
             if isinstance(pre_lora, ControlLoRACrossAttnProcessor):
                 lora_in = lora_in + pre_lora.process_control_states(
                     hidden_states, scale)
             query = query + scale * pre_lora.to_q_lora(lora_in)
@@ -623,16 +625,18 @@
                  attention_mask=None,
                  scale=1.0):
         pre_lora: LoRACrossAttnProcessor
         post_lora: LoRACrossAttnProcessor
         assert self.control_states is not None
 
         batch_size, sequence_length, _ = hidden_states.shape
-        attention_mask = attn.prepare_attention_mask(attention_mask,
-                                                     sequence_length)
+        attention_mask = attn.prepare_attention_mask(
+            attention_mask=attention_mask,
+            target_length=sequence_length,
+            batch_size=batch_size)
         for pre_lora in self.pre_loras:
             if isinstance(pre_lora, ControlLoRACrossAttnProcessorV2):
                 hidden_states = hidden_states + pre_lora.process_control_states(
                     hidden_states, scale)
         hidden_states = hidden_states + self.process_control_states(
             hidden_states, scale)
         for post_lora in self.post_loras:
@@ -779,15 +783,15 @@
             eps=eps,
             affine=True)
         self.dropout = torch.nn.Dropout(dropout)
 
         if non_linearity == 'swish':
             self.nonlinearity = lambda x: F.silu(x)
         elif non_linearity == 'mish':
-            self.nonlinearity = Mish()
+            self.nonlinearity = nn.Mish()
         elif non_linearity == 'silu':
             self.nonlinearity = nn.SiLU()
 
         self.upsample = self.downsample = None
         if self.up:
             if kernel == 'fir':
                 fir_kernel = (1, 3, 3, 1)
```

### Comparing `modelscope-1.6.1/modelscope/tuners/lora.py` & `modelscope-1.7.0/modelscope/swift/lora.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,126 +1,194 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License (MIT). See LICENSE in the repo root for license information.
 import logging
 import math
 import os.path
+import re
 import types
+from dataclasses import dataclass, field
 from typing import Dict, List
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
+from modelscope import snapshot_download
+from modelscope.utils.constant import ModelFile
+from .base import SwiftConfig
+
 logger = logging.getLogger(__name__)
 
 
-class LoRATuner:
+@dataclass
+class LoRAConfig(SwiftConfig):
+    """
+    The configuration class for the loRA module.
+
+    Args:
+        rank: The rank of the LoRA module
+        replace_modules: The modules to be replaced by LoRA, can be the end of the module name or a regex string
+        lora_alpha: The factor to add the lora weights
+        lora_dropout: The dropout rate of the lora module
+        merge_weights: Whether to merge weights when validating
+        use_merged_linear: Whether to replace with merged linear layer
+        enable_lora: The modules need to be turned on when using the merged linear layer
+        fan_in_fan_out: Set this to True if the layer to replace stores weight like (fan_in, fan_out)
+        bias: Bias type. Values ca be "none", "all" or "lora_only"
+        only_lora_trainable: Whether to train only lora
+        pretrained_weights: The pretrained lora weights.
+            Can be a local dir, local file, or a model id from modelscope
+    """
+
+    rank: int = field(
+        default=6, metadata={'help': 'The rank of the LoRA module'})
+    replace_modules: List = field(
+        default=None,
+        metadata={
+            'help':
+            'The modules to be replaced by LoRA, can be the end of the module name or a regex string'
+        })
+    lora_alpha: float = field(
+        default=1., metadata={'help': 'The factor to add the lora weights'})
+    lora_dropout: float = field(
+        default=0., metadata={'help': 'The dropout rate of the lora module'})
+    merge_weights: bool = field(
+        default=True,
+        metadata={'help': 'Whether to merge weights when validating'})
+    use_merged_linear: bool = field(
+        default=False,
+        metadata={'help': 'Whether to replace with merged linear layer'})
+    enable_lora: List = field(
+        default=None,
+        metadata={
+            'help':
+            'The modules need to be turned on when using the merged linear layer'
+        })
+    fan_in_fan_out: bool = field(
+        default=False,
+        metadata={
+            'help':
+            'Set this to True if the layer to replace stores weight like (fan_in, fan_out)'
+        })
+    bias: str = field(
+        default='none',
+        metadata={
+            'help': 'Bias type. Values ca be "none", "all" or "lora_only"'
+        })
+    only_lora_trainable: bool = field(
+        default=True, metadata={'help': 'Whether to train only lora'})
+    pretrained_weights: str = field(
+        default=None,
+        metadata={
+            'help':
+            'The pretrained lora weights. Can be a local dir, local file, or a model id from modelscope'
+        })
+
+
+class LoRA:
 
     @staticmethod
-    def tune(model: nn.Module,
-             rank=6,
-             replace_modules=None,
-             lora_alpha=1.,
-             lora_dropout=0.,
-             merge_weights=True,
-             fan_in_fan_out=False,
-             bias='none',
-             pretrained_tuner=None):
-        """Tune a model with lora.
+    def prepare_model(model: nn.Module, config: LoRAConfig):
+        """Tune a model with LoRA.
 
         Args:
-            model: The torch.nn.Module containing the target module to be patched.
-            rank: The lora rank.
-            replace_modules: The module names to be replaced, the replacing strategy is `end with`.
-            lora_alpha: The alpha value for lora module.
-            lora_dropout: The dropout value for lora module.
-            merge_weights: If merge_weights set to True, when the module turns to `eval`, the lora weights
-                will be added into the origin weight to reduce calculation.
-            fan_in_fan_out: Set this to True if the layer to replace stores weight like (fan_in, fan_out).
-            bias: The grad strategy for bias, can be `none`, 'all' or 'lora_only'.
-            pretrained_tuner: The pretrained file of lora.
+            config: The LoRAConfig instance.
 
         Returns:
             The lora modules
         """
-        modules = LoRATuner._dynamic_patch_lora(
+        LoRA._dynamic_patch_lora(
             model,
-            replace_modules=replace_modules,
-            r=rank,
-            lora_alpha=lora_alpha,
-            lora_dropout=lora_dropout,
-            merge_weights=merge_weights,
-            fan_in_fan_out=fan_in_fan_out)
+            replace_modules=config.replace_modules,
+            r=config.rank,
+            lora_alpha=config.lora_alpha,
+            lora_dropout=config.lora_dropout,
+            merge_weights=config.merge_weights,
+            use_merged_linear=config.use_merged_linear,
+            enable_lora=config.enable_lora,
+            fan_in_fan_out=config.fan_in_fan_out)
 
-        mark_only_lora_as_trainable(model, bias)
+        if config.only_lora_trainable:
+            mark_only_lora_as_trainable(model, config.bias)
 
         def state_dict_hook(module, destination, prefix, local_metadata):
-            return lora_state_dict(destination, bias)
+            return lora_state_dict(destination, config.bias)
 
         model.state_dict_hook_handle = model._register_state_dict_hook(
             state_dict_hook)
 
-        def warning_hook(module, incompatible_keys):
-            logger.info(
-                f'The {module.__class__.__name__} module has unmatched keys: {incompatible_keys},'
-                f'this is converted to a notice with respect to LoRA')
-            for ik in incompatible_keys:
-                ik.clear()
-
-        if hasattr(model, 'register_load_state_dict_post_hook'):
-            model.load_state_dict_hook_handle = model.register_load_state_dict_post_hook(
-                warning_hook)
-        else:
-
-            def load_state_dict(self, state_dict, strict=True):
-                return self.load_state_dict_origin(state_dict, False)
-
-            model.load_state_dict_origin = model.load_state_dict
-            model.load_state_dict = types.MethodType(load_state_dict, model)
-
-        if pretrained_tuner is not None and os.path.isfile(pretrained_tuner):
-            logger.info(f'Loading LoRA weights from file: {pretrained_tuner}')
-            model.load_state_dict(torch.load(pretrained_tuner))
+        def load_state_dict(self, state_dict, strict=True):
+            return self.load_state_dict_origin(state_dict, False)
 
-        return modules
+        model.load_state_dict_origin = model.load_state_dict
+        model.load_state_dict = types.MethodType(load_state_dict, model)
+
+        if config.pretrained_weights is not None:
+            if not os.path.exists(config.pretrained_weights):
+                model_dir = snapshot_download(config.pretrained_weights)
+                pretrained_weights = os.path.join(
+                    model_dir, ModelFile.TORCH_MODEL_BIN_FILE)
+            elif os.path.isfile(config.pretrained_weights):
+                pretrained_weights = config.pretrained_weights
+            else:
+                pretrained_weights = os.path.join(
+                    config.pretrained_weights, ModelFile.TORCH_MODEL_BIN_FILE)
+            model.load_state_dict(torch.load(pretrained_weights))
+
+        return model
 
     @staticmethod
-    def _dynamic_patch_lora(model, replace_modules, **kwargs):
+    def _dynamic_patch_lora(model, replace_modules, use_merged_linear,
+                            **kwargs):
         """Dynamic patch lora to model
 
         Args:
             model: The torch.nn.Module containing the target module to be patched.
             replace_modules: The module names to be replaced, the replacing strategy is `end with`.
+            use_merged_linear: Whether to replace with merged linear layer
             **kwargs: The arguments passed from `tune` which are needed by lora.
 
         Returns:
             The lora modules
         """
         modules = []
         module_keys = [key for key, _ in model.named_modules()]
         assert isinstance(replace_modules, (str, list))
         if isinstance(replace_modules, str):
             replace_modules = [replace_modules]
 
         for module_key in module_keys:
-            if any([module_key.endswith(name)
-                    for name in replace_modules]):  # noqa
+            if isinstance(replace_modules, str):
+                target_module_found = re.fullmatch(replace_modules, module_key)
+            else:
+                target_module_found = any(
+                    module_key.endswith(target_key)
+                    for target_key in replace_modules)
+            if target_module_found:  # noqa
                 parts = module_key.split('.')
                 module = model.get_submodule('.'.join(parts[:-1]))
                 sub_module = model.get_submodule(module_key)
                 _key = parts[-1]
 
                 lora_module = None
                 if isinstance(sub_module, torch.nn.Linear):
-                    lora_module = Linear(
-                        sub_module.in_features,
-                        sub_module.out_features,
-                        bias=sub_module.bias is not None,
-                        **kwargs)
+                    if use_merged_linear:
+                        lora_module = MergedLinear(
+                            sub_module.in_features,
+                            sub_module.out_features,
+                            bias=sub_module.bias is not None,
+                            **kwargs)
+                    else:
+                        kwargs.pop('enable_lora', None)
+                        lora_module = Linear(
+                            sub_module.in_features,
+                            sub_module.out_features,
+                            bias=sub_module.bias is not None,
+                            **kwargs)
                 elif isinstance(sub_module, torch.nn.Conv2d):
                     kwargs.pop('fan_in_fan_out', None)
                     lora_module = Conv2d(
                         sub_module.in_channels,
                         sub_module.out_channels,
                         kernel_size=sub_module.kernel_size,
                         stride=sub_module.stride,
@@ -136,33 +204,41 @@
                     lora_module.to(sub_module.weight.device).to(
                         sub_module.weight.dtype)
                     setattr(module, _key, lora_module)
                     modules.append(lora_module)
         return modules
 
     @staticmethod
-    def unpatch_lora(model, replace_modules):
+    def unpatch_lora(model, config: LoRAConfig):
         """Unpatch lora modules and merge the weights to original modules.
 
+        LoRA constructs an additional layer with low-rank decomposition matrices of the weights in the network.
+        'LoRA: Low-Rank Adaptation of Large Language Models' by Hu et al.(2021)
+        See https://arxiv.org/abs/2106.09685
+
         Args:
             model: The model called with `tune` function.
             replace_modules: The module names to be replaced, the replacing strategy is `end with`.
 
         Returns:
             The lora modules.
         """
         modules = []
         module_keys = [key for key, _ in model.named_modules()]
-        assert isinstance(replace_modules, (str, list))
-        if isinstance(replace_modules, str):
-            replace_modules = [replace_modules]
+        assert isinstance(config.replace_modules, (str, list))
+        replace_modules = config.replace_modules
 
         for module_key in module_keys:
-            if any([module_key.endswith(name)
-                    for name in replace_modules]):  # noqa
+            if isinstance(replace_modules, str):
+                target_module_found = re.fullmatch(replace_modules, module_key)
+            else:
+                target_module_found = any(
+                    module_key.endswith(target_key)
+                    for target_key in replace_modules)
+            if target_module_found:  # noqa
                 parts = module_key.split('.')
                 module = model.get_submodule('.'.join(parts[:-1]))
                 sub_module = model.get_submodule(module_key)
                 _key = parts[-1]
 
                 origin_module = None
                 if isinstance(sub_module, Linear):
```

### Comparing `modelscope-1.6.1/modelscope/tuners/sd_lora.py` & `modelscope-1.7.0/modelscope/swift/sd_lora.py`

 * *Files 1% similar despite different names*

```diff
@@ -86,17 +86,18 @@
     def __call__(self,
                  attn: CrossAttention,
                  hidden_states,
                  encoder_hidden_states=None,
                  attention_mask=None,
                  scale=1.0):
         batch_size, sequence_length, _ = hidden_states.shape
-        attention_mask = attn.prepare_attention_mask(attention_mask,
-                                                     sequence_length,
-                                                     batch_size)
+        attention_mask = attn.prepare_attention_mask(
+            attention_mask=attention_mask,
+            target_length=sequence_length,
+            batch_size=batch_size)
 
         query = attn.to_q(hidden_states)
         query = query + scale * self.to_q_lora(
             query if self.post_add else hidden_states)
         query = attn.head_to_batch_dim(query)
 
         encoder_hidden_states = encoder_hidden_states if encoder_hidden_states is not None else hidden_states
```

### Comparing `modelscope-1.6.1/modelscope/utils/ast_index_file.py` & `modelscope-1.7.0/modelscope/utils/ast_index_file.py`

 * *Files 6% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.7691755443635383%*

 * *Differences: {"'files_mtime'": "{'TEMPLATE_PATH/models/base/base_torch_head.py': 1688302933.2671905, "*

 * *                  "'TEMPLATE_PATH/models/base/base_torch_model.py': 1688302933.2671905, "*

 * *                  "'TEMPLATE_PATH/models/base/base_model.py': 1688302933.2671905, "*

 * *                  "'TEMPLATE_PATH/models/base/base_head.py': 1688302933.2671905, "*

 * *                  "'TEMPLATE_PATH/models/science/unifold/data/process_multimer.py': "*

 * *                  "1688302933.3591883, 'TEMPLATE_PATH/models/science/unifold/da […]*

```diff
@@ -1,1673 +1,1696 @@
 {
     "files_mtime": {
-        "TEMPLATE_PATH/exporters/audio/ans_dfsmn_exporter.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/base.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/builder.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/cv/cartoon_translation_exporter.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/cv/face_detection_scrfd_exporter.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/cv/object_detection_damoyolo_exporter.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/nlp/csanmt_for_translation_exporter.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/nlp/sbert_for_zero_shot_classification_exporter.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/tf_model_exporter.py": 1686315994.6486099,
-        "TEMPLATE_PATH/exporters/torch_model_exporter.py": 1686315994.6486099,
-        "TEMPLATE_PATH/metrics/accuracy_metric.py": 1686315994.6486099,
-        "TEMPLATE_PATH/metrics/action_detection_evaluator.py": 1686315994.6486099,
-        "TEMPLATE_PATH/metrics/audio_noise_metric.py": 1686315994.6486099,
-        "TEMPLATE_PATH/metrics/base.py": 1686315994.6486099,
-        "TEMPLATE_PATH/metrics/bleu_metric.py": 1686315994.6486099,
-        "TEMPLATE_PATH/metrics/builder.py": 1686315994.6486099,
-        "TEMPLATE_PATH/metrics/ciderD/ciderD.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/ciderD/ciderD_scorer.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/image_color_enhance_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/image_colorization_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/image_denoise_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/image_inpainting_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/image_instance_segmentation_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/image_portrait_enhancement_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/image_quality_assessment_degradation_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/image_quality_assessment_mos_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/inbatch_recall_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/loss_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/map_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/movie_scene_segmentation_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/ned_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/ocr_recognition_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/ppl_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/prediction_saving_wrapper.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/referring_video_object_segmentation_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/sequence_classification_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/text_generation_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/text_ranking_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/token_classification_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/translation_evaluation_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/video_frame_interpolation_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/video_stabilization_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/video_summarization_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/video_super_resolution_metric/matlab_functions.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/video_super_resolution_metric/metric_util.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/video_super_resolution_metric/niqe.py": 1686315994.6526098,
-        "TEMPLATE_PATH/metrics/video_super_resolution_metric/video_super_resolution_metric.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/aec/layers/activations.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/aec/layers/affine_transform.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/aec/layers/deep_fsmn.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/aec/layers/layer_base.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/aec/layers/uni_deep_fsmn.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/aec/network/loss.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/aec/network/modulation_loss.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/aec/network/se_net.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/ans/complex_nn.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/ans/conv_stft.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/ans/denoise_net.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/ans/frcrn.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/ans/layers/activations.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/ans/layers/affine_transform.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/ans/layers/layer_base.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/ans/layers/uni_deep_fsmn.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/ans/se_module_complex.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/ans/unet.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/asr/wenet_automatic_speech_recognition.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/itn/generic_inverse_text_processing.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn_sele_v2.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn_sele_v3.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/kws/farfield/model.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/kws/farfield/model_def.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/kws/generic_key_word_spotting.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/kws/nearfield/cmvn.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/kws/nearfield/fsmn.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/kws/nearfield/model.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/punc/generic_punctuation.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/separation/layer_norm.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/separation/mossformer.py": 1686315994.6526098,
-        "TEMPLATE_PATH/models/audio/separation/mossformer_block.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/separation/mossformer_conv_module.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/sv/DTDNN.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/sv/DTDNN_layers.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/sv/ERes2Net.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/sv/ecapa_tdnn.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/sv/fusion.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/sv/generic_speaker_verification.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/sv/pooling_layers.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/sv/rdino.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/sv/speaker_change_locator.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/tts/sambert_hifi.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/audio/tts/voice.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/base/base_head.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/base/base_model.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/base/base_torch_head.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/base/base_torch_model.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/builder.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_model.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/action_detection/action_detection_onnx.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/action_detection/modules/action_detection_pytorch.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/action_detection/modules/resnet.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/action_recognition/models.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/action_recognition/s3dg.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/action_recognition/tada_convnext.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/action_recognition/temporal_patch_shift_transformer.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/animal_recognition/resnet.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/animal_recognition/splat.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/bad_image_detecting/bad_image_detecting.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_2d_keypoints/hrnet_basic_modules.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_2d_keypoints/hrnet_v2.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_2d_keypoints/w48.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/backbone.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/block.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/directed_graph.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/hdformer.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/skeleton.py": 1686315994.65661,
-        "TEMPLATE_PATH/models/cv/cartoon/facelib/LK/lk.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cartoon/facelib/config.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cartoon/facelib/face_detector.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cartoon/facelib/face_landmark.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cartoon/facelib/facer.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cartoon/loss.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cartoon/model_tf.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cartoon/network.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cartoon/utils.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/c3d.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/resnet2p1d.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/resnet3d.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/annotator.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/api.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/vit.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/utils.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/mlsd/utils.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/body.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/hand.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/model.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/util.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/controlnet.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/crowd_counting/cc_model.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/crowd_counting/hrnet_aspp_relu.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/detectors.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/mogface.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/mogprednet.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/resnet.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/utils.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/box_utils.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/detector.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/first_stage.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/get_nets.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/LK/lk.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/face_detector.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/face_landmark.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/facer.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/retinaface/detection.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/retinaface/models/net.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/retinaface/models/retinaface.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/retinaface/utils.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/damofd_detect.py": 1686315994.66061,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/preprocessor.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/scrfd_detect.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/tinymog_detect.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/detection.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/box_utils.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/transforms.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_emotion/efficient/model.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_emotion/efficient/utils.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_emotion/emotion_infer.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_emotion/emotion_model.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_emotion/face_alignment/face.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_emotion/face_alignment/face_align.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_generation/op/conv2d_gradfix.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_generation/op/fused_act.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_generation/op/upfirdn2d.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_generation/stylegan2.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/det_infer.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/ghost_pan.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/nanodet_plus_head.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/one_stage_detector.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/shufflenetv2.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/utils.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_recognition/align_face.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/common.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/model_irse.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/model_resnet.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/rts_backbone.py": 1686315994.6646101,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/bfm.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/de_retouching_module.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facerecon_model.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/losses.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/networks.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/nv_diffrast.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/opt.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/networks.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/renderer.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/unet.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/utils.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/transforms.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/vgg.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/hand_static/hand_model.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/hand_static/networks.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/Reconstruction.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Embedding.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/PixToMesh.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Res_backbone.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Surface_head.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/detectors.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/geometry.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/human_segmenter.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/networks.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/utils.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_binary_quant_classification/binary_quant_model.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_binary_quant_classification/bnext.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/image_body_reshaping.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/model.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/person_info.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/body.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/model.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/util.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/slim_utils.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_classification/backbones/beit_v2.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_classification/backbones/nextvit.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_classification/mmcls_model.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_classification/resnet50_cc.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_classification/utils.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_color_enhance/adaint/adaint.py": 1686315994.6686103,
-        "TEMPLATE_PATH/models/cv/image_color_enhance/csrnet.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_color_enhance/deeplpf/deeplpfnet.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_color_enhance/image_color_enhance.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/ddcolor.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/loss.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/convnext.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/position_encoding.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/transformer_utils.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/unet.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/vgg.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_colorization/unet/unet.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_colorization/unet/utils.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_debanding/rrdb/rrdb_image_debanding.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_deblur/nafnet_for_image_deblur.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/evaluator.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/calibration_layer.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/defrcn.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/fast_rcnn.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/gdl.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/resnet.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/roi_heads.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/coco_register.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/register_data.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/requirements_check.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/voc_register.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_denoise/nafnet/NAFNet_arch.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_denoise/nafnet/arch_util.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_denoise/nafnet_for_image_denoise.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_depth.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_layers.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_utils.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/swin_transformer.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/uper_crf_head.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/newcrfs_model.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/bts_model.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/decoder.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/encoder.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/utils.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_driving_perception/image_driving_percetion_model.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_driving_perception/preprocessor.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_driving_perception/utils.py": 1686315994.6726103,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/gan_wrap.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/model.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/fused_act.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/upfirdn2d.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facelib/align_trans.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facelib/matlab_cp2tform.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/image_face_fusion.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/aad_layer.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/aei_flow_net.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/bfm.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/dense_motion.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/facerecon_model.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/model_irse.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/ops.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_human_parsing/backbone/deeplab_resnet.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp/m2fp_decoder.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp/m2fp_encoder.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp_net.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_human_parsing/parsing_utils.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/base.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/default.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/model.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ade20k/base.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ade20k/resnet.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/adversarial.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/feature_matching.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ffc.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/inception.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/perceptual.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/pix2pixhd.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_inpainting/refinement.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/backbones/resnet.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/backbones/swin_transformer.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/datasets/transforms.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst_model.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/dino_decoder.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/position_encoding.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/utils.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino_model.py": 1686315994.6766105,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino_swin.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/postprocess_utils.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/config/default.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/quadtree_attention_model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_matching/utils/misc.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/cas_mvsnet.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/casmvs_model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/depth_filter.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/general_eval_dataset.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/module.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/utils.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_paintbyexample/model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_panoptic_segmentation/panseg_model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/align_faces.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/eqface/fqa.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/eqface/model_resnet.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/gpen.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/image_portrait_enhancement.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/helpers.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/losses.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/model_irse.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/detection.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/models/net.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/utils.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_probing_model/backbone.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_probing_model/model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_probing_model/utils.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_degradation/degradation_model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/image_quality_assessment_man.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/maniqa.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/swin.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/backbones/resnet.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/heads/simple_head.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_reid_person/pass_model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_reid_person/transreid_model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_restoration/demoire_models/nets.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_restoration/image_restoration_model.py": 1686315994.6806104,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/utils.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/semantic_seg_model.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_skychange/preprocessor.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/BlockModules.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/hrnet_backnone.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/unet.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_skychange/skychange.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_skychange/skychange_model.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/data/transforms.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/model.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/models/autoencoder.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/models/clip.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/ops/diffusion.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/ops/losses.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/data/transforms.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/model_translation.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/models/autoencoder.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/models/clip.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/apps.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/degradation.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/diffusion.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/losses.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/metrics.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/random_color.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/random_mask.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/svd.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/utils.py": 1686315994.6846106,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/fourier.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/panostretch.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/post_proc.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/modality/layout.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/panovit.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/utils.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/panovit.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/summarizer.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/layers.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/models.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/modules.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/sub_layers.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/motion_generation/model.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/cfg_sampler.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/gaussian_diffusion.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/mdm.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/respace.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/rotation2xyz.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/smpl.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/get_model.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/model.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/head.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/save_op.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/shot_encoder.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/trn.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/dataloader/read_write_model.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_preprocess.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_recon_acc.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/nerf.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/segmenter.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/utils.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_model.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/backbones/vit.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/necks/fpn.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/utils/checkpoint.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/depe_detect.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py": 1686315994.6886106,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/result_vis.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_detection/model.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_detection/modules/dbnet.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_detection/modules/seg_detector_loss.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_detection/preprocessor.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_detection/utils.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/model.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/convnext.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/convnextvit.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/crnn.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/timm_tinyc.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/vitstr.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/preprocessor.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/open_vocabulary_detection_vild/vild.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/equi.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/layers.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/mobilenet.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/resnet.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/unifuse.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/util.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/unifuse_model.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/pedestrian_attribute_recognition/model.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/common.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/rcp_model.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_detection.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_embedding.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_model.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/product_segmentation/net.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/product_segmentation/seg_infer.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/model.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/backbone.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/criterion.py": 1686315994.6926107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/matcher.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/misc.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/mttr.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/postprocessing.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/segmentation.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/swin_transformer.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/robust_image_classification/easyrobust_model.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/salient_detection/models/backbone/Res2Net_v1b.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/salient_detection/models/modules.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/salient_detection/models/senet.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/salient_detection/models/u2net.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/salient_detection/models/utils.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/salient_detection/salient_model.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/common.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/head_fpn.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/models.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/neck_fpn.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/shop_seg_base.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/shop_seg_model.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/utils.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/detection_model/detection_module.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/detection_model/detection_unet_in.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/inpainting_model/gconv.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/inpainting_model/inpainting_unet.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/box_utils.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/net.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/network.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/predict_single.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/prior_box.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/utils.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/unet_deploy.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/utils.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/skin_retouching/weights_init.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/data/data_augment.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/exp/base_exp.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/exp/build.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/exp/default/streamyolo.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/exp/yolox_base.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/models/darknet.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/models/dfp_pafpn.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/models/network_blocks.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/models/streamyolo.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/models/tal_head.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/realtime_video_detector.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/utils/boxes.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/stream_yolo/utils/format.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/super_resolution/arch_util.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/super_resolution/ecb.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/super_resolution/ecbsr_model.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/super_resolution/rrdbnet_arch.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/table_recognition/lineless_table_process.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/table_recognition/model_lore.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/table_recognition/modules/lore_detector.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/table_recognition/modules/lore_processor.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/clip.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_base.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_blocks.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_model.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_net.py": 1686315994.6966107,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_vit.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/model.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/simple_tokenizer.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/basic_blocks.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/global_utils.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/master_net.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/model_zoo.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/plain_net_utils.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_blocks.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_idwexkx.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_k1kxk1.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_kxkx.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/apis/detector_evaluater.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/apis/detector_inference.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/base_ops.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/ops.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/utils.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/weight_init.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/detectors/detector.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/bounding_box.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/boxlist_ops.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/image_list.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/boxes.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/model_utils.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/scheduler.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/detector.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_damoyolo.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_detector.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/utils.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/UNet_for_video_deinterlace.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/deinterlace_arch.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/models/archs.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/models/deep_fourier_upsampling.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/models/enh.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/models/fre.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/models/utils.py": 1686315994.7006109,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/configs/default_config.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/dro_model.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/camera.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/camera_utils.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/pose.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/pose_utils.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_checkpoint.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_utils.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_wrapper.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/sfm_model_mf.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/sup_model_mf.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/layers.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/optim/extractor.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/optim/update.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/augmentations.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/config.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/depth.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/horovod.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/image.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/image_gt.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/load.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/misc.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/types.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/VFINet_arch.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/corr.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/extractor.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/raft.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/update.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/UNet.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/flow_reversal.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/transformer_layers.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/utils/scene_change_detection.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/utils/utils.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_human_matting/model.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_human_matting/models/decoder.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_human_matting/models/deep_guided_filter.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_human_matting/models/effv2.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_human_matting/models/lraspp.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_human_matting/models/matting.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_inpainting/inpainting.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_inpainting/inpainting_model.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_head.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_iter_head.py": 1686315994.7046108,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_update_head.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_updator.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/kernel_update_head.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/utils.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/video_knet.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/common.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/decode.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/model.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/yolo.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/basetrack.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/matching.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/multitracker.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/image.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/kalman_filter.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/utils.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/visualization.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/aggregate.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/cbam.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/eval_network.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/inference_core.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/inference_memory_bank.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/mod_resnet.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/model.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/modules.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/network.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_head.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_update_head.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_updator.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/mask.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/track_heads.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/neck/fpn.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/video_k_net.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/visualizer.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/config/ostrack.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/attn.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/attn_blocks.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/head.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/patch_embed.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/ostrack.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/utils.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/procontext.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/utils.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/vit_ce.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/tracker/ostrack.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/tracker/procontext.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/utils/utils.py": 1686315994.708611,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/DUT_raft.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/MotionPro.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/corr.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/extractor.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/raft.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/update.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/Smoother.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/config.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/rf_det_module.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/rf_det_so.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUTRAFTStabilizer.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/IterativeSmooth.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/MedianFilter.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/ProjectionUtils.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/RAFTUtils.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/WarpUtils.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/image_utils.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/math_utils.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/longshortnet.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/longshort.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_summarization/base_model.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_summarization/kts/cpd_auto.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_summarization/kts/cpd_nonlin.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_summarization/pgl_sum.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_summarization/summarizer.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_super_resolution/basicvsr_net.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_super_resolution/common.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_super_resolution/msrresnet_lite_model.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/video_super_resolution/real_basicvsr_net.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vidt/backbone.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vidt/deformable_transformer.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vidt/fpn_fusion.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vidt/head.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vidt/model.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/virual_tryon/sdafnet.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/backbone.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/head.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/model.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/petl.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_helpers.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_vision_transformer.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_weight_init.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/vision_efficient_tuning.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_middleware/backbone.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_middleware/head.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_middleware/model.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vision_middleware/vim.py": 1686315994.7126112,
-        "TEMPLATE_PATH/models/cv/vop_retrieval/backbone.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/cv/vop_retrieval/basic_utils.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/cv/vop_retrieval/model.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/cv/vop_retrieval/model_se.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/cv/vop_retrieval/tokenization_clip.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/clip/bert_tokenizer.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/clip/configuration_bert.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/clip/model.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/clip/modeling_bert.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/clip_interrogator/model.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/diffusion.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/model.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/structbert.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/tokenizer.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_generator.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_upsampler_1024.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_upsampler_256.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/dpm_solver_pytorch.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/gemm/gemm_base.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/gemm/gemm_model.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/gemm/tokenizer.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/gaussian_diffusion.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/respace.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/script.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/unet.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/mgeo/backbone.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/mgeo/text_classification.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/mgeo/text_ranking.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/mgeo/token_classification.py": 1686315994.7166111,
-        "TEMPLATE_PATH/models/multi_modal/mmr/dataloaders/rawvideo_util.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/dynamic_inverted_softmax.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/modeling.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/module_clip.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/module_cross.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/tokenization_clip.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/until_module.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mplug/clip/clip.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mplug/configuration_mplug.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mplug/modeling_mplug.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mplug/mvit.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mplug/predictor.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mplug_owl/configuration_mplug_owl.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/mplug_owl/modeling_mplug_owl.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/clip.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/decoder.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/model.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/prior.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/tokenizer.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/upsampler.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/xglm.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/configuration_mmspeech.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/configuration_ofa.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/incremental_decoding_utils.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/multihead_attention.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/ngram_repeat_block.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/search.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/sequence_generator.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/token_generation_constraints.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/utils.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/modeling_mmspeech.py": 1686315994.7206113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/modeling_ofa.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/resnet.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/tokenization_ofa.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/tokenization_ofa_fast.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/utils/constant.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/utils/utils.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/ofa/vit.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/ofa_for_text_to_image_synthesis_model.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/rleg/model.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/rleg/rleg.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/soonet/blocks.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/soonet/clip.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/soonet/model.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/soonet/swin_transformer.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/soonet/tokenizer.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/soonet/utils.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/team/team_model.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/team/utils.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/video_synthesis/autoencoder.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/video_synthesis/diffusion.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/video_synthesis/unet_sd.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/conv_fpn_trans.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/convnext.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/model.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/modeling_layout_roberta.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/processing.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/tokenization.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/transformer_local.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/nlp/T5/backbone.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/nlp/T5/configuration.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/nlp/T5/text2text_generation.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/nlp/bart/text_error_correction.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/nlp/bert/backbone.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/nlp/bert/configuration.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/nlp/bert/document_segmentation.py": 1686315994.7246113,
-        "TEMPLATE_PATH/models/nlp/bert/fill_mask.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/bert/sentence_embedding.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/bert/siamese_uie.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/bert/text_classification.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/bert/text_ranking.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/bert/token_classification.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/bert/word_alignment.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/bloom/backbone.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/canmt/canmt_model.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/canmt/canmt_translation.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/canmt/sequence_generator.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/codegeex/codegeex.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_generation.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_translation.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/codegeex/inference.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/codegeex/tokenizer.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/csanmt/translation.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/deberta_v2/backbone.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/deberta_v2/configuration.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/deberta_v2/fill_mask.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/deberta_v2/tokenization.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/deberta_v2/tokenization_fast.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/dgds/backbone.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_generate.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_rerank.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_retrieval.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/fid_T5/text_generation.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/fid_plug/backbone.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/fid_plug/configuration.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/fid_plug/text_generation.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/glm_130b/generation/strategies.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/glm_130b/initialize.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/glm_130b/quantization/functional.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/glm_130b/quantization/layers.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/glm_130b/text_generation.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/gpt2/backbone.py": 1686315994.7286115,
-        "TEMPLATE_PATH/models/nlp/gpt3/backbone.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt3/configuration.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt3/distributed_gpt3.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt3/text_generation.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt3/tokenizer.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/backbone.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/checkpointing.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/configuration.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/distributed_gpt_moe.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/experts.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/layer.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/mappings.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/sharded_moe.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/utils.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/text_generation.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/tokenizer.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/gpt_neo/backbone.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/heads/crf_head.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/heads/fill_mask_head.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/heads/infromation_extraction_head.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/heads/text_generation_head.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/heads/text_ranking_head.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/heads/token_classification_head.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/heads/torch_pretrain_head.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/hf_transformers/backbone.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/llama/backbone.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/llama/configuration.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/llama/convert_llama_weights_to_hf.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/llama/text_generation.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/llama/tokenization.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/llama/tokenization_fast.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/lstm/backbone.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/lstm/token_classification.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/megatron_bert/backbone.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/megatron_bert/configuration.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/megatron_bert/fill_mask.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/arguments.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/blocklm_utils.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/configure_data.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/corpora.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/datasets.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/extraction.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/file_utils.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/lazy_loader.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/samplers.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/sp_tokenizer.py": 1686315994.7326114,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/tokenization.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/tokenization_gpt2.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/wordpiece.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/generation_utils.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/mglm_for_text_summarization.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/model/distributed.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/model/downstream.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/model/modeling_bert.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/model/modeling_glm.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/model/prompt.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/model/transformer.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/process_grid.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/run_test.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/data_utils.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/eval_utils.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/dataset.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/detokenizer.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/finetune.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/dataset.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/evaluate.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/finetune.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/dataset.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/evaluate.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/finetune.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/pvp.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/test/test_block.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/test/test_rel_shift.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/train_utils.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/mglm/utils.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/palm_v2/configuration.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/palm_v2/dureader_eval.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/palm_v2/text_generation.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/peer/backbone.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/peer/configuration.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/peer/sas_utils.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/peer/text_classification.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/plug/AnnealingLR.py": 1686315994.7366116,
-        "TEMPLATE_PATH/models/nlp/plug/backbone.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/plug/configuration.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/plug/distributed_plug.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/plug/generator.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/plug_mental/adv_utils.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/plug_mental/backbone.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/plug_mental/configuration.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/plug_mental/text_classification.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/ponet/backbone.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/ponet/configuration.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/ponet/document_segmentation.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/ponet/fill_mask.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/ponet/tokenization.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/configuration.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/dialog_intent_prediction.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/dialog_modeling.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/dialog_state_tracking.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/model/gen_unified_transformer.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/model/generator.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/model/intent_unified_transformer.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/model/model_base.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/model/tokenization_space.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/model/unified_transformer.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/modules/embedder.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/modules/feedforward.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/modules/functions.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/modules/multihead_attention.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space/modules/transformer_block.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space_T_cn/backbone.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space_T_cn/configuration.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space_T_cn/table_question_answering.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/space_T_en/text_to_sql.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/structbert/adv_utils.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/structbert/backbone.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/structbert/configuration.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/structbert/faq_question_answering.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/structbert/fill_mask.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/structbert/text_classification.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/structbert/token_classification.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/task_models/feature_extraction.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/task_models/fill_mask.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/task_models/information_extraction.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/task_models/task_model.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/task_models/text_classification.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/task_models/text_generation.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/task_models/text_ranking.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/task_models/token_classification.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/unite/configuration.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/unite/translation_evaluation.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/use/transformer.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/use/user_satisfaction_estimation.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/veco/backbone.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/veco/configuration.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/veco/fill_mask.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/veco/text_classification.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/veco/token_classification.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/xlm_roberta/backbone.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/nlp/xlm_roberta/configuration.py": 1686315994.7406116,
-        "TEMPLATE_PATH/models/science/unifold/config.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/data/data_ops.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/data/msa_pairing.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/data/process.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/data/process_multimer.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/data/protein.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/data/residue_constants.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/data/utils.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/dataset.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/model.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/alphafold.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/attentions.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/auxillary_heads.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/common.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/confidence.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/embedders.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/evoformer.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/featurization.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/frame.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/structure_module.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/template.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/modules/triangle_multiplication.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/mmcif.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/msa_identifiers.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/parsers.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/pipeline.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/templates.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/hhblits.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/hhsearch.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/hmmbuild.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/hmmsearch.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/jackhmmer.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/kalign.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/utils.py": 1686315994.7446117,
-        "TEMPLATE_PATH/models/science/unifold/msa/utils.py": 1686315994.7446117,
-        "TEMPLATE_PATH/msdatasets/audio/asr_dataset.py": 1686315994.7446117,
-        "TEMPLATE_PATH/msdatasets/auth/auth_config.py": 1686315994.7446117,
-        "TEMPLATE_PATH/msdatasets/context/dataset_context_config.py": 1686315994.7446117,
-        "TEMPLATE_PATH/msdatasets/data_files/data_files_manager.py": 1686315994.7446117,
-        "TEMPLATE_PATH/msdatasets/data_loader/data_loader.py": 1686315994.7446117,
-        "TEMPLATE_PATH/msdatasets/data_loader/data_loader_manager.py": 1686315994.7446117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py": 1686315994.7446117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py": 1686315994.7446117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/builder.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/easycv_base.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/veco_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/dataset.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/download/dataset_builder.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/download/download_config.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/download/download_manager.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/meta/data_meta_config.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/meta/data_meta_manager.py": 1686315994.7486117,
-        "TEMPLATE_PATH/msdatasets/ms_dataset.py": 1686315994.7526119,
-        "TEMPLATE_PATH/msdatasets/task_datasets/gopro_image_deblurring_dataset.py": 1686315994.7526119,
-        "TEMPLATE_PATH/msdatasets/task_datasets/reds_image_deblurring_dataset.py": 1686315994.7526119,
-        "TEMPLATE_PATH/msdatasets/task_datasets/sidd_image_denoising.py": 1686315994.7526119,
-        "TEMPLATE_PATH/msdatasets/task_datasets/torch_base_dataset.py": 1686315994.7526119,
-        "TEMPLATE_PATH/msdatasets/task_datasets/video_summarization_dataset.py": 1686315994.7526119,
-        "TEMPLATE_PATH/msdatasets/utils/dataset_utils.py": 1686315994.7526119,
-        "TEMPLATE_PATH/msdatasets/utils/delete_utils.py": 1686315994.7526119,
-        "TEMPLATE_PATH/msdatasets/utils/maxcompute_utils.py": 1686315994.7526119,
-        "TEMPLATE_PATH/msdatasets/utils/oss_utils.py": 1686315994.7526119,
-        "TEMPLATE_PATH/msdatasets/utils/upload_utils.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/ans_dfsmn_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/ans_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/asr_inference_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/asr_wenet_inference_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/inverse_text_processing_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/kws_farfield_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/kws_kwsbp_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/linear_aec_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/lm_infer_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/punctuation_processing_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/separation_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/speaker_change_locating_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/speaker_diarization_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/speaker_verification_eres2net_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/speaker_verification_light_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/speaker_verification_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/speaker_verification_rdino_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/text_to_speech_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/timestamp_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/audio/voice_activity_detection_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/base.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/builder.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/cv/action_detection_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/cv/action_recognition_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/cv/animal_recognition_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/cv/arc_face_recognition_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/cv/bad_image_detecting_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/cv/body_2d_keypoints_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/cv/body_3d_keypoints_pipeline.py": 1686315994.7526119,
-        "TEMPLATE_PATH/pipelines/cv/card_detection_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/cmdssl_video_embedding_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/content_check_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/controllable_image_generation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/crowd_counting_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/ddcolor_image_colorization_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/ddpm_semantic_segmentation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_attribute_recognition_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_detection_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_emotion_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_human_hand_detection_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_image_generation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_liveness_ir_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_liveness_xc_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_processing_base_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_quality_assessment_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_fm_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_ir_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_recognition_ood_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_recognition_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/face_reconstruction_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/facial_expression_recognition_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/facial_landmark_confidence_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/fast_instance_segmentation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/general_recognition_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/hand_static_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/hicossl_video_embedding_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/human_reconstruction_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_body_reshaping_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_bts_depth_estimation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_cartoon_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_color_enhance_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_colorization_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_debanding_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_deblur_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_defrcn_fewshot_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_denoise_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_depth_estimation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_detection_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_driving_perception_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_face_fusion_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_human_parsing_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_inpainting_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_inpainting_sdv2_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_instance_segmentation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_matching_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_matting_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_mvs_depth_estimation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_open_vocabulary_detection_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_paintbyexample_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_portrait_enhancement_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_degradation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_man_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_mos_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_reid_person_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_restoration_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_salient_detection_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_semantic_segmentation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_skychange_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_structured_model_probing_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_style_transfer_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_super_resolution_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_to_image_generate_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/image_to_image_translation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/indoor_layout_estimation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/language_guided_video_summarization_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/license_plate_detection_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/lineless_table_recognition_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/live_category_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/mask_face_recognition_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/maskdino_instance_segmentation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/mobile_image_super_resolution_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/mog_face_detection_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/motion_generation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/movie_scene_segmentation_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/mtcnn_face_detection_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/nerf_recon_acc_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/object_detection_3d_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_detection_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_recognition_pipeline.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_convnext_transformer.py": 1686315994.756612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_dla34.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_resnet18_half.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_vlpt.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/convnext.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/vitstr.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ops.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/resnet18_v1.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/resnet_utils.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/table_process.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/utils.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/panorama_depth_estimation_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/pedestrian_attribute_recognition_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/product_retrieval_embedding_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/product_segmentation_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/realtime_video_object_detection_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/referring_video_object_segmentation_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/retina_face_detection_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/shop_segmentation_pipleline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/skin_retouching_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/table_recognition_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/tbs_detection_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/tbs_detection_utils/utils.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/text_driven_segmentation_pipleline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/tinynas_classification_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/tinynas_detection_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/ulfd_face_detection_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_category_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_colorization_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_deinterlace_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_depth_estimation_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_frame_interpolation_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_human_matting_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_inpainting_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_instance_segmentation_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_multi_object_tracking_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_object_segmentation_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_panoptic_segmentation_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_single_object_tracking_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_stabilization_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_summarization_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/video_super_resolution_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/vidt_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/virtual_try_on_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/vision_efficient_tuning_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/vision_middleware_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/vop_retrieval_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/cv/vop_retrieval_se_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/asr_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/document_vl_embedding_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/gridvlp_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/image_captioning_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/image_text_retrieval_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/mgeo_ranking_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/multi_modal_embedding_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/multimodal_dialogue_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/ocr_recognition_pipeline.py": 1686315994.760612,
-        "TEMPLATE_PATH/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/sudoku_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/text2sql_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/text_to_image_synthesis_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/text_to_video_synthesis_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/video_captioning_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/video_question_answering_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/visual_entailment_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/visual_grounding_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/multi_modal/visual_question_answering_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/automatic_post_editing_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/canmt_translation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/codegeex_code_generation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/codegeex_code_translation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/conversational_text_to_sql_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/dialog_intent_prediction_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/dialog_modeling_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/dialog_state_tracking_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/distributed_gpt3_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/distributed_gpt_moe_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/distributed_plug_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_generate_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/document_segmentation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/extractive_summarization_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/faq_question_answering_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/fasttext_text_classification_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/feature_extraction_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/fid_dialogue_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/fill_mask_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/glm130b_text_generation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/information_extraction_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/interactive_translation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/language_identification_pipline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/mglm_text_summarization_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/named_entity_recognition_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/sentence_embedding_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/siamese_uie_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/summarization_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/table_question_answering_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/text_error_correction_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/text_ranking_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/translation_evaluation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/translation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/translation_quality_estimation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/user_satisfaction_estimation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/word_alignment_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/word_segmentation_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/nlp/zero_shot_classification_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/pipeline_template.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/science/protein_structure_pipeline.py": 1686315994.7646122,
-        "TEMPLATE_PATH/pipelines/util.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/asr.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/audio.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/base.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/builder.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/common.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/action_detection_mapper.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/bad_image_detecting_preprocessor.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/controllable_image_generation.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/cv2_transforms.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_man.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_mos.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/image_restoration_preprocessor.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/mmcls_preprocessor.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/timer.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/util.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/video_stabilization.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/cv/video_super_resolution.py": 1686315994.7646122,
-        "TEMPLATE_PATH/preprocessors/image.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/kws.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/movie_scene_segmentation/transforms.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/multi_modal.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/bert_seq_cls_tokenizer.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/canmt_translation.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/dialog_classification_use_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/document_segmentation_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/faq_question_answering_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/feature_extraction_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/fill_mask_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/mgeo_ranking_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/mglm_summarization_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/relation_extraction_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/sentence_embedding_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/siamese_uie_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/args.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/batch.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/data_loader.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_modeling_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/dst_processors.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/fields/gen_field.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/fields/intent_field.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/lazy_dataset.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/preprocess.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/sampler.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/tensorlistdataset.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space/tokenizer.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/database.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/schema_link.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/struct.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/common_utils.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/parse.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/process_dataset.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/text_classification_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/text_clean.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/text_error_correction.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/text_ranking_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/token_classification_thai_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/token_classification_viet_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/transformers_tokenizer.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/translation_evaluation_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/utils.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/word_alignment_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/nlp/zero_shot_classification_preprocessor.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/ofa/asr.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/ofa/base.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/ofa/image_captioning.py": 1686315994.7686121,
-        "TEMPLATE_PATH/preprocessors/ofa/image_classification.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/ocr_recognition.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/sudoku.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/summarization.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/text2sql.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/text_classification.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/text_to_image_synthesis.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/audio_helper.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/bridge_content_encoder.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/collate.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/constant.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/get_tables.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/random_help.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/text2phone.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/transforms.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/vision_helper.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/visual_entailment.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/visual_grounding.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/ofa/visual_question_answering.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/science/uni_fold.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/tts.py": 1686315994.7726123,
-        "TEMPLATE_PATH/preprocessors/video.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/ans_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/asr_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/kws_farfield_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/kws_nearfield_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/kws_utils/batch_utils.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/kws_utils/det_utils.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/kws_utils/file_utils.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/kws_utils/model_utils.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/kws_utils/runtime_utils.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/separation_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/audio/tts_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/base.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/builder.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cli_argument_parser.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/action_detection_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/card_detection_scrfd_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/cartoon_translation_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/face_detection_scrfd_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/image_classifition_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/image_defrcn_fewshot_detection_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/image_detection_damoyolo_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/image_inpainting_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/image_instance_segmentation_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/image_portrait_enhancement_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/movie_scene_segmentation_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/nerf_recon_acc_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/ocr_detection_db_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/ocr_recognition_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/referring_video_object_segmentation_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/cv/vision_efficient_tuning_trainer.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/default_config.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/hooks/builder.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_hook.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_processor.py": 1686315994.7726123,
-        "TEMPLATE_PATH/trainers/hooks/checkpoint/load_checkpoint_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/clip_clamp_logit_scale_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/compression/sparsity_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/compression/utils.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/distributed/ddp_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/distributed/deepspeed_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/distributed/megatron_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/early_stop_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/evaluation_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/iter_timer_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/logger/base.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/logger/tensorboard_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/logger/text_logger_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/lr_scheduler_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/optimizer/apex_optimizer_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/optimizer/base.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/optimizer/torch_optimizer_hook.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/hooks/priority.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/lrscheduler/builder.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/lrscheduler/warmup/base.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/lrscheduler/warmup/warmup.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/multi_modal/clip/clip_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/multi_modal/clip/clip_trainer_utils.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/multi_modal/mgeo_ranking_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/multi_modal/mplug/mplug_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/multi_modal/ofa/ofa_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/multi_modal/ofa/ofa_trainer_utils.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/multi_modal/team/team_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/multi_modal/team/team_trainer_utils.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/csanmt_translation_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_generate_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_rerank_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_retrieval_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/faq_question_answering_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/gpt3_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/gpt_moe_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/plug_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/sentence_embedding_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/sequence_classification_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/siamese_uie_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/space/dialog_intent_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/space/dialog_modeling_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/space/eval.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/space/metrics/metrics_tracker.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/space/trainer/gen_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/space/trainer/intent_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/table_question_answering_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/text_generation_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/text_ranking_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp/translation_evaluation_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/nlp_trainer.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/optimizer/builder.py": 1686315994.7766123,
-        "TEMPLATE_PATH/trainers/optimizer/child_tuning_adamw_optimizer.py": 1686315994.7806125,
-        "TEMPLATE_PATH/trainers/parallel/builder.py": 1686315994.7806125,
-        "TEMPLATE_PATH/trainers/parallel/utils.py": 1686315994.7806125,
-        "TEMPLATE_PATH/trainers/trainer.py": 1686315994.7806125,
-        "TEMPLATE_PATH/trainers/training_args.py": 1686315994.7806125,
-        "TEMPLATE_PATH/trainers/utils/inference.py": 1686315994.7806125,
-        "TEMPLATE_PATH/trainers/utils/log_buffer.py": 1686315994.7806125
+        "TEMPLATE_PATH/exporters/audio/ans_dfsmn_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/base.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/builder.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/cv/cartoon_translation_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/cv/face_detection_scrfd_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/cv/object_detection_damoyolo_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/multi_modal/stable_diffusion_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/nlp/csanmt_for_translation_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/nlp/sbert_for_zero_shot_classification_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/tf_model_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/exporters/torch_model_exporter.py": 1688302933.2591906,
+        "TEMPLATE_PATH/metrics/accuracy_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/action_detection_evaluator.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/audio_noise_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/base.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/bleu_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/builder.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/ciderD/ciderD.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/ciderD/ciderD_scorer.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/image_color_enhance_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/image_colorization_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/image_denoise_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/image_inpainting_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/image_instance_segmentation_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/image_portrait_enhancement_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/image_quality_assessment_degradation_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/image_quality_assessment_mos_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/inbatch_recall_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/loss_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/map_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/movie_scene_segmentation_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/ned_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/ocr_recognition_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/ppl_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/prediction_saving_wrapper.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/referring_video_object_segmentation_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/sequence_classification_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/text_generation_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/text_ranking_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/token_classification_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/translation_evaluation_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/video_frame_interpolation_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/video_stabilization_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/video_summarization_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/video_super_resolution_metric/matlab_functions.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/video_super_resolution_metric/metric_util.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/video_super_resolution_metric/niqe.py": 1688302933.2631905,
+        "TEMPLATE_PATH/metrics/video_super_resolution_metric/video_super_resolution_metric.py": 1688302933.2631905,
+        "TEMPLATE_PATH/models/audio/aec/layers/activations.py": 1688302933.2631905,
+        "TEMPLATE_PATH/models/audio/aec/layers/affine_transform.py": 1688302933.2631905,
+        "TEMPLATE_PATH/models/audio/aec/layers/deep_fsmn.py": 1688302933.2631905,
+        "TEMPLATE_PATH/models/audio/aec/layers/layer_base.py": 1688302933.2631905,
+        "TEMPLATE_PATH/models/audio/aec/layers/uni_deep_fsmn.py": 1688302933.2631905,
+        "TEMPLATE_PATH/models/audio/aec/network/loss.py": 1688302933.2631905,
+        "TEMPLATE_PATH/models/audio/aec/network/modulation_loss.py": 1688302933.2631905,
+        "TEMPLATE_PATH/models/audio/aec/network/se_net.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/ans/complex_nn.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/ans/conv_stft.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/ans/denoise_net.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/ans/frcrn.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/ans/layers/activations.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/ans/layers/affine_transform.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/ans/layers/layer_base.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/ans/layers/uni_deep_fsmn.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/ans/se_module_complex.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/ans/unet.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/asr/wenet_automatic_speech_recognition.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/itn/generic_inverse_text_processing.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn_sele_v2.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn_sele_v3.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/kws/farfield/model.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/kws/farfield/model_def.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/kws/generic_key_word_spotting.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/kws/nearfield/cmvn.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/kws/nearfield/fsmn.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/kws/nearfield/model.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/punc/generic_punctuation.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/separation/layer_norm.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/separation/mossformer.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/separation/mossformer_block.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/separation/mossformer_conv_module.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/DTDNN.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/DTDNN_layers.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/ERes2Net.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/ERes2Net_aug.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/cluster_backend.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/ecapa_tdnn.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/fusion.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/generic_speaker_verification.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/pooling_layers.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/rdino.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/sv/speaker_change_locator.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/tts/sambert_hifi.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/audio/tts/voice.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/base/base_head.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/base/base_model.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/base/base_torch_head.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/base/base_torch_model.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/builder.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_model.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/cv/action_detection/action_detection_onnx.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/cv/action_detection/modules/action_detection_pytorch.py": 1688302933.2671905,
+        "TEMPLATE_PATH/models/cv/action_detection/modules/resnet.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/action_recognition/models.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/action_recognition/s3dg.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/action_recognition/tada_convnext.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/action_recognition/temporal_patch_shift_transformer.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/animal_recognition/resnet.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/animal_recognition/splat.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/bad_image_detecting/bad_image_detecting.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_2d_keypoints/hrnet_basic_modules.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_2d_keypoints/hrnet_v2.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_2d_keypoints/w48.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/backbone.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/block.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/directed_graph.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/hdformer.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/skeleton.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/facelib/LK/lk.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/facelib/config.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/facelib/face_detector.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/facelib/face_landmark.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/facelib/facer.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/loss.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/model_tf.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/network.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cartoon/utils.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/c3d.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/resnet2p1d.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/resnet3d.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/annotator.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/api.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/vit.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/utils.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/mlsd/utils.py": 1688302933.2711904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/body.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/hand.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/model.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/util.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/controlnet.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/crowd_counting/cc_model.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/crowd_counting/hrnet_aspp_relu.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/detectors.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/mogface.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/mogprednet.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/resnet.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/utils.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/box_utils.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/detector.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/first_stage.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/get_nets.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/LK/lk.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/face_detector.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/face_landmark.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/facer.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/retinaface/detection.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/retinaface/models/net.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/retinaface/models/retinaface.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/retinaface/utils.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/damofd_detect.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/preprocessor.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/scrfd_detect.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/tinymog_detect.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/detection.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/box_utils.py": 1688302933.2751904,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/transforms.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_emotion/efficient/model.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_emotion/efficient/utils.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_emotion/emotion_infer.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_emotion/emotion_model.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_emotion/face_alignment/face.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_emotion/face_alignment/face_align.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_generation/op/conv2d_gradfix.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_generation/op/fused_act.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_generation/op/upfirdn2d.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_generation/stylegan2.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/det_infer.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/ghost_pan.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/nanodet_plus_head.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/one_stage_detector.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/shufflenetv2.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/utils.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_recognition/align_face.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/common.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/model_irse.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/model_resnet.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/rts_backbone.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/bfm.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/de_retouching_module.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facerecon_model.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/losses.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/networks.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/nv_diffrast.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/opt.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/networks.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/renderer.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/unet.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/utils.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/transforms.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/vgg.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py": 1688302933.2791903,
+        "TEMPLATE_PATH/models/cv/hand_static/hand_model.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/hand_static/networks.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/Reconstruction.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Embedding.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/PixToMesh.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Res_backbone.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Surface_head.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/detectors.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/geometry.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/human_segmenter.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/networks.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/utils.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_binary_quant_classification/binary_quant_model.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_binary_quant_classification/bnext.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/image_body_reshaping.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/model.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/person_info.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/body.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/model.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/util.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/slim_utils.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_classification/backbones/beit_v2.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_classification/backbones/nextvit.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_classification/mmcls_model.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_classification/resnet50_cc.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_classification/utils.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_color_enhance/adaint/adaint.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_color_enhance/csrnet.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_color_enhance/deeplpf/deeplpfnet.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_color_enhance/image_color_enhance.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/ddcolor.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/loss.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/convnext.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/position_encoding.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/transformer_utils.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/unet.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/vgg.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_colorization/unet/unet.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_colorization/unet/utils.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_debanding/rrdb/rrdb_image_debanding.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_deblur/nafnet_for_image_deblur.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/evaluator.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py": 1688302933.28319,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/calibration_layer.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/defrcn.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/fast_rcnn.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/gdl.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/resnet.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/roi_heads.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/coco_register.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/register_data.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/requirements_check.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/voc_register.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_denoise/nafnet/NAFNet_arch.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_denoise/nafnet/arch_util.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_denoise/nafnet_for_image_denoise.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_depth.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_layers.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_utils.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/swin_transformer.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/uper_crf_head.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/newcrfs_model.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/bts_model.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/decoder.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/encoder.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/utils.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_driving_perception/image_driving_percetion_model.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_driving_perception/preprocessor.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_driving_perception/utils.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/gan_wrap.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/model.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/fused_act.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/upfirdn2d.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facelib/align_trans.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facelib/matlab_cp2tform.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/image_face_fusion.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/aad_layer.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/aei_flow_net.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/bfm.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/dense_motion.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/facerecon_model.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/model_irse.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/ops.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_human_parsing/backbone/deeplab_resnet.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp/m2fp_decoder.py": 1688302933.28719,
+        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp/m2fp_encoder.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp_net.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_human_parsing/parsing_utils.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/base.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/default.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/model.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ade20k/base.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ade20k/resnet.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/adversarial.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/feature_matching.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ffc.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/inception.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/perceptual.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/pix2pixhd.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_inpainting/refinement.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/backbones/resnet.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/backbones/swin_transformer.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/datasets/transforms.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst_model.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/dino_decoder.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/position_encoding.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/utils.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino_model.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino_swin.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/model.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/postprocess_utils.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/config/default.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/quadtree_attention_model.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_matching/utils/misc.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/cas_mvsnet.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/casmvs_model.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/depth_filter.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/general_eval_dataset.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/module.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/utils.py": 1688302933.29119,
+        "TEMPLATE_PATH/models/cv/image_paintbyexample/model.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_panoptic_segmentation/panseg_model.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/align_faces.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/eqface/fqa.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/eqface/model_resnet.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/gpen.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/image_portrait_enhancement.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/helpers.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/losses.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/model_irse.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/detection.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/models/net.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/utils.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_probing_model/backbone.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_probing_model/model.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_probing_model/utils.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_degradation/degradation_model.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/image_quality_assessment_man.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/maniqa.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/swin.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/backbones/resnet.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/heads/simple_head.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_reid_person/pass_model.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_reid_person/transreid_model.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_restoration/demoire_models/nets.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_restoration/image_restoration_model.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/utils.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/semantic_seg_model.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py": 1688302933.2951899,
+        "TEMPLATE_PATH/models/cv/image_skychange/preprocessor.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/BlockModules.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/hrnet_backnone.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/unet.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_skychange/skychange.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_skychange/skychange_model.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/data/transforms.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/model.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/models/autoencoder.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/models/clip.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/ops/diffusion.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/ops/losses.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/data/transforms.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/model_translation.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/models/autoencoder.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/models/clip.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/apps.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/degradation.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/diffusion.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/losses.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/metrics.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/random_color.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/random_mask.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/svd.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/utils.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/fourier.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/panostretch.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/post_proc.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/modality/layout.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/panovit.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/utils.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/panovit.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/summarizer.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/layers.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/models.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/modules.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/sub_layers.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/motion_generation/model.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/cfg_sampler.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/gaussian_diffusion.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/mdm.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/respace.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/rotation2xyz.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/smpl.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/get_model.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/model.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/head.py": 1688302933.2991898,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/save_op.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/shot_encoder.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/trn.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/dataloader/read_write_model.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_preprocess.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_recon_acc.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/nerf.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/segmenter.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/utils.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_model.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/backbones/vit.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/necks/fpn.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/utils/checkpoint.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/depe_detect.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/result_vis.py": 1688302933.3031898,
+        "TEMPLATE_PATH/models/cv/ocr_detection/model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_detection/modules/dbnet.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_detection/modules/layers.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_detection/modules/mix_ops.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_detection/modules/proxyless.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_detection/modules/seg_detector_loss.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_detection/preprocessor.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_detection/utils.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/CRNN/main_model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/main_model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/layers.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/mix_ops.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/proxyless.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/preprocessor.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/open_vocabulary_detection_vild/vild.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/equi.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/layers.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/mobilenet.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/resnet.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/unifuse.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/util.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/unifuse_model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/pedestrian_attribute_recognition/model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/common.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/rcp_model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_detection.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_embedding.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/product_segmentation/net.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/product_segmentation/seg_infer.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/backbone.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/criterion.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/matcher.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/misc.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/mttr.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/postprocessing.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/segmentation.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/swin_transformer.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/robust_image_classification/easyrobust_model.py": 1688302933.3071895,
+        "TEMPLATE_PATH/models/cv/salient_detection/models/backbone/Res2Net_v1b.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/salient_detection/models/modules.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/salient_detection/models/senet.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/salient_detection/models/u2net.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/salient_detection/models/utils.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/salient_detection/salient_model.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/common.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/head_fpn.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/models.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/neck_fpn.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/shop_seg_base.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/shop_seg_model.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/utils.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/detection_model/detection_module.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/detection_model/detection_unet_in.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/inpainting_model/gconv.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/inpainting_model/inpainting_unet.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/box_utils.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/net.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/network.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/predict_single.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/prior_box.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/utils.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/unet_deploy.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/utils.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/skin_retouching/weights_init.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/data/data_augment.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/exp/base_exp.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/exp/build.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/exp/default/streamyolo.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/exp/yolox_base.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/models/darknet.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/models/dfp_pafpn.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/models/network_blocks.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/models/streamyolo.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/models/tal_head.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/realtime_video_detector.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/utils/boxes.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/stream_yolo/utils/format.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/super_resolution/arch_util.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/super_resolution/ecb.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/super_resolution/ecbsr_model.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/super_resolution/rrdbnet_arch.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/table_recognition/lineless_table_process.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/table_recognition/model_lore.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/table_recognition/modules/lore_detector.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/table_recognition/modules/lore_processor.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/clip.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_base.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_blocks.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_model.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_net.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_vit.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/model.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/simple_tokenizer.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/basic_blocks.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/global_utils.py": 1688302933.3111894,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/master_net.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/model_zoo.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/plain_net_utils.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_blocks.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_idwexkx.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_k1kxk1.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_kxkx.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/apis/detector_evaluater.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/apis/detector_inference.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/base_ops.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/ops.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/utils.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/weight_init.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/detectors/detector.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/bounding_box.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/boxlist_ops.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/image_list.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/boxes.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/model_utils.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/scheduler.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/detector.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_damoyolo.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_detector.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/utils.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/UNet_for_video_deinterlace.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/deinterlace_arch.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/models/archs.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/models/deep_fourier_upsampling.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/models/enh.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/models/fre.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/models/utils.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/configs/default_config.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/dro_model.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/camera.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/camera_utils.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/pose.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/pose_utils.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_checkpoint.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_utils.py": 1688302933.3151894,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_wrapper.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/sfm_model_mf.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/sup_model_mf.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/layers.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/optim/extractor.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/optim/update.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/augmentations.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/config.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/depth.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/horovod.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/image.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/image_gt.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/load.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/misc.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/types.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/VFINet_arch.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/corr.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/extractor.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/raft.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/update.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/UNet.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/flow_reversal.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/transformer_layers.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/utils/scene_change_detection.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/utils/utils.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_human_matting/model.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_human_matting/models/decoder.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_human_matting/models/deep_guided_filter.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_human_matting/models/effv2.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_human_matting/models/lraspp.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_human_matting/models/matting.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_inpainting/inpainting.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_inpainting/inpainting_model.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_head.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_iter_head.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_update_head.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_updator.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/kernel_update_head.py": 1688302933.3191893,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/utils.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/video_knet.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/common.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/decode.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/model.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/yolo.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/basetrack.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/matching.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/multitracker.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/image.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/kalman_filter.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/utils.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/visualization.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/aggregate.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/cbam.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/eval_network.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/inference_core.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/inference_memory_bank.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/mod_resnet.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/model.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/modules.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/network.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_head.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_update_head.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_updator.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/mask.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/track_heads.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/neck/fpn.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/video_k_net.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/visualizer.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/config/ostrack.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/attn.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/attn_blocks.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/head.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/patch_embed.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/ostrack.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/utils.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/procontext.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/utils.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/vit_ce.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/tracker/ostrack.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/tracker/procontext.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/utils/utils.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/DUT_raft.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/MotionPro.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/corr.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/extractor.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/raft.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/update.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/Smoother.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/config.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/rf_det_module.py": 1688302933.3231893,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/rf_det_so.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUTRAFTStabilizer.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/IterativeSmooth.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/MedianFilter.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/ProjectionUtils.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/RAFTUtils.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/WarpUtils.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/image_utils.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/math_utils.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/longshortnet.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/longshort.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_summarization/base_model.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_summarization/kts/cpd_auto.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_summarization/kts/cpd_nonlin.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_summarization/pgl_sum.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_summarization/summarizer.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_super_resolution/basicvsr_net.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_super_resolution/common.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_super_resolution/msrresnet_lite_model.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/video_super_resolution/real_basicvsr_net.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vidt/backbone.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vidt/deformable_transformer.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vidt/fpn_fusion.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vidt/head.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vidt/model.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/virual_tryon/sdafnet.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/backbone.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/head.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/model.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/petl.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_helpers.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_vision_transformer.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_weight_init.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/vision_efficient_tuning.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_middleware/backbone.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_middleware/head.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_middleware/model.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vision_middleware/vim.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vop_retrieval/backbone.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vop_retrieval/basic_utils.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vop_retrieval/model.py": 1688302933.3271892,
+        "TEMPLATE_PATH/models/cv/vop_retrieval/model_se.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/cv/vop_retrieval/tokenization_clip.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/clip/bert_tokenizer.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/clip/configuration_bert.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/clip/model.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/clip/modeling_bert.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/clip_interrogator/model.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/diffusion.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/model.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/structbert.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/tokenizer.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_generator.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_upsampler_1024.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_upsampler_256.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/dpm_solver_pytorch.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/gemm/gemm_base.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/gemm/gemm_model.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/gemm/tokenizer.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/gaussian_diffusion.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/respace.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/script.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/unet.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/mgeo/backbone.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/mgeo/text_classification.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/mgeo/text_ranking.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/mgeo/token_classification.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/mmr/dataloaders/rawvideo_util.py": 1688302933.331189,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/dynamic_inverted_softmax.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/modeling.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/module_clip.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/module_cross.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/tokenization_clip.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/until_module.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mplug/clip/clip.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mplug/configuration_mplug.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mplug/modeling_mplug.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mplug/mvit.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mplug/predictor.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mplug_owl/configuration_mplug_owl.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/mplug_owl/modeling_mplug_owl.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/clip.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/decoder.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/model.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/prior.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/tokenizer.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/upsampler.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/xglm.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/configuration_mmspeech.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/configuration_ofa.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/incremental_decoding_utils.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/multihead_attention.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/ngram_repeat_block.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/search.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/sequence_generator.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/token_generation_constraints.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/utils.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/modeling_mmspeech.py": 1688302933.3351889,
+        "TEMPLATE_PATH/models/multi_modal/ofa/modeling_ofa.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/ofa/resnet.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/ofa/tokenization_ofa.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/ofa/tokenization_ofa_fast.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/ofa/utils/constant.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/ofa/utils/utils.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/ofa/vit.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/ofa_for_text_to_image_synthesis_model.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/rleg/model.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/rleg/rleg.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/soonet/blocks.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/soonet/clip.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/soonet/model.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/soonet/swin_transformer.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/soonet/tokenizer.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/soonet/utils.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/stable_diffusion/stable_diffusion.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/team/team_model.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/team/utils.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/video_synthesis/autoencoder.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/video_synthesis/diffusion.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/video_synthesis/unet_sd.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/conv_fpn_trans.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/convnext.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/model.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/modeling_layout_roberta.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/processing.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/tokenization.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/transformer_local.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/nlp/T5/backbone.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/nlp/T5/configuration.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/nlp/T5/text2text_generation.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/nlp/bart/text_error_correction.py": 1688302933.3391888,
+        "TEMPLATE_PATH/models/nlp/bert/backbone.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/bert/configuration.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/bert/document_segmentation.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/bert/fill_mask.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/bert/sentence_embedding.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/bert/siamese_uie.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/bert/text_classification.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/bert/text_ranking.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/bert/token_classification.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/bert/word_alignment.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/bloom/backbone.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/canmt/canmt_model.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/canmt/canmt_translation.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/canmt/sequence_generator.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/chatglm/configuration.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/chatglm/quantization.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/chatglm/text_generation.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/chatglm/tokenization.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/chatglm2/configuration.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/chatglm2/quantization.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/chatglm2/text_generation.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/chatglm2/tokenization.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/codegeex/codegeex.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_generation.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_translation.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/codegeex/inference.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/codegeex/tokenizer.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/csanmt/translation.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/deberta_v2/backbone.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/deberta_v2/configuration.py": 1688302933.3431888,
+        "TEMPLATE_PATH/models/nlp/deberta_v2/fill_mask.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/deberta_v2/tokenization.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/deberta_v2/tokenization_fast.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/dgds/backbone.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_generate.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_rerank.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_retrieval.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/fid_T5/text_generation.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/fid_plug/backbone.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/fid_plug/configuration.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/fid_plug/text_generation.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/glm_130b/generation/strategies.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/glm_130b/initialize.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/glm_130b/quantization/functional.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/glm_130b/quantization/layers.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/glm_130b/text_generation.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt2/backbone.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt3/backbone.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt3/configuration.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt3/distributed_gpt3.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt3/text_generation.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt3/tokenizer.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/backbone.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/checkpointing.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/configuration.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/distributed_gpt_moe.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/experts.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/layer.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/mappings.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/sharded_moe.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/utils.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/text_generation.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/tokenizer.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/gpt_neo/backbone.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/heads/crf_head.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/heads/fill_mask_head.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/heads/infromation_extraction_head.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/heads/text_generation_head.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/heads/text_ranking_head.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/heads/token_classification_head.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/heads/torch_pretrain_head.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/hf_transformers/backbone.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/llama/backbone.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/llama/configuration.py": 1688302933.3471887,
+        "TEMPLATE_PATH/models/nlp/llama/convert_llama_weights_to_hf.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/llama/text_generation.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/llama/tokenization.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/llama/tokenization_fast.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/lstm/backbone.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/lstm/token_classification.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/megatron_bert/backbone.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/megatron_bert/configuration.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/megatron_bert/fill_mask.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/arguments.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/blocklm_utils.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/configure_data.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/corpora.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/datasets.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/extraction.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/file_utils.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/lazy_loader.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/samplers.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/sp_tokenizer.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/tokenization.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/tokenization_gpt2.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/wordpiece.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/generation_utils.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/mglm_for_text_summarization.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/model/distributed.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/model/downstream.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/model/modeling_bert.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/model/modeling_glm.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/model/prompt.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/model/transformer.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/process_grid.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/run_test.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/data_utils.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/eval_utils.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/dataset.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/detokenizer.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/finetune.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/dataset.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/evaluate.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/finetune.py": 1688302933.3511887,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/dataset.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/evaluate.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/finetune.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/pvp.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/mglm/test/test_block.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/mglm/test/test_rel_shift.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/mglm/train_utils.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/mglm/utils.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/palm_v2/configuration.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/palm_v2/dureader_eval.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/palm_v2/text_generation.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/peer/backbone.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/peer/configuration.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/peer/sas_utils.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/peer/text_classification.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/plug/AnnealingLR.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/plug/backbone.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/plug/configuration.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/plug/distributed_plug.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/plug/generator.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/plug_mental/adv_utils.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/plug_mental/backbone.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/plug_mental/configuration.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/plug_mental/text_classification.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/ponet/backbone.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/ponet/configuration.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/ponet/document_segmentation.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/ponet/fill_mask.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/ponet/tokenization.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/configuration.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/dialog_intent_prediction.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/dialog_modeling.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/dialog_state_tracking.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/model/gen_unified_transformer.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/model/generator.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/model/intent_unified_transformer.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/model/model_base.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/model/tokenization_space.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/model/unified_transformer.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/modules/embedder.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/modules/feedforward.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/modules/functions.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/modules/multihead_attention.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space/modules/transformer_block.py": 1688302933.3551886,
+        "TEMPLATE_PATH/models/nlp/space_T_cn/backbone.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/space_T_cn/configuration.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/space_T_cn/table_question_answering.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/space_T_en/text_to_sql.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/structbert/adv_utils.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/structbert/backbone.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/structbert/configuration.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/structbert/faq_question_answering.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/structbert/fill_mask.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/structbert/text_classification.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/structbert/token_classification.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/task_models/feature_extraction.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/task_models/fill_mask.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/task_models/information_extraction.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/task_models/task_model.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/task_models/text_classification.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/task_models/text_generation.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/task_models/text_ranking.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/task_models/token_classification.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/unite/configuration.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/unite/translation_evaluation.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/use/transformer.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/use/user_satisfaction_estimation.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/veco/backbone.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/veco/configuration.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/veco/fill_mask.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/veco/text_classification.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/veco/token_classification.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/xlm_roberta/backbone.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/nlp/xlm_roberta/configuration.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/config.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/data/data_ops.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/data/msa_pairing.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/data/process.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/data/process_multimer.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/data/protein.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/data/residue_constants.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/data/utils.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/dataset.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/model.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/modules/alphafold.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/modules/attentions.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/modules/auxillary_heads.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/modules/common.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/modules/confidence.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/modules/embedders.py": 1688302933.3591883,
+        "TEMPLATE_PATH/models/science/unifold/modules/evoformer.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/modules/featurization.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/modules/frame.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/modules/structure_module.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/modules/template.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/modules/triangle_multiplication.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/mmcif.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/msa_identifiers.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/parsers.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/pipeline.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/templates.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/hhblits.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/hhsearch.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/hmmbuild.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/hmmsearch.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/jackhmmer.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/kalign.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/utils.py": 1688302933.3631883,
+        "TEMPLATE_PATH/models/science/unifold/msa/utils.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/audio/asr_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/auth/auth_config.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/context/dataset_context_config.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/data_files/data_files_manager.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/data_loader/data_loader.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/data_loader/data_loader_manager.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/builder.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/easycv_base.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py": 1688302933.3631883,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/veco_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/download/dataset_builder.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/download/download_config.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/download/download_manager.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/meta/data_meta_config.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/meta/data_meta_manager.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/ms_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/task_datasets/gopro_image_deblurring_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/task_datasets/reds_image_deblurring_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/task_datasets/sidd_image_denoising.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/task_datasets/torch_base_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/task_datasets/video_summarization_dataset.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/utils/dataset_utils.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/utils/delete_utils.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/utils/maxcompute_utils.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/utils/oss_utils.py": 1688302933.3671882,
+        "TEMPLATE_PATH/msdatasets/utils/upload_utils.py": 1688302933.3671882,
+        "TEMPLATE_PATH/pipelines/audio/ans_dfsmn_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/ans_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/asr_inference_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/asr_wenet_inference_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/inverse_text_processing_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/kws_farfield_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/kws_kwsbp_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/linear_aec_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/lm_infer_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/punctuation_processing_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/segmentation_clustering_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/separation_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/speaker_change_locating_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/speaker_diarization_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/speaker_verification_eres2net_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/speaker_verification_light_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/speaker_verification_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/speaker_verification_rdino_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/text_to_speech_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/timestamp_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/audio/voice_activity_detection_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/base.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/builder.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/action_detection_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/action_recognition_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/animal_recognition_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/arc_face_recognition_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/bad_image_detecting_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/body_2d_keypoints_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/body_3d_keypoints_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/card_detection_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/cmdssl_video_embedding_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/content_check_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/controllable_image_generation_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/crowd_counting_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/ddcolor_image_colorization_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/ddpm_semantic_segmentation_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_attribute_recognition_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_detection_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_emotion_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_human_hand_detection_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_image_generation_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_liveness_ir_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_liveness_xc_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_processing_base_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_quality_assessment_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_fm_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_ir_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_recognition_ood_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_recognition_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/face_reconstruction_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/facial_expression_recognition_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/facial_landmark_confidence_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/fast_instance_segmentation_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/general_recognition_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/hand_static_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/hicossl_video_embedding_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/human_reconstruction_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/image_body_reshaping_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/image_bts_depth_estimation_pipeline.py": 1688302933.3711882,
+        "TEMPLATE_PATH/pipelines/cv/image_cartoon_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_color_enhance_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_colorization_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_debanding_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_deblur_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_defrcn_fewshot_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_denoise_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_depth_estimation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_detection_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_driving_perception_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_face_fusion_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_human_parsing_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_inpainting_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_inpainting_sdv2_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_instance_segmentation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_matching_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_matting_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_mvs_depth_estimation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_open_vocabulary_detection_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_paintbyexample_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_panoptic_segmentation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_portrait_enhancement_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_degradation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_man_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_mos_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_reid_person_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_restoration_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_salient_detection_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_semantic_segmentation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_skychange_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_structured_model_probing_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_style_transfer_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_super_resolution_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_to_image_generate_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/image_to_image_translation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/indoor_layout_estimation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/language_guided_video_summarization_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/license_plate_detection_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/lineless_table_recognition_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/live_category_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/mask_face_recognition_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/maskdino_instance_segmentation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/mobile_image_super_resolution_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/mog_face_detection_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/motion_generation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/movie_scene_segmentation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/mtcnn_face_detection_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/nerf_recon_acc_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/object_detection_3d_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_detection_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_recognition_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_convnext_transformer.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_dla34.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_resnet18_half.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_vlpt.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/convnext.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/vitstr.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ops.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/resnet18_v1.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/resnet_utils.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/table_process.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/utils.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/panorama_depth_estimation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/pedestrian_attribute_recognition_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/product_retrieval_embedding_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/product_segmentation_pipeline.py": 1688302933.375188,
+        "TEMPLATE_PATH/pipelines/cv/realtime_video_object_detection_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/referring_video_object_segmentation_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/retina_face_detection_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/shop_segmentation_pipleline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/skin_retouching_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/table_recognition_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/tbs_detection_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/tbs_detection_utils/utils.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/text_driven_segmentation_pipleline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/tinynas_classification_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/tinynas_detection_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/ulfd_face_detection_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_category_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_colorization_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_deinterlace_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_depth_estimation_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_frame_interpolation_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_human_matting_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_inpainting_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_instance_segmentation_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_multi_object_tracking_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_object_segmentation_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_panoptic_segmentation_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_single_object_tracking_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_stabilization_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_summarization_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/video_super_resolution_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/vidt_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/virtual_try_on_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/vision_efficient_tuning_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/vision_middleware_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/vop_retrieval_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/cv/vop_retrieval_se_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/asr_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/document_vl_embedding_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/gridvlp_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/image_captioning_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/image_text_retrieval_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/mgeo_ranking_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/multi_modal_embedding_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/multimodal_dialogue_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/ocr_recognition_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/sudoku_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/text2sql_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/text_to_image_synthesis_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/text_to_video_synthesis_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/video_captioning_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/video_question_answering_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/visual_entailment_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/visual_grounding_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/multi_modal/visual_question_answering_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/automatic_post_editing_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/canmt_translation_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/codegeex_code_generation_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/codegeex_code_translation_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/conversational_text_to_sql_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/dialog_intent_prediction_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/dialog_modeling_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/dialog_state_tracking_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/distributed_gpt3_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/distributed_gpt_moe_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/distributed_plug_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_generate_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py": 1688302933.379188,
+        "TEMPLATE_PATH/pipelines/nlp/document_segmentation_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/extractive_summarization_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/faq_question_answering_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/fasttext_text_classification_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/feature_extraction_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/fid_dialogue_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/fill_mask_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/glm130b_text_generation_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/information_extraction_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/interactive_translation_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/language_identification_pipline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/mglm_text_summarization_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/named_entity_recognition_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/sentence_embedding_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/siamese_uie_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/summarization_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/table_question_answering_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/text_error_correction_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/text_ranking_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/translation_evaluation_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/translation_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/translation_quality_estimation_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/user_satisfaction_estimation_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/word_alignment_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/word_segmentation_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/nlp/zero_shot_classification_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/pipeline_template.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/science/protein_structure_pipeline.py": 1688302933.3831878,
+        "TEMPLATE_PATH/pipelines/util.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/asr.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/audio.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/base.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/builder.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/common.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/action_detection_mapper.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/bad_image_detecting_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/controllable_image_generation.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/cv2_transforms.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_man.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_mos.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/image_restoration_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/mmcls_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/timer.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/util.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/video_stabilization.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/cv/video_super_resolution.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/image.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/kws.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/movie_scene_segmentation/transforms.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/multi_modal.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/bert_seq_cls_tokenizer.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/canmt_translation.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/dialog_classification_use_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/document_segmentation_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/faq_question_answering_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/feature_extraction_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/fill_mask_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/mgeo_ranking_preprocessor.py": 1688302933.3831878,
+        "TEMPLATE_PATH/preprocessors/nlp/mglm_summarization_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/relation_extraction_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/sentence_embedding_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/siamese_uie_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/args.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/batch.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/data_loader.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_modeling_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/dst_processors.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/fields/gen_field.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/fields/intent_field.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/lazy_dataset.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/preprocess.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/sampler.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/tensorlistdataset.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space/tokenizer.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/database.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/schema_link.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/struct.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/common_utils.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/parse.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/process_dataset.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/text_classification_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/text_clean.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/text_error_correction.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/text_ranking_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/token_classification_thai_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/token_classification_viet_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/transformers_tokenizer.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/translation_evaluation_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/utils.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/word_alignment_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/nlp/zero_shot_classification_preprocessor.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/asr.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/base.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/image_captioning.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/image_classification.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/ocr_recognition.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/sudoku.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/summarization.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/text2sql.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/text_classification.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/text_to_image_synthesis.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/audio_helper.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/bridge_content_encoder.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/collate.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/constant.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/get_tables.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/random_help.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/text2phone.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/transforms.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/vision_helper.py": 1688302933.3871877,
+        "TEMPLATE_PATH/preprocessors/ofa/visual_entailment.py": 1688302933.3911877,
+        "TEMPLATE_PATH/preprocessors/ofa/visual_grounding.py": 1688302933.3911877,
+        "TEMPLATE_PATH/preprocessors/ofa/visual_question_answering.py": 1688302933.3911877,
+        "TEMPLATE_PATH/preprocessors/science/uni_fold.py": 1688302933.3911877,
+        "TEMPLATE_PATH/preprocessors/tts.py": 1688302933.3911877,
+        "TEMPLATE_PATH/preprocessors/video.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/ans_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/asr_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/kws_farfield_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/kws_nearfield_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/kws_utils/batch_utils.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/kws_utils/det_utils.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/kws_utils/file_utils.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/kws_utils/model_utils.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/kws_utils/runtime_utils.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/separation_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/audio/tts_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/base.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/builder.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cli_argument_parser.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/action_detection_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/card_detection_scrfd_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/cartoon_translation_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/face_detection_scrfd_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/image_classifition_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/image_defrcn_fewshot_detection_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/image_detection_damoyolo_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/image_inpainting_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/image_instance_segmentation_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/image_portrait_enhancement_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/movie_scene_segmentation_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/nerf_recon_acc_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/ocr_detection_db_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/ocr_recognition_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/referring_video_object_segmentation_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/cv/vision_efficient_tuning_trainer.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/default_config.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/hooks/builder.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_hook.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_processor.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/hooks/checkpoint/load_checkpoint_hook.py": 1688302933.3911877,
+        "TEMPLATE_PATH/trainers/hooks/clip_clamp_logit_scale_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/compression/sparsity_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/compression/utils.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/distributed/ddp_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/distributed/deepspeed_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/distributed/megatron_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/early_stop_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/evaluation_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/iter_timer_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/logger/base.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/logger/tensorboard_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/logger/text_logger_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/lr_scheduler_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/optimizer/apex_optimizer_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/optimizer/base.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/optimizer/torch_optimizer_hook.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/hooks/priority.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/lrscheduler/builder.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/lrscheduler/warmup/base.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/lrscheduler/warmup/warmup.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/clip/clip_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/clip/clip_trainer_utils.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/mgeo_ranking_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/mplug/mplug_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/ofa/ofa_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/ofa/ofa_trainer_utils.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/team/team_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/multi_modal/team/team_trainer_utils.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/csanmt_translation_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_generate_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_rerank_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_retrieval_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/faq_question_answering_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/gpt3_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/gpt_moe_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/plug_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/sentence_embedding_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/sequence_classification_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/siamese_uie_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/space/dialog_intent_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/space/dialog_modeling_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/space/eval.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/space/metrics/metrics_tracker.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/space/trainer/gen_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/space/trainer/intent_trainer.py": 1688302933.3951876,
+        "TEMPLATE_PATH/trainers/nlp/table_question_answering_trainer.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/nlp/text_generation_trainer.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/nlp/text_ranking_trainer.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/nlp/translation_evaluation_trainer.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/nlp_trainer.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/optimizer/builder.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/parallel/builder.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/parallel/utils.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/trainer.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/training_args.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/utils/inference.py": 1688302933.3991876,
+        "TEMPLATE_PATH/trainers/utils/log_buffer.py": 1688302933.3991876
     },
     "index": {
         "('ATTENTION', 'default', 'PETRMultiheadAttention')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py",
             "imports": [
-                "typing",
-                "copy",
                 "torch",
+                "warnings",
+                "typing",
                 "math",
                 "mmcv",
-                "warnings",
-                "mmdet"
+                "mmdet",
+                "copy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer"
         },
         "('BACKBONES', 'backbone', 'bloom')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bloom/backbone.py",
             "imports": [
                 "transformers"
@@ -1688,47 +1711,47 @@
             ],
             "module": "modelscope.models.nlp.gpt2.backbone"
         },
         "('BACKBONES', 'default', 'BASEBEiT')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py",
             "imports": [
                 "torch",
+                "timm",
                 "math",
-                "functools",
                 "mmcv",
-                "mmdet",
-                "timm"
+                "functools",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.backbone.base.beit"
         },
         "('BACKBONES', 'default', 'BEiTAdapter')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py",
             "imports": [
-                "mmdet",
                 "torch",
-                "math",
+                "logging",
+                "mmdet",
                 "timm",
-                "logging"
+                "math"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.backbone.beit_adapter"
         },
         "('BACKBONES', 'default', 'BEiTv2')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_classification/backbones/beit_v2.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
-                "math",
-                "itertools",
+                "einops",
                 "functools",
-                "mmcls",
+                "itertools",
+                "warnings",
                 "typing",
-                "einops",
+                "mmcls",
+                "math",
                 "mmcv",
-                "warnings"
+                "collections"
             ],
             "module": "modelscope.models.cv.image_classification.backbones.beit_v2"
         },
         "('BACKBONES', 'default', 'MasterNet')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py",
             "imports": [
                 "torch",
@@ -1736,63 +1759,63 @@
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.master_net"
         },
         "('BACKBONES', 'default', 'MobileNetV1')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py",
             "imports": [
                 "torch",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.mobilenet"
         },
         "('BACKBONES', 'default', 'NextViT')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_classification/backbones/nextvit.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
-                "math",
-                "itertools",
+                "einops",
                 "functools",
-                "mmcls",
+                "itertools",
+                "warnings",
                 "typing",
-                "einops",
+                "mmcls",
+                "math",
                 "mmcv",
-                "warnings"
+                "collections"
             ],
             "module": "modelscope.models.cv.image_classification.backbones.nextvit"
         },
         "('BACKBONES', 'default', 'ResNetV1e')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py",
             "imports": [
                 "torch",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.resnet"
         },
         "('BACKBONES', 'default', 'ViT')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/backbones/vit.py",
             "imports": [
                 "torch",
-                "math",
                 "functools",
+                "mmdet",
                 "timm",
-                "mmdet"
+                "math"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.backbones.vit"
         },
         "('BACKBONES', 'default', 'VoVNet')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py",
             "imports": [
-                "mmdet",
-                "collections",
                 "torch",
-                "mmcv"
+                "mmcv",
+                "collections",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.backbones.vovnet"
         },
         "('BBOX_ASSIGNERS', 'default', 'HungarianAssigner3D')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py",
             "imports": [
                 "torch",
@@ -1801,17 +1824,17 @@
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.assigners.hungarian_assigner_3d"
         },
         "('BBOX_ASSIGNERS', 'default', 'MaskHungarianAssignerVideo')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py",
             "imports": [
                 "numpy",
-                "mmdet",
+                "torch",
                 "scipy",
-                "torch"
+                "mmdet"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.track.mask_hungarian_assigner"
         },
         "('BBOX_CODERS', 'default', 'NMSFreeCoder')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py",
             "imports": [
                 "torch",
@@ -1824,16 +1847,16 @@
             "imports": [],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.bad_image_detecting.bad_image_detecting_dataset"
         },
         "('CUSTOM_DATASETS', 'image-colorization', 'ddcolor')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py",
             "imports": [
                 "numpy",
-                "cv2",
-                "torch"
+                "torch",
+                "cv2"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.image_colorization.image_colorization_dataset"
         },
         "('CUSTOM_DATASETS', 'image-deblurring', 'GoproDataset')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py",
             "imports": [
                 "numpy",
@@ -1857,19 +1880,19 @@
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.sidd_image_denoising_dataset"
         },
         "('CUSTOM_DATASETS', 'image-inpainting', 'FFTInpainting')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py",
             "imports": [
                 "os",
-                "numpy",
                 "enum",
-                "albumentations",
                 "cv2",
-                "glob"
+                "albumentations",
+                "glob",
+                "numpy"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.image_inpainting.image_inpainting_dataset"
         },
         "('CUSTOM_DATASETS', 'image-portrait-enhancement', 'PairedDataset')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py",
             "imports": [
                 "numpy",
@@ -1888,40 +1911,40 @@
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py",
             "imports": [],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.image_quality_assmessment_mos.image_quality_assessment_mos_dataset"
         },
         "('CUSTOM_DATASETS', 'image-segmentation', 'cascade_mask_rcnn_swin')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py",
             "imports": [
-                "numpy",
                 "os",
+                "numpy",
                 "pycocotools"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.image_instance_segmentation_coco_dataset"
         },
         "('CUSTOM_DATASETS', 'language-guided-video-summarization', 'clip-it-language-guided-video-summarization')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py",
             "imports": [
                 "os",
                 "torch",
+                "json",
                 "numpy",
-                "h5py",
-                "json"
+                "h5py"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.language_guided_video_summarization_dataset"
         },
         "('CUSTOM_DATASETS', 'movie-scene-segmentation', 'resnet50-bert')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
+                "torchvision",
                 "copy",
-                "random",
-                "json"
+                "json",
+                "random"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.movie_scene_segmentation.movie_scene_segmentation_dataset"
         },
         "('CUSTOM_DATASETS', 'nli', 'veco')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/veco_dataset.py",
             "imports": [
                 "numpy",
@@ -1931,96 +1954,96 @@
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.veco_dataset"
         },
         "('CUSTOM_DATASETS', 'ocr-recognition', 'OCRRecognition')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
                 "PIL",
                 "cv2",
-                "six",
+                "json",
+                "numpy",
                 "lmdb",
-                "json"
+                "six"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_recognition_dataset"
         },
         "('CUSTOM_DATASETS', 'referring-video-object-segmentation', 'swinT-referring-video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py",
             "imports": [
-                "pycocotools",
-                "torchvision",
-                "os",
                 "torch",
-                "numpy",
-                "h5py",
+                "os",
+                "tqdm",
                 "pandas",
+                "torchvision",
+                "pycocotools",
                 "json",
                 "glob",
-                "tqdm"
+                "numpy",
+                "h5py"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.referring_video_object_segmentation.referring_video_object_segmentation_dataset"
         },
         "('CUSTOM_DATASETS', 'sentence-embedding', 'bert')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "random"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.text_ranking_dataset"
         },
         "('CUSTOM_DATASETS', 'text-ranking', 'bert')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "random"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.text_ranking_dataset"
         },
         "('CUSTOM_DATASETS', 'text-ranking', 'mgeo')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py",
             "imports": [
-                "typing",
-                "json",
                 "torch",
-                "random"
+                "typing",
+                "random",
+                "json"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.mgeo_ranking_dataset"
         },
         "('CUSTOM_DATASETS', 'video-frame-interpolation', 'video-frame-interpolation')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py",
             "imports": [
                 "numpy",
-                "cv2",
-                "torch"
+                "torch",
+                "cv2"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.video_frame_interpolation.video_frame_interpolation_dataset"
         },
         "('CUSTOM_DATASETS', 'video-stabilization', 'video-stabilization')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py",
             "imports": [],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.video_stabilization.video_stabilization_dataset"
         },
         "('CUSTOM_DATASETS', 'video-super-resolution', 'real-basicvsr')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py",
             "imports": [
+                "torch",
                 "numpy",
-                "cv2",
                 "collections",
-                "torch"
+                "cv2"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.video_super_resolution.video_super_resolution_dataset"
         },
         "('DATASETS', 'default', 'CustomNuScenesDataset')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py",
             "imports": [
-                "numpy",
                 "mmdet3d",
+                "numpy",
                 "mmdet"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.nuscenes_dataset"
         },
         "('DATASETS', 'default', 'RetinaFaceDataset')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py",
             "imports": [
@@ -2045,18 +2068,18 @@
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.segmentors.encoder_decoder_mask2former"
         },
         "('DETECTORS', 'default', 'Petr3D')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py",
             "imports": [
                 "torch",
-                "numpy",
+                "mmdet",
                 "mmdet3d",
-                "mmcv",
-                "mmdet"
+                "numpy",
+                "mmcv"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.detectors.petr3d"
         },
         "('DETECTORS', 'default', 'SCRFD')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py",
             "imports": [
                 "torch",
@@ -2079,180 +2102,196 @@
                 "torch"
             ],
             "module": "modelscope.exporters.audio.ans_dfsmn_exporter"
         },
         "('EXPORTERS', 'default', 'cartoon-translation')": {
             "filepath": "TEMPLATE_PATH/exporters/cv/cartoon_translation_exporter.py",
             "imports": [
-                "typing",
                 "packaging",
                 "os",
+                "typing",
                 "tensorflow"
             ],
             "module": "modelscope.exporters.cv.cartoon_translation_exporter"
         },
         "('EXPORTERS', 'domain-specific-object-detection', 'tinynas-damoyolo')": {
             "filepath": "TEMPLATE_PATH/exporters/cv/object_detection_damoyolo_exporter.py",
             "imports": [
                 "os",
+                "onnx",
                 "torch",
                 "functools",
-                "numpy",
                 "typing",
-                "onnx"
+                "numpy"
             ],
             "module": "modelscope.exporters.cv.object_detection_damoyolo_exporter"
         },
         "('EXPORTERS', 'face-detection', 'scrfd')": {
             "filepath": "TEMPLATE_PATH/exporters/cv/face_detection_scrfd_exporter.py",
             "imports": [
                 "os",
+                "onnx",
                 "torch",
                 "functools",
-                "numpy",
                 "typing",
-                "onnx"
+                "numpy"
             ],
             "module": "modelscope.exporters.cv.face_detection_scrfd_exporter"
         },
         "('EXPORTERS', 'image-object-detection', 'tinynas-damoyolo')": {
             "filepath": "TEMPLATE_PATH/exporters/cv/object_detection_damoyolo_exporter.py",
             "imports": [
                 "os",
+                "onnx",
                 "torch",
                 "functools",
-                "numpy",
                 "typing",
-                "onnx"
+                "numpy"
             ],
             "module": "modelscope.exporters.cv.object_detection_damoyolo_exporter"
         },
         "('EXPORTERS', 'named-entity-recognition', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.model_for_token_classification_exporter"
         },
         "('EXPORTERS', 'nli', 'bert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'nli', 'structbert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'part-of-speech', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.model_for_token_classification_exporter"
         },
         "('EXPORTERS', 'sentence-similarity', 'bert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'sentence-similarity', 'structbert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'sentiment-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'sentiment-classification', 'structbert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'text-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'text-classification', 'structbert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
+        "('EXPORTERS', 'text-to-image-synthesis', 'stable-diffusion')": {
+            "filepath": "TEMPLATE_PATH/exporters/multi_modal/stable_diffusion_exporter.py",
+            "imports": [
+                "os",
+                "onnx",
+                "torch",
+                "argparse",
+                "packaging",
+                "pathlib",
+                "typing",
+                "shutil",
+                "diffusers",
+                "collections"
+            ],
+            "module": "modelscope.exporters.multi_modal.stable_diffusion_exporter"
+        },
         "('EXPORTERS', 'token-classification', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.model_for_token_classification_exporter"
         },
         "('EXPORTERS', 'transformer-crf', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.model_for_token_classification_exporter"
         },
         "('EXPORTERS', 'translation', 'csanmt-translation')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/csanmt_for_translation_exporter.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "tensorflow"
             ],
             "module": "modelscope.exporters.nlp.csanmt_for_translation_exporter"
         },
         "('EXPORTERS', 'word-segmentation', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.exporters.nlp.model_for_token_classification_exporter"
         },
         "('EXPORTERS', 'zero-shot-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_zero_shot_classification_exporter.py",
             "imports": [
                 "typing",
@@ -2283,74 +2322,74 @@
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.roi_heads.bbox_heads.convfc_bbox_head"
         },
         "('HEADS', 'default', 'ConvKernelHeadVideo')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_head.py",
             "imports": [
                 "torch",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.head.kernel_head"
         },
         "('HEADS', 'default', 'FCNMaskNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py",
             "imports": [
                 "torch",
-                "numpy",
-                "mmcv",
+                "mmdet",
                 "warnings",
-                "mmdet"
+                "numpy",
+                "mmcv"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.roi_heads.mask_heads.fcn_mask_head"
         },
         "('HEADS', 'default', 'KernelFrameIterHeadVideo')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py",
             "imports": [
                 "torch",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.head.kernel_frame_iter_head"
         },
         "('HEADS', 'default', 'KernelIterHeadVideo')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_iter_head.py",
             "imports": [
                 "torch",
                 "mmdet"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.head.kernel_iter_head"
         },
         "('HEADS', 'default', 'KernelUpdateHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_update_head.py",
             "imports": [
-                "numpy",
-                "mmdet",
                 "torch",
-                "mmcv"
+                "mmcv",
+                "mmdet",
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.head.kernel_update_head"
         },
         "('HEADS', 'default', 'KernelUpdateHeadVideo')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/kernel_update_head.py",
             "imports": [
-                "numpy",
-                "mmdet",
                 "torch",
-                "mmcv"
+                "mmcv",
+                "mmdet",
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.track.kernel_update_head"
         },
         "('HEADS', 'default', 'Mask2FormerHeadFromMMSeg')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py",
             "imports": [
-                "mmdet",
-                "copy",
                 "torch",
-                "mmcv"
+                "mmcv",
+                "mmdet",
+                "copy"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.decode_heads.mask2former_head_from_mmseg"
         },
         "('HEADS', 'default', 'MaskFormerSemanticHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py",
             "imports": [
                 "torch",
@@ -2366,40 +2405,40 @@
             ],
             "module": "modelscope.models.cv.abnormal_object_detection.mmdet_ms.roi_head.mask_scoring_roi_head"
         },
         "('HEADS', 'default', 'PETRv2DEDNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py",
             "imports": [
                 "torch",
+                "mmdet",
+                "copy",
                 "math",
-                "numpy",
                 "mmdet3d",
-                "copy",
-                "mmcv",
-                "mmdet"
+                "numpy",
+                "mmcv"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.dense_heads.petrv2_dednhead"
         },
         "('HEADS', 'default', 'RPNNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py",
             "imports": [
-                "mmdet",
-                "copy",
                 "torch",
-                "mmcv"
+                "mmcv",
+                "mmdet",
+                "copy"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.dense_heads.rpn_head"
         },
         "('HEADS', 'default', 'SCRFDHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py",
             "imports": [
-                "numpy",
-                "mmdet",
                 "torch",
-                "mmcv"
+                "mmcv",
+                "mmdet",
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.dense_heads.scrfd_head"
         },
         "('HEADS', 'default', 'Shared2FCBBoxNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py",
             "imports": [
                 "torch",
@@ -2422,256 +2461,256 @@
                 "mmdet"
             ],
             "module": "modelscope.models.cv.video_panoptic_segmentation.head.kernel_iter_head"
         },
         "('HEADS', 'default', 'VideoKernelUpdateHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_update_head.py",
             "imports": [
-                "numpy",
-                "mmdet",
                 "torch",
-                "mmcv"
+                "mmcv",
+                "mmdet",
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_panoptic_segmentation.head.kernel_update_head"
         },
         "('HEADS', 'fill-mask', 'bert-mlm')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/fill_mask_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.fill_mask_head"
         },
         "('HEADS', 'fill-mask', 'fill-mask')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/fill_mask_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.fill_mask_head"
         },
         "('HEADS', 'fill-mask', 'roberta-mlm')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/torch_pretrain_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.torch_pretrain_head"
         },
         "('HEADS', 'fill-mask', 'xlm-roberta-mlm')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/fill_mask_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.fill_mask_head"
         },
         "('HEADS', 'information-extraction', 'information-extraction')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/infromation_extraction_head.py",
             "imports": [
                 "torch"
             ],
             "module": "modelscope.models.nlp.heads.infromation_extraction_head"
         },
         "('HEADS', 'named-entity-recognition', 'lstm-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'named-entity-recognition', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/token_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.token_classification_head"
         },
         "('HEADS', 'named-entity-recognition', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'nli', 'text-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_classification_head"
         },
         "('HEADS', 'part-of-speech', 'lstm-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'part-of-speech', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/token_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.token_classification_head"
         },
         "('HEADS', 'part-of-speech', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'relation-extraction', 'information-extraction')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/infromation_extraction_head.py",
             "imports": [
                 "torch"
             ],
             "module": "modelscope.models.nlp.heads.infromation_extraction_head"
         },
         "('HEADS', 'sentence-similarity', 'text-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_classification_head"
         },
         "('HEADS', 'sentiment-classification', 'text-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_classification_head"
         },
         "('HEADS', 'text-classification', 'text-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_classification_head"
         },
         "('HEADS', 'text-generation', 'text-generation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_generation_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_generation_head"
         },
         "('HEADS', 'text-ranking', 'text-ranking')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_ranking_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_ranking_head"
         },
         "('HEADS', 'token-classification', 'lstm-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'token-classification', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/token_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.token_classification_head"
         },
         "('HEADS', 'token-classification', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'transformer-crf', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'word-segmentation', 'lstm-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'word-segmentation', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HOOKS', 'default', 'ApexAMPOptimizerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/optimizer/apex_optimizer_hook.py",
             "imports": [
-                "logging",
                 "packaging",
-                "torch"
+                "torch",
+                "logging"
             ],
             "module": "modelscope.trainers.hooks.optimizer.apex_optimizer_hook"
         },
         "('HOOKS', 'default', 'BestCkptSaverHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_hook.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "shutil",
+                "json",
                 "typing",
-                "random",
-                "json"
+                "shutil",
+                "numpy",
+                "random"
             ],
             "module": "modelscope.trainers.hooks.checkpoint.checkpoint_hook"
         },
         "('HOOKS', 'default', 'CheckpointHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_hook.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "shutil",
+                "json",
                 "typing",
-                "random",
-                "json"
+                "shutil",
+                "numpy",
+                "random"
             ],
             "module": "modelscope.trainers.hooks.checkpoint.checkpoint_hook"
         },
         "('HOOKS', 'default', 'ClipClampLogitScaleHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/clip_clamp_logit_scale_hook.py",
             "imports": [
                 "torch"
@@ -2684,17 +2723,20 @@
             "module": "modelscope.trainers.hooks.distributed.ddp_hook"
         },
         "('HOOKS', 'default', 'DeepspeedHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/distributed/deepspeed_hook.py",
             "imports": [
                 "os",
                 "torch",
-                "shutil",
+                "functools",
+                "deepspeed",
                 "megatron_util",
-                "deepspeed"
+                "shutil",
+                "math",
+                "transformers"
             ],
             "module": "modelscope.trainers.hooks.distributed.deepspeed_hook"
         },
         "('HOOKS', 'default', 'EarlyStopHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/early_stop_hook.py",
             "imports": [
                 "numpy"
@@ -2716,54 +2758,54 @@
             ],
             "module": "modelscope.trainers.hooks.iter_timer_hook"
         },
         "('HOOKS', 'default', 'LoadCheckpointHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/checkpoint/load_checkpoint_hook.py",
             "imports": [
                 "torch",
-                "numpy",
+                "packaging",
                 "typing",
-                "random",
-                "packaging"
+                "numpy",
+                "random"
             ],
             "module": "modelscope.trainers.hooks.checkpoint.load_checkpoint_hook"
         },
         "('HOOKS', 'default', 'LrSchedulerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/lr_scheduler_hook.py",
             "imports": [],
             "module": "modelscope.trainers.hooks.lr_scheduler_hook"
         },
         "('HOOKS', 'default', 'MegatronHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/distributed/megatron_hook.py",
             "imports": [
-                "shutil",
+                "megatron_util",
                 "os",
                 "torch",
-                "megatron_util"
+                "shutil"
             ],
             "module": "modelscope.trainers.hooks.distributed.megatron_hook"
         },
         "('HOOKS', 'default', 'NoneLrSchedulerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/lr_scheduler_hook.py",
             "imports": [],
             "module": "modelscope.trainers.hooks.lr_scheduler_hook"
         },
         "('HOOKS', 'default', 'NoneOptimizerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/optimizer/base.py",
             "imports": [
-                "logging",
-                "torch"
+                "torch",
+                "logging"
             ],
             "module": "modelscope.trainers.hooks.optimizer.base"
         },
         "('HOOKS', 'default', 'OptimizerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/optimizer/base.py",
             "imports": [
-                "logging",
-                "torch"
+                "torch",
+                "logging"
             ],
             "module": "modelscope.trainers.hooks.optimizer.base"
         },
         "('HOOKS', 'default', 'PlateauLrSchedulerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/lr_scheduler_hook.py",
             "imports": [],
             "module": "modelscope.trainers.hooks.lr_scheduler_hook"
@@ -2774,28 +2816,28 @@
                 "os"
             ],
             "module": "modelscope.trainers.hooks.compression.sparsity_hook"
         },
         "('HOOKS', 'default', 'TensorboardHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/logger/tensorboard_hook.py",
             "imports": [
-                "numpy",
                 "os",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.trainers.hooks.logger.tensorboard_hook"
         },
         "('HOOKS', 'default', 'TextLoggerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/logger/text_logger_hook.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
                 "datetime",
-                "json"
+                "json",
+                "collections"
             ],
             "module": "modelscope.trainers.hooks.logger.text_logger_hook"
         },
         "('HOOKS', 'default', 'TorchAMPOptimizerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/optimizer/torch_optimizer_hook.py",
             "imports": [
                 "logging"
@@ -2825,17 +2867,17 @@
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.match_costs.match_cost"
         },
         "('MATCH_COST', 'default', 'MaskCost')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py",
             "imports": [
                 "numpy",
-                "mmdet",
+                "torch",
                 "scipy",
-                "torch"
+                "mmdet"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.track.mask_hungarian_assigner"
         },
         "('METRICS', 'default', 'accuracy')": {
             "filepath": "TEMPLATE_PATH/metrics/accuracy_metric.py",
             "imports": [
                 "numpy",
@@ -2849,119 +2891,119 @@
                 "typing"
             ],
             "module": "modelscope.metrics.audio_noise_metric"
         },
         "('METRICS', 'default', 'bleu')": {
             "filepath": "TEMPLATE_PATH/metrics/bleu_metric.py",
             "imports": [
-                "typing",
                 "sacrebleu",
-                "itertools"
+                "itertools",
+                "typing"
             ],
             "module": "modelscope.metrics.bleu_metric"
         },
         "('METRICS', 'default', 'image-color-enhance-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_color_enhance_metric.py",
             "imports": [
                 "numpy",
-                "cv2",
-                "typing"
+                "typing",
+                "cv2"
             ],
             "module": "modelscope.metrics.image_color_enhance_metric"
         },
         "('METRICS', 'default', 'image-colorization-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_colorization_metric.py",
             "imports": [
-                "torchvision",
                 "torch",
-                "numpy",
                 "scipy",
+                "torchvision",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.metrics.image_colorization_metric"
         },
         "('METRICS', 'default', 'image-denoise-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_denoise_metric.py",
             "imports": [
-                "numpy",
-                "cv2",
+                "torch",
                 "typing",
-                "torch"
+                "numpy",
+                "cv2"
             ],
             "module": "modelscope.metrics.image_denoise_metric"
         },
         "('METRICS', 'default', 'image-inpainting-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_inpainting_metric.py",
             "imports": [
-                "numpy",
+                "torch",
                 "typing",
                 "scipy",
-                "torch"
+                "numpy"
             ],
             "module": "modelscope.metrics.image_inpainting_metric"
         },
         "('METRICS', 'default', 'image-ins-seg-coco-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_instance_segmentation_metric.py",
             "imports": [
-                "pycocotools",
                 "os",
-                "collections",
                 "tempfile",
+                "pycocotools",
+                "typing",
                 "numpy",
-                "typing"
+                "collections"
             ],
             "module": "modelscope.metrics.image_instance_segmentation_metric"
         },
         "('METRICS', 'default', 'image-portrait-enhancement-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_portrait_enhancement_metric.py",
             "imports": [
                 "numpy",
-                "cv2",
-                "typing"
+                "typing",
+                "cv2"
             ],
             "module": "modelscope.metrics.image_portrait_enhancement_metric"
         },
         "('METRICS', 'default', 'image-quality-assessment-degradation-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_quality_assessment_degradation_metric.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
-                "tempfile",
-                "sys",
-                "numpy",
                 "scipy",
-                "typing",
+                "tqdm",
+                "tempfile",
                 "cv2",
-                "tqdm"
+                "typing",
+                "numpy",
+                "sys",
+                "collections"
             ],
             "module": "modelscope.metrics.image_quality_assessment_degradation_metric"
         },
         "('METRICS', 'default', 'image-quality-assessment-mos-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_quality_assessment_mos_metric.py",
             "imports": [
                 "os",
                 "torch",
-                "tempfile",
-                "sys",
-                "numpy",
                 "scipy",
-                "typing",
+                "tqdm",
+                "tempfile",
                 "cv2",
-                "tqdm"
+                "typing",
+                "numpy",
+                "sys"
             ],
             "module": "modelscope.metrics.image_quality_assessment_mos_metric"
         },
         "('METRICS', 'default', 'inbatch_recall')": {
             "filepath": "TEMPLATE_PATH/metrics/inbatch_recall_metric.py",
             "imports": [
-                "numpy",
+                "torch",
                 "typing",
-                "torch"
+                "numpy"
             ],
             "module": "modelscope.metrics.inbatch_recall_metric"
         },
         "('METRICS', 'default', 'loss-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/loss_metric.py",
             "imports": [
                 "numpy",
@@ -2993,28 +3035,28 @@
                 "typing"
             ],
             "module": "modelscope.metrics.ned_metric"
         },
         "('METRICS', 'default', 'ocr-recognition-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/ocr_recognition_metric.py",
             "imports": [
-                "numpy",
-                "edit_distance",
+                "torch",
                 "typing",
-                "torch"
+                "edit_distance",
+                "numpy"
             ],
             "module": "modelscope.metrics.ocr_recognition_metric"
         },
         "('METRICS', 'default', 'ppl')": {
             "filepath": "TEMPLATE_PATH/metrics/ppl_metric.py",
             "imports": [
-                "numpy",
-                "typing",
+                "math",
                 "torch",
-                "math"
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.metrics.ppl_metric"
         },
         "('METRICS', 'default', 'prediction-saving-wrapper')": {
             "filepath": "TEMPLATE_PATH/metrics/prediction_saving_wrapper.py",
             "imports": [
                 "numpy",
@@ -3022,19 +3064,19 @@
                 "sklearn"
             ],
             "module": "modelscope.metrics.prediction_saving_wrapper"
         },
         "('METRICS', 'default', 'referring-video-object-segmentation-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/referring_video_object_segmentation_metric.py",
             "imports": [
-                "pycocotools",
                 "torch",
-                "numpy",
+                "tqdm",
+                "pycocotools",
                 "typing",
-                "tqdm"
+                "numpy"
             ],
             "module": "modelscope.metrics.referring_video_object_segmentation_metric"
         },
         "('METRICS', 'default', 'seq-cls-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/sequence_classification_metric.py",
             "imports": [
                 "numpy",
@@ -3042,17 +3084,19 @@
                 "sklearn"
             ],
             "module": "modelscope.metrics.sequence_classification_metric"
         },
         "('METRICS', 'default', 'text-gen-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/text_generation_metric.py",
             "imports": [
-                "typing",
+                "rouge",
+                "contextlib",
                 "nltk",
-                "rouge"
+                "typing",
+                "sys"
             ],
             "module": "modelscope.metrics.text_generation_metric"
         },
         "('METRICS', 'default', 'text-ranking-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/text_ranking_metric.py",
             "imports": [
                 "numpy",
@@ -3060,49 +3104,49 @@
             ],
             "module": "modelscope.metrics.text_ranking_metric"
         },
         "('METRICS', 'default', 'token-cls-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/token_classification_metric.py",
             "imports": [
                 "numpy",
-                "typing",
-                "importlib"
+                "importlib",
+                "typing"
             ],
             "module": "modelscope.metrics.token_classification_metric"
         },
         "('METRICS', 'default', 'translation-evaluation-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/translation_evaluation_metric.py",
             "imports": [
+                "importlib",
                 "typing",
-                "pandas",
-                "importlib"
+                "pandas"
             ],
             "module": "modelscope.metrics.translation_evaluation_metric"
         },
         "('METRICS', 'default', 'video-frame-interpolation-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/video_frame_interpolation_metric.py",
             "imports": [
                 "torch",
-                "math",
                 "lpips",
+                "typing",
                 "numpy",
-                "typing"
+                "math"
             ],
             "module": "modelscope.metrics.video_frame_interpolation_metric"
         },
         "('METRICS', 'default', 'video-stabilization-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/video_stabilization_metric.py",
             "imports": [
                 "os",
+                "tqdm",
                 "tempfile",
-                "sys",
-                "numpy",
-                "typing",
                 "cv2",
-                "tqdm"
+                "typing",
+                "numpy",
+                "sys"
             ],
             "module": "modelscope.metrics.video_stabilization_metric"
         },
         "('METRICS', 'default', 'video-summarization-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/video_summarization_metric.py",
             "imports": [
                 "numpy",
@@ -3124,157 +3168,157 @@
                 "torch"
             ],
             "module": "modelscope.models.audio.ans.denoise_net"
         },
         "('MODELS', 'acoustic-noise-suppression', 'speech_frcrn_ans_cirm_16k')": {
             "filepath": "TEMPLATE_PATH/models/audio/ans/frcrn.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.audio.ans.frcrn"
         },
         "('MODELS', 'auto-speech-recognition', 'generic-asr')": {
             "filepath": "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.asr.generic_automatic_speech_recognition"
         },
         "('MODELS', 'auto-speech-recognition', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'auto-speech-recognition', 'wenet-asr')": {
             "filepath": "TEMPLATE_PATH/models/audio/asr/wenet_automatic_speech_recognition.py",
             "imports": [
-                "typing",
                 "os",
-                "wenetruntime",
-                "json"
+                "typing",
+                "json",
+                "wenetruntime"
             ],
             "module": "modelscope.models.audio.asr.wenet_automatic_speech_recognition"
         },
         "('MODELS', 'backbone', 'T5')": {
             "filepath": "TEMPLATE_PATH/models/nlp/T5/backbone.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "transformers",
-                "typing",
                 "copy",
-                "warnings"
+                "warnings",
+                "typing",
+                "math",
+                "transformers"
             ],
             "module": "modelscope.models.nlp.T5.backbone"
         },
         "('MODELS', 'backbone', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/backbone.py",
             "imports": [
                 "packaging",
-                "transformers",
                 "torch",
-                "math"
+                "math",
+                "transformers"
             ],
             "module": "modelscope.models.nlp.bert.backbone"
         },
         "('MODELS', 'backbone', 'deberta_v2')": {
             "filepath": "TEMPLATE_PATH/models/nlp/deberta_v2/backbone.py",
             "imports": [
+                "torch",
                 "typing",
                 "collections",
-                "torch",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.deberta_v2.backbone"
         },
         "('MODELS', 'backbone', 'llama')": {
             "filepath": "TEMPLATE_PATH/models/nlp/llama/backbone.py",
             "imports": [
-                "typing",
-                "transformers",
                 "torch",
-                "math"
+                "typing",
+                "math",
+                "transformers"
             ],
             "module": "modelscope.models.nlp.llama.backbone"
         },
         "('MODELS', 'backbone', 'lstm')": {
             "filepath": "TEMPLATE_PATH/models/nlp/lstm/backbone.py",
             "imports": [
                 "torch"
             ],
             "module": "modelscope.models.nlp.lstm.backbone"
         },
         "('MODELS', 'backbone', 'megatron-bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/megatron_bert/backbone.py",
             "imports": [
-                "transformers",
                 "torch",
-                "math"
+                "math",
+                "transformers"
             ],
             "module": "modelscope.models.nlp.megatron_bert.backbone"
         },
         "('MODELS', 'backbone', 'mgeo')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mgeo/backbone.py",
             "imports": [
-                "dataclasses",
                 "os",
                 "torch",
-                "math",
-                "transformers",
+                "dataclasses",
+                "warnings",
                 "typing",
+                "math",
                 "random",
-                "warnings"
+                "transformers"
             ],
             "module": "modelscope.models.multi_modal.mgeo.backbone"
         },
         "('MODELS', 'backbone', 'plug-mental')": {
             "filepath": "TEMPLATE_PATH/models/nlp/plug_mental/backbone.py",
             "imports": [
-                "dataclasses",
                 "torch",
-                "math",
-                "transformers",
+                "dataclasses",
+                "packaging",
                 "typing",
-                "packaging"
+                "math",
+                "transformers"
             ],
             "module": "modelscope.models.nlp.plug_mental.backbone"
         },
         "('MODELS', 'backbone', 'ponet')": {
             "filepath": "TEMPLATE_PATH/models/nlp/ponet/backbone.py",
             "imports": [
                 "torch",
                 "distutils",
+                "packaging",
                 "math",
-                "transformers",
-                "packaging"
+                "transformers"
             ],
             "module": "modelscope.models.nlp.ponet.backbone"
         },
         "('MODELS', 'backbone', 'structbert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/structbert/backbone.py",
             "imports": [
-                "dataclasses",
                 "torch",
-                "math",
-                "transformers",
+                "dataclasses",
+                "packaging",
                 "typing",
-                "packaging"
+                "math",
+                "transformers"
             ],
             "module": "modelscope.models.nlp.structbert.backbone"
         },
         "('MODELS', 'backbone', 'transformers')": {
             "filepath": "TEMPLATE_PATH/models/nlp/hf_transformers/backbone.py",
             "imports": [
                 "transformers"
@@ -3288,403 +3332,432 @@
             ],
             "module": "modelscope.models.nlp.veco.backbone"
         },
         "('MODELS', 'backbone', 'xlm-roberta')": {
             "filepath": "TEMPLATE_PATH/models/nlp/xlm_roberta/backbone.py",
             "imports": [
                 "packaging",
-                "transformers",
                 "torch",
-                "math"
+                "math",
+                "transformers"
             ],
             "module": "modelscope.models.nlp.xlm_roberta.backbone"
         },
         "('MODELS', 'bad-image-detecting', 'bad-image-detecting')": {
             "filepath": "TEMPLATE_PATH/models/cv/bad_image_detecting/bad_image_detecting.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing"
+                "torchvision",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.models.cv.bad_image_detecting.bad_image_detecting"
         },
         "('MODELS', 'body-2d-keypoints', 'body-2d-keypoints')": {
             "filepath": "TEMPLATE_PATH/models/cv/body_2d_keypoints/hrnet_v2.py",
             "imports": [
-                "numpy",
                 "os",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.body_2d_keypoints.hrnet_v2"
         },
         "('MODELS', 'body-3d-keypoints', 'body-3d-keypoints')": {
             "filepath": "TEMPLATE_PATH/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "logging",
                 "typing",
-                "logging"
+                "numpy"
             ],
             "module": "modelscope.models.cv.body_3d_keypoints.cannonical_pose.body_3d_pose"
         },
         "('MODELS', 'body-3d-keypoints', 'hdformer')": {
             "filepath": "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.body_3d_keypoints.hdformer.hdformer_detector"
         },
         "('MODELS', 'card-detection', 'scrfd')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/scrfd_detect.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "copy",
                 "typing",
-                "copy"
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.scrfd_detect"
         },
+        "('MODELS', 'chat', 'chatglm2-6b')": {
+            "filepath": "TEMPLATE_PATH/models/nlp/chatglm2/text_generation.py",
+            "imports": [
+                "torch",
+                "copy",
+                "warnings",
+                "typing",
+                "math",
+                "sys",
+                "re",
+                "transformers"
+            ],
+            "module": "modelscope.models.nlp.chatglm2.text_generation"
+        },
+        "('MODELS', 'chat', 'chatglm6b')": {
+            "filepath": "TEMPLATE_PATH/models/nlp/chatglm/text_generation.py",
+            "imports": [
+                "os",
+                "torch",
+                "copy",
+                "warnings",
+                "typing",
+                "math",
+                "sys",
+                "re",
+                "transformers"
+            ],
+            "module": "modelscope.models.nlp.chatglm.text_generation"
+        },
         "('MODELS', 'code-generation', 'codegeex')": {
             "filepath": "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_generation.py",
             "imports": [
+                "torch",
                 "typing",
-                "copy",
-                "torch"
+                "copy"
             ],
             "module": "modelscope.models.nlp.codegeex.codegeex_for_code_generation"
         },
         "('MODELS', 'code-translation', 'codegeex')": {
             "filepath": "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_translation.py",
             "imports": [
+                "torch",
                 "typing",
-                "copy",
-                "torch"
+                "copy"
             ],
             "module": "modelscope.models.nlp.codegeex.codegeex_for_code_translation"
         },
         "('MODELS', 'competency-aware-translation', 'canmt')": {
             "filepath": "TEMPLATE_PATH/models/nlp/canmt/canmt_translation.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
+                "typing",
                 "numpy",
-                "typing"
+                "math"
             ],
             "module": "modelscope.models.nlp.canmt.canmt_translation"
         },
         "('MODELS', 'controllable-image-generation', 'controllable-image-generation')": {
             "filepath": "TEMPLATE_PATH/models/cv/controllable_image_generation/controlnet.py",
             "imports": [
                 "os",
+                "einops",
                 "torch",
-                "math",
+                "PIL",
                 "tempfile",
-                "sys",
-                "numpy",
                 "control_ldm",
-                "typing",
-                "PIL",
                 "cv2",
-                "einops",
+                "typing",
+                "numpy",
+                "math",
+                "sys",
                 "random"
             ],
             "module": "modelscope.models.cv.controllable_image_generation.controlnet"
         },
         "('MODELS', 'crowd-counting', 'HRNetCrowdCounting')": {
             "filepath": "TEMPLATE_PATH/models/cv/crowd_counting/cc_model.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.crowd_counting.cc_model"
         },
         "('MODELS', 'document-grounded-dialog-generate', 'doc2bot')": {
             "filepath": "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_generate.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.nlp.dgds.document_grounded_dialog_generate"
         },
         "('MODELS', 'document-grounded-dialog-rerank', 'doc2bot')": {
             "filepath": "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_rerank.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.nlp.dgds.document_grounded_dialog_rerank"
         },
         "('MODELS', 'document-grounded-dialog-retrieval', 'doc2bot')": {
             "filepath": "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_retrieval.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.nlp.dgds.document_grounded_dialog_retrieval"
         },
         "('MODELS', 'document-segmentation', 'bert-for-document-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/document_segmentation.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.bert.document_segmentation"
         },
         "('MODELS', 'document-segmentation', 'ponet-for-document-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/ponet/document_segmentation.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.ponet.document_segmentation"
         },
         "('MODELS', 'document-vl-embedding', 'vldoc')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/vldoc/model.py",
             "imports": [
-                "torchvision",
                 "os",
-                "re",
                 "torch",
-                "math",
-                "sys",
+                "logging",
                 "copy",
+                "torchvision",
                 "json",
-                "logging"
+                "math",
+                "sys",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.vldoc.model"
         },
         "('MODELS', 'domain-specific-object-detection', 'tinynas-damoyolo')": {
             "filepath": "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_damoyolo.py",
             "imports": [],
             "module": "modelscope.models.cv.tinynas_detection.tinynas_damoyolo"
         },
         "('MODELS', 'efficient-diffusion-tuning', 'efficient-diffusion-tuning')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py",
             "imports": [
                 "os",
                 "torch",
                 "functools",
+                "typing",
                 "diffusers",
-                "transformers",
-                "typing"
+                "transformers"
             ],
             "module": "modelscope.models.multi_modal.efficient_diffusion_tuning.efficient_stable_diffusion"
         },
         "('MODELS', 'extractive-summarization', 'ponet-for-document-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/ponet/document_segmentation.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.ponet.document_segmentation"
         },
         "('MODELS', 'face-2d-keypoints', 'flc')": {
             "filepath": "TEMPLATE_PATH/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
                 "PIL",
-                "cv2"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.models.cv.facial_landmark_confidence.flc.facial_landmark_confidence"
         },
         "('MODELS', 'face-attribute-recognition', 'fairface')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
+                "cv2",
+                "torchvision",
                 "numpy",
-                "PIL",
-                "cv2"
+                "PIL"
             ],
             "module": "modelscope.models.cv.face_attribute_recognition.fair_face.face_attribute_recognition"
         },
         "('MODELS', 'face-detection', 'damofd')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/damofd_detect.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "copy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.damofd_detect"
         },
         "('MODELS', 'face-detection', 'mogface')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/mogface/models/detectors.py",
             "imports": [
-                "numpy",
-                "cv2",
                 "os",
-                "torch"
+                "torch",
+                "numpy",
+                "cv2"
             ],
             "module": "modelscope.models.cv.face_detection.mogface.models.detectors"
         },
         "('MODELS', 'face-detection', 'mtcnn')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/detector.py",
             "imports": [
-                "numpy",
-                "PIL",
                 "os",
-                "torch"
+                "torch",
+                "PIL",
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.mtcnn.models.detector"
         },
         "('MODELS', 'face-detection', 'retinaface')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/retinaface/detection.py",
             "imports": [
+                "torch",
                 "numpy",
-                "cv2",
-                "torch"
+                "cv2"
             ],
             "module": "modelscope.models.cv.face_detection.retinaface.detection"
         },
         "('MODELS', 'face-detection', 'scrfd')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/scrfd_detect.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "copy",
                 "typing",
-                "copy"
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.scrfd_detect"
         },
         "('MODELS', 'face-detection', 'tinymog')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/tinymog_detect.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "copy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.tinymog_detect"
         },
         "('MODELS', 'face-detection', 'ulfd')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/detection.py",
             "imports": [
-                "numpy",
-                "cv2",
                 "os",
-                "torch"
+                "torch",
+                "numpy",
+                "cv2"
             ],
             "module": "modelscope.models.cv.face_detection.ulfd_slim.detection"
         },
         "('MODELS', 'face-emotion', 'face-emotion')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_emotion/emotion_model.py",
             "imports": [
-                "sys",
                 "os",
+                "sys",
                 "torch"
             ],
             "module": "modelscope.models.cv.face_emotion.emotion_model"
         },
         "('MODELS', 'face-human-hand-detection', 'face-human-hand-detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_human_hand_detection/det_infer.py",
             "imports": [
+                "torch",
                 "numpy",
-                "cv2",
-                "torch"
+                "cv2"
             ],
             "module": "modelscope.models.cv.face_human_hand_detection.det_infer"
         },
         "('MODELS', 'face-recognition', 'rts-backbone')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_recognition/torchkit/rts_backbone.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
+                "collections",
                 "math"
             ],
             "module": "modelscope.models.cv.face_recognition.torchkit.rts_backbone"
         },
         "('MODELS', 'face-reconstruction', 'face_reconstruction')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_reconstruction/models/facerecon_model.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
+                "cv2",
                 "numpy",
-                "cv2"
+                "collections"
             ],
             "module": "modelscope.models.cv.face_reconstruction.models.facerecon_model"
         },
         "('MODELS', 'facial-expression-recognition', 'fer')": {
             "filepath": "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
                 "PIL",
-                "cv2"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.models.cv.facial_expression_recognition.fer.facial_expression_recognition"
         },
         "('MODELS', 'faq-question-answering', 'structbert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/structbert/faq_question_answering.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
+                "typing",
                 "math",
-                "typing"
+                "collections"
             ],
             "module": "modelscope.models.nlp.structbert.faq_question_answering"
         },
         "('MODELS', 'feature-extraction', 'feature-extraction')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/feature_extraction.py",
             "imports": [
                 "numpy",
                 "typing"
             ],
             "module": "modelscope.models.nlp.task_models.feature_extraction"
         },
         "('MODELS', 'fid-dialogue', 'fid-T5')": {
             "filepath": "TEMPLATE_PATH/models/nlp/fid_T5/text_generation.py",
             "imports": [
+                "io",
                 "os",
                 "torch",
-                "transformers",
-                "io"
+                "transformers"
             ],
             "module": "modelscope.models.nlp.fid_T5.text_generation"
         },
         "('MODELS', 'fid-dialogue', 'fid-plug')": {
             "filepath": "TEMPLATE_PATH/models/nlp/fid_plug/text_generation.py",
             "imports": [
+                "io",
                 "os",
                 "torch",
-                "transformers",
-                "io"
+                "transformers"
             ],
             "module": "modelscope.models.nlp.fid_plug.text_generation"
         },
         "('MODELS', 'fill-mask', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/fill_mask.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.fill_mask"
         },
         "('MODELS', 'fill-mask', 'deberta_v2')": {
             "filepath": "TEMPLATE_PATH/models/nlp/deberta_v2/fill_mask.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.deberta_v2.fill_mask"
         },
         "('MODELS', 'fill-mask', 'fill-mask')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/fill_mask.py",
             "imports": [
@@ -3724,120 +3797,120 @@
                 "transformers"
             ],
             "module": "modelscope.models.nlp.veco.fill_mask"
         },
         "('MODELS', 'generative-multi-modal-embedding', 'gemm-generative-multi-modal')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/gemm/gemm_model.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "json"
+                "torchvision",
+                "json",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.models.multi_modal.gemm.gemm_model"
         },
         "('MODELS', 'generative-multi-modal-embedding', 'rleg-generative-multi-modal')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/rleg/rleg.py",
             "imports": [
+                "torch",
                 "typing",
-                "torchvision",
-                "torch"
+                "torchvision"
             ],
             "module": "modelscope.models.multi_modal.rleg.rleg"
         },
         "('MODELS', 'hand-static', 'hand-static')": {
             "filepath": "TEMPLATE_PATH/models/cv/hand_static/hand_model.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
+                "torchvision",
+                "cv2",
                 "numpy",
-                "sys",
                 "PIL",
-                "cv2"
+                "sys"
             ],
             "module": "modelscope.models.cv.hand_static.hand_model"
         },
         "('MODELS', 'human-detection', 'detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_model.py",
             "imports": [
-                "numpy",
                 "os",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_model"
         },
         "('MODELS', 'human-reconstruction', 'human-reconstruction')": {
             "filepath": "TEMPLATE_PATH/models/cv/human_reconstruction/Reconstruction.py",
             "imports": [
-                "torchvision",
                 "os",
-                "skimage",
                 "torch",
-                "numpy",
                 "PIL",
+                "skimage",
+                "cv2",
+                "torchvision",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.models.cv.human_reconstruction.Reconstruction"
         },
         "('MODELS', 'image-body-reshaping', 'image-body-reshaping')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_body_reshaping/image_body_reshaping.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_body_reshaping.image_body_reshaping"
         },
         "('MODELS', 'image-captioning', 'clip-interrogator')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/clip_interrogator/model.py",
             "imports": [
-                "dataclasses",
-                "torchvision",
                 "os",
-                "torch",
-                "hashlib",
-                "transformers",
-                "PIL",
+                "safetensors",
                 "open_clip",
-                "tqdm",
-                "math",
+                "requests",
                 "numpy",
-                "safetensors",
+                "math",
+                "transformers",
+                "torch",
+                "dataclasses",
+                "tqdm",
+                "hashlib",
+                "torchvision",
                 "typing",
-                "time",
-                "requests"
+                "PIL",
+                "time"
             ],
             "module": "modelscope.models.multi_modal.clip_interrogator.model"
         },
         "('MODELS', 'image-captioning', 'mplug')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.mplug_for_all_tasks"
         },
         "('MODELS', 'image-captioning', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'image-classification', 'ClassificationModel')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_classification/mmcls_model.py",
             "imports": [
                 "os"
@@ -3852,127 +3925,127 @@
             ],
             "module": "modelscope.models.cv.robust_image_classification.easyrobust_model"
         },
         "('MODELS', 'image-classification', 'bnext')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_binary_quant_classification/binary_quant_model.py",
             "imports": [
                 "os",
-                "collections",
-                "torch"
+                "torch",
+                "collections"
             ],
             "module": "modelscope.models.cv.image_binary_quant_classification.binary_quant_model"
         },
         "('MODELS', 'image-classification', 'content-check')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_classification/resnet50_cc.py",
             "imports": [
-                "torchvision",
                 "os",
-                "collections",
                 "torch",
-                "math"
+                "torchvision",
+                "math",
+                "collections"
             ],
             "module": "modelscope.models.cv.image_classification.resnet50_cc"
         },
         "('MODELS', 'image-classification', 'image-probing-model')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_probing_model/model.py",
             "imports": [
-                "typing",
                 "os",
-                "json",
-                "torch"
+                "typing",
+                "torch",
+                "json"
             ],
             "module": "modelscope.models.cv.image_probing_model.model"
         },
         "('MODELS', 'image-classification', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'image-color-enhancement', 'adaint')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_color_enhance/adaint/adaint.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
+                "torchvision",
                 "typing",
                 "numbers"
             ],
             "module": "modelscope.models.cv.image_color_enhance.adaint.adaint"
         },
         "('MODELS', 'image-color-enhancement', 'csrnet')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_color_enhance/image_color_enhance.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_color_enhance.image_color_enhance"
         },
         "('MODELS', 'image-color-enhancement', 'deeplpfnet')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_color_enhance.deeplpf.deeplpf_image_color_enhance"
         },
         "('MODELS', 'image-colorization', 'ddcolor')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "copy",
                 "typing",
-                "copy"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_colorization.ddcolor.ddcolor_for_image_colorization"
         },
         "('MODELS', 'image-debanding', 'rrdb')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_debanding/rrdb/rrdb_image_debanding.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_debanding.rrdb.rrdb_image_debanding"
         },
         "('MODELS', 'image-deblurring', 'nafnet')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_deblur/nafnet_for_image_deblur.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_deblur.nafnet_for_image_deblur"
         },
         "('MODELS', 'image-demoireing', 'image-restoration')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_restoration/image_restoration_model.py",
             "imports": [
-                "numpy",
-                "cv2",
                 "os",
-                "torch"
+                "torch",
+                "numpy",
+                "cv2"
             ],
             "module": "modelscope.models.cv.image_restoration.image_restoration_model"
         },
         "('MODELS', 'image-denoising', 'nafnet')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_denoise/nafnet_for_image_denoise.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_denoise.nafnet_for_image_denoise"
         },
         "('MODELS', 'image-depth-estimation', 'bts-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py",
             "imports": [
@@ -3980,100 +4053,100 @@
                 "torch"
             ],
             "module": "modelscope.models.cv.image_depth_estimation_bts.depth_estimation_bts_model"
         },
         "('MODELS', 'image-depth-estimation', 'newcrfs-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_depth_estimation/newcrfs_model.py",
             "imports": [
-                "numpy",
                 "os",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_depth_estimation.newcrfs_model"
         },
         "('MODELS', 'image-driving-perception', 'yolopv2')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_driving_perception/image_driving_percetion_model.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_driving_perception.image_driving_percetion_model"
         },
         "('MODELS', 'image-face-fusion', 'image-face-fusion')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_face_fusion/image_face_fusion.py",
             "imports": [
-                "torchvision",
                 "os",
-                "collections",
                 "torch",
+                "torchvision",
+                "cv2",
+                "typing",
                 "numpy",
                 "PIL",
-                "typing",
-                "cv2"
+                "collections"
             ],
             "module": "modelscope.models.cv.image_face_fusion.image_face_fusion"
         },
         "('MODELS', 'image-fewshot-detection', 'defrcn')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_defrcn_fewshot.defrcn_for_fewshot"
         },
         "('MODELS', 'image-inpainting', 'FFTInpainting')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_inpainting/model.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_inpainting.model"
         },
         "('MODELS', 'image-matching', 'quadtree-attention-image-matching')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_matching/quadtree_attention_model.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
                 "cv2",
-                "pathlib"
+                "pathlib",
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_matching.quadtree_attention_model"
         },
         "('MODELS', 'image-multi-view-depth-estimation', 'image-casmvs-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/casmvs_model.py",
             "imports": [
                 "os",
                 "torch",
+                "cv2",
                 "easydict",
-                "numpy",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_mvs_depth_estimation.casmvs_model"
         },
         "('MODELS', 'image-object-detection', 'MaskScoring')": {
             "filepath": "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_model.py",
             "imports": [
-                "numpy",
                 "os",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.abnormal_object_detection.mmdet_model"
         },
         "('MODELS', 'image-object-detection', 'detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_model.py",
             "imports": [
-                "numpy",
                 "os",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_model"
         },
         "('MODELS', 'image-object-detection', 'tinynas-damoyolo')": {
             "filepath": "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_damoyolo.py",
             "imports": [],
             "module": "modelscope.models.cv.tinynas_detection.tinynas_damoyolo"
@@ -4092,98 +4165,98 @@
             "module": "modelscope.models.cv.vidt.model"
         },
         "('MODELS', 'image-paintbyexample', 'Stablediffusion-Paintbyexample')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_paintbyexample/model.py",
             "imports": [
                 "os",
                 "torch",
+                "paint_ldm",
                 "omegaconf",
-                "typing",
-                "paint_ldm"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_paintbyexample.model"
         },
         "('MODELS', 'image-portrait-enhancement', 'gpen')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_portrait_enhancement/image_portrait_enhancement.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "math"
             ],
             "module": "modelscope.models.cv.image_portrait_enhancement.image_portrait_enhancement"
         },
         "('MODELS', 'image-quality-assessment-degradation', 'image-quality-assessment-degradation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_quality_assessment_degradation.image_quality_assessment_degradation"
         },
         "('MODELS', 'image-quality-assessment-mos', 'image-quality-assessment-man')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_quality_assessment_man/image_quality_assessment_man.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_quality_assessment_man.image_quality_assessment_man"
         },
         "('MODELS', 'image-quality-assessment-mos', 'image-quality-assessment-mos')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_quality_assessment_mos.image_quality_assessment_mos"
         },
         "('MODELS', 'image-reid-person', 'passvitb')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_reid_person/pass_model.py",
             "imports": [
-                "os",
                 "enum",
+                "os",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_reid_person.pass_model"
         },
         "('MODELS', 'image-segmentation', 'cascade_mask_rcnn_swin')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_instance_segmentation/model.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_instance_segmentation.model"
         },
         "('MODELS', 'image-segmentation', 'fastinst')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst_model.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_instance_segmentation.fastinst_model"
         },
         "('MODELS', 'image-segmentation', 'm2fp')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp_net.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_human_parsing.m2fp_net"
         },
         "('MODELS', 'image-segmentation', 'maskdino_swin')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino_model.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.image_instance_segmentation.maskdino_model"
         },
         "('MODELS', 'image-segmentation', 'swinL-panoptic-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_panoptic_segmentation/panseg_model.py",
             "imports": [
@@ -4191,77 +4264,77 @@
                 "torch"
             ],
             "module": "modelscope.models.cv.image_panoptic_segmentation.panseg_model"
         },
         "('MODELS', 'image-segmentation', 'swinL-semantic-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/semantic_seg_model.py",
             "imports": [
-                "numpy",
                 "os",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.semantic_seg_model"
         },
         "('MODELS', 'image-segmentation', 'vision-middleware')": {
             "filepath": "TEMPLATE_PATH/models/cv/vision_middleware/model.py",
             "imports": [
-                "typing",
                 "os",
-                "json",
-                "torch"
+                "typing",
+                "torch",
+                "json"
             ],
             "module": "modelscope.models.cv.vision_middleware.model"
         },
         "('MODELS', 'image-segmentation', 'vitadapter-semantic-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/semantic_seg_model.py",
             "imports": [
-                "numpy",
                 "os",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.semantic_seg_model"
         },
         "('MODELS', 'image-skychange', 'image-skychange')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_skychange/skychange_model.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
-                "math",
-                "typing",
                 "cv2",
-                "time",
                 "json",
-                "pdb"
+                "pdb",
+                "typing",
+                "math",
+                "time",
+                "collections"
             ],
             "module": "modelscope.models.cv.image_skychange.skychange_model"
         },
         "('MODELS', 'image-super-resolution', 'ecbsr')": {
             "filepath": "TEMPLATE_PATH/models/cv/super_resolution/ecbsr_model.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.super_resolution.ecbsr_model"
         },
         "('MODELS', 'image-text-retrieval', 'mplug')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.mplug_for_all_tasks"
         },
         "('MODELS', 'indoor-layout-estimation', 'panovit-layout-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/indoor_layout_estimation/panovit.py",
             "imports": [
-                "numpy",
                 "os",
                 "torch",
+                "numpy",
                 "yacs"
             ],
             "module": "modelscope.models.cv.indoor_layout_estimation.panovit"
         },
         "('MODELS', 'information-extraction', 'information-extraction')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/information_extraction.py",
             "imports": [
@@ -4269,177 +4342,177 @@
                 "typing"
             ],
             "module": "modelscope.models.nlp.task_models.information_extraction"
         },
         "('MODELS', 'inverse-text-processing', 'generic-itn')": {
             "filepath": "TEMPLATE_PATH/models/audio/itn/generic_inverse_text_processing.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.itn.generic_inverse_text_processing"
         },
         "('MODELS', 'keyword-spotting', 'kws-kwsbp')": {
             "filepath": "TEMPLATE_PATH/models/audio/kws/generic_key_word_spotting.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.kws.generic_key_word_spotting"
         },
         "('MODELS', 'keyword-spotting', 'speech_dfsmn_kws_char_farfield')": {
             "filepath": "TEMPLATE_PATH/models/audio/kws/farfield/model.py",
             "imports": [
-                "tempfile",
                 "os",
-                "typing"
+                "typing",
+                "tempfile"
             ],
             "module": "modelscope.models.audio.kws.farfield.model"
         },
         "('MODELS', 'keyword-spotting', 'speech_dfsmn_kws_char_farfield_iot')": {
             "filepath": "TEMPLATE_PATH/models/audio/kws/farfield/model.py",
             "imports": [
-                "tempfile",
                 "os",
-                "typing"
+                "typing",
+                "tempfile"
             ],
             "module": "modelscope.models.audio.kws.farfield.model"
         },
         "('MODELS', 'keyword-spotting', 'speech_kws_fsmn_char_ctc_nearfield')": {
             "filepath": "TEMPLATE_PATH/models/audio/kws/nearfield/model.py",
             "imports": [
                 "os",
                 "torch",
                 "tempfile",
-                "sys",
-                "typing"
+                "typing",
+                "sys"
             ],
             "module": "modelscope.models.audio.kws.nearfield.model"
         },
         "('MODELS', 'language-guided-video-summarization', 'clip-it-language-guided-video-summarization')": {
             "filepath": "TEMPLATE_PATH/models/cv/language_guided_video_summarization/summarizer.py",
             "imports": [
                 "os",
                 "torch",
-                "bmt_clipit",
                 "argparse",
-                "numpy",
+                "videofeatures_clipit",
                 "typing",
-                "videofeatures_clipit"
+                "bmt_clipit",
+                "numpy"
             ],
             "module": "modelscope.models.cv.language_guided_video_summarization.summarizer"
         },
         "('MODELS', 'language-score-prediction', 'generic-asr')": {
             "filepath": "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.asr.generic_automatic_speech_recognition"
         },
         "('MODELS', 'lineless-table-recognition', 'LoreModel')": {
             "filepath": "TEMPLATE_PATH/models/cv/table_recognition/model_lore.py",
             "imports": [
                 "os",
                 "torch",
+                "copy",
                 "math",
-                "numpy",
                 "typing",
-                "copy"
+                "numpy"
             ],
             "module": "modelscope.models.cv.table_recognition.model_lore"
         },
         "('MODELS', 'movie-scene-segmentation', 'resnet50-bert')": {
             "filepath": "TEMPLATE_PATH/models/cv/movie_scene_segmentation/model.py",
             "imports": [
-                "torchvision",
                 "os",
+                "einops",
                 "torch",
-                "math",
-                "numpy",
-                "typing",
+                "shotdetect_scenedetect_lgss",
                 "PIL",
-                "einops",
                 "tqdm",
-                "shotdetect_scenedetect_lgss"
+                "torchvision",
+                "typing",
+                "numpy",
+                "math"
             ],
             "module": "modelscope.models.cv.movie_scene_segmentation.model"
         },
         "('MODELS', 'multi-modal-embedding', 'clip-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/clip/model.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
-                "numpy",
+                "json",
                 "typing",
-                "json"
+                "numpy",
+                "collections"
             ],
             "module": "modelscope.models.multi_modal.clip.model"
         },
         "('MODELS', 'multi-modal-similarity', 'team-multi-modal-similarity')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/team/team_model.py",
             "imports": [
-                "torchvision",
                 "torch",
-                "numpy",
                 "tokenizers",
-                "PIL",
+                "torchvision",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.models.multi_modal.team.team_model"
         },
         "('MODELS', 'multimodal-dialogue', 'mplug-owl')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_owl/modeling_mplug_owl.py",
             "imports": [
-                "dataclasses",
                 "os",
                 "torch",
-                "math",
-                "transformers",
-                "typing",
+                "dataclasses",
+                "logging",
                 "copy",
+                "typing",
+                "io",
+                "math",
                 "random",
-                "logging",
-                "io"
+                "transformers"
             ],
             "module": "modelscope.models.multi_modal.mplug_owl.modeling_mplug_owl"
         },
         "('MODELS', 'named-entity-recognition', 'lstm-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/lstm/token_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.lstm.token_classification"
         },
         "('MODELS', 'named-entity-recognition', 'token-classification-for-ner')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'named-entity-recognition', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'nerf-recon-acc', 'nerf-recon-acc')": {
             "filepath": "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_recon_acc.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "tqdm",
                 "cv2",
-                "time",
                 "glob",
-                "tqdm"
+                "numpy",
+                "time"
             ],
             "module": "modelscope.models.cv.nerf_recon_acc.nerf_recon_acc"
         },
         "('MODELS', 'nli', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/text_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.text_classification"
@@ -4450,16 +4523,16 @@
                 "torch"
             ],
             "module": "modelscope.models.multi_modal.mgeo.text_classification"
         },
         "('MODELS', 'nli', 'peer')": {
             "filepath": "TEMPLATE_PATH/models/nlp/peer/text_classification.py",
             "imports": [
-                "copy",
-                "torch"
+                "torch",
+                "copy"
             ],
             "module": "modelscope.models.nlp.peer.text_classification"
         },
         "('MODELS', 'nli', 'plug-mental')": {
             "filepath": "TEMPLATE_PATH/models/nlp/plug_mental/text_classification.py",
             "imports": [
                 "torch"
@@ -4479,28 +4552,28 @@
                 "transformers"
             ],
             "module": "modelscope.models.nlp.veco.text_classification"
         },
         "('MODELS', 'object-detection-3d', 'depe')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/depe_detect.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.depe_detect"
         },
         "('MODELS', 'ocr-detection', 'OCRDetection')": {
             "filepath": "TEMPLATE_PATH/models/cv/ocr_detection/model.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.ocr_detection.model"
         },
         "('MODELS', 'ocr-recognition', 'OCRRecognition')": {
             "filepath": "TEMPLATE_PATH/models/cv/ocr_recognition/model.py",
             "imports": [
                 "os",
@@ -4508,44 +4581,44 @@
             ],
             "module": "modelscope.models.cv.ocr_recognition.model"
         },
         "('MODELS', 'ocr-recognition', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'open-vocabulary-detection', 'open-vocabulary-detection-vild')": {
             "filepath": "TEMPLATE_PATH/models/cv/open_vocabulary_detection_vild/vild.py",
             "imports": [
                 "os",
-                "clip",
                 "torch",
-                "numpy",
+                "clip",
                 "scipy",
                 "typing",
-                "tensorflow"
+                "tensorflow",
+                "numpy"
             ],
             "module": "modelscope.models.cv.open_vocabulary_detection_vild.vild"
         },
         "('MODELS', 'panorama-depth-estimation', 'unifuse-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/panorama_depth_estimation/unifuse_model.py",
             "imports": [
-                "numpy",
-                "torchvision",
                 "os",
-                "torch"
+                "torch",
+                "numpy",
+                "torchvision"
             ],
             "module": "modelscope.models.cv.panorama_depth_estimation.unifuse_model"
         },
         "('MODELS', 'part-of-speech', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/token_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.token_classification"
@@ -4568,63 +4641,63 @@
                 "torch"
             ],
             "module": "modelscope.models.nlp.structbert.token_classification"
         },
         "('MODELS', 'part-of-speech', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'part-of-speech', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'pedestrian-attribute-recognition', 'pedestrian-attribute-recognition')": {
             "filepath": "TEMPLATE_PATH/models/cv/pedestrian_attribute_recognition/model.py",
             "imports": [
-                "numpy",
-                "torchvision",
                 "os",
-                "torch"
+                "torch",
+                "numpy",
+                "torchvision"
             ],
             "module": "modelscope.models.cv.pedestrian_attribute_recognition.model"
         },
         "('MODELS', 'pointcloud-sceneflow-estimation', 'rcp-sceneflow-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/rcp_model.py",
             "imports": [
-                "numpy",
                 "os",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.pointcloud_sceneflow_estimation.rcp_model"
         },
         "('MODELS', 'product-retrieval-embedding', 'product-retrieval-embedding')": {
             "filepath": "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_model.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.product_retrieval_embedding.item_model"
         },
         "('MODELS', 'product-segmentation', 'product-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/product_segmentation/seg_infer.py",
             "imports": [
+                "torch",
                 "numpy",
                 "PIL",
-                "cv2",
-                "torch"
+                "cv2"
             ],
             "module": "modelscope.models.cv.product_segmentation.seg_infer"
         },
         "('MODELS', 'protein-structure', 'unifold')": {
             "filepath": "TEMPLATE_PATH/models/science/unifold/model.py",
             "imports": [
                 "argparse",
@@ -4633,24 +4706,24 @@
                 "torch"
             ],
             "module": "modelscope.models.science.unifold.model"
         },
         "('MODELS', 'punctuation', 'generic-punc')": {
             "filepath": "TEMPLATE_PATH/models/audio/punc/generic_punctuation.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.punc.generic_punctuation"
         },
         "('MODELS', 'referring-video-object-segmentation', 'swinT-referring-video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/model.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.referring_video_object_segmentation.model"
         },
         "('MODELS', 'relation-extraction', 'information-extraction')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/information_extraction.py",
             "imports": [
@@ -4658,29 +4731,29 @@
                 "typing"
             ],
             "module": "modelscope.models.nlp.task_models.information_extraction"
         },
         "('MODELS', 'semantic-segmentation', 'ddpm')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "ddpm_guided_diffusion"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.ddpm_segmentation_model"
         },
         "('MODELS', 'semantic-segmentation', 'detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/salient_detection/salient_model.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "PIL",
-                "cv2"
+                "cv2",
+                "torchvision",
+                "PIL"
             ],
             "module": "modelscope.models.cv.salient_detection.salient_model"
         },
         "('MODELS', 'sentence-embedding', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/sentence_embedding.py",
             "imports": [
                 "torch"
@@ -4698,16 +4771,16 @@
                 "torch"
             ],
             "module": "modelscope.models.multi_modal.mgeo.text_classification"
         },
         "('MODELS', 'sentence-similarity', 'peer')": {
             "filepath": "TEMPLATE_PATH/models/nlp/peer/text_classification.py",
             "imports": [
-                "copy",
-                "torch"
+                "torch",
+                "copy"
             ],
             "module": "modelscope.models.nlp.peer.text_classification"
         },
         "('MODELS', 'sentence-similarity', 'plug-mental')": {
             "filepath": "TEMPLATE_PATH/models/nlp/plug_mental/text_classification.py",
             "imports": [
                 "torch"
@@ -4739,16 +4812,16 @@
                 "torch"
             ],
             "module": "modelscope.models.multi_modal.mgeo.text_classification"
         },
         "('MODELS', 'sentiment-classification', 'peer')": {
             "filepath": "TEMPLATE_PATH/models/nlp/peer/text_classification.py",
             "imports": [
-                "copy",
-                "torch"
+                "torch",
+                "copy"
             ],
             "module": "modelscope.models.nlp.peer.text_classification"
         },
         "('MODELS', 'sentiment-classification', 'plug-mental')": {
             "filepath": "TEMPLATE_PATH/models/nlp/plug_mental/text_classification.py",
             "imports": [
                 "torch"
@@ -4770,176 +4843,199 @@
             "module": "modelscope.models.nlp.veco.text_classification"
         },
         "('MODELS', 'shop-segmentation', 'shop-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/shop_segmentation/shop_seg_model.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "json",
                 "typing",
-                "json"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.models.cv.shop_segmentation.shop_seg_model"
         },
         "('MODELS', 'siamese-uie', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/siamese_uie.py",
             "imports": [
-                "copy",
-                "torch"
+                "torch",
+                "copy"
             ],
             "module": "modelscope.models.nlp.bert.siamese_uie"
         },
+        "('MODELS', 'speaker-diarization', 'cluster-backend')": {
+            "filepath": "TEMPLATE_PATH/models/audio/sv/cluster_backend.py",
+            "imports": [
+                "numpy",
+                "sklearn",
+                "scipy",
+                "typing"
+            ],
+            "module": "modelscope.models.audio.sv.cluster_backend"
+        },
         "('MODELS', 'speaker-diarization', 'generic-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/generic_speaker_verification.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.sv.generic_speaker_verification"
         },
         "('MODELS', 'speaker-diarization', 'scl-sd')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/speaker_change_locator.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
-                "numpy",
                 "torchaudio",
-                "typing"
+                "typing",
+                "numpy",
+                "collections"
             ],
             "module": "modelscope.models.audio.sv.speaker_change_locator"
         },
         "('MODELS', 'speaker-verification', 'cam++-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/DTDNN.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
                 "torchaudio",
-                "typing"
+                "typing",
+                "numpy",
+                "collections"
             ],
             "module": "modelscope.models.audio.sv.DTDNN"
         },
         "('MODELS', 'speaker-verification', 'ecapa-tdnn-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/ecapa_tdnn.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
                 "torchaudio",
-                "typing"
+                "math",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.models.audio.sv.ecapa_tdnn"
         },
+        "('MODELS', 'speaker-verification', 'eres2net-aug-sv')": {
+            "filepath": "TEMPLATE_PATH/models/audio/sv/ERes2Net_aug.py",
+            "imports": [
+                "os",
+                "torch",
+                "torchaudio",
+                "typing",
+                "math"
+            ],
+            "module": "modelscope.models.audio.sv.ERes2Net_aug"
+        },
         "('MODELS', 'speaker-verification', 'eres2net-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/ERes2Net.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
                 "torchaudio",
-                "typing"
+                "typing",
+                "math"
             ],
             "module": "modelscope.models.audio.sv.ERes2Net"
         },
         "('MODELS', 'speaker-verification', 'generic-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/generic_speaker_verification.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.sv.generic_speaker_verification"
         },
         "('MODELS', 'speaker-verification', 'rdino_ecapa-tdnn-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/rdino.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
                 "torchaudio",
-                "typing"
+                "typing",
+                "math"
             ],
             "module": "modelscope.models.audio.sv.rdino"
         },
         "('MODELS', 'speech-separation', 'speech_mossformer_separation_temporal_8k')": {
             "filepath": "TEMPLATE_PATH/models/audio/separation/mossformer.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "copy"
             ],
             "module": "modelscope.models.audio.separation.mossformer"
         },
         "('MODELS', 'speech-timestamp', 'generic-asr')": {
             "filepath": "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.asr.generic_automatic_speech_recognition"
         },
         "('MODELS', 'sudoku', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'table-question-answering', 'space-T-cn')": {
             "filepath": "TEMPLATE_PATH/models/nlp/space_T_cn/table_question_answering.py",
             "imports": [
                 "os",
                 "torch",
+                "typing",
                 "numpy",
-                "transformers",
-                "typing"
+                "transformers"
             ],
             "module": "modelscope.models.nlp.space_T_cn.table_question_answering"
         },
         "('MODELS', 'table-question-answering', 'space-T-en')": {
             "filepath": "TEMPLATE_PATH/models/nlp/space_T_en/text_to_sql.py",
             "imports": [
-                "typing",
+                "text2sql_lgesql",
                 "os",
-                "torch",
-                "text2sql_lgesql"
+                "typing",
+                "torch"
             ],
             "module": "modelscope.models.nlp.space_T_en.text_to_sql"
         },
         "('MODELS', 'task-oriented-conversation', 'space-dst')": {
             "filepath": "TEMPLATE_PATH/models/nlp/space/dialog_state_tracking.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.space.dialog_state_tracking"
         },
         "('MODELS', 'task-oriented-conversation', 'space-intent')": {
             "filepath": "TEMPLATE_PATH/models/nlp/space/dialog_intent_prediction.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.nlp.space.dialog_intent_prediction"
         },
         "('MODELS', 'task-oriented-conversation', 'space-modeling')": {
             "filepath": "TEMPLATE_PATH/models/nlp/space/dialog_modeling.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.nlp.space.dialog_modeling"
         },
         "('MODELS', 'text-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/text_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.text_classification"
@@ -4951,29 +5047,29 @@
             ],
             "module": "modelscope.models.multi_modal.mgeo.text_classification"
         },
         "('MODELS', 'text-classification', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'text-classification', 'peer')": {
             "filepath": "TEMPLATE_PATH/models/nlp/peer/text_classification.py",
             "imports": [
-                "copy",
-                "torch"
+                "torch",
+                "copy"
             ],
             "module": "modelscope.models.nlp.peer.text_classification"
         },
         "('MODELS', 'text-classification', 'plug-mental')": {
             "filepath": "TEMPLATE_PATH/models/nlp/plug_mental/text_classification.py",
             "imports": [
                 "torch"
@@ -4996,17 +5092,17 @@
             "module": "modelscope.models.nlp.task_models.text_classification"
         },
         "('MODELS', 'text-classification', 'user-satisfaction-estimation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/use/user_satisfaction_estimation.py",
             "imports": [
                 "os",
                 "torch",
+                "typing",
                 "numpy",
-                "transformers",
-                "typing"
+                "transformers"
             ],
             "module": "modelscope.models.nlp.use.user_satisfaction_estimation"
         },
         "('MODELS', 'text-classification', 'veco')": {
             "filepath": "TEMPLATE_PATH/models/nlp/veco/text_classification.py",
             "imports": [
                 "transformers"
@@ -5014,96 +5110,96 @@
             "module": "modelscope.models.nlp.veco.text_classification"
         },
         "('MODELS', 'text-driven-segmentation', 'text-driven-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_model.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "json",
                 "typing",
-                "json"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.models.cv.text_driven_segmentation.lseg_model"
         },
         "('MODELS', 'text-error-correction', 'bart')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bart/text_error_correction.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.nlp.bart.text_error_correction"
         },
         "('MODELS', 'text-generation', 'glm130b')": {
             "filepath": "TEMPLATE_PATH/models/nlp/glm_130b/text_generation.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
                 "functools",
-                "sys",
+                "time",
                 "SwissArmyTransformer",
-                "typing",
                 "copy",
-                "time",
-                "random",
-                "stat"
+                "stat",
+                "typing",
+                "sys",
+                "re",
+                "random"
             ],
             "module": "modelscope.models.nlp.glm_130b.text_generation"
         },
         "('MODELS', 'text-generation', 'gpt-moe')": {
             "filepath": "TEMPLATE_PATH/models/nlp/gpt_moe/text_generation.py",
             "imports": [
                 "typing",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.gpt_moe.text_generation"
         },
         "('MODELS', 'text-generation', 'gpt3')": {
             "filepath": "TEMPLATE_PATH/models/nlp/gpt3/text_generation.py",
             "imports": [
+                "torch",
                 "typing",
                 "collections",
-                "torch",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.gpt3.text_generation"
         },
         "('MODELS', 'text-generation', 'llama')": {
             "filepath": "TEMPLATE_PATH/models/nlp/llama/text_generation.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.llama.text_generation"
         },
         "('MODELS', 'text-generation', 'palm-v2')": {
             "filepath": "TEMPLATE_PATH/models/nlp/palm_v2/text_generation.py",
             "imports": [
-                "dataclasses",
                 "os",
-                "codecs",
-                "math",
                 "torch",
-                "numpy",
-                "transformers",
                 "subprocess",
-                "typing",
+                "dataclasses",
                 "copy",
-                "json"
+                "codecs",
+                "json",
+                "typing",
+                "numpy",
+                "math",
+                "transformers"
             ],
             "module": "modelscope.models.nlp.palm_v2.text_generation"
         },
         "('MODELS', 'text-generation', 'text-generation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/text_generation.py",
             "imports": [
-                "numpy",
-                "typing",
                 "torch",
+                "typing",
+                "numpy",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.task_models.text_generation"
         },
         "('MODELS', 'text-ranking', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/text_ranking.py",
             "imports": [],
@@ -5125,123 +5221,135 @@
             "module": "modelscope.models.nlp.task_models.text_ranking"
         },
         "('MODELS', 'text-summarization', 'mglm')": {
             "filepath": "TEMPLATE_PATH/models/nlp/mglm/mglm_for_text_summarization.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "megatron_util",
+                "typing",
+                "numpy",
                 "random"
             ],
             "module": "modelscope.models.nlp.mglm.mglm_for_text_summarization"
         },
         "('MODELS', 'text-summarization', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'text-to-image-synthesis', 'diffusion-text-to-image-synthesis')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/diffusion/model.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "json",
                 "typing",
-                "json"
+                "numpy"
             ],
             "module": "modelscope.models.multi_modal.diffusion.model"
         },
         "('MODELS', 'text-to-image-synthesis', 'multi-stage-diffusion-text-to-image-synthesis')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/model.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "numpy",
-                "typing",
                 "PIL",
-                "json"
+                "json",
+                "typing",
+                "numpy",
+                "math"
             ],
             "module": "modelscope.models.multi_modal.multi_stage_diffusion.model"
         },
         "('MODELS', 'text-to-image-synthesis', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_text_to_image_synthesis_model.py",
             "imports": [
+                "os",
+                "torch",
+                "PIL",
                 "taming",
                 "torchvision",
+                "json",
+                "typing",
+                "numpy",
+                "pkg_resources"
+            ],
+            "module": "modelscope.models.multi_modal.ofa_for_text_to_image_synthesis_model"
+        },
+        "('MODELS', 'text-to-image-synthesis', 'stable-diffusion')": {
+            "filepath": "TEMPLATE_PATH/models/multi_modal/stable_diffusion/stable_diffusion.py",
+            "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "pkg_resources",
+                "functools",
                 "typing",
-                "PIL",
-                "json"
+                "diffusers",
+                "transformers"
             ],
-            "module": "modelscope.models.multi_modal.ofa_for_text_to_image_synthesis_model"
+            "module": "modelscope.models.multi_modal.stable_diffusion.stable_diffusion"
         },
         "('MODELS', 'text-to-speech', 'sambert-hifigan')": {
             "filepath": "TEMPLATE_PATH/models/audio/tts/sambert_hifi.py",
             "imports": [
                 "os",
-                "wave",
-                "numpy",
-                "shutil",
-                "matplotlib",
-                "datetime",
                 "__future__",
                 "zipfile",
+                "datetime",
+                "wave",
+                "yaml",
                 "json",
-                "yaml"
+                "matplotlib",
+                "shutil",
+                "numpy"
             ],
             "module": "modelscope.models.audio.tts.sambert_hifi"
         },
         "('MODELS', 'text-to-video-synthesis', 'latent-text-to-video-synthesis')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py",
             "imports": [
                 "os",
+                "einops",
                 "torch",
                 "typing",
-                "einops",
                 "open_clip"
             ],
             "module": "modelscope.models.multi_modal.video_synthesis.text_to_video_synthesis_model"
         },
         "('MODELS', 'text2sql', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'text2text-generation', 'T5')": {
             "filepath": "TEMPLATE_PATH/models/nlp/T5/text2text_generation.py",
             "imports": [
                 "torch",
-                "transformers",
-                "typing",
                 "copy",
-                "warnings"
+                "warnings",
+                "typing",
+                "transformers"
             ],
             "module": "modelscope.models.nlp.T5.text2text_generation"
         },
         "('MODELS', 'token-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/token_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.token_classification"
@@ -5264,133 +5372,133 @@
                 "torch"
             ],
             "module": "modelscope.models.nlp.structbert.token_classification"
         },
         "('MODELS', 'token-classification', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'token-classification', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'token-classification', 'transformer-crf-for-word-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'token-classification', 'veco')": {
             "filepath": "TEMPLATE_PATH/models/nlp/veco/token_classification.py",
             "imports": [
                 "torch",
                 "transformers"
             ],
             "module": "modelscope.models.nlp.veco.token_classification"
         },
         "('MODELS', 'transformer-crf', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'translation', 'csanmt-translation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/csanmt/translation.py",
             "imports": [
+                "math",
                 "typing",
-                "tensorflow",
                 "collections",
-                "math"
+                "tensorflow"
             ],
             "module": "modelscope.models.nlp.csanmt.translation"
         },
         "('MODELS', 'translation-evaluation', 'unite')": {
             "filepath": "TEMPLATE_PATH/models/nlp/unite/translation_evaluation.py",
             "imports": [
-                "dataclasses",
                 "torch",
-                "math",
-                "numpy",
-                "transformers",
-                "typing",
+                "dataclasses",
                 "packaging",
-                "warnings"
+                "warnings",
+                "typing",
+                "numpy",
+                "math",
+                "transformers"
             ],
             "module": "modelscope.models.nlp.unite.translation_evaluation"
         },
         "('MODELS', 'video-captioning', 'hitea')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.mplug_for_all_tasks"
         },
         "('MODELS', 'video-deinterlace', 'video-deinterlace')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_deinterlace/UNet_for_video_deinterlace.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "copy"
             ],
             "module": "modelscope.models.cv.video_deinterlace.UNet_for_video_deinterlace"
         },
         "('MODELS', 'video-depth-estimation', 'dro-resnet18-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_depth_estimation/dro_model.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "tqdm",
                 "cv2",
                 "glob",
-                "tqdm"
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_depth_estimation.dro_model"
         },
         "('MODELS', 'video-frame-interpolation', 'video-frame-interpolation')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "copy"
             ],
             "module": "modelscope.models.cv.video_frame_interpolation.VFINet_for_video_frame_interpolation"
         },
         "('MODELS', 'video-human-matting', 'video-human-matting')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_human_matting/model.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing"
+                "torchvision",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_human_matting.model"
         },
         "('MODELS', 'video-inpainting', 'video-inpainting')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_inpainting/inpainting_model.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "math",
                 "torch",
-                "math"
+                "numpy",
+                "torchvision"
             ],
             "module": "modelscope.models.cv.video_inpainting.inpainting_model"
         },
         "('MODELS', 'video-instance-segmentation', 'swinb-video-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/video_knet.py",
             "imports": [
                 "torch",
@@ -5398,123 +5506,123 @@
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.video_knet"
         },
         "('MODELS', 'video-multi-modal-embedding', 'video-clip-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py",
             "imports": [
                 "os",
-                "urllib",
                 "torch",
-                "numpy",
+                "PIL",
                 "tempfile",
+                "uuid",
                 "decord",
+                "urllib",
+                "json",
                 "typing",
-                "PIL",
-                "uuid",
-                "random",
-                "json"
+                "numpy",
+                "random"
             ],
             "module": "modelscope.models.multi_modal.mmr.models.clip_for_mm_video_embedding"
         },
         "('MODELS', 'video-object-detection', 'longshortnet')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/longshortnet.py",
             "imports": [
                 "os",
                 "torch",
+                "tqdm",
+                "logging",
                 "argparse",
-                "numpy",
                 "cv2",
-                "time",
                 "json",
-                "logging",
-                "tqdm"
+                "numpy",
+                "time"
             ],
             "module": "modelscope.models.cv.video_streaming_perception.longshortnet.longshortnet"
         },
         "('MODELS', 'video-object-detection', 'realtime-video-object-detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/stream_yolo/realtime_video_detector.py",
             "imports": [
                 "os",
                 "torch",
+                "tqdm",
+                "logging",
                 "argparse",
-                "numpy",
                 "cv2",
-                "time",
                 "json",
-                "logging",
-                "tqdm"
+                "numpy",
+                "time"
             ],
             "module": "modelscope.models.cv.stream_yolo.realtime_video_detector"
         },
         "('MODELS', 'video-object-segmentation', 'video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_object_segmentation/model.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.video_object_segmentation.model"
         },
         "('MODELS', 'video-panoptic-segmentation', 'swinb-video-panoptic-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/video_k_net.py",
             "imports": [
-                "numpy",
-                "mmdet",
                 "torch",
-                "mmcv"
+                "mmcv",
+                "mmdet",
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_panoptic_segmentation.video_k_net"
         },
         "('MODELS', 'video-question-answering', 'hitea')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.mplug_for_all_tasks"
         },
         "('MODELS', 'video-stabilization', 'video-stabilization')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_stabilization/DUTRAFTStabilizer.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
                 "tempfile",
-                "sys",
-                "numpy",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "math",
+                "sys"
             ],
             "module": "modelscope.models.cv.video_stabilization.DUTRAFTStabilizer"
         },
         "('MODELS', 'video-summarization', 'pgl-video-summarization')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_summarization/summarizer.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_summarization.summarizer"
         },
         "('MODELS', 'video-super-resolution', 'msrresnet-lite')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_super_resolution/msrresnet_lite_model.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "functools"
             ],
             "module": "modelscope.models.cv.video_super_resolution.msrresnet_lite_model"
         },
         "('MODELS', 'video-super-resolution', 'real-basicvsr')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.models.cv.video_super_resolution.real_basicvsr_for_video_super_resolution"
         },
         "('MODELS', 'video-temporal-grounding', 'soonet')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/soonet/model.py",
             "imports": [
@@ -5538,74 +5646,74 @@
                 "torch"
             ],
             "module": "modelscope.models.cv.vop_retrieval.model_se"
         },
         "('MODELS', 'vision-efficient-tuning', 'vision-efficient-tuning')": {
             "filepath": "TEMPLATE_PATH/models/cv/vision_efficient_tuning/model.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.cv.vision_efficient_tuning.model"
         },
         "('MODELS', 'visual-entailment', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'visual-grounding', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'visual-question-answering', 'mplug')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.mplug_for_all_tasks"
         },
         "('MODELS', 'visual-question-answering', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "math",
                 "functools",
-                "typing",
                 "json",
-                "string"
+                "typing",
+                "string",
+                "math",
+                "re"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'voice-activity-detection', 'generic-asr')": {
             "filepath": "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.asr.generic_automatic_speech_recognition"
         },
         "('MODELS', 'word-alignment', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/word_alignment.py",
             "imports": [
                 "torch"
@@ -5640,24 +5748,24 @@
                 "torch"
             ],
             "module": "modelscope.models.nlp.structbert.token_classification"
         },
         "('MODELS', 'word-segmentation', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'word-segmentation', 'transformer-crf-for-word-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'zero-shot-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/text_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.text_classification"
@@ -5668,16 +5776,16 @@
                 "torch"
             ],
             "module": "modelscope.models.multi_modal.mgeo.text_classification"
         },
         "('MODELS', 'zero-shot-classification', 'peer')": {
             "filepath": "TEMPLATE_PATH/models/nlp/peer/text_classification.py",
             "imports": [
-                "copy",
-                "torch"
+                "torch",
+                "copy"
             ],
             "module": "modelscope.models.nlp.peer.text_classification"
         },
         "('MODELS', 'zero-shot-classification', 'plug-mental')": {
             "filepath": "TEMPLATE_PATH/models/nlp/plug_mental/text_classification.py",
             "imports": [
                 "torch"
@@ -5691,168 +5799,157 @@
             ],
             "module": "modelscope.models.nlp.structbert.text_classification"
         },
         "('NECKS', 'default', 'CPFPN')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py",
             "imports": [
                 "torch",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.necks.cp_fpn"
         },
         "('NECKS', 'default', 'FPNF')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/necks/fpn.py",
             "imports": [
                 "torch",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.necks.fpn"
         },
         "('NECKS', 'default', 'MSDeformAttnPixelDecoder')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py",
             "imports": [
                 "torch",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.neck.msdeformattn_decoder"
         },
         "('NECKS', 'default', 'SemanticFPNWrapper')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py",
             "imports": [
                 "torch",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.video_panoptic_segmentation.head.semantic_fpn_wrapper"
         },
-        "('OPTIMIZERS', 'default', 'ChildTuningAdamW')": {
-            "filepath": "TEMPLATE_PATH/trainers/optimizer/child_tuning_adamw_optimizer.py",
-            "imports": [
-                "torch",
-                "math",
-                "numpy",
-                "typing",
-                "types"
-            ],
-            "module": "modelscope.trainers.optimizer.child_tuning_adamw_optimizer"
-        },
         "('PARALLEL', 'default', 'DistributedDataParallel')": {
             "filepath": "TEMPLATE_PATH/trainers/parallel/builder.py",
             "imports": [
                 "torch"
             ],
             "module": "modelscope.trainers.parallel.builder"
         },
         "('PIPELINES', 'acoustic-echo-cancellation', 'speech-dfsmn-aec-psm-16k')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/linear_aec_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
                 "scipy",
+                "yaml",
                 "importlib",
                 "typing",
-                "yaml"
+                "numpy"
             ],
             "module": "modelscope.pipelines.audio.linear_aec_pipeline"
         },
         "('PIPELINES', 'acoustic-noise-suppression', 'speech_dfsmn_ans_psm_48k_causal')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/ans_dfsmn_pipeline.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
-                "numpy",
-                "sys",
                 "librosa",
                 "typing",
-                "soundfile",
-                "io"
+                "io",
+                "numpy",
+                "sys",
+                "collections",
+                "soundfile"
             ],
             "module": "modelscope.pipelines.audio.ans_dfsmn_pipeline"
         },
         "('PIPELINES', 'acoustic-noise-suppression', 'speech_frcrn_ans_cirm_16k')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/ans_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
                 "librosa",
                 "typing",
-                "soundfile",
-                "io"
+                "io",
+                "numpy",
+                "soundfile"
             ],
             "module": "modelscope.pipelines.audio.ans_pipeline"
         },
         "('PIPELINES', 'action-detection', 'ResNetC3D-action-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/action_detection_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "math"
             ],
             "module": "modelscope.pipelines.cv.action_detection_pipeline"
         },
         "('PIPELINES', 'action-recognition', 'TAdaConv_action-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/action_recognition_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "math"
             ],
             "module": "modelscope.pipelines.cv.action_recognition_pipeline"
         },
         "('PIPELINES', 'action-recognition', 'patchshift-action-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/action_recognition_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "math"
             ],
             "module": "modelscope.pipelines.cv.action_recognition_pipeline"
         },
         "('PIPELINES', 'animal-recognition', 'resnet101-animal-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/animal_recognition_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "cv2",
+                "torchvision",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.animal_recognition_pipeline"
         },
         "('PIPELINES', 'auto-speech-recognition', 'asr-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/asr_inference_pipeline.py",
             "imports": [
-                "typing",
                 "yaml",
                 "os",
+                "typing",
                 "json"
             ],
             "module": "modelscope.pipelines.audio.asr_inference_pipeline"
         },
         "('PIPELINES', 'auto-speech-recognition', 'asr-wenet-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/asr_wenet_inference_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.audio.asr_wenet_inference_pipeline"
         },
         "('PIPELINES', 'auto-speech-recognition', 'ofa-asr')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/asr_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.asr_pipeline"
         },
         "('PIPELINES', 'bad-image-detecting', 'bad-image-detecting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/bad_image_detecting_pipeline.py",
             "imports": [
                 "numpy",
@@ -5860,47 +5957,65 @@
                 "torch"
             ],
             "module": "modelscope.pipelines.cv.bad_image_detecting_pipeline"
         },
         "('PIPELINES', 'body-2d-keypoints', 'hrnetv2w32_body-2d-keypoints_image')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/body_2d_keypoints_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
                 "cv2",
-                "json"
+                "torchvision",
+                "json",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.body_2d_keypoints_pipeline"
         },
         "('PIPELINES', 'body-3d-keypoints', 'canonical_body-3d-keypoints_video')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/body_3d_keypoints_pipeline.py",
             "imports": [
                 "os",
+                "mpl_toolkits",
                 "torch",
                 "tempfile",
-                "mpl_toolkits",
-                "numpy",
-                "matplotlib",
                 "datetime",
+                "cv2",
+                "matplotlib",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.body_3d_keypoints_pipeline"
         },
         "('PIPELINES', 'card-detection', 'resnet-card-detection-scrfd34gkps')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/card_detection_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.card_detection_pipeline"
         },
+        "('PIPELINES', 'chat', 'chatglm2_6b-text-generation')": {
+            "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
+            "imports": [
+                "os",
+                "typing",
+                "torch"
+            ],
+            "module": "modelscope.pipelines.nlp.text_generation_pipeline"
+        },
+        "('PIPELINES', 'chat', 'chatglm6b-text-generation')": {
+            "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
+            "imports": [
+                "os",
+                "typing",
+                "torch"
+            ],
+            "module": "modelscope.pipelines.nlp.text_generation_pipeline"
+        },
         "('PIPELINES', 'code-generation', 'codegeex-code-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/codegeex_code_generation_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.codegeex_code_generation_pipeline"
         },
@@ -5910,322 +6025,322 @@
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.codegeex_code_translation_pipeline"
         },
         "('PIPELINES', 'competency-aware-translation', 'canmt-translation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/canmt_translation_pipeline.py",
             "imports": [
-                "typing",
                 "os",
-                "sacremoses",
-                "torch"
+                "typing",
+                "torch",
+                "sacremoses"
             ],
             "module": "modelscope.pipelines.nlp.canmt_translation_pipeline"
         },
         "('PIPELINES', 'controllable-image-generation', 'controllable-image-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/controllable_image_generation_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "tempfile",
-                "numpy",
                 "subprocess",
-                "typing",
+                "tempfile",
                 "cv2",
-                "glob"
+                "typing",
+                "numpy",
+                "glob",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.controllable_image_generation_pipeline"
         },
         "('PIPELINES', 'crowd-counting', 'hrnet-crowd-counting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/crowd_counting_pipeline.py",
             "imports": [
-                "torchvision",
                 "torch",
+                "PIL",
+                "torchvision",
                 "math",
-                "numpy",
                 "typing",
-                "PIL"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.crowd_counting_pipeline"
         },
         "('PIPELINES', 'default', 'DefaultFormatBundleV2')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py",
             "imports": [
                 "numpy",
-                "mmdet",
+                "mmcv",
                 "torch",
-                "mmcv"
+                "mmdet"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.formating"
         },
         "('PIPELINES', 'default', 'LoadAnnotationsV2')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py",
             "imports": [
-                "numpy",
+                "mmdet",
                 "os",
                 "pycocotools",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.loading"
         },
         "('PIPELINES', 'default', 'LoadMultiViewImageFromMultiSweepsFiles')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py",
             "imports": [
                 "numpy",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.loading"
         },
         "('PIPELINES', 'default', 'NormalizeMultiviewImage')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py",
             "imports": [
-                "PIL",
-                "mmdet3d",
-                "copy",
                 "torch",
-                "mmcv",
+                "mmdet3d",
                 "numpy",
-                "mmdet"
+                "PIL",
+                "mmcv",
+                "mmdet",
+                "copy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.transform_3d"
         },
         "('PIPELINES', 'default', 'PadMultiViewImage')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py",
             "imports": [
-                "PIL",
-                "mmdet3d",
-                "copy",
                 "torch",
-                "mmcv",
+                "mmdet3d",
                 "numpy",
-                "mmdet"
+                "PIL",
+                "mmcv",
+                "mmdet",
+                "copy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.transform_3d"
         },
         "('PIPELINES', 'default', 'RandomFlipV2')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py",
             "imports": [
                 "numpy",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.transforms"
         },
         "('PIPELINES', 'default', 'RandomSquareCrop')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py",
             "imports": [
                 "numpy",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.transforms"
         },
         "('PIPELINES', 'default', 'ResizeCropFlipImage')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py",
             "imports": [
-                "PIL",
-                "mmdet3d",
-                "copy",
                 "torch",
-                "mmcv",
+                "mmdet3d",
                 "numpy",
-                "mmdet"
+                "PIL",
+                "mmcv",
+                "mmdet",
+                "copy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.transform_3d"
         },
         "('PIPELINES', 'default', 'ResizeToMultiple')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py",
             "imports": [
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.vit_adapter.utils.data_process_func"
         },
         "('PIPELINES', 'default', 'ResizeV2')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py",
             "imports": [
                 "numpy",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.transforms"
         },
         "('PIPELINES', 'default', 'RotateV2')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py",
             "imports": [
-                "cv2",
                 "copy",
-                "mmcv",
                 "numpy",
-                "mmdet"
+                "mmcv",
+                "mmdet",
+                "cv2"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.auto_augment"
         },
         "('PIPELINES', 'document-grounded-dialog-generate', 'document-grounded-dialog-generate')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_generate_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.document_grounded_dialog_generate_pipeline"
         },
         "('PIPELINES', 'document-grounded-dialog-rerank', 'document-grounded-dialog-rerank')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "collections",
                 "pprint",
-                "sys",
-                "numpy",
-                "transformers",
-                "typing",
                 "time",
+                "ujson",
+                "typing",
+                "numpy",
+                "sys",
+                "collections",
+                "re",
                 "random",
-                "ujson"
+                "transformers"
             ],
             "module": "modelscope.pipelines.nlp.document_grounded_dialog_rerank_pipeline"
         },
         "('PIPELINES', 'document-grounded-dialog-retrieval', 'document-grounded-dialog-retrieval')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py",
             "imports": [
-                "faiss",
                 "os",
-                "numpy",
+                "faiss",
+                "json",
                 "typing",
-                "json"
+                "numpy"
             ],
             "module": "modelscope.pipelines.nlp.document_grounded_dialog_retrieval_pipeline"
         },
         "('PIPELINES', 'document-segmentation', 'document-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/document_segmentation_pipeline.py",
             "imports": [
-                "re",
                 "torch",
-                "numpy",
                 "typing",
-                "datasets"
+                "numpy",
+                "datasets",
+                "re"
             ],
             "module": "modelscope.pipelines.nlp.document_segmentation_pipeline"
         },
         "('PIPELINES', 'document-vl-embedding', 'document-vl-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/document_vl_embedding_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.document_vl_embedding_pipeline"
         },
         "('PIPELINES', 'domain-specific-object-detection', 'tinynas-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/tinynas_detection_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.tinynas_detection_pipeline"
         },
         "('PIPELINES', 'efficient-diffusion-tuning', 'efficient-diffusion-tuning')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py",
             "imports": [
-                "torchvision",
                 "torch",
-                "numpy",
+                "cv2",
+                "torchvision",
                 "typing",
-                "PIL",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.multi_modal.efficient_diffusion_tuning_pipeline"
         },
         "('PIPELINES', 'extractive-summarization', 'extractive-summarization')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/extractive_summarization_pipeline.py",
             "imports": [
-                "re",
                 "torch",
-                "numpy",
                 "typing",
-                "datasets"
+                "numpy",
+                "datasets",
+                "re"
             ],
             "module": "modelscope.pipelines.nlp.extractive_summarization_pipeline"
         },
         "('PIPELINES', 'face-2d-keypoints', 'manual-facial-landmark-confidence-flcm')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/facial_landmark_confidence_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.facial_landmark_confidence_pipeline"
         },
         "('PIPELINES', 'face-attribute-recognition', 'resnet34-face-attribute-recognition-fairface')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_attribute_recognition_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.face_attribute_recognition_pipeline"
         },
         "('PIPELINES', 'face-detection', 'manual-face-detection-mtcnn')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/mtcnn_face_detection_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.pipelines.cv.mtcnn_face_detection_pipeline"
         },
         "('PIPELINES', 'face-detection', 'manual-face-detection-ulfd')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/ulfd_face_detection_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.ulfd_face_detection_pipeline"
         },
         "('PIPELINES', 'face-detection', 'resnet-face-detection-scrfd10gkps')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_detection_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.face_detection_pipeline"
         },
         "('PIPELINES', 'face-detection', 'resnet101-face-detection-cvpr22papermogface')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/mog_face_detection_pipeline.py",
             "imports": [
-                "numpy",
                 "os",
-                "typing"
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.mog_face_detection_pipeline"
         },
         "('PIPELINES', 'face-detection', 'resnet50-face-detection-retinaface')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/retina_face_detection_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.retina_face_detection_pipeline"
         },
         "('PIPELINES', 'face-emotion', 'face-emotion')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_emotion_pipeline.py",
             "imports": [
                 "numpy",
@@ -6242,186 +6357,186 @@
             "module": "modelscope.pipelines.cv.face_human_hand_detection_pipeline"
         },
         "('PIPELINES', 'face-image-generation', 'gan-face-image-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_image_generation_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.face_image_generation_pipeline"
         },
         "('PIPELINES', 'face-liveness', 'manual-face-liveness-flir')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_liveness_ir_pipeline.py",
             "imports": [
                 "os",
-                "onnxruntime",
                 "torch",
+                "cv2",
+                "typing",
                 "numpy",
                 "PIL",
-                "typing",
-                "cv2"
+                "onnxruntime"
             ],
             "module": "modelscope.pipelines.cv.face_liveness_ir_pipeline"
         },
         "('PIPELINES', 'face-liveness', 'manual-face-liveness-flxc')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_liveness_xc_pipeline.py",
             "imports": [
                 "os",
-                "onnxruntime",
                 "torch",
+                "cv2",
+                "typing",
                 "numpy",
                 "PIL",
-                "typing",
-                "cv2"
+                "onnxruntime"
             ],
             "module": "modelscope.pipelines.cv.face_liveness_xc_pipeline"
         },
         "('PIPELINES', 'face-quality-assessment', 'manual-face-quality-assessment-fqa')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_quality_assessment_pipeline.py",
             "imports": [
                 "os",
-                "onnxruntime",
                 "torch",
+                "cv2",
+                "typing",
                 "numpy",
                 "PIL",
-                "typing",
-                "cv2"
+                "onnxruntime"
             ],
             "module": "modelscope.pipelines.cv.face_quality_assessment_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'ir-face-recognition-rts')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_recognition_ood_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.face_recognition_ood_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'ir101-face-recognition-cfglint')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_recognition_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.face_recognition_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'ir50-face-recognition-arcface')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/arc_face_recognition_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.arc_face_recognition_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'manual-face-recognition-frfm')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_fm_pipeline.py",
             "imports": [
                 "os",
-                "onnxruntime",
                 "torch",
+                "cv2",
+                "typing",
                 "numpy",
                 "PIL",
-                "typing",
-                "cv2"
+                "onnxruntime"
             ],
             "module": "modelscope.pipelines.cv.face_recognition_onnx_fm_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'manual-face-recognition-frir')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_ir_pipeline.py",
             "imports": [
                 "os",
-                "onnxruntime",
                 "torch",
+                "cv2",
+                "typing",
                 "numpy",
                 "PIL",
-                "typing",
-                "cv2"
+                "onnxruntime"
             ],
             "module": "modelscope.pipelines.cv.face_recognition_onnx_ir_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'resnet-face-recognition-facemask')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/mask_face_recognition_pipeline.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
+                "cv2",
+                "typing",
                 "numpy",
                 "PIL",
-                "typing",
-                "cv2"
+                "collections"
             ],
             "module": "modelscope.pipelines.cv.mask_face_recognition_pipeline"
         },
         "('PIPELINES', 'face-reconstruction', 'resnet50-face-reconstruction')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_reconstruction_pipeline.py",
             "imports": [
                 "os",
-                "face_alignment",
                 "torch",
-                "numpy",
-                "shutil",
                 "scipy",
                 "PIL",
-                "typing",
                 "cv2",
+                "face_alignment",
+                "typing",
+                "io",
                 "tensorflow",
-                "io"
+                "shutil",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_reconstruction_pipeline"
         },
         "('PIPELINES', 'facial-expression-recognition', 'vgg19-facial-expression-recognition-fer')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/facial_expression_recognition_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.facial_expression_recognition_pipeline"
         },
         "('PIPELINES', 'faq-question-answering', 'faq-question-answering')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/faq_question_answering_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.faq_question_answering_pipeline"
         },
         "('PIPELINES', 'feature-extraction', 'feature-extraction')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/feature_extraction_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.pipelines.nlp.feature_extraction_pipeline"
         },
         "('PIPELINES', 'fid-dialogue', 'fid-dialogue')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/fid_dialogue_pipeline.py",
             "imports": [
+                "torch",
                 "typing",
-                "re",
-                "torch"
+                "re"
             ],
             "module": "modelscope.pipelines.nlp.fid_dialogue_pipeline"
         },
         "('PIPELINES', 'fill-mask', 'fill-mask')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/fill_mask_pipeline.py",
             "imports": [
                 "numpy",
@@ -6436,21 +6551,21 @@
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.fill_mask_pipeline"
         },
         "('PIPELINES', 'general-recognition', 'resnet101-general-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/general_recognition_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "cv2",
+                "torchvision",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.general_recognition_pipeline"
         },
         "('PIPELINES', 'generative-multi-modal-embedding', 'generative-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py",
             "imports": [
                 "typing"
@@ -6474,18 +6589,18 @@
             "module": "modelscope.pipelines.cv.image_detection_pipeline"
         },
         "('PIPELINES', 'human-reconstruction', 'human-reconstruction')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/human_reconstruction_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "typing",
                 "shutil",
-                "trimesh",
-                "typing"
+                "numpy",
+                "trimesh"
             ],
             "module": "modelscope.pipelines.cv.human_reconstruction_pipeline"
         },
         "('PIPELINES', 'image-body-reshaping', 'flow-based-body-reshaping')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_body_reshaping_pipeline.py",
             "imports": [
                 "typing"
@@ -6545,20 +6660,20 @@
                 "torch"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'image-structured-model-probing')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_structured_model_probing_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "math",
-                "numpy",
+                "torchvision",
                 "typing",
+                "numpy",
+                "math",
                 "mmcv"
             ],
             "module": "modelscope.pipelines.cv.image_structured_model_probing_pipeline"
         },
         "('PIPELINES', 'image-classification', 'nextvit-small_image-classification_Dailylife-labels')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py",
             "imports": [
@@ -6567,32 +6682,32 @@
                 "torch"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'resnet50-image-classification-cc')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/content_check_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
                 "PIL",
+                "cv2",
+                "torchvision",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.content_check_pipeline"
         },
         "('PIPELINES', 'image-classification', 'tinynas-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/tinynas_classification_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "math",
-                "typing"
+                "torchvision",
+                "typing",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.tinynas_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'vit-base_image-classification_Dailylife-labels')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py",
             "imports": [
                 "numpy",
@@ -6609,189 +6724,189 @@
                 "torch"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-color-enhancement', 'adaint-image-color-enhance')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_color_enhance_pipeline.py",
             "imports": [
+                "torch",
                 "typing",
-                "torchvision",
-                "torch"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.image_color_enhance_pipeline"
         },
         "('PIPELINES', 'image-color-enhancement', 'csrnet-image-color-enhance')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_color_enhance_pipeline.py",
             "imports": [
+                "torch",
                 "typing",
-                "torchvision",
-                "torch"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.image_color_enhance_pipeline"
         },
         "('PIPELINES', 'image-color-enhancement', 'deeplpf-image-color-enhance')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_color_enhance_pipeline.py",
             "imports": [
+                "torch",
                 "typing",
-                "torchvision",
-                "torch"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.image_color_enhance_pipeline"
         },
         "('PIPELINES', 'image-colorization', 'ddcolor-image-colorization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/ddcolor_image_colorization_pipeline.py",
             "imports": [
-                "torchvision",
                 "torch",
-                "numpy",
+                "cv2",
+                "torchvision",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.ddcolor_image_colorization_pipeline"
         },
         "('PIPELINES', 'image-colorization', 'unet-image-colorization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_colorization_pipeline.py",
             "imports": [
-                "torchvision",
                 "torch",
-                "numpy",
+                "torchvision",
+                "cv2",
                 "typing",
-                "PIL",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.image_colorization_pipeline"
         },
         "('PIPELINES', 'image-debanding', 'rrdb-image-debanding')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_debanding_pipeline.py",
             "imports": [
+                "torch",
                 "typing",
-                "torchvision",
-                "torch"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.image_debanding_pipeline"
         },
         "('PIPELINES', 'image-deblurring', 'nafnet-image-deblur')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_deblur_pipeline.py",
             "imports": [
+                "torch",
                 "typing",
-                "torchvision",
-                "torch"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.image_deblur_pipeline"
         },
         "('PIPELINES', 'image-demoireing', 'uhdm-image-demoireing')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_restoration_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.image_restoration_pipeline"
         },
         "('PIPELINES', 'image-denoising', 'nafnet-image-denoise')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_denoise_pipeline.py",
             "imports": [
+                "torch",
                 "typing",
-                "torchvision",
-                "torch"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.image_denoise_pipeline"
         },
         "('PIPELINES', 'image-depth-estimation', 'image-bts-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_bts_depth_estimation_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
+                "cv2",
                 "albumentations",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_bts_depth_estimation_pipeline"
         },
         "('PIPELINES', 'image-depth-estimation', 'image-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_depth_estimation_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_depth_estimation_pipeline"
         },
         "('PIPELINES', 'image-driving-perception', 'yolopv2_image-driving-percetion_bdd100k')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_driving_perception_pipeline.py",
             "imports": [
-                "numpy",
-                "cv2",
                 "os",
-                "typing"
+                "typing",
+                "numpy",
+                "cv2"
             ],
             "module": "modelscope.pipelines.cv.image_driving_perception_pipeline"
         },
         "('PIPELINES', 'image-face-fusion', 'image-face-fusion')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_face_fusion_pipeline.py",
             "imports": [
                 "numpy",
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.image_face_fusion_pipeline"
         },
         "('PIPELINES', 'image-fewshot-detection', 'image-fewshot-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_defrcn_fewshot_pipeline.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_defrcn_fewshot_pipeline"
         },
         "('PIPELINES', 'image-inpainting', 'fft-inpainting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_inpainting_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_inpainting_pipeline"
         },
         "('PIPELINES', 'image-inpainting', 'image-inpainting-sdv2')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_inpainting_sdv2_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
                 "tempfile",
-                "sys",
+                "cv2",
+                "typing",
                 "numpy",
                 "diffusers",
-                "typing",
-                "cv2"
+                "math",
+                "sys"
             ],
             "module": "modelscope.pipelines.cv.image_inpainting_sdv2_pipeline"
         },
         "('PIPELINES', 'image-matching', 'image-matching')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_matching_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_matching_pipeline"
         },
         "('PIPELINES', 'image-multi-view-depth-estimation', 'image-multi-view-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_mvs_depth_estimation_pipeline.py",
             "imports": [
-                "tempfile",
-                "shutil",
                 "os",
-                "typing"
+                "typing",
+                "tempfile",
+                "shutil"
             ],
             "module": "modelscope.pipelines.cv.image_mvs_depth_estimation_pipeline"
         },
         "('PIPELINES', 'image-object-detection', 'abnormal-object-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_detection_pipeline.py",
             "imports": [
                 "numpy",
@@ -6800,427 +6915,438 @@
             "module": "modelscope.pipelines.cv.image_detection_pipeline"
         },
         "('PIPELINES', 'image-object-detection', 'tbs-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/tbs_detection_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
                 "cv2",
-                "colorsys"
+                "colorsys",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.tbs_detection_pipeline"
         },
         "('PIPELINES', 'image-object-detection', 'tinynas-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/tinynas_detection_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.tinynas_detection_pipeline"
         },
         "('PIPELINES', 'image-object-detection', 'vidt')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/vidt_pipeline.py",
             "imports": [
+                "torch",
                 "typing",
-                "torchvision",
-                "torch"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.vidt_pipeline"
         },
         "('PIPELINES', 'image-object-detection', 'vit-object-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_detection_pipeline.py",
             "imports": [
                 "numpy",
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.image_detection_pipeline"
         },
         "('PIPELINES', 'image-paintbyexample', 'stablediffusion-paintbyexample')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_paintbyexample_pipeline.py",
             "imports": [
-                "torchvision",
                 "torch",
-                "numpy",
+                "einops",
                 "PIL",
-                "typing",
+                "torchvision",
                 "cv2",
-                "einops"
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_paintbyexample_pipeline"
         },
         "('PIPELINES', 'image-portrait-enhancement', 'gpen-image-portrait-enhancement')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_portrait_enhancement_pipeline.py",
             "imports": [
                 "torch",
-                "math",
-                "numpy",
                 "scipy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.image_portrait_enhancement_pipeline"
         },
         "('PIPELINES', 'image-portrait-stylization', 'unet-person-image-cartoon')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_cartoon_pipeline.py",
             "imports": [
                 "os",
-                "numpy",
-                "typing",
                 "cv2",
-                "tensorflow"
+                "typing",
+                "tensorflow",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_cartoon_pipeline"
         },
         "('PIPELINES', 'image-quality-assessment-degradation', 'image-quality-assessment-degradation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_degradation_pipeline.py",
             "imports": [
-                "torchvision",
                 "torch",
-                "math",
                 "tempfile",
-                "numpy",
+                "cv2",
+                "torchvision",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.image_quality_assessment_degradation_pipeline"
         },
         "('PIPELINES', 'image-quality-assessment-mos', 'image-quality-assessment-man')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_man_pipeline.py",
             "imports": [
-                "torchvision",
                 "torch",
-                "math",
                 "tempfile",
-                "numpy",
+                "cv2",
+                "torchvision",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.image_quality_assessment_man_pipeline"
         },
         "('PIPELINES', 'image-quality-assessment-mos', 'image-quality-assessment-mos')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_mos_pipeline.py",
             "imports": [
-                "torchvision",
                 "torch",
-                "math",
                 "tempfile",
-                "numpy",
+                "cv2",
+                "torchvision",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.image_quality_assessment_mos_pipeline"
         },
         "('PIPELINES', 'image-reid-person', 'passvitb-image-reid-person')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_reid_person_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
+                "torchvision",
                 "math",
                 "typing",
                 "PIL"
             ],
             "module": "modelscope.pipelines.cv.image_reid_person_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'cascade-mask-rcnn-swin-image-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_instance_segmentation_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.image_instance_segmentation_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'fast-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/fast_instance_segmentation_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "torch",
                 "typing",
-                "torch"
+                "numpy",
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.fast_instance_segmentation_pipeline"
         },
+        "('PIPELINES', 'image-segmentation', 'image-panoptic-segmentation')": {
+            "filepath": "TEMPLATE_PATH/pipelines/cv/image_panoptic_segmentation_pipeline.py",
+            "imports": [
+                "torch",
+                "PIL",
+                "cv2",
+                "typing",
+                "numpy"
+            ],
+            "module": "modelscope.pipelines.cv.image_panoptic_segmentation_pipeline"
+        },
         "('PIPELINES', 'image-segmentation', 'image-semantic-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_semantic_segmentation_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_semantic_segmentation_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'm2fp-image-human-parsing')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_human_parsing_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "torch",
                 "typing",
-                "torch"
+                "numpy",
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.image_human_parsing_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'maskdino-swin-image-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/maskdino_instance_segmentation_pipeline.py",
             "imports": [
+                "torch",
                 "typing",
-                "torchvision",
-                "torch"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.maskdino_instance_segmentation_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'vision-middleware-multi-task')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/vision_middleware_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "math",
-                "numpy",
+                "torchvision",
                 "typing",
+                "numpy",
+                "math",
                 "mmcv"
             ],
             "module": "modelscope.pipelines.cv.vision_middleware_pipeline"
         },
         "('PIPELINES', 'image-skychange', 'image-skychange')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_skychange_pipeline.py",
             "imports": [
+                "cv2",
+                "pdb",
+                "typing",
                 "numpy",
                 "PIL",
-                "typing",
-                "cv2",
-                "time",
-                "pdb"
+                "time"
             ],
             "module": "modelscope.pipelines.cv.image_skychange_pipeline"
         },
         "('PIPELINES', 'image-style-transfer', 'AAMS-style-transfer')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_style_transfer_pipeline.py",
             "imports": [
-                "numpy",
-                "cv2",
                 "os",
-                "typing"
+                "typing",
+                "numpy",
+                "cv2"
             ],
             "module": "modelscope.pipelines.cv.image_style_transfer_pipeline"
         },
         "('PIPELINES', 'image-super-resolution', 'mobile-image-super-resolution')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/mobile_image_super_resolution_pipeline.py",
             "imports": [
-                "torchvision",
-                "skimage",
                 "torch",
-                "numpy",
-                "typing"
+                "skimage",
+                "torchvision",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.mobile_image_super_resolution_pipeline"
         },
         "('PIPELINES', 'image-super-resolution', 'rrdb-image-super-resolution')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_super_resolution_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_super_resolution_pipeline"
         },
         "('PIPELINES', 'image-text-retrieval', 'image-text-retrieval')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/image_text_retrieval_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.image_text_retrieval_pipeline"
         },
         "('PIPELINES', 'image-text-retrieval', 'multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/multi_modal_embedding_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.multi_modal_embedding_pipeline"
         },
         "('PIPELINES', 'image-to-image-generation', 'image-to-image-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_to_image_generate_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
                 "PIL",
+                "cv2",
+                "torchvision",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_to_image_generate_pipeline"
         },
         "('PIPELINES', 'image-to-image-translation', 'image-to-image-translation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_to_image_translation_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "sys",
-                "typing",
                 "PIL",
                 "cv2",
-                "io"
+                "torchvision",
+                "typing",
+                "io",
+                "numpy",
+                "sys"
             ],
             "module": "modelscope.pipelines.cv.image_to_image_translation_pipeline"
         },
         "('PIPELINES', 'indoor-layout-estimation', 'indoor-layout-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/indoor_layout_estimation_pipeline.py",
             "imports": [
                 "numpy",
-                "cv2",
-                "typing"
+                "typing",
+                "cv2"
             ],
             "module": "modelscope.pipelines.cv.indoor_layout_estimation_pipeline"
         },
         "('PIPELINES', 'information-extraction', 'relation-extraction')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/information_extraction_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.information_extraction_pipeline"
         },
         "('PIPELINES', 'inverse-text-processing', 'itn-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/inverse_text_processing_pipeline.py",
             "imports": [
-                "typing",
-                "shutil",
+                "yaml",
                 "os",
-                "yaml"
+                "typing",
+                "shutil"
             ],
             "module": "modelscope.pipelines.audio.inverse_text_processing_pipeline"
         },
         "('PIPELINES', 'keyword-spotting', 'kws-kwsbp')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/kws_kwsbp_pipeline.py",
             "imports": [
-                "json",
                 "os",
-                "typing"
+                "typing",
+                "json"
             ],
             "module": "modelscope.pipelines.audio.kws_kwsbp_pipeline"
         },
         "('PIPELINES', 'keyword-spotting', 'speech_dfsmn_kws_char_farfield')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/kws_farfield_pipeline.py",
             "imports": [
                 "wave",
-                "numpy",
                 "typing",
-                "soundfile",
-                "io"
+                "io",
+                "numpy",
+                "soundfile"
             ],
             "module": "modelscope.pipelines.audio.kws_farfield_pipeline"
         },
         "('PIPELINES', 'language-guided-video-summarization', 'clip-it-video-summarization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/language_guided_video_summarization_pipeline.py",
             "imports": [
                 "os",
                 "clip",
                 "torch",
+                "PIL",
                 "tempfile",
+                "cv2",
+                "typing",
                 "shutil",
                 "numpy",
-                "typing",
-                "PIL",
-                "cv2",
                 "random"
             ],
             "module": "modelscope.pipelines.cv.language_guided_video_summarization_pipeline"
         },
         "('PIPELINES', 'language-score-prediction', 'language-score-prediction')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/lm_infer_pipeline.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.pipelines.audio.lm_infer_pipeline"
         },
         "('PIPELINES', 'license-plate-detection', 'resnet18-license-plate-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/license_plate_detection_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "numpy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.license_plate_detection_pipeline"
         },
         "('PIPELINES', 'lineless-table-recognition', 'lore-lineless-table-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/lineless_table_recognition_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "numpy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.lineless_table_recognition_pipeline"
         },
         "('PIPELINES', 'live-category', 'live-category')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/live_category_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
+                "PIL",
                 "decord",
+                "torchvision",
                 "typing",
-                "PIL"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.live_category_pipeline"
         },
         "('PIPELINES', 'motion-generation', 'mdm-motion-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/motion_generation_pipeline.py",
             "imports": [
                 "os",
                 "torch",
                 "tempfile",
-                "numpy",
-                "typing"
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.motion_generation_pipeline"
         },
         "('PIPELINES', 'movie-scene-segmentation', 'resnet50-bert-movie-scene-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/movie_scene_segmentation_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.movie_scene_segmentation_pipeline"
         },
         "('PIPELINES', 'multi-modal-embedding', 'gridvlp-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/gridvlp_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "transformers",
+                "PIL",
                 "traceback",
+                "json",
                 "typing",
-                "PIL",
+                "numpy",
                 "time",
-                "json"
+                "transformers"
             ],
             "module": "modelscope.pipelines.multi_modal.gridvlp_pipeline"
         },
         "('PIPELINES', 'multi-modal-embedding', 'multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/multi_modal_embedding_pipeline.py",
             "imports": [
                 "typing"
@@ -7233,16 +7359,16 @@
                 "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.team_multi_modal_similarity_pipeline"
         },
         "('PIPELINES', 'multimodal-dialogue', 'multimodal-dialogue')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/multimodal_dialogue_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.multimodal_dialogue_pipeline"
         },
         "('PIPELINES', 'named-entity-recognition', 'named-entity-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/named_entity_recognition_pipeline.py",
             "imports": [
                 "typing"
@@ -7280,69 +7406,69 @@
             "module": "modelscope.pipelines.nlp.text_classification_pipeline"
         },
         "('PIPELINES', 'object-detection-3d', 'object-detection-3d-depe')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/object_detection_3d_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "tempfile",
                 "PIL",
+                "tempfile",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.object_detection_3d_pipeline"
         },
         "('PIPELINES', 'ocr-detection', 'resnet18-ocr-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/ocr_detection_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "numpy",
                 "tf_slim",
-                "typing",
                 "cv2",
-                "tensorflow"
+                "math",
+                "typing",
+                "tensorflow",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.ocr_detection_pipeline"
         },
         "('PIPELINES', 'ocr-recognition', 'convnextTiny-ocr-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/ocr_recognition_pipeline.py",
             "imports": [],
             "module": "modelscope.pipelines.cv.ocr_recognition_pipeline"
         },
         "('PIPELINES', 'ocr-recognition', 'ofa-ocr-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/ocr_recognition_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.ocr_recognition_pipeline"
         },
         "('PIPELINES', 'open-vocabulary-detection', 'open-vocabulary-detection-vild')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_open_vocabulary_detection_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.image_open_vocabulary_detection_pipeline"
         },
         "('PIPELINES', 'panorama-depth-estimation', 'panorama-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/panorama_depth_estimation_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.panorama_depth_estimation_pipeline"
         },
         "('PIPELINES', 'part-of-speech', 'part-of-speech')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py",
             "imports": [
                 "numpy",
@@ -7350,56 +7476,56 @@
                 "torch"
             ],
             "module": "modelscope.pipelines.nlp.token_classification_pipeline"
         },
         "('PIPELINES', 'pedestrian-attribute-recognition', 'resnet50_pedestrian-attribute-recognition_image')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/pedestrian_attribute_recognition_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
                 "cv2",
-                "json"
+                "torchvision",
+                "json",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.pedestrian_attribute_recognition_pipeline"
         },
         "('PIPELINES', 'pointcloud-sceneflow-estimation', 'pointcloud-sceneflow-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py",
             "imports": [
-                "numpy",
-                "typing",
                 "torch",
-                "plyfile"
+                "typing",
+                "plyfile",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.pointcloud_sceneflow_estimation_pipeline"
         },
         "('PIPELINES', 'portrait-matting', 'unet-image-matting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_matting_pipeline.py",
             "imports": [
                 "os",
-                "numpy",
-                "typing",
                 "cv2",
-                "tensorflow"
+                "typing",
+                "tensorflow",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_matting_pipeline"
         },
         "('PIPELINES', 'product-retrieval-embedding', 'resnet50-product-retrieval-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/product_retrieval_embedding_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "cv2",
+                "torchvision",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.product_retrieval_embedding_pipeline"
         },
         "('PIPELINES', 'product-segmentation', 'product-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/product_segmentation_pipeline.py",
             "imports": [
                 "numpy",
@@ -7408,61 +7534,61 @@
             "module": "modelscope.pipelines.cv.product_segmentation_pipeline"
         },
         "('PIPELINES', 'protein-structure', 'unifold-protein-structure')": {
             "filepath": "TEMPLATE_PATH/pipelines/science/protein_structure_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
                 "unicore",
+                "json",
                 "typing",
-                "time",
-                "json"
+                "numpy",
+                "time"
             ],
             "module": "modelscope.pipelines.science.protein_structure_pipeline"
         },
         "('PIPELINES', 'punctuation', 'punc-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/punctuation_processing_pipeline.py",
             "imports": [
-                "typing",
-                "shutil",
+                "yaml",
                 "os",
-                "yaml"
+                "typing",
+                "shutil"
             ],
             "module": "modelscope.pipelines.audio.punctuation_processing_pipeline"
         },
         "('PIPELINES', 'referring-video-object-segmentation', 'referring-video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/referring_video_object_segmentation_pipeline.py",
             "imports": [
-                "torchvision",
-                "moviepy",
                 "torch",
+                "einops",
+                "PIL",
                 "tempfile",
-                "numpy",
+                "tqdm",
+                "torchvision",
+                "moviepy",
                 "typing",
-                "PIL",
-                "einops",
-                "tqdm"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.referring_video_object_segmentation_pipeline"
         },
         "('PIPELINES', 'relation-extraction', 'relation-extraction')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/information_extraction_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.information_extraction_pipeline"
         },
         "('PIPELINES', 'semantic-segmentation', 'ddpm-image-semantic-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/ddpm_semantic_segmentation_pipeline.py",
             "imports": [
+                "torch",
                 "typing",
-                "torchvision",
-                "torch"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.ddpm_semantic_segmentation_pipeline"
         },
         "('PIPELINES', 'semantic-segmentation', 'res2net-camouflaged-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_salient_detection_pipeline.py",
             "imports": [
                 "typing"
@@ -7502,17 +7628,17 @@
             "module": "modelscope.pipelines.nlp.text_classification_pipeline"
         },
         "('PIPELINES', 'sentence-similarity', 'translation-quality-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/translation_quality_estimation_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "transformers",
                 "typing",
-                "io"
+                "io",
+                "transformers"
             ],
             "module": "modelscope.pipelines.nlp.translation_quality_estimation_pipeline"
         },
         "('PIPELINES', 'sentiment-classification', 'sentiment-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py",
             "imports": [
                 "numpy",
@@ -7529,163 +7655,179 @@
             "module": "modelscope.pipelines.cv.shop_segmentation_pipleline"
         },
         "('PIPELINES', 'siamese-uie', 'siamese-uie')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/siamese_uie_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
                 "scipy",
-                "typing",
+                "tqdm",
+                "logging",
                 "copy",
-                "time",
-                "pathlib",
                 "json",
-                "logging",
-                "tqdm"
+                "pathlib",
+                "typing",
+                "math",
+                "time"
             ],
             "module": "modelscope.pipelines.nlp.siamese_uie_pipeline"
         },
         "('PIPELINES', 'skin-retouching', 'unet-skin-retouching')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/skin_retouching_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
                 "PIL",
-                "typing",
                 "cv2",
-                "tensorflow"
+                "torchvision",
+                "typing",
+                "tensorflow",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.skin_retouching_pipeline"
         },
+        "('PIPELINES', 'speaker-diarization', 'segmentation-clustering')": {
+            "filepath": "TEMPLATE_PATH/pipelines/audio/segmentation_clustering_pipeline.py",
+            "imports": [
+                "torch",
+                "torchaudio",
+                "typing",
+                "io",
+                "numpy",
+                "soundfile"
+            ],
+            "module": "modelscope.pipelines.audio.segmentation_clustering_pipeline"
+        },
         "('PIPELINES', 'speaker-diarization', 'speaker-change-locating')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_change_locating_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
+                "torchaudio",
                 "typing",
-                "soundfile",
-                "io"
+                "io",
+                "numpy",
+                "soundfile"
             ],
             "module": "modelscope.pipelines.audio.speaker_change_locating_pipeline"
         },
         "('PIPELINES', 'speaker-diarization', 'speaker-diarization-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_diarization_pipeline.py",
             "imports": [
                 "os",
-                "numpy",
-                "shutil",
-                "typing",
+                "yaml",
                 "json",
-                "yaml"
+                "typing",
+                "shutil",
+                "numpy"
             ],
             "module": "modelscope.pipelines.audio.speaker_diarization_pipeline"
         },
         "('PIPELINES', 'speaker-verification', 'speaker-verification')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_verification_light_pipeline.py",
             "imports": [
-                "typing",
-                "soundfile",
+                "os",
                 "torch",
-                "io"
+                "torchaudio",
+                "typing",
+                "io",
+                "numpy",
+                "soundfile"
             ],
             "module": "modelscope.pipelines.audio.speaker_verification_light_pipeline"
         },
         "('PIPELINES', 'speaker-verification', 'speaker-verification-eres2net')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_verification_eres2net_pipeline.py",
             "imports": [
-                "typing",
-                "soundfile",
                 "torch",
-                "io"
+                "typing",
+                "io",
+                "soundfile"
             ],
             "module": "modelscope.pipelines.audio.speaker_verification_eres2net_pipeline"
         },
         "('PIPELINES', 'speaker-verification', 'speaker-verification-rdino')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_verification_rdino_pipeline.py",
             "imports": [
-                "typing",
-                "soundfile",
                 "torch",
-                "io"
+                "typing",
+                "io",
+                "soundfile"
             ],
             "module": "modelscope.pipelines.audio.speaker_verification_rdino_pipeline"
         },
         "('PIPELINES', 'speaker-verification', 'sv-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_verification_pipeline.py",
             "imports": [
-                "typing",
-                "shutil",
+                "yaml",
                 "os",
-                "yaml"
+                "typing",
+                "shutil"
             ],
             "module": "modelscope.pipelines.audio.speaker_verification_pipeline"
         },
         "('PIPELINES', 'speech-separation', 'speech-separation')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/separation_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
                 "typing",
-                "soundfile",
-                "io"
+                "io",
+                "numpy",
+                "soundfile"
             ],
             "module": "modelscope.pipelines.audio.separation_pipeline"
         },
         "('PIPELINES', 'speech-timestamp', 'speech-timestamp-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/timestamp_pipeline.py",
             "imports": [
                 "os",
-                "funasr",
-                "typing",
+                "yaml",
                 "json",
-                "yaml"
+                "typing",
+                "funasr"
             ],
             "module": "modelscope.pipelines.audio.timestamp_pipeline"
         },
         "('PIPELINES', 'sudoku', 'ofa-sudoku')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/sudoku_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.sudoku_pipeline"
         },
         "('PIPELINES', 'table-question-answering', 'conversational-text-to-sql')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/conversational_text_to_sql_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "text2sql_lgesql"
             ],
             "module": "modelscope.pipelines.nlp.conversational_text_to_sql_pipeline"
         },
         "('PIPELINES', 'table-question-answering', 'table-question-answering-pipeline')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/table_question_answering_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "transformers",
+                "json",
                 "typing",
-                "json"
+                "transformers"
             ],
             "module": "modelscope.pipelines.nlp.table_question_answering_pipeline"
         },
         "('PIPELINES', 'table-recognition', 'dla34-table-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/table_recognition_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "numpy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.table_recognition_pipeline"
         },
         "('PIPELINES', 'task-oriented-conversation', 'dialog-intent-prediction')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/dialog_intent_prediction_pipeline.py",
             "imports": [
                 "typing"
@@ -7713,30 +7855,30 @@
                 "typing"
             ],
             "module": "modelscope.pipelines.pipeline_template"
         },
         "('PIPELINES', 'text-classification', 'domain-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/fasttext_text_classification_pipeline.py",
             "imports": [
-                "sentencepiece",
                 "os",
-                "numpy",
                 "fasttext",
-                "typing"
+                "typing",
+                "sentencepiece",
+                "numpy"
             ],
             "module": "modelscope.pipelines.nlp.fasttext_text_classification_pipeline"
         },
         "('PIPELINES', 'text-classification', 'language_identification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/language_identification_pipline.py",
             "imports": [
                 "os",
-                "re",
-                "numpy",
                 "typing",
-                "tensorflow"
+                "tensorflow",
+                "numpy",
+                "re"
             ],
             "module": "modelscope.pipelines.nlp.language_identification_pipline"
         },
         "('PIPELINES', 'text-classification', 'sentence-similarity')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py",
             "imports": [
                 "numpy",
@@ -7787,55 +7929,55 @@
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.text_driven_segmentation_pipleline"
         },
         "('PIPELINES', 'text-error-correction', 'text-error-correction')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_error_correction_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_error_correction_pipeline"
         },
         "('PIPELINES', 'text-generation', 'glm130b-text-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/glm130b_text_generation_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.glm130b_text_generation_pipeline"
         },
         "('PIPELINES', 'text-generation', 'gpt-moe-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/distributed_gpt_moe_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.distributed_gpt_moe_pipeline"
         },
         "('PIPELINES', 'text-generation', 'gpt3-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/distributed_gpt3_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.distributed_gpt3_pipeline"
         },
         "('PIPELINES', 'text-generation', 'plug-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/distributed_plug_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.distributed_plug_pipeline"
         },
         "('PIPELINES', 'text-generation', 'text-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'text-ranking', 'mgeo-ranking')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/mgeo_ranking_pipeline.py",
             "imports": [
@@ -7852,137 +7994,139 @@
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_ranking_pipeline"
         },
         "('PIPELINES', 'text-summarization', 'mglm-text-summarization')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/mglm_text_summarization_pipeline.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.mglm_text_summarization_pipeline"
         },
         "('PIPELINES', 'text-summarization', 'text-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/summarization_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.summarization_pipeline"
         },
         "('PIPELINES', 'text-to-image-synthesis', 'chinese-stable-diffusion')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py",
             "imports": [
                 "torch",
-                "numpy",
-                "diffusers",
-                "transformers",
-                "typing",
                 "PIL",
-                "cv2"
+                "cv2",
+                "typing",
+                "diffusers",
+                "numpy",
+                "transformers"
             ],
             "module": "modelscope.pipelines.multi_modal.diffusers_wrapped.stable_diffusion.chinese_stable_diffusion_pipeline"
         },
         "('PIPELINES', 'text-to-image-synthesis', 'diffusers-stable-diffusion')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py",
             "imports": [
+                "os",
                 "torch",
-                "numpy",
-                "diffusers",
                 "PIL",
+                "torchvision",
+                "cv2",
                 "typing",
-                "cv2"
+                "diffusers",
+                "numpy"
             ],
             "module": "modelscope.pipelines.multi_modal.diffusers_wrapped.stable_diffusion.stable_diffusion_pipeline"
         },
         "('PIPELINES', 'text-to-image-synthesis', 'disco_guided_diffusion')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py",
             "imports": [
-                "torchvision",
-                "clip",
                 "os",
+                "clip",
                 "torch",
-                "math",
-                "numpy",
-                "importlib",
                 "PIL",
+                "gc",
                 "cv2",
+                "torchvision",
                 "json",
-                "gc"
+                "importlib",
+                "numpy",
+                "math"
             ],
             "module": "modelscope.pipelines.multi_modal.disco_guided_diffusion_pipeline.disco_guided_diffusion"
         },
         "('PIPELINES', 'text-to-image-synthesis', 'text-to-image-synthesis')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/text_to_image_synthesis_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.text_to_image_synthesis_pipeline"
         },
         "('PIPELINES', 'text-to-speech', 'sambert-hifigan-tts')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/text_to_speech_pipeline.py",
             "imports": [
                 "numpy",
                 "typing"
             ],
             "module": "modelscope.pipelines.audio.text_to_speech_pipeline"
         },
         "('PIPELINES', 'text-to-video-synthesis', 'latent-text-to-video-synthesis')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/text_to_video_synthesis_pipeline.py",
             "imports": [
+                "einops",
                 "os",
                 "torch",
                 "tempfile",
-                "typing",
                 "cv2",
-                "einops"
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.text_to_video_synthesis_pipeline"
         },
         "('PIPELINES', 'text2sql', 'ofa-text2sql')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/text2sql_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.text2sql_pipeline"
         },
         "('PIPELINES', 'text2text-generation', 'text2text-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'text2text-generation', 'translation_en_to_de')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'text2text-generation', 'translation_en_to_fr')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'text2text-generation', 'translation_en_to_ro')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'token-classification', 'named-entity-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py",
             "imports": [
@@ -8018,180 +8162,180 @@
                 "torch"
             ],
             "module": "modelscope.pipelines.nlp.token_classification_pipeline"
         },
         "('PIPELINES', 'translation', 'automatic-post-editing')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/automatic_post_editing_pipeline.py",
             "imports": [
-                "sentencepiece",
                 "os",
-                "numpy",
-                "html",
                 "sacremoses",
                 "typing",
                 "tensorflow",
-                "jieba"
+                "sentencepiece",
+                "numpy",
+                "jieba",
+                "html"
             ],
             "module": "modelscope.pipelines.nlp.automatic_post_editing_pipeline"
         },
         "('PIPELINES', 'translation', 'csanmt-translation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/translation_pipeline.py",
             "imports": [
                 "os",
-                "numpy",
                 "subword_nmt",
                 "sacremoses",
                 "typing",
                 "tensorflow",
+                "numpy",
                 "jieba"
             ],
             "module": "modelscope.pipelines.nlp.translation_pipeline"
         },
         "('PIPELINES', 'translation', 'interactive-translation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/interactive_translation_pipeline.py",
             "imports": [
                 "os",
-                "numpy",
                 "subword_nmt",
                 "sacremoses",
                 "typing",
                 "tensorflow",
+                "numpy",
                 "jieba"
             ],
             "module": "modelscope.pipelines.nlp.interactive_translation_pipeline"
         },
         "('PIPELINES', 'translation-evaluation', 'translation-evaluation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/translation_evaluation_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
                 "enum",
-                "typing"
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.nlp.translation_evaluation_pipeline"
         },
         "('PIPELINES', 'universal-matting', 'unet-universal-matting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_matting_pipeline.py",
             "imports": [
                 "os",
-                "numpy",
-                "typing",
                 "cv2",
-                "tensorflow"
+                "typing",
+                "tensorflow",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_matting_pipeline"
         },
         "('PIPELINES', 'video-captioning', 'video-captioning')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/video_captioning_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.video_captioning_pipeline"
         },
         "('PIPELINES', 'video-category', 'video-category')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_category_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
+                "PIL",
                 "decord",
+                "torchvision",
+                "json",
                 "typing",
-                "PIL",
-                "json"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_category_pipeline"
         },
         "('PIPELINES', 'video-colorization', 'video-colorization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_colorization_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "tempfile",
-                "numpy",
                 "subprocess",
                 "PIL",
+                "tempfile",
                 "cv2",
-                "typing"
+                "torchvision",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_colorization_pipeline"
         },
         "('PIPELINES', 'video-deinterlace', 'video-deinterlace')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_deinterlace_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "math",
-                "tempfile",
-                "numpy",
                 "subprocess",
+                "tempfile",
+                "cv2",
+                "torchvision",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.video_deinterlace_pipeline"
         },
         "('PIPELINES', 'video-depth-estimation', 'video-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_depth_estimation_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.video_depth_estimation_pipeline"
         },
         "('PIPELINES', 'video-embedding', 'cmdssl-r2p1d_video_embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/cmdssl_video_embedding_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
+                "PIL",
                 "decord",
+                "torchvision",
                 "typing",
-                "PIL"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.cmdssl_video_embedding_pipeline"
         },
         "('PIPELINES', 'video-embedding', 'hicossl-s3dg-video_embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/hicossl_video_embedding_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "math"
             ],
             "module": "modelscope.pipelines.cv.hicossl_video_embedding_pipeline"
         },
         "('PIPELINES', 'video-frame-interpolation', 'video-frame-interpolation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_frame_interpolation_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "math",
-                "tempfile",
-                "numpy",
                 "subprocess",
-                "typing",
+                "tempfile",
                 "cv2",
-                "glob"
+                "torchvision",
+                "typing",
+                "numpy",
+                "glob",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.video_frame_interpolation_pipeline"
         },
         "('PIPELINES', 'video-human-matting', 'video-human-matting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_human_matting_pipeline.py",
             "imports": [
                 "os",
-                "moviepy",
                 "torch",
-                "numpy",
+                "moviepy",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_human_matting_pipeline"
         },
         "('PIPELINES', 'video-inpainting', 'video-inpainting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_inpainting_pipeline.py",
             "imports": [
                 "typing"
@@ -8199,892 +8343,892 @@
             "module": "modelscope.pipelines.cv.video_inpainting_pipeline"
         },
         "('PIPELINES', 'video-instance-segmentation', 'video-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_instance_segmentation_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "typing",
+                "tqdm",
                 "cv2",
-                "mmcv",
-                "tqdm"
+                "typing",
+                "numpy",
+                "mmcv"
             ],
             "module": "modelscope.pipelines.cv.video_instance_segmentation_pipeline"
         },
         "('PIPELINES', 'video-multi-modal-embedding', 'video-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.video_multi_modal_embedding_pipeline"
         },
         "('PIPELINES', 'video-multi-object-tracking', 'video-multi-object-tracking')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_multi_object_tracking_pipeline.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch"
             ],
             "module": "modelscope.pipelines.cv.video_multi_object_tracking_pipeline"
         },
         "('PIPELINES', 'video-object-detection', 'cspnet_realtime-video-object-detection_streamyolo')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/realtime_video_object_detection_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
                 "cv2",
-                "json"
+                "torchvision",
+                "json",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.realtime_video_object_detection_pipeline"
         },
         "('PIPELINES', 'video-object-segmentation', 'video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_object_segmentation_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
                 "PIL",
-                "typing"
+                "torchvision",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_object_segmentation_pipeline"
         },
         "('PIPELINES', 'video-panoptic-segmentation', 'video-panoptic-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_panoptic_segmentation_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "typing",
+                "tqdm",
                 "cv2",
-                "mmcv",
-                "tqdm"
+                "typing",
+                "numpy",
+                "mmcv"
             ],
             "module": "modelscope.pipelines.cv.video_panoptic_segmentation_pipeline"
         },
         "('PIPELINES', 'video-question-answering', 'video-question-answering')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/video_question_answering_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.video_question_answering_pipeline"
         },
         "('PIPELINES', 'video-single-object-tracking', 'ostrack-vitb-video-single-object-tracking')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_single_object_tracking_pipeline.py",
             "imports": [
+                "os",
                 "typing",
-                "cv2",
-                "os"
+                "cv2"
             ],
             "module": "modelscope.pipelines.cv.video_single_object_tracking_pipeline"
         },
         "('PIPELINES', 'video-single-object-tracking', 'procontext-vitb-video-single-object-tracking')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_single_object_tracking_pipeline.py",
             "imports": [
+                "os",
                 "typing",
-                "cv2",
-                "os"
+                "cv2"
             ],
             "module": "modelscope.pipelines.cv.video_single_object_tracking_pipeline"
         },
         "('PIPELINES', 'video-stabilization', 'video-stabilization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_stabilization_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "tempfile",
-                "numpy",
                 "subprocess",
-                "typing",
+                "tempfile",
                 "cv2",
-                "glob"
+                "typing",
+                "numpy",
+                "glob",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.video_stabilization_pipeline"
         },
         "('PIPELINES', 'video-summarization', 'googlenet_pgl_video_summarization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_summarization_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "typing",
+                "tqdm",
                 "cv2",
-                "tqdm"
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_summarization_pipeline"
         },
         "('PIPELINES', 'video-super-resolution', 'realbasicvsr-video-super-resolution')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_super_resolution_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "math",
-                "tempfile",
-                "numpy",
                 "subprocess",
+                "tempfile",
+                "cv2",
+                "torchvision",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.pipelines.cv.video_super_resolution_pipeline"
         },
         "('PIPELINES', 'video-temporal-grounding', 'soonet-video-temporal-grounding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing"
+                "torchvision",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.multi_modal.soonet_video_temporal_grounding_pipeline"
         },
         "('PIPELINES', 'video-text-retrieval', 'vop-video-text-retrieval')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/vop_retrieval_pipeline.py",
             "imports": [
+                "gzip",
                 "os",
-                "collections",
                 "torch",
-                "math",
-                "numpy",
-                "gzip",
+                "tqdm",
                 "typing",
+                "numpy",
+                "math",
                 "pickle",
-                "random",
-                "tqdm"
+                "collections",
+                "random"
             ],
             "module": "modelscope.pipelines.cv.vop_retrieval_pipeline"
         },
         "('PIPELINES', 'video-text-retrieval', 'vop-video-text-retrieval-se')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/vop_retrieval_se_pipeline.py",
             "imports": [
+                "gzip",
                 "os",
                 "torch",
-                "numpy",
-                "gzip",
-                "typing"
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.vop_retrieval_se_pipeline"
         },
         "('PIPELINES', 'virtual-try-on', 'virtual-try-on')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/virtual_try_on_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.pipelines.cv.virtual_try_on_pipeline"
         },
         "('PIPELINES', 'vision-efficient-tuning', 'vision-efficient-tuning')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/vision_efficient_tuning_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "torch",
                 "typing",
-                "torch"
+                "numpy",
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.vision_efficient_tuning_pipeline"
         },
         "('PIPELINES', 'visual-entailment', 'visual-entailment')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/visual_entailment_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.visual_entailment_pipeline"
         },
         "('PIPELINES', 'visual-grounding', 'visual-grounding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/visual_grounding_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.visual_grounding_pipeline"
         },
         "('PIPELINES', 'visual-question-answering', 'gridvlp-multi-modal-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/gridvlp_pipeline.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "transformers",
+                "PIL",
                 "traceback",
+                "json",
                 "typing",
-                "PIL",
+                "numpy",
                 "time",
-                "json"
+                "transformers"
             ],
             "module": "modelscope.pipelines.multi_modal.gridvlp_pipeline"
         },
         "('PIPELINES', 'visual-question-answering', 'visual-question-answering')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/visual_question_answering_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.visual_question_answering_pipeline"
         },
         "('PIPELINES', 'voice-activity-detection', 'vad-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/voice_activity_detection_pipeline.py",
             "imports": [
                 "os",
-                "funasr",
-                "typing",
+                "yaml",
                 "json",
-                "yaml"
+                "typing",
+                "funasr"
             ],
             "module": "modelscope.pipelines.audio.voice_activity_detection_pipeline"
         },
         "('PIPELINES', 'word-alignment', 'word-alignment')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/word_alignment_pipeline.py",
             "imports": [
                 "numpy",
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.word_alignment_pipeline"
         },
         "('PIPELINES', 'word-segmentation', 'multilingual-word-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/word_segmentation_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.word_segmentation_pipeline"
         },
         "('PIPELINES', 'word-segmentation', 'word-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/word_segmentation_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.word_segmentation_pipeline"
         },
         "('PIPELINES', 'word-segmentation', 'word-segmentation-thai')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/word_segmentation_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.word_segmentation_pipeline"
         },
         "('PIPELINES', 'zero-shot-classification', 'zero-shot-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/zero_shot_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "scipy"
             ],
             "module": "modelscope.pipelines.nlp.zero_shot_classification_pipeline"
         },
         "('POSITIONAL_ENCODING', 'default', 'SinePositionalEncoding3D')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py",
             "imports": [
-                "torch",
                 "math",
-                "mmcv"
+                "mmcv",
+                "torch"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.positional_encoding"
         },
         "('PREPROCESSORS', 'audio', 'LinearAECAndFbank')": {
             "filepath": "TEMPLATE_PATH/preprocessors/audio.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
                 "scipy",
                 "typing",
-                "io"
+                "io",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.audio"
         },
         "('PREPROCESSORS', 'audio', 'wav-to-lists')": {
             "filepath": "TEMPLATE_PATH/preprocessors/kws.py",
             "imports": [
-                "typing",
+                "yaml",
                 "os",
-                "yaml"
+                "typing"
             ],
             "module": "modelscope.preprocessors.kws"
         },
         "('PREPROCESSORS', 'audio', 'wav-to-scp')": {
             "filepath": "TEMPLATE_PATH/preprocessors/asr.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.preprocessors.asr"
         },
         "('PREPROCESSORS', 'cv', 'CenterCrop')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "torchvision",
+                "cv2",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'ImageToTensor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "torchvision",
+                "cv2",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'Normalize')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "torchvision",
+                "cv2",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'RandomCrop')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "torchvision",
+                "cv2",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'RandomHorizontalFlip')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "torchvision",
+                "cv2",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'RandomResizedCrop')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "torchvision",
+                "cv2",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'Resize')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "torchvision",
+                "cv2",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'bad-image-detecting-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/bad_image_detecting_preprocessor.py",
             "imports": [
-                "torchvision",
                 "torch",
+                "PIL",
+                "torchvision",
                 "math",
-                "numpy",
                 "typing",
-                "PIL"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.bad_image_detecting_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'controllable-image-generation-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/controllable_image_generation.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "math",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "cv2",
+                "torchvision",
+                "typing",
+                "numpy",
+                "math"
             ],
             "module": "modelscope.preprocessors.cv.controllable_image_generation"
         },
         "('PREPROCESSORS', 'cv', 'image-classification-bypass-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "PIL",
-                "typing",
                 "cv2",
-                "io"
+                "typing",
+                "io",
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-classification-mmcv-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/mmcls_preprocessor.py",
             "imports": [
-                "numpy",
                 "os",
-                "typing"
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.mmcls_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'image-classification-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "torchvision",
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "PIL",
-                "cv2"
+                "torchvision",
+                "cv2",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'image-color-enhance-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "PIL",
-                "typing",
                 "cv2",
-                "io"
+                "typing",
+                "io",
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-deblur-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "PIL",
-                "typing",
                 "cv2",
-                "io"
+                "typing",
+                "io",
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-demoire-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_restoration_preprocessor.py",
             "imports": [
-                "torchvision",
                 "torch",
+                "PIL",
+                "torchvision",
                 "math",
-                "numpy",
                 "typing",
-                "PIL"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_restoration_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'image-denoise-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "PIL",
-                "typing",
                 "cv2",
-                "io"
+                "typing",
+                "io",
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-driving-perception-preprocessor')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_driving_perception/preprocessor.py",
             "imports": [
-                "numpy",
-                "cv2",
+                "torch",
                 "typing",
-                "torch"
+                "numpy",
+                "cv2"
             ],
             "module": "modelscope.models.cv.image_driving_perception.preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'image-instance-segmentation-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "PIL",
-                "typing",
                 "cv2",
-                "io"
+                "typing",
+                "io",
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-portrait-enhancement-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "PIL",
-                "typing",
                 "cv2",
-                "io"
+                "typing",
+                "io",
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-quality_assessment-man-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_man.py",
             "imports": [
-                "torchvision",
                 "torch",
+                "PIL",
+                "torchvision",
                 "math",
-                "numpy",
                 "typing",
-                "PIL"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_quality_assessment_man"
         },
         "('PREPROCESSORS', 'cv', 'image-quality_assessment-mos-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_mos.py",
             "imports": [
+                "cv2",
                 "torchvision",
-                "math",
-                "numpy",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.preprocessors.cv.image_quality_assessment_mos"
         },
         "('PREPROCESSORS', 'cv', 'image-sky-change-preprocessor')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_skychange/preprocessor.py",
             "imports": [
-                "torchvision",
                 "torch",
-                "numpy",
-                "typing",
                 "cv2",
+                "torchvision",
+                "pdb",
                 "json",
-                "numbers",
-                "pdb"
+                "typing",
+                "numpy",
+                "numbers"
             ],
             "module": "modelscope.models.cv.image_skychange.preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'load-image')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "PIL",
-                "typing",
                 "cv2",
-                "io"
+                "typing",
+                "io",
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'movie-scene-segmentation-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/video.py",
             "imports": [
-                "torchvision",
                 "os",
-                "urllib",
                 "torch",
-                "math",
-                "numpy",
                 "tempfile",
-                "decord",
                 "uuid",
+                "decord",
+                "torchvision",
+                "urllib",
+                "numpy",
+                "math",
                 "random"
             ],
             "module": "modelscope.preprocessors.video"
         },
         "('PREPROCESSORS', 'cv', 'nerf-recon-acc-preprocessor')": {
             "filepath": "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_preprocess.py",
             "imports": [
                 "os",
-                "numpy",
                 "subprocess",
-                "typing",
                 "cv2",
+                "typing",
                 "tensorflow",
-                "glob"
+                "glob",
+                "numpy"
             ],
             "module": "modelscope.models.cv.nerf_recon_acc.nerf_preprocess"
         },
         "('PREPROCESSORS', 'cv', 'object-detection-scrfd')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/preprocessor.py",
             "imports": [
                 "numpy",
-                "PIL",
-                "typing"
+                "typing",
+                "PIL"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'object-detection-tinynas-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "PIL",
-                "typing",
                 "cv2",
-                "io"
+                "typing",
+                "io",
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'ocr-detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/ocr_detection/preprocessor.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "numpy",
                 "PIL",
+                "cv2",
                 "typing",
-                "cv2"
+                "numpy",
+                "math"
             ],
             "module": "modelscope.models.cv.ocr_detection.preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'ocr-recognition')": {
             "filepath": "TEMPLATE_PATH/models/cv/ocr_recognition/preprocessor.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
                 "PIL",
-                "cv2"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.models.cv.ocr_recognition.preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'video-summarization-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "PIL",
-                "typing",
                 "cv2",
-                "io"
+                "typing",
+                "io",
+                "numpy",
+                "PIL"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'default', 'Compose')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "collections",
                 "torch",
-                "numpy",
                 "typing",
-                "time"
+                "numpy",
+                "time",
+                "collections"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'default', 'Filter')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "collections",
                 "torch",
-                "numpy",
                 "typing",
-                "time"
+                "numpy",
+                "time",
+                "collections"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'default', 'Identity')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "collections",
                 "torch",
-                "numpy",
                 "typing",
-                "time"
+                "numpy",
+                "time",
+                "collections"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'default', 'Rename')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "collections",
                 "torch",
-                "numpy",
                 "typing",
-                "time"
+                "numpy",
+                "time",
+                "collections"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'default', 'ToNumpy')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "collections",
                 "torch",
-                "numpy",
                 "typing",
-                "time"
+                "numpy",
+                "time",
+                "collections"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'default', 'ToTensor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "collections",
                 "torch",
-                "numpy",
                 "typing",
-                "time"
+                "numpy",
+                "time",
+                "collections"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'multi-modal', 'clip-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "torchvision",
                 "os",
-                "re",
                 "torch",
-                "numpy",
-                "decord",
-                "timm",
-                "typing",
                 "PIL",
+                "decord",
+                "torchvision",
                 "json",
-                "io"
+                "typing",
+                "io",
+                "timm",
+                "numpy",
+                "re"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'diffusion-image-generation-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "torchvision",
                 "os",
-                "re",
                 "torch",
-                "numpy",
-                "decord",
-                "timm",
-                "typing",
                 "PIL",
+                "decord",
+                "torchvision",
                 "json",
-                "io"
+                "typing",
+                "io",
+                "timm",
+                "numpy",
+                "re"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'hitea-tasks-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "torchvision",
                 "os",
-                "re",
                 "torch",
-                "numpy",
-                "decord",
-                "timm",
-                "typing",
                 "PIL",
+                "decord",
+                "torchvision",
                 "json",
-                "io"
+                "typing",
+                "io",
+                "timm",
+                "numpy",
+                "re"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'image-captioning-clip-interrogator-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "torchvision",
                 "os",
-                "re",
                 "torch",
-                "numpy",
-                "decord",
-                "timm",
-                "typing",
                 "PIL",
+                "decord",
+                "torchvision",
                 "json",
-                "io"
+                "typing",
+                "io",
+                "timm",
+                "numpy",
+                "re"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'mplug-owl-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "torchvision",
                 "os",
-                "re",
                 "torch",
-                "numpy",
-                "decord",
-                "timm",
-                "typing",
                 "PIL",
+                "decord",
+                "torchvision",
                 "json",
-                "io"
+                "typing",
+                "io",
+                "timm",
+                "numpy",
+                "re"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'mplug-tasks-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "torchvision",
                 "os",
-                "re",
                 "torch",
-                "numpy",
-                "decord",
-                "timm",
-                "typing",
                 "PIL",
+                "decord",
+                "torchvision",
                 "json",
-                "io"
+                "typing",
+                "io",
+                "timm",
+                "numpy",
+                "re"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'ofa-tasks-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "torchvision",
                 "os",
-                "re",
                 "torch",
-                "numpy",
-                "decord",
-                "timm",
-                "typing",
                 "PIL",
+                "decord",
+                "torchvision",
                 "json",
-                "io"
+                "typing",
+                "io",
+                "timm",
+                "numpy",
+                "re"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'vldoc-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "torchvision",
                 "os",
-                "re",
                 "torch",
-                "numpy",
-                "decord",
-                "timm",
-                "typing",
                 "PIL",
+                "decord",
+                "torchvision",
                 "json",
-                "io"
+                "typing",
+                "io",
+                "timm",
+                "numpy",
+                "re"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'nlp', 'Tokenize')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/bert_seq_cls_tokenizer.py",
             "imports": [
                 "typing",
@@ -9113,79 +9257,79 @@
             "module": "modelscope.preprocessors.nlp.canmt_translation"
         },
         "('PREPROCESSORS', 'nlp', 'conversational-text-to-sql')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py",
             "imports": [
                 "os",
                 "torch",
-                "text2sql_lgesql",
+                "json",
                 "typing",
-                "json"
+                "text2sql_lgesql"
             ],
             "module": "modelscope.preprocessors.nlp.space_T_en.conversational_text_to_sql_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'dialog-intent-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py",
             "imports": [
-                "json",
                 "os",
-                "typing"
+                "typing",
+                "json"
             ],
             "module": "modelscope.preprocessors.nlp.space.dialog_intent_prediction_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'dialog-modeling-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/space/dialog_modeling_preprocessor.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.space.dialog_modeling_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'dialog-state-tracking-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.preprocessors.nlp.space.dialog_state_tracking_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'dialog-use-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/dialog_classification_use_preprocessor.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.preprocessors.nlp.dialog_classification_use_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'document-grounded-dialog-generate')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "transformers"
             ],
             "module": "modelscope.preprocessors.nlp.document_grounded_dialog_generate_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'document-grounded-dialog-rerank')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py",
             "imports": [
                 "os",
                 "torch",
-                "transformers",
+                "copy",
                 "typing",
-                "copy"
+                "transformers"
             ],
             "module": "modelscope.preprocessors.nlp.document_grounded_dialog_rerank_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'document-grounded-dialog-retrieval')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "transformers"
             ],
             "module": "modelscope.preprocessors.nlp.document_grounded_dialog_retrieval_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'document-segmentation')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/document_segmentation_preprocessor.py",
@@ -9193,16 +9337,16 @@
                 "typing"
             ],
             "module": "modelscope.preprocessors.nlp.document_segmentation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'faq-question-answering-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/faq_question_answering_preprocessor.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.faq_question_answering_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'feature-extraction')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/feature_extraction_preprocessor.py",
             "imports": [
                 "numpy",
@@ -9210,58 +9354,58 @@
             ],
             "module": "modelscope.preprocessors.nlp.feature_extraction_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'fill-mask')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/fill_mask_preprocessor.py",
             "imports": [
                 "os",
-                "abc",
-                "re",
                 "torch",
+                "abc",
+                "typing",
                 "numpy",
-                "typing"
+                "re"
             ],
             "module": "modelscope.preprocessors.nlp.fill_mask_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'fill-mask-ponet')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/fill_mask_preprocessor.py",
             "imports": [
                 "os",
-                "abc",
-                "re",
                 "torch",
+                "abc",
+                "typing",
                 "numpy",
-                "typing"
+                "re"
             ],
             "module": "modelscope.preprocessors.nlp.fill_mask_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'mgeo-ranking')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/mgeo_ranking_preprocessor.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.preprocessors.nlp.mgeo_ranking_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'mglm-summarization')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/mglm_summarization_preprocessor.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "re"
             ],
             "module": "modelscope.preprocessors.nlp.mglm_summarization_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'ner-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py",
             "imports": [
-                "numpy",
+                "torch",
                 "typing",
-                "torch"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'nli-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_classification_preprocessor.py",
             "imports": [
                 "numpy",
@@ -9299,93 +9443,93 @@
                 "typing"
             ],
             "module": "modelscope.preprocessors.nlp.sentence_embedding_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'sentence-piece')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.text_generation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'sequence-labeling-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py",
             "imports": [
-                "numpy",
+                "torch",
                 "typing",
-                "torch"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'siamese-uie-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/siamese_uie_preprocessor.py",
             "imports": [
                 "typing",
                 "transformers"
             ],
             "module": "modelscope.preprocessors.nlp.siamese_uie_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'table-question-answering-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "transformers"
             ],
             "module": "modelscope.preprocessors.nlp.space_T_cn.table_question_answering_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'text-error-correction')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_error_correction.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "transformers"
             ],
             "module": "modelscope.preprocessors.nlp.text_error_correction"
         },
         "('PREPROCESSORS', 'nlp', 'text-gen-jieba-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.text_generation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'text-gen-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.text_generation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'text-ranking')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_ranking_preprocessor.py",
             "imports": [
                 "typing",
                 "transformers"
             ],
             "module": "modelscope.preprocessors.nlp.text_ranking_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'text2text-gen-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.text_generation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'thai-ner-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_thai_preprocessor.py",
             "imports": [
                 "typing"
@@ -9398,484 +9542,511 @@
                 "typing"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_thai_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'token-cls-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py",
             "imports": [
-                "numpy",
+                "torch",
                 "typing",
-                "torch"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'translation-evaluation-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/translation_evaluation_preprocessor.py",
             "imports": [
-                "typing",
                 "torch",
+                "typing",
                 "transformers"
             ],
             "module": "modelscope.preprocessors.nlp.translation_evaluation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'viet-ner-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_viet_preprocessor.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_viet_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'word-alignment')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/word_alignment_preprocessor.py",
             "imports": [
                 "os",
                 "torch",
                 "itertools",
-                "numpy",
-                "typing"
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.word_alignment_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'word-segment-text-to-label-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py",
             "imports": [
-                "numpy",
+                "torch",
                 "typing",
-                "torch"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'zero-shot-cls-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/zero_shot_classification_preprocessor.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.preprocessors.nlp.zero_shot_classification_preprocessor"
         },
         "('PREPROCESSORS', 'science', 'unifold-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/science/uni_fold.py",
             "imports": [
                 "os",
+                "logging",
+                "ipdb",
+                "requests",
+                "numpy",
                 "re",
+                "random",
+                "pickle",
+                "gzip",
                 "torch",
+                "tqdm",
                 "tarfile",
                 "hashlib",
                 "unittest",
-                "ipdb",
-                "pickle",
-                "tqdm",
-                "numpy",
-                "gzip",
-                "typing",
-                "time",
-                "pathlib",
-                "requests",
-                "random",
                 "json",
-                "logging"
+                "pathlib",
+                "typing",
+                "time"
             ],
             "module": "modelscope.preprocessors.science.uni_fold"
         },
         "('PREPROCESSORS', 'text-to-speech', 'kantts-data-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/tts.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "kantts"
             ],
             "module": "modelscope.preprocessors.tts"
         },
         "('ROI_EXTRACTORS', 'default', 'SingleRoINExtractor')": {
             "filepath": "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py",
             "imports": [
                 "torch",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.abnormal_object_detection.mmdet_ms.roi_head.roi_extractors.single_level_roi_extractor"
         },
         "('TRACKERS', 'default', 'QuasiDenseEmbedTracker')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py",
             "imports": [
                 "torch",
-                "mmdet",
-                "mmcv"
+                "mmcv",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.video_panoptic_segmentation.track.quasi_dense_embed_tracker"
         },
         "('TRAINERS', 'default', 'action-detection')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/action_detection_trainer.py",
             "imports": [
                 "os",
                 "torch",
+                "fvcore",
                 "typing",
-                "detectron2",
-                "fvcore"
+                "detectron2"
             ],
             "module": "modelscope.trainers.cv.action_detection_trainer"
         },
         "('TRAINERS', 'default', 'bert-sentiment-analysis')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/sequence_classification_trainer.py",
             "imports": [
                 "numpy",
-                "typing",
-                "time"
+                "time",
+                "typing"
             ],
             "module": "modelscope.trainers.nlp.sequence_classification_trainer"
         },
         "('TRAINERS', 'default', 'card-detection-scrfd')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/card_detection_scrfd_trainer.py",
             "imports": [],
             "module": "modelscope.trainers.cv.card_detection_scrfd_trainer"
         },
         "('TRAINERS', 'default', 'cartoon-translation')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/cartoon_translation_trainer.py",
             "imports": [
                 "os",
-                "numpy",
+                "tqdm",
+                "packaging",
                 "typing",
                 "tensorflow",
-                "packaging",
-                "tqdm"
+                "numpy"
             ],
             "module": "modelscope.trainers.cv.cartoon_translation_trainer"
         },
         "('TRAINERS', 'default', 'clip-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/clip/clip_trainer.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "math"
             ],
             "module": "modelscope.trainers.multi_modal.clip.clip_trainer"
         },
         "('TRAINERS', 'default', 'csanmt-translation')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/csanmt_translation_trainer.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "time",
                 "tensorflow"
             ],
             "module": "modelscope.trainers.nlp.csanmt_translation_trainer"
         },
         "('TRAINERS', 'default', 'dialog-intent-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/space/dialog_intent_trainer.py",
             "imports": [
-                "numpy",
                 "os",
-                "typing"
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.trainers.nlp.space.dialog_intent_trainer"
         },
         "('TRAINERS', 'default', 'dialog-modeling-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/space/dialog_modeling_trainer.py",
             "imports": [
-                "numpy",
-                "time",
                 "os",
-                "typing"
+                "typing",
+                "time",
+                "numpy"
             ],
             "module": "modelscope.trainers.nlp.space.dialog_modeling_trainer"
         },
         "('TRAINERS', 'default', 'document-grounded-dialog-generate-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_generate_trainer.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
-                "collections",
-                "sacrebleu",
-                "transformers",
                 "rouge",
+                "tqdm",
+                "sacrebleu",
                 "json",
                 "string",
-                "tqdm"
+                "collections",
+                "re",
+                "transformers"
             ],
             "module": "modelscope.trainers.nlp.document_grounded_dialog_generate_trainer"
         },
         "('TRAINERS', 'default', 'document-grounded-dialog-rerank-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_rerank_trainer.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "transformers",
                 "typing",
+                "numpy",
                 "time",
-                "random"
+                "random",
+                "transformers"
             ],
             "module": "modelscope.trainers.nlp.document_grounded_dialog_rerank_trainer"
         },
         "('TRAINERS', 'default', 'document-grounded-dialog-retrieval-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_retrieval_trainer.py",
             "imports": [
-                "faiss",
                 "os",
+                "faiss",
                 "torch",
-                "numpy",
-                "transformers",
+                "tqdm",
                 "json",
-                "tqdm"
+                "numpy",
+                "transformers"
             ],
             "module": "modelscope.trainers.nlp.document_grounded_dialog_retrieval_trainer"
         },
+        "('TRAINERS', 'default', 'dreambooth-diffusion')": {
+            "filepath": "TEMPLATE_PATH/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py",
+            "imports": [
+                "torch",
+                "tqdm",
+                "hashlib",
+                "torchvision",
+                "itertools",
+                "warnings",
+                "pathlib",
+                "typing",
+                "shutil",
+                "diffusers",
+                "PIL",
+                "collections"
+            ],
+            "module": "modelscope.trainers.multi_modal.dreambooth_diffusion.dreambooth_diffusion_trainer"
+        },
         "('TRAINERS', 'default', 'dummy')": {
             "filepath": "TEMPLATE_PATH/trainers/base.py",
             "imports": [
+                "os",
                 "typing",
                 "time",
-                "os",
                 "abc"
             ],
             "module": "modelscope.trainers.base"
         },
         "('TRAINERS', 'default', 'efficient-diffusion-tuning')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.trainers.multi_modal.efficient_diffusion_tuning.efficient_diffusion_tuning_trainer"
         },
         "('TRAINERS', 'default', 'face-detection-scrfd')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/face_detection_scrfd_trainer.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "time",
                 "copy"
             ],
             "module": "modelscope.trainers.cv.face_detection_scrfd_trainer"
         },
         "('TRAINERS', 'default', 'faq-question-answering-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/faq_question_answering_trainer.py",
             "imports": [
-                "dataclasses",
-                "contextlib",
-                "collections",
                 "torch",
                 "distutils",
+                "contextlib",
+                "dataclasses",
                 "functools",
+                "typing",
                 "numpy",
-                "typing"
+                "collections"
             ],
             "module": "modelscope.trainers.nlp.faq_question_answering_trainer"
         },
         "('TRAINERS', 'default', 'image-classification')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_classifition_trainer.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "typing",
                 "copy",
+                "typing",
+                "numpy",
                 "time"
             ],
             "module": "modelscope.trainers.cv.image_classifition_trainer"
         },
         "('TRAINERS', 'default', 'image-classification-team')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/team/team_trainer.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
-                "numpy",
                 "typing",
-                "sklearn"
+                "sklearn",
+                "numpy",
+                "collections"
             ],
             "module": "modelscope.trainers.multi_modal.team.team_trainer"
         },
         "('TRAINERS', 'default', 'image-fewshot-detection')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_defrcn_fewshot_detection_trainer.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
                 "typing",
-                "detectron2"
+                "detectron2",
+                "collections"
             ],
             "module": "modelscope.trainers.cv.image_defrcn_fewshot_detection_trainer"
         },
         "('TRAINERS', 'default', 'image-inpainting')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_inpainting_trainer.py",
             "imports": [
+                "torch",
                 "time",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.trainers.cv.image_inpainting_trainer"
         },
         "('TRAINERS', 'default', 'image-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_instance_segmentation_trainer.py",
             "imports": [],
             "module": "modelscope.trainers.cv.image_instance_segmentation_trainer"
         },
         "('TRAINERS', 'default', 'image-portrait-enhancement')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_portrait_enhancement_trainer.py",
             "imports": [
-                "collections",
-                "torch"
+                "torch",
+                "collections"
             ],
             "module": "modelscope.trainers.cv.image_portrait_enhancement_trainer"
         },
+        "('TRAINERS', 'default', 'lora-diffusion')": {
+            "filepath": "TEMPLATE_PATH/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py",
+            "imports": [
+                "diffusers",
+                "torch",
+                "typing"
+            ],
+            "module": "modelscope.trainers.multi_modal.lora_diffusion.lora_diffusion_trainer"
+        },
         "('TRAINERS', 'default', 'mgeo-ranking-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/mgeo_ranking_trainer.py",
             "imports": [
-                "dataclasses",
+                "torch",
                 "typing",
-                "torch"
+                "dataclasses"
             ],
             "module": "modelscope.trainers.multi_modal.mgeo_ranking_trainer"
         },
         "('TRAINERS', 'default', 'movie-scene-segmentation')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/movie_scene_segmentation_trainer.py",
             "imports": [],
             "module": "modelscope.trainers.cv.movie_scene_segmentation_trainer"
         },
         "('TRAINERS', 'default', 'mplug')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/mplug/mplug_trainer.py",
             "imports": [
+                "torch",
                 "typing",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.trainers.multi_modal.mplug.mplug_trainer"
         },
         "('TRAINERS', 'default', 'nerf-recon-acc')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/nerf_recon_acc_trainer.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
+                "tqdm",
                 "datetime",
-                "typing",
                 "cv2",
-                "time",
-                "random",
+                "typing",
                 "glob",
-                "tqdm"
+                "numpy",
+                "time",
+                "random"
             ],
             "module": "modelscope.trainers.cv.nerf_recon_acc_trainer"
         },
         "('TRAINERS', 'default', 'nlp-base-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp_trainer.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.trainers.nlp_trainer"
         },
         "('TRAINERS', 'default', 'nlp-gpt-moe-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/gpt_moe_trainer.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
+                "megatron_util",
                 "typing",
-                "megatron_util"
+                "collections"
             ],
             "module": "modelscope.trainers.nlp.gpt_moe_trainer"
         },
         "('TRAINERS', 'default', 'nlp-gpt3-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/gpt3_trainer.py",
             "imports": [
-                "typing",
                 "os",
+                "typing",
                 "torch",
                 "copy"
             ],
             "module": "modelscope.trainers.nlp.gpt3_trainer"
         },
         "('TRAINERS', 'default', 'nlp-plug-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/plug_trainer.py",
             "imports": [
                 "os",
                 "torch",
-                "typing",
                 "megatron_util",
-                "deepspeed"
+                "deepspeed",
+                "typing"
             ],
             "module": "modelscope.trainers.nlp.plug_trainer"
         },
         "('TRAINERS', 'default', 'nlp-sentence-embedding-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/sentence_embedding_trainer.py",
             "imports": [
-                "dataclasses",
                 "torch",
-                "numpy",
-                "transformers",
+                "dataclasses",
+                "tqdm",
                 "typing",
+                "numpy",
                 "time",
-                "tqdm"
+                "transformers"
             ],
             "module": "modelscope.trainers.nlp.sentence_embedding_trainer"
         },
         "('TRAINERS', 'default', 'nlp-text-ranking-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/text_ranking_trainer.py",
             "imports": [
-                "dataclasses",
                 "torch",
-                "numpy",
+                "dataclasses",
+                "tqdm",
                 "typing",
-                "time",
-                "tqdm"
+                "numpy",
+                "time"
             ],
             "module": "modelscope.trainers.nlp.text_ranking_trainer"
         },
         "('TRAINERS', 'default', 'nlp-veco-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp_trainer.py",
             "imports": [
-                "numpy",
                 "os",
                 "typing",
-                "torch"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.trainers.nlp_trainer"
         },
         "('TRAINERS', 'default', 'ocr-detection-db')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/ocr_detection_db_trainer.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "easydict",
-                "numpy",
+                "tqdm",
                 "datetime",
-                "typing",
                 "copy",
-                "time",
-                "tqdm"
+                "typing",
+                "numpy",
+                "easydict",
+                "math",
+                "time"
             ],
             "module": "modelscope.trainers.cv.ocr_detection_db_trainer"
         },
         "('TRAINERS', 'default', 'ocr-recognition')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/ocr_recognition_trainer.py",
             "imports": [
+                "torch",
                 "time",
-                "collections",
-                "torch"
+                "collections"
             ],
             "module": "modelscope.trainers.cv.ocr_recognition_trainer"
         },
         "('TRAINERS', 'default', 'ofa')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/ofa/ofa_trainer.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "functools",
                 "tempfile",
-                "shutil",
+                "functools",
+                "json",
                 "typing",
-                "json"
+                "shutil",
+                "math"
             ],
             "module": "modelscope.trainers.multi_modal.ofa.ofa_trainer"
         },
         "('TRAINERS', 'default', 'referring-video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/referring_video_object_segmentation_trainer.py",
             "imports": [
                 "os",
@@ -9883,401 +10054,421 @@
             ],
             "module": "modelscope.trainers.cv.referring_video_object_segmentation_trainer"
         },
         "('TRAINERS', 'default', 'siamese-uie-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/siamese_uie_trainer.py",
             "imports": [
                 "os",
-                "collections",
                 "torch",
-                "math",
-                "numpy",
+                "json",
                 "typing",
+                "numpy",
+                "math",
                 "time",
-                "random",
-                "json"
+                "collections",
+                "random"
             ],
             "module": "modelscope.trainers.nlp.siamese_uie_trainer"
         },
         "('TRAINERS', 'default', 'speech-asr-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/asr_trainer.py",
             "imports": [
                 "os",
                 "tempfile",
-                "shutil",
+                "json",
                 "funasr",
                 "typing",
-                "json"
+                "shutil"
             ],
             "module": "modelscope.trainers.audio.asr_trainer"
         },
         "('TRAINERS', 'default', 'speech-kantts-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/tts_trainer.py",
             "imports": [
                 "os",
+                "zipfile",
                 "tempfile",
-                "shutil",
+                "json",
                 "typing",
-                "zipfile",
-                "json"
+                "shutil"
             ],
             "module": "modelscope.trainers.audio.tts_trainer"
         },
         "('TRAINERS', 'default', 'speech-separation')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/separation_trainer.py",
             "imports": [
                 "os",
-                "speechbrain",
                 "torch",
-                "numpy",
                 "torchaudio",
-                "typing",
+                "speechbrain",
                 "tqdm",
-                "csv"
+                "csv",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.trainers.audio.separation_trainer"
         },
         "('TRAINERS', 'default', 'speech_dfsmn_kws_char_farfield')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/kws_farfield_trainer.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "numpy",
                 "datetime",
                 "typing",
-                "pickle",
-                "glob"
+                "numpy",
+                "glob",
+                "math",
+                "pickle"
             ],
             "module": "modelscope.trainers.audio.kws_farfield_trainer"
         },
         "('TRAINERS', 'default', 'speech_frcrn_ans_cirm_16k')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/ans_trainer.py",
             "imports": [],
             "module": "modelscope.trainers.audio.ans_trainer"
         },
         "('TRAINERS', 'default', 'speech_kws_fsmn_char_ctc_nearfield')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/kws_nearfield_trainer.py",
             "imports": [
                 "os",
-                "re",
                 "torch",
                 "datetime",
-                "typing",
                 "copy",
                 "yaml",
-                "tensorboardX"
+                "typing",
+                "tensorboardX",
+                "re"
             ],
             "module": "modelscope.trainers.audio.kws_nearfield_trainer"
         },
+        "('TRAINERS', 'default', 'stable-diffusion')": {
+            "filepath": "TEMPLATE_PATH/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py",
+            "imports": [
+                "torch",
+                "typing"
+            ],
+            "module": "modelscope.trainers.multi_modal.stable_diffusion.stable_diffusion_trainer"
+        },
         "('TRAINERS', 'default', 'table-question-answering-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/table_question_answering_trainer.py",
             "imports": [
                 "os",
                 "torch",
-                "numpy",
-                "typing",
-                "time",
+                "tqdm",
                 "json",
-                "tqdm"
+                "typing",
+                "numpy",
+                "time"
             ],
             "module": "modelscope.trainers.nlp.table_question_answering_trainer"
         },
         "('TRAINERS', 'default', 'text-generation-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/text_generation_trainer.py",
             "imports": [
-                "collections",
-                "torch"
+                "torch",
+                "collections"
             ],
             "module": "modelscope.trainers.nlp.text_generation_trainer"
         },
         "('TRAINERS', 'default', 'tinynas-damoyolo')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_detection_damoyolo_trainer.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "easydict",
                 "datetime",
                 "typing",
+                "easydict",
+                "math",
                 "time"
             ],
             "module": "modelscope.trainers.cv.image_detection_damoyolo_trainer"
         },
         "('TRAINERS', 'default', 'trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/trainer.py",
             "imports": [
                 "os",
-                "collections",
-                "distutils",
+                "inspect",
                 "torch",
+                "distutils",
                 "functools",
-                "typing",
-                "inspect",
                 "copy",
-                "json"
+                "json",
+                "typing",
+                "collections"
             ],
             "module": "modelscope.trainers.trainer"
         },
         "('TRAINERS', 'default', 'translation-evaluation-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/translation_evaluation_trainer.py",
             "imports": [
                 "os",
                 "torch",
-                "math",
-                "transformers",
-                "typing",
+                "tqdm",
                 "pandas",
+                "typing",
+                "math",
                 "random",
-                "tqdm"
+                "transformers"
             ],
             "module": "modelscope.trainers.nlp.translation_evaluation_trainer"
         },
         "('TRAINERS', 'default', 'vision-efficient-tuning')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/vision_efficient_tuning_trainer.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.trainers.cv.vision_efficient_tuning_trainer"
         },
         "('TRANSFORMER', 'default', 'PETRDNTransformer')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py",
             "imports": [
-                "typing",
-                "copy",
                 "torch",
+                "warnings",
+                "typing",
                 "math",
                 "mmcv",
-                "warnings",
-                "mmdet"
+                "mmdet",
+                "copy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer"
         },
         "('TRANSFORMER_LAYER', 'default', 'KernelUpdator')": {
-            "filepath": "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_updator.py",
+            "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_updator.py",
             "imports": [
                 "torch",
                 "mmcv"
             ],
-            "module": "modelscope.models.cv.video_panoptic_segmentation.head.kernel_updator"
+            "module": "modelscope.models.cv.video_instance_segmentation.head.kernel_updator"
         },
         "('TRANSFORMER_LAYER', 'default', 'PETRTransformerDecoderLayer')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py",
             "imports": [
-                "typing",
-                "copy",
                 "torch",
+                "warnings",
+                "typing",
                 "math",
                 "mmcv",
-                "warnings",
-                "mmdet"
+                "mmdet",
+                "copy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer"
         },
         "('TRANSFORMER_LAYER_SEQUENCE', 'default', 'PETRTransformerDecoder')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py",
             "imports": [
-                "typing",
-                "copy",
                 "torch",
+                "warnings",
+                "typing",
                 "math",
                 "mmcv",
-                "warnings",
-                "mmdet"
+                "mmdet",
+                "copy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer"
         },
         "('TRANSFORMER_LAYER_SEQUENCE', 'default', 'PETRTransformerEncoder')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py",
             "imports": [
-                "typing",
-                "copy",
                 "torch",
+                "warnings",
+                "typing",
                 "math",
                 "mmcv",
-                "warnings",
-                "mmdet"
+                "mmdet",
+                "copy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer"
         }
     },
-    "md5": "d362f3cfb0c53629028f887c44222bb5",
+    "md5": "9d950f5b75a9faad23f199e7d6da1d6c",
     "modelscope_path": "TEMPLATE_PATH",
     "requirements": {
         "modelscope.exporters.audio.ans_dfsmn_exporter": [
             "os",
             "torch"
         ],
         "modelscope.exporters.base": [
-            "typing",
             "os",
+            "typing",
             "abc"
         ],
         "modelscope.exporters.builder": [],
         "modelscope.exporters.cv.cartoon_translation_exporter": [
-            "typing",
             "packaging",
             "os",
+            "typing",
             "tensorflow"
         ],
         "modelscope.exporters.cv.face_detection_scrfd_exporter": [
             "os",
+            "onnx",
             "torch",
             "functools",
-            "numpy",
             "typing",
-            "onnx"
+            "numpy"
         ],
         "modelscope.exporters.cv.object_detection_damoyolo_exporter": [
             "os",
+            "onnx",
             "torch",
             "functools",
-            "numpy",
             "typing",
-            "onnx"
+            "numpy"
         ],
-        "modelscope.exporters.nlp.csanmt_for_translation_exporter": [
+        "modelscope.exporters.multi_modal.stable_diffusion_exporter": [
+            "os",
+            "onnx",
+            "torch",
+            "argparse",
+            "packaging",
+            "pathlib",
             "typing",
+            "shutil",
+            "diffusers",
+            "collections"
+        ],
+        "modelscope.exporters.nlp.csanmt_for_translation_exporter": [
             "os",
+            "typing",
             "tensorflow"
         ],
         "modelscope.exporters.nlp.model_for_token_classification_exporter": [
+            "torch",
             "typing",
-            "collections",
-            "torch"
+            "collections"
         ],
         "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter": [
+            "torch",
             "typing",
-            "collections",
-            "torch"
+            "collections"
         ],
         "modelscope.exporters.nlp.sbert_for_zero_shot_classification_exporter": [
             "typing",
             "collections"
         ],
         "modelscope.exporters.tf_model_exporter": [
-            "typing",
             "os",
+            "typing",
             "tensorflow"
         ],
         "modelscope.exporters.torch_model_exporter": [
-            "contextlib",
             "os",
             "torch",
+            "contextlib",
             "itertools",
             "typing"
         ],
         "modelscope.metrics.accuracy_metric": [
             "numpy",
             "typing"
         ],
         "modelscope.metrics.action_detection_evaluator": [
             "os",
-            "collections",
-            "numpy",
             "scipy",
+            "logging",
             "pandas",
             "copy",
+            "numpy",
             "detectron2",
-            "logging"
+            "collections"
         ],
         "modelscope.metrics.audio_noise_metric": [
             "typing"
         ],
         "modelscope.metrics.base": [
             "typing",
             "abc"
         ],
         "modelscope.metrics.bleu_metric": [
-            "typing",
             "sacrebleu",
-            "itertools"
+            "itertools",
+            "typing"
         ],
         "modelscope.metrics.builder": [
             "typing"
         ],
         "modelscope.metrics.ciderD.ciderD": [
             "__future__"
         ],
         "modelscope.metrics.ciderD.ciderD_scorer": [
             "os",
-            "collections",
-            "math",
-            "numpy",
-            "copy",
-            "six",
             "__future__",
-            "pdb"
+            "copy",
+            "pdb",
+            "numpy",
+            "math",
+            "collections",
+            "six"
         ],
         "modelscope.metrics.image_color_enhance_metric": [
             "numpy",
-            "cv2",
-            "typing"
+            "typing",
+            "cv2"
         ],
         "modelscope.metrics.image_colorization_metric": [
-            "torchvision",
             "torch",
-            "numpy",
             "scipy",
+            "torchvision",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.metrics.image_denoise_metric": [
-            "numpy",
-            "cv2",
+            "torch",
             "typing",
-            "torch"
+            "numpy",
+            "cv2"
         ],
         "modelscope.metrics.image_inpainting_metric": [
-            "numpy",
+            "torch",
             "typing",
             "scipy",
-            "torch"
+            "numpy"
         ],
         "modelscope.metrics.image_instance_segmentation_metric": [
-            "pycocotools",
             "os",
-            "collections",
             "tempfile",
+            "pycocotools",
+            "typing",
             "numpy",
-            "typing"
+            "collections"
         ],
         "modelscope.metrics.image_portrait_enhancement_metric": [
             "numpy",
-            "cv2",
-            "typing"
+            "typing",
+            "cv2"
         ],
         "modelscope.metrics.image_quality_assessment_degradation_metric": [
             "os",
-            "collections",
             "torch",
-            "tempfile",
-            "sys",
-            "numpy",
             "scipy",
-            "typing",
+            "tqdm",
+            "tempfile",
             "cv2",
-            "tqdm"
+            "typing",
+            "numpy",
+            "sys",
+            "collections"
         ],
         "modelscope.metrics.image_quality_assessment_mos_metric": [
             "os",
             "torch",
-            "tempfile",
-            "sys",
-            "numpy",
             "scipy",
-            "typing",
+            "tqdm",
+            "tempfile",
             "cv2",
-            "tqdm"
+            "typing",
+            "numpy",
+            "sys"
         ],
         "modelscope.metrics.inbatch_recall_metric": [
-            "numpy",
+            "torch",
             "typing",
-            "torch"
+            "numpy"
         ],
         "modelscope.metrics.loss_metric": [
             "numpy",
             "typing",
             "sklearn"
         ],
         "modelscope.metrics.map_metric": [
@@ -10289,94 +10480,96 @@
             "typing"
         ],
         "modelscope.metrics.ned_metric": [
             "numpy",
             "typing"
         ],
         "modelscope.metrics.ocr_recognition_metric": [
-            "numpy",
-            "edit_distance",
+            "torch",
             "typing",
-            "torch"
+            "edit_distance",
+            "numpy"
         ],
         "modelscope.metrics.ppl_metric": [
-            "numpy",
-            "typing",
+            "math",
             "torch",
-            "math"
+            "typing",
+            "numpy"
         ],
         "modelscope.metrics.prediction_saving_wrapper": [
             "numpy",
             "typing",
             "sklearn"
         ],
         "modelscope.metrics.referring_video_object_segmentation_metric": [
-            "pycocotools",
             "torch",
-            "numpy",
+            "tqdm",
+            "pycocotools",
             "typing",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.metrics.sequence_classification_metric": [
             "numpy",
             "typing",
             "sklearn"
         ],
         "modelscope.metrics.text_generation_metric": [
-            "typing",
+            "rouge",
+            "contextlib",
             "nltk",
-            "rouge"
+            "typing",
+            "sys"
         ],
         "modelscope.metrics.text_ranking_metric": [
             "numpy",
             "typing"
         ],
         "modelscope.metrics.token_classification_metric": [
             "numpy",
-            "typing",
-            "importlib"
+            "importlib",
+            "typing"
         ],
         "modelscope.metrics.translation_evaluation_metric": [
+            "importlib",
             "typing",
-            "pandas",
-            "importlib"
+            "pandas"
         ],
         "modelscope.metrics.video_frame_interpolation_metric": [
             "torch",
-            "math",
             "lpips",
+            "typing",
             "numpy",
-            "typing"
+            "math"
         ],
         "modelscope.metrics.video_stabilization_metric": [
             "os",
+            "tqdm",
             "tempfile",
-            "sys",
-            "numpy",
-            "typing",
             "cv2",
-            "tqdm"
+            "typing",
+            "numpy",
+            "sys"
         ],
         "modelscope.metrics.video_summarization_metric": [
             "numpy",
             "typing"
         ],
         "modelscope.metrics.video_super_resolution_metric.matlab_functions": [
-            "numpy",
+            "math",
             "torch",
-            "math"
+            "numpy"
         ],
         "modelscope.metrics.video_super_resolution_metric.metric_util": [
             "numpy"
         ],
         "modelscope.metrics.video_super_resolution_metric.niqe": [
+            "math",
             "numpy",
-            "cv2",
             "scipy",
-            "math"
+            "cv2"
         ],
         "modelscope.metrics.video_super_resolution_metric.video_super_resolution_metric": [
             "numpy",
             "typing"
         ],
         "modelscope.models.audio.aec.layers.activations": [
             "torch"
@@ -10387,29 +10580,29 @@
         ],
         "modelscope.models.audio.aec.layers.deep_fsmn": [
             "numpy",
             "torch"
         ],
         "modelscope.models.audio.aec.layers.layer_base": [
             "numpy",
-            "abc",
+            "torch",
             "re",
-            "torch"
+            "abc"
         ],
         "modelscope.models.audio.aec.layers.uni_deep_fsmn": [
             "numpy",
             "torch"
         ],
         "modelscope.models.audio.aec.network.loss": [
             "torch"
         ],
         "modelscope.models.audio.aec.network.modulation_loss": [
-            "torchaudio",
+            "math",
             "torch",
-            "math"
+            "torchaudio"
         ],
         "modelscope.models.audio.aec.network.se_net": [
             "torch"
         ],
         "modelscope.models.audio.ans.complex_nn": [
             "torch"
         ],
@@ -10418,355 +10611,370 @@
             "torch",
             "scipy"
         ],
         "modelscope.models.audio.ans.denoise_net": [
             "torch"
         ],
         "modelscope.models.audio.ans.frcrn": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.audio.ans.layers.activations": [
             "torch"
         ],
         "modelscope.models.audio.ans.layers.affine_transform": [
             "torch"
         ],
         "modelscope.models.audio.ans.layers.layer_base": [
             "numpy",
-            "six",
+            "torch",
             "abc",
-            "torch"
+            "six"
         ],
         "modelscope.models.audio.ans.layers.uni_deep_fsmn": [
             "numpy",
             "torch"
         ],
         "modelscope.models.audio.ans.se_module_complex": [
             "torch"
         ],
         "modelscope.models.audio.ans.unet": [
             "torch"
         ],
         "modelscope.models.audio.asr.generic_automatic_speech_recognition": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.audio.asr.wenet_automatic_speech_recognition": [
-            "typing",
             "os",
-            "wenetruntime",
-            "json"
+            "typing",
+            "json",
+            "wenetruntime"
         ],
         "modelscope.models.audio.itn.generic_inverse_text_processing": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.audio.kws.farfield.fsmn": [
             "numpy",
             "torch"
         ],
         "modelscope.models.audio.kws.farfield.fsmn_sele_v2": [
             "torch"
         ],
         "modelscope.models.audio.kws.farfield.fsmn_sele_v3": [
             "torch"
         ],
         "modelscope.models.audio.kws.farfield.model": [
-            "tempfile",
             "os",
-            "typing"
+            "typing",
+            "tempfile"
         ],
         "modelscope.models.audio.kws.farfield.model_def": [
-            "struct",
             "enum",
-            "math"
+            "math",
+            "struct"
         ],
         "modelscope.models.audio.kws.generic_key_word_spotting": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.audio.kws.nearfield.cmvn": [
             "numpy",
-            "re",
-            "torch"
+            "torch",
+            "re"
         ],
         "modelscope.models.audio.kws.nearfield.fsmn": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.models.audio.kws.nearfield.model": [
             "os",
             "torch",
             "tempfile",
-            "sys",
-            "typing"
+            "typing",
+            "sys"
         ],
         "modelscope.models.audio.punc.generic_punctuation": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.audio.separation.layer_norm": [
-            "__future__",
-            "torch"
+            "torch",
+            "__future__"
         ],
         "modelscope.models.audio.separation.mossformer": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "copy"
         ],
         "modelscope.models.audio.separation.mossformer_block": [
             "torch"
         ],
         "modelscope.models.audio.separation.mossformer_conv_module": [
             "torch"
         ],
         "modelscope.models.audio.sv.DTDNN": [
             "os",
-            "collections",
             "torch",
             "torchaudio",
-            "typing"
+            "typing",
+            "numpy",
+            "collections"
         ],
         "modelscope.models.audio.sv.DTDNN_layers": [
             "torch"
         ],
         "modelscope.models.audio.sv.ERes2Net": [
             "os",
             "torch",
-            "math",
             "torchaudio",
+            "typing",
+            "math"
+        ],
+        "modelscope.models.audio.sv.ERes2Net_aug": [
+            "os",
+            "torch",
+            "torchaudio",
+            "typing",
+            "math"
+        ],
+        "modelscope.models.audio.sv.cluster_backend": [
+            "numpy",
+            "sklearn",
+            "scipy",
             "typing"
         ],
         "modelscope.models.audio.sv.ecapa_tdnn": [
             "os",
             "torch",
-            "math",
             "torchaudio",
-            "typing"
+            "math",
+            "typing",
+            "numpy"
         ],
         "modelscope.models.audio.sv.fusion": [
             "torch"
         ],
         "modelscope.models.audio.sv.generic_speaker_verification": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.audio.sv.pooling_layers": [
             "torch"
         ],
         "modelscope.models.audio.sv.rdino": [
             "os",
             "torch",
-            "math",
             "torchaudio",
-            "typing"
+            "typing",
+            "math"
         ],
         "modelscope.models.audio.sv.speaker_change_locator": [
             "os",
-            "collections",
             "torch",
-            "numpy",
             "torchaudio",
-            "typing"
+            "typing",
+            "numpy",
+            "collections"
         ],
         "modelscope.models.audio.tts.sambert_hifi": [
             "os",
-            "wave",
-            "numpy",
-            "shutil",
-            "matplotlib",
-            "datetime",
             "__future__",
             "zipfile",
+            "datetime",
+            "wave",
+            "yaml",
             "json",
-            "yaml"
+            "matplotlib",
+            "shutil",
+            "numpy"
         ],
         "modelscope.models.audio.tts.voice": [
             "os",
-            "kantts",
-            "collections",
             "torch",
-            "numpy",
-            "threading",
             "time",
-            "pickle",
+            "threading",
+            "yaml",
             "json",
-            "yaml"
+            "kantts",
+            "numpy",
+            "pickle",
+            "collections"
         ],
         "modelscope.models.base.base_head": [
             "typing",
             "abc"
         ],
         "modelscope.models.base.base_model": [
-            "typing",
             "os",
+            "typing",
             "abc"
         ],
         "modelscope.models.base.base_torch_head": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.base.base_torch_model": [
             "os",
             "torch",
+            "packaging",
             "functools",
-            "typing",
             "copy",
-            "packaging"
+            "typing"
         ],
         "modelscope.models.builder": [],
         "modelscope.models.cv.abnormal_object_detection.mmdet_model": [
-            "numpy",
             "os",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.abnormal_object_detection.mmdet_ms.roi_head.mask_scoring_roi_head": [
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.abnormal_object_detection.mmdet_ms.roi_head.roi_extractors.single_level_roi_extractor": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.action_detection.action_detection_onnx": [
             "os",
-            "onnxruntime",
-            "urllib",
-            "numpy",
-            "shutil",
-            "tempfile",
             "subprocess",
+            "tempfile",
+            "uuid",
             "cv2",
-            "uuid"
+            "urllib",
+            "shutil",
+            "numpy",
+            "onnxruntime"
         ],
         "modelscope.models.cv.action_detection.modules.action_detection_pytorch": [
             "torch",
-            "typing",
-            "detectron2",
+            "logging",
             "fvcore",
-            "logging"
+            "typing",
+            "detectron2"
         ],
         "modelscope.models.cv.action_detection.modules.resnet": [
-            "detectron2",
-            "torch"
+            "torch",
+            "detectron2"
         ],
         "modelscope.models.cv.action_recognition.models": [
             "torch"
         ],
         "modelscope.models.cv.action_recognition.s3dg": [
             "torch"
         ],
         "modelscope.models.cv.action_recognition.tada_convnext": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.action_recognition.temporal_patch_shift_transformer": [
-            "torchvision",
-            "abc",
             "torch",
+            "einops",
+            "abc",
             "functools",
-            "numpy",
-            "timm",
+            "torchvision",
             "operator",
-            "einops"
+            "timm",
+            "numpy"
         ],
         "modelscope.models.cv.animal_recognition.resnet": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.animal_recognition.splat": [
             "torch"
         ],
         "modelscope.models.cv.bad_image_detecting.bad_image_detecting": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing"
+            "torchvision",
+            "typing",
+            "numpy"
         ],
         "modelscope.models.cv.body_2d_keypoints.hrnet_basic_modules": [
             "torch"
         ],
         "modelscope.models.cv.body_2d_keypoints.hrnet_v2": [
-            "numpy",
             "os",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.body_2d_keypoints.w48": [],
         "modelscope.models.cv.body_3d_keypoints.cannonical_pose.body_3d_pose": [
             "os",
             "torch",
-            "numpy",
+            "logging",
             "typing",
-            "logging"
+            "numpy"
         ],
         "modelscope.models.cv.body_3d_keypoints.cannonical_pose.canonical_pose_modules": [
             "torch"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.backbone": [
             "torch"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.block": [
+            "einops",
             "torch",
-            "math",
-            "einops"
+            "math"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.directed_graph": [
             "numpy",
             "sys",
             "typing"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.hdformer": [
             "torch"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.hdformer_detector": [
-            "numpy",
             "os",
             "typing",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.skeleton": [
             "numpy"
         ],
         "modelscope.models.cv.cartoon.facelib.LK.lk": [
             "numpy"
         ],
         "modelscope.models.cv.cartoon.facelib.config": [
-            "numpy",
+            "easydict",
             "os",
-            "easydict"
+            "numpy"
         ],
         "modelscope.models.cv.cartoon.facelib.face_detector": [
             "numpy",
-            "cv2",
             "time",
-            "tensorflow"
+            "tensorflow",
+            "cv2"
         ],
         "modelscope.models.cv.cartoon.facelib.face_landmark": [
             "numpy",
-            "cv2",
-            "tensorflow"
+            "tensorflow",
+            "cv2"
         ],
         "modelscope.models.cv.cartoon.facelib.facer": [
             "numpy",
-            "cv2",
-            "time"
+            "time",
+            "cv2"
         ],
         "modelscope.models.cv.cartoon.loss": [
-            "skimage",
             "os",
-            "joblib",
-            "numpy",
             "scipy",
-            "tensorflow"
+            "skimage",
+            "joblib",
+            "tensorflow",
+            "numpy"
         ],
         "modelscope.models.cv.cartoon.model_tf": [
             "typing",
             "tensorflow"
         ],
         "modelscope.models.cv.cartoon.mtcnn_pytorch.src.align_trans": [
             "numpy",
@@ -10776,42 +10984,42 @@
             "numpy"
         ],
         "modelscope.models.cv.cartoon.network": [
             "tensorflow"
         ],
         "modelscope.models.cv.cartoon.utils": [
             "os",
-            "cv2",
             "tensorflow",
+            "numpy",
             "random",
-            "numpy"
+            "cv2"
         ],
         "modelscope.models.cv.cmdssl_video_embedding.c3d": [
             "torch"
         ],
         "modelscope.models.cv.cmdssl_video_embedding.resnet2p1d": [
             "torch"
         ],
         "modelscope.models.cv.cmdssl_video_embedding.resnet3d": [
             "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.annotator": [
             "os",
             "torch",
-            "numpy",
+            "einops",
             "mmseg",
             "cv2",
-            "einops",
+            "numpy",
             "mmcv"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.api": [
-            "torchvision",
             "os",
+            "torch",
             "cv2",
-            "torch"
+            "torchvision"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.base_model": [
             "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.blocks": [
             "torch"
         ],
@@ -10821,255 +11029,255 @@
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.midas_net": [
             "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.midas_net_custom": [
             "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.transforms": [
-            "numpy",
+            "math",
             "cv2",
-            "math"
+            "numpy"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.vit": [
-            "types",
-            "torch",
+            "timm",
             "math",
-            "timm"
+            "types",
+            "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.utils": [
-            "cv2",
-            "re",
             "torch",
             "numpy",
-            "sys"
+            "sys",
+            "re",
+            "cv2"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.mlsd.mbv2_mlsd_large": [
-            "sys",
             "os",
+            "sys",
             "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.mlsd.utils": [
+            "os",
             "numpy",
             "cv2",
-            "os",
             "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.openpose.body": [
-            "torchvision",
             "torch",
-            "math",
-            "numpy",
-            "matplotlib",
             "scipy",
             "cv2",
+            "torchvision",
+            "matplotlib",
+            "numpy",
+            "math",
             "time"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.openpose.hand": [
-            "skimage",
             "torch",
-            "math",
-            "numpy",
-            "matplotlib",
             "scipy",
+            "skimage",
             "cv2",
-            "time",
-            "json"
+            "json",
+            "matplotlib",
+            "numpy",
+            "math",
+            "time"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.openpose.model": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.openpose.util": [
-            "numpy",
-            "cv2",
+            "math",
             "matplotlib",
-            "math"
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.controllable_image_generation.controlnet": [
             "os",
+            "einops",
             "torch",
-            "math",
+            "PIL",
             "tempfile",
-            "sys",
-            "numpy",
             "control_ldm",
-            "typing",
-            "PIL",
             "cv2",
-            "einops",
+            "typing",
+            "numpy",
+            "math",
+            "sys",
             "random"
         ],
         "modelscope.models.cv.crowd_counting.cc_model": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.crowd_counting.hrnet_aspp_relu": [
             "os",
             "torch",
+            "logging",
             "functools",
-            "numpy",
-            "logging"
+            "numpy"
         ],
         "modelscope.models.cv.face_attribute_recognition.fair_face.face_attribute_recognition": [
-            "torchvision",
             "os",
             "torch",
+            "cv2",
+            "torchvision",
             "numpy",
-            "PIL",
-            "cv2"
+            "PIL"
         ],
         "modelscope.models.cv.face_detection.mogface.models.detectors": [
-            "numpy",
-            "cv2",
             "os",
-            "torch"
+            "torch",
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.face_detection.mogface.models.mogface": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.mogface.models.mogprednet": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.face_detection.mogface.models.resnet": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.mogface.models.utils": [
-            "numpy",
-            "torch",
+            "itertools",
             "math",
-            "itertools"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.mtcnn.models.box_utils": [
             "numpy",
             "PIL"
         ],
         "modelscope.models.cv.face_detection.mtcnn.models.detector": [
-            "numpy",
-            "PIL",
             "os",
-            "torch"
+            "torch",
+            "PIL",
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.mtcnn.models.first_stage": [
-            "numpy",
-            "PIL",
+            "math",
             "torch",
-            "math"
+            "PIL",
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.mtcnn.models.get_nets": [
             "numpy",
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.face_detection.peppa_pig_face.LK.lk": [
             "numpy"
         ],
         "modelscope.models.cv.face_detection.peppa_pig_face.face_detector": [
             "numpy",
-            "cv2",
-            "tensorflow"
+            "tensorflow",
+            "cv2"
         ],
         "modelscope.models.cv.face_detection.peppa_pig_face.face_landmark": [
             "numpy",
-            "cv2",
-            "tensorflow"
+            "tensorflow",
+            "cv2"
         ],
         "modelscope.models.cv.face_detection.peppa_pig_face.facer": [
             "numpy",
             "cv2"
         ],
         "modelscope.models.cv.face_detection.retinaface.detection": [
+            "torch",
             "numpy",
-            "cv2",
-            "torch"
+            "cv2"
         ],
         "modelscope.models.cv.face_detection.retinaface.models.net": [
-            "torchvision",
+            "torch",
             "time",
-            "torch"
+            "torchvision"
         ],
         "modelscope.models.cv.face_detection.retinaface.models.retinaface": [
-            "torchvision",
+            "torch",
             "collections",
-            "torch"
+            "torchvision"
         ],
         "modelscope.models.cv.face_detection.retinaface.utils": [
+            "itertools",
             "numpy",
             "torch",
-            "math",
-            "itertools"
+            "math"
         ],
         "modelscope.models.cv.face_detection.scrfd.damofd_detect": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "copy"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.core.bbox.transforms": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.core.post_processing.bbox_nms": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.auto_augment": [
-            "cv2",
             "copy",
-            "mmcv",
             "numpy",
-            "mmdet"
+            "mmcv",
+            "mmdet",
+            "cv2"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.formating": [
             "numpy",
-            "mmdet",
+            "mmcv",
             "torch",
-            "mmcv"
+            "mmdet"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.loading": [
-            "numpy",
+            "mmdet",
             "os",
             "pycocotools",
-            "mmdet"
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.transforms": [
             "numpy",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.retinaface": [
             "numpy",
             "mmdet"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.master_net": [
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.mobilenet": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.resnet": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.dense_heads.scrfd_head": [
-            "numpy",
-            "mmdet",
             "torch",
-            "mmcv"
+            "mmcv",
+            "mmdet",
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.base": [
-            "abc",
-            "collections",
             "torch",
-            "mmcv",
+            "abc",
             "numpy",
+            "mmcv",
+            "collections",
             "mmdet"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.scrfd": [
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.single_stage": [
@@ -11078,39 +11286,39 @@
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.tinymog": [
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.face_detection.scrfd.preprocessor": [
             "numpy",
-            "PIL",
-            "typing"
+            "typing",
+            "PIL"
         ],
         "modelscope.models.cv.face_detection.scrfd.scrfd_detect": [
             "os",
             "torch",
-            "numpy",
+            "copy",
             "typing",
-            "copy"
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.scrfd.tinymog_detect": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "copy"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.detection": [
-            "numpy",
-            "cv2",
             "os",
-            "torch"
+            "torch",
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.box_utils": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.mb_tiny": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.ssd.data_preprocessing": [],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.ssd.fd_config": [
             "numpy"
@@ -11118,94 +11326,94 @@
         "modelscope.models.cv.face_detection.ulfd_slim.vision.ssd.mb_tiny_fd": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.ssd.predictor": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.ssd.ssd": [
-            "numpy",
+            "torch",
             "typing",
             "collections",
-            "torch"
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.transforms": [
             "numpy",
             "types",
             "cv2",
             "torch"
         ],
         "modelscope.models.cv.face_emotion.efficient.model": [
             "torch"
         ],
         "modelscope.models.cv.face_emotion.efficient.utils": [
+            "torch",
+            "math",
             "functools",
             "collections",
-            "torch",
-            "re",
-            "math"
+            "re"
         ],
         "modelscope.models.cv.face_emotion.emotion_infer": [
+            "torch",
             "PIL",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.models.cv.face_emotion.emotion_model": [
-            "sys",
             "os",
+            "sys",
             "torch"
         ],
         "modelscope.models.cv.face_emotion.face_alignment.face": [
-            "numpy",
-            "cv2",
             "os",
-            "tensorflow"
+            "numpy",
+            "tensorflow",
+            "cv2"
         ],
         "modelscope.models.cv.face_emotion.face_alignment.face_align": [
             "os",
-            "numpy",
-            "sys",
             "PIL",
-            "cv2"
+            "cv2",
+            "numpy",
+            "sys"
         ],
         "modelscope.models.cv.face_generation.op.conv2d_gradfix": [
-            "contextlib",
             "warnings",
+            "contextlib",
             "torch"
         ],
         "modelscope.models.cv.face_generation.op.fused_act": [
             "os",
             "torch"
         ],
         "modelscope.models.cv.face_generation.op.upfirdn2d": [
             "os",
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.face_generation.stylegan2": [
             "torch",
-            "math",
             "functools",
             "operator",
+            "math",
             "random"
         ],
         "modelscope.models.cv.face_human_hand_detection.det_infer": [
+            "torch",
             "numpy",
-            "cv2",
-            "torch"
+            "cv2"
         ],
         "modelscope.models.cv.face_human_hand_detection.ghost_pan": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.face_human_hand_detection.nanodet_plus_head": [
-            "torchvision",
             "torch",
-            "math",
+            "cv2",
+            "torchvision",
             "numpy",
-            "cv2"
+            "math"
         ],
         "modelscope.models.cv.face_human_hand_detection.one_stage_detector": [
             "torch"
         ],
         "modelscope.models.cv.face_human_hand_detection.shufflenetv2": [
             "torch"
         ],
@@ -11220,35 +11428,35 @@
         "modelscope.models.cv.face_recognition.torchkit.backbone.arcface_backbone": [
             "torch"
         ],
         "modelscope.models.cv.face_recognition.torchkit.backbone.common": [
             "torch"
         ],
         "modelscope.models.cv.face_recognition.torchkit.backbone.facemask_backbone": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.face_recognition.torchkit.backbone.model_irse": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.face_recognition.torchkit.backbone.model_resnet": [
             "torch"
         ],
         "modelscope.models.cv.face_recognition.torchkit.rts_backbone": [
             "os",
-            "collections",
             "torch",
+            "collections",
             "math"
         ],
         "modelscope.models.cv.face_reconstruction.models.bfm": [
-            "numpy",
             "os",
+            "torch",
             "scipy",
-            "torch"
+            "numpy"
         ],
         "modelscope.models.cv.face_reconstruction.models.de_retouching_module": [
             "torch"
         ],
         "modelscope.models.cv.face_reconstruction.models.facelandmark.large_base_lmks_infer": [
             "numpy",
             "torch"
@@ -11257,119 +11465,119 @@
             "torch"
         ],
         "modelscope.models.cv.face_reconstruction.models.facelandmark.nets.large_eyeball_net": [
             "torch"
         ],
         "modelscope.models.cv.face_reconstruction.models.facerecon_model": [
             "os",
-            "collections",
             "torch",
+            "cv2",
             "numpy",
-            "cv2"
+            "collections"
         ],
         "modelscope.models.cv.face_reconstruction.models.losses": [
             "numpy",
-            "kornia",
-            "torch"
+            "torch",
+            "kornia"
         ],
         "modelscope.models.cv.face_reconstruction.models.networks": [
-            "typing",
             "os",
-            "kornia",
-            "torch"
+            "typing",
+            "torch",
+            "kornia"
         ],
         "modelscope.models.cv.face_reconstruction.models.nv_diffrast": [
             "torch",
-            "numpy",
-            "typing",
+            "nvdiffrast",
             "warnings",
-            "nvdiffrast"
+            "typing",
+            "numpy"
         ],
         "modelscope.models.cv.face_reconstruction.models.opt": [],
         "modelscope.models.cv.face_reconstruction.models.pix2pix.networks": [
             "torch",
             "functools"
         ],
         "modelscope.models.cv.face_reconstruction.models.pix2pix.pix2pix_model": [
             "torch"
         ],
         "modelscope.models.cv.face_reconstruction.models.pix2pix.pix2pix_options": [],
         "modelscope.models.cv.face_reconstruction.models.renderer": [
-            "numpy",
+            "torch",
             "skimage",
             "imageio",
-            "torch"
+            "numpy"
         ],
         "modelscope.models.cv.face_reconstruction.models.unet": [
             "warnings",
             "torch"
         ],
         "modelscope.models.cv.face_reconstruction.utils": [
             "os",
             "torch",
-            "math",
-            "argparse",
-            "numpy",
-            "numba",
             "scipy",
             "PIL",
+            "argparse",
             "cv2",
-            "array"
+            "array",
+            "numpy",
+            "math",
+            "numba"
         ],
         "modelscope.models.cv.facial_expression_recognition.fer.facial_expression_recognition": [
             "os",
             "torch",
-            "numpy",
             "PIL",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.facial_expression_recognition.fer.transforms": [
-            "PIL",
             "torch",
             "numpy",
+            "PIL",
             "types",
             "numbers"
         ],
         "modelscope.models.cv.facial_expression_recognition.fer.vgg": [
             "torch"
         ],
         "modelscope.models.cv.facial_landmark_confidence.flc.facial_landmark_confidence": [
             "os",
             "torch",
-            "numpy",
             "PIL",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.facial_landmark_confidence.flc.manual_landmark_net": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.hand_static.hand_model": [
-            "torchvision",
             "os",
             "torch",
+            "torchvision",
+            "cv2",
             "numpy",
-            "sys",
             "PIL",
-            "cv2"
+            "sys"
         ],
         "modelscope.models.cv.hand_static.networks": [
-            "torchvision",
             "os",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.human_reconstruction.Reconstruction": [
-            "torchvision",
             "os",
-            "skimage",
             "torch",
-            "numpy",
             "PIL",
+            "skimage",
+            "cv2",
+            "torchvision",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.models.cv.human_reconstruction.models.Embedding": [
             "torch"
         ],
         "modelscope.models.cv.human_reconstruction.models.PixToMesh": [
             "torch"
         ],
@@ -11385,443 +11593,443 @@
             "torch"
         ],
         "modelscope.models.cv.human_reconstruction.models.geometry": [
             "torch"
         ],
         "modelscope.models.cv.human_reconstruction.models.human_segmenter": [
             "numpy",
-            "cv2",
-            "tensorflow"
+            "tensorflow",
+            "cv2"
         ],
         "modelscope.models.cv.human_reconstruction.models.networks": [
             "numpy",
-            "torch",
-            "functools"
+            "functools",
+            "torch"
         ],
         "modelscope.models.cv.human_reconstruction.utils": [
-            "numpy",
             "os",
             "mcubes",
+            "numpy",
             "torch"
         ],
         "modelscope.models.cv.image_binary_quant_classification.binary_quant_model": [
             "os",
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.image_binary_quant_classification.bnext": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.image_body_reshaping.image_body_reshaping": [
             "os",
             "torch",
-            "numpy",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.models.cv.image_body_reshaping.model": [
             "torch"
         ],
         "modelscope.models.cv.image_body_reshaping.person_info": [
-            "numpy",
-            "cv2",
+            "copy",
             "torch",
-            "copy"
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.image_body_reshaping.pose_estimator.body": [
             "torch",
-            "math",
-            "numpy",
             "scipy",
-            "cv2"
+            "cv2",
+            "numpy",
+            "math"
         ],
         "modelscope.models.cv.image_body_reshaping.pose_estimator.model": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.image_body_reshaping.pose_estimator.util": [
             "numpy"
         ],
         "modelscope.models.cv.image_body_reshaping.slim_utils": [
+            "math",
             "os",
-            "cv2",
             "torch",
-            "math",
-            "random",
+            "numba",
             "numpy",
-            "numba"
+            "random",
+            "cv2"
         ],
         "modelscope.models.cv.image_classification.backbones.beit_v2": [
             "os",
-            "collections",
             "torch",
-            "math",
-            "itertools",
+            "einops",
             "functools",
-            "mmcls",
+            "itertools",
+            "warnings",
             "typing",
-            "einops",
+            "mmcls",
+            "math",
             "mmcv",
-            "warnings"
+            "collections"
         ],
         "modelscope.models.cv.image_classification.backbones.nextvit": [
             "os",
-            "collections",
             "torch",
-            "math",
-            "itertools",
+            "einops",
             "functools",
-            "mmcls",
+            "itertools",
+            "warnings",
             "typing",
-            "einops",
+            "mmcls",
+            "math",
             "mmcv",
-            "warnings"
+            "collections"
         ],
         "modelscope.models.cv.image_classification.mmcls_model": [
             "os"
         ],
         "modelscope.models.cv.image_classification.resnet50_cc": [
-            "torchvision",
             "os",
-            "collections",
             "torch",
-            "math"
+            "torchvision",
+            "math",
+            "collections"
         ],
         "modelscope.models.cv.image_classification.utils": [
             "os",
-            "collections",
             "torch",
-            "math",
             "itertools",
+            "mmcls",
             "numpy",
-            "mmcls"
+            "collections",
+            "math"
         ],
         "modelscope.models.cv.image_color_enhance.adaint.adaint": [
-            "torchvision",
             "os",
             "torch",
+            "torchvision",
             "typing",
             "numbers"
         ],
         "modelscope.models.cv.image_color_enhance.csrnet": [
-            "torch",
             "math",
-            "functools"
+            "functools",
+            "torch"
         ],
         "modelscope.models.cv.image_color_enhance.deeplpf.deeplpf_image_color_enhance": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_color_enhance.deeplpf.deeplpfnet": [
+            "math",
             "matplotlib",
-            "torch",
-            "math"
+            "torch"
         ],
         "modelscope.models.cv.image_color_enhance.image_color_enhance": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.ddcolor": [
             "torch"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.ddcolor_for_image_colorization": [
             "os",
             "torch",
-            "numpy",
+            "copy",
             "typing",
-            "copy"
+            "numpy"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.loss": [
             "torch"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.utils.convnext": [
-            "torch",
-            "timm"
+            "timm",
+            "torch"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.utils.position_encoding": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.utils.transformer_utils": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.utils.unet": [
             "enum",
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.utils.vgg": [
-            "torchvision",
             "os",
+            "torch",
             "collections",
-            "torch"
+            "torchvision"
         ],
         "modelscope.models.cv.image_colorization.unet.unet": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.image_colorization.unet.utils": [
             "enum",
             "torch",
             "functools"
         ],
         "modelscope.models.cv.image_debanding.rrdb.rrdb_image_debanding": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_deblur.nafnet_for_image_deblur": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.defrcn_for_fewshot": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.evaluation.coco_evaluation": [
-            "pycocotools",
-            "contextlib",
             "os",
-            "collections",
             "torch",
-            "itertools",
-            "numpy",
+            "contextlib",
+            "logging",
             "tabulate",
             "copy",
-            "detectron2",
-            "fvcore",
+            "pycocotools",
+            "itertools",
             "json",
-            "logging",
-            "io"
+            "io",
+            "fvcore",
+            "numpy",
+            "detectron2",
+            "collections"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.evaluation.evaluator": [
             "torch",
-            "datetime",
-            "detectron2",
+            "logging",
             "time",
-            "logging"
+            "datetime",
+            "detectron2"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.evaluation.pascal_voc_evaluation": [
             "os",
-            "detectron2",
-            "collections",
+            "tempfile",
             "numpy",
-            "tempfile"
+            "detectron2",
+            "collections"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.calibration_layer": [
-            "cv2",
             "detectron2",
             "torch",
-            "sklearn"
+            "sklearn",
+            "cv2"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.defrcn": [
-            "typing",
-            "os",
             "detectron2",
+            "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.fast_rcnn": [
+            "fvcore",
             "numpy",
             "detectron2",
-            "torch",
-            "fvcore"
+            "torch"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.gdl": [
             "torch"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.resnet": [
-            "torchvision",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.roi_heads": [
-            "detectron2",
-            "torch"
+            "torch",
+            "detectron2"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.utils.coco_register": [
-            "pycocotools",
-            "contextlib",
             "os",
-            "detectron2",
             "fvcore",
-            "io"
+            "contextlib",
+            "io",
+            "detectron2",
+            "pycocotools"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.utils.configuration_mapper": [
             "detectron2"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.utils.model_surgery_op": [
             "argparse",
             "os",
             "torch"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.utils.register_data": [],
         "modelscope.models.cv.image_defrcn_fewshot.utils.requirements_check": [
-            "collections",
-            "sys",
+            "packaging",
             "importlib",
             "importlib_metadata",
-            "packaging"
+            "sys",
+            "collections"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.utils.voc_register": [
             "os",
-            "detectron2",
             "fvcore",
+            "xml",
             "numpy",
-            "xml"
+            "detectron2"
         ],
         "modelscope.models.cv.image_denoise.nafnet.NAFNet_arch": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.image_denoise.nafnet.arch_util": [
             "torch"
         ],
         "modelscope.models.cv.image_denoise.nafnet_for_image_denoise": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_depth_estimation.networks.newcrf_depth": [
             "torch"
         ],
         "modelscope.models.cv.image_depth_estimation.networks.newcrf_layers": [
+            "timm",
             "numpy",
-            "torch",
-            "timm"
+            "torch"
         ],
         "modelscope.models.cv.image_depth_estimation.networks.newcrf_utils": [
-            "torchvision",
             "os",
-            "collections",
             "torch",
             "warnings",
             "importlib",
-            "pkgutil"
+            "pkgutil",
+            "collections",
+            "torchvision"
         ],
         "modelscope.models.cv.image_depth_estimation.networks.swin_transformer": [
+            "timm",
             "numpy",
-            "torch",
-            "timm"
+            "torch"
         ],
         "modelscope.models.cv.image_depth_estimation.networks.uper_crf_head": [
             "torch",
             "mmcv"
         ],
         "modelscope.models.cv.image_depth_estimation.newcrfs_model": [
-            "numpy",
             "os",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.image_depth_estimation_bts.depth_estimation_bts_model": [
             "os",
             "torch"
         ],
         "modelscope.models.cv.image_depth_estimation_bts.networks.bts_model": [
             "torch"
         ],
         "modelscope.models.cv.image_depth_estimation_bts.networks.decoder": [
             "torch"
         ],
         "modelscope.models.cv.image_depth_estimation_bts.networks.encoder": [
-            "torchvision",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.image_depth_estimation_bts.networks.utils": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_driving_perception.image_driving_percetion_model": [
             "os",
             "torch",
-            "numpy",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.models.cv.image_driving_perception.preprocessor": [
-            "numpy",
-            "cv2",
+            "torch",
             "typing",
-            "torch"
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.image_driving_perception.utils": [
             "numpy",
-            "torchvision",
             "time",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.image_face_fusion.facegan.gan_wrap": [
-            "torchvision",
             "os",
             "torch",
+            "torchvision",
+            "cv2",
             "numpy",
-            "PIL",
-            "cv2"
+            "PIL"
         ],
         "modelscope.models.cv.image_face_fusion.facegan.model": [
-            "torch",
             "math",
+            "torch",
             "random"
         ],
         "modelscope.models.cv.image_face_fusion.facegan.op.conv2d_gradfix": [
-            "contextlib",
             "warnings",
+            "contextlib",
             "torch"
         ],
         "modelscope.models.cv.image_face_fusion.facegan.op.fused_act": [
             "torch"
         ],
         "modelscope.models.cv.image_face_fusion.facegan.op.upfirdn2d": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.image_face_fusion.facelib.align_trans": [
             "numpy",
             "cv2"
         ],
         "modelscope.models.cv.image_face_fusion.facelib.matlab_cp2tform": [
             "numpy"
         ],
         "modelscope.models.cv.image_face_fusion.image_face_fusion": [
-            "torchvision",
             "os",
-            "collections",
             "torch",
+            "torchvision",
+            "cv2",
+            "typing",
             "numpy",
             "PIL",
-            "typing",
-            "cv2"
+            "collections"
         ],
         "modelscope.models.cv.image_face_fusion.network.aad_layer": [
             "torch"
         ],
         "modelscope.models.cv.image_face_fusion.network.aei_flow_net": [
             "torch"
         ],
         "modelscope.models.cv.image_face_fusion.network.bfm": [
-            "numpy",
             "os",
+            "torch",
             "scipy",
-            "torch"
+            "numpy"
         ],
         "modelscope.models.cv.image_face_fusion.network.dense_motion": [
             "torch"
         ],
         "modelscope.models.cv.image_face_fusion.network.facerecon_model": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_face_fusion.network.model_irse": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.image_face_fusion.network.ops": [
             "torch"
         ],
         "modelscope.models.cv.image_human_parsing.backbone.deeplab_resnet": [
             "numpy",
             "torch"
@@ -11831,715 +12039,715 @@
         ],
         "modelscope.models.cv.image_human_parsing.m2fp.m2fp_encoder": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.models.cv.image_human_parsing.m2fp_net": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_human_parsing.parsing_utils": [
             "numpy",
+            "torch",
             "PIL",
-            "copy",
-            "torch"
+            "copy"
         ],
         "modelscope.models.cv.image_inpainting.base": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_inpainting.default": [
-            "bisect",
-            "torch"
+            "torch",
+            "bisect"
         ],
         "modelscope.models.cv.image_inpainting.model": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_inpainting.modules.ade20k.base": [
             "os",
             "torch"
         ],
         "modelscope.models.cv.image_inpainting.modules.ade20k.resnet": [
             "os",
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_inpainting.modules.adversarial": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_inpainting.modules.feature_matching": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_inpainting.modules.ffc": [
             "numpy",
-            "kornia",
-            "torch"
+            "torch",
+            "kornia"
         ],
         "modelscope.models.cv.image_inpainting.modules.inception": [
-            "torchvision",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.image_inpainting.modules.perceptual": [
-            "torchvision",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.image_inpainting.modules.pix2pixhd": [
-            "collections",
             "torch",
-            "functools",
+            "logging",
             "numpy",
-            "logging"
+            "functools",
+            "collections"
         ],
         "modelscope.models.cv.image_inpainting.refinement": [
             "torch",
-            "numpy",
+            "tqdm",
             "cv2",
             "kornia",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.models.cv.image_instance_segmentation.backbones.resnet": [
             "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.backbones.swin_transformer": [
+            "timm",
             "numpy",
-            "torch",
-            "timm"
+            "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.cascade_mask_rcnn_swin": [
             "os",
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.image_instance_segmentation.datasets.transforms": [
-            "numpy",
-            "os"
+            "os",
+            "numpy"
         ],
         "modelscope.models.cv.image_instance_segmentation.fastinst.fastinst_decoder": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.fastinst.fastinst_encoder": [
+            "torch",
             "typing",
-            "logging",
-            "torch"
+            "logging"
         ],
         "modelscope.models.cv.image_instance_segmentation.fastinst_model": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.dino_decoder": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.maskdino_decoder": [
             "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.maskdino_encoder": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.ms_deform_attn": [
-            "__future__",
             "torch",
+            "warnings",
+            "__future__",
             "math",
-            "mmcv",
-            "warnings"
+            "mmcv"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.position_encoding": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.utils": [
-            "copy",
+            "math",
             "torch",
-            "math"
+            "copy"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino_model": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino_swin": [
             "os",
             "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.model": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.postprocess_utils": [
-            "pycocotools",
             "torch",
+            "cv2",
+            "pycocotools",
             "itertools",
-            "numpy",
-            "cv2"
+            "numpy"
         ],
         "modelscope.models.cv.image_matching.config.default": [
             "yacs"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.backbone.resnet_fpn": [
             "torch"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.loftr": [
-            "torch",
-            "einops"
+            "einops",
+            "torch"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.loftr_module.fine_preprocess": [
-            "torch",
-            "einops"
+            "einops",
+            "torch"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.loftr_module.linear_attention": [
             "torch"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.loftr_module.quadtree_attention": [
-            "torch",
-            "timm"
+            "timm",
+            "torch"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.loftr_module.transformer": [
+            "einops",
             "torch",
-            "math",
-            "timm",
             "copy",
-            "einops"
+            "timm",
+            "math"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.utils.coarse_matching": [
-            "torch",
-            "einops"
+            "einops",
+            "torch"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.utils.fine_matching": [
-            "kornia",
+            "math",
             "torch",
-            "math"
+            "kornia"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.utils.position_encoding": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_matching.quadtree_attention_model": [
             "os",
             "torch",
-            "numpy",
             "cv2",
-            "pathlib"
+            "pathlib",
+            "numpy"
         ],
         "modelscope.models.cv.image_matching.utils.misc": [
             "yacs"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.cas_mvsnet": [
             "torch"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.casmvs_model": [
             "os",
             "torch",
+            "cv2",
             "easydict",
-            "numpy",
-            "cv2"
+            "numpy"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.colmap2mvsnet": [
             "os",
-            "collections",
+            "__future__",
             "functools",
-            "numpy",
-            "shutil",
+            "cv2",
             "struct",
+            "shutil",
+            "numpy",
             "multiprocessing",
-            "cv2",
-            "__future__"
+            "collections"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.depth_filter": [
             "os",
-            "numpy",
             "PIL",
             "cv2",
+            "numpy",
             "plyfile"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.general_eval_dataset": [
-            "PIL",
             "os",
-            "cv2",
-            "re",
             "torch",
             "numpy",
-            "sys"
+            "PIL",
+            "sys",
+            "re",
+            "cv2"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.module": [
             "torch"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.utils": [
             "numpy",
-            "torchvision",
             "torch",
-            "random"
+            "random",
+            "torchvision"
         ],
         "modelscope.models.cv.image_paintbyexample.model": [
             "os",
             "torch",
+            "paint_ldm",
             "omegaconf",
-            "typing",
-            "paint_ldm"
+            "typing"
         ],
         "modelscope.models.cv.image_panoptic_segmentation.panseg_model": [
             "os",
             "torch"
         ],
         "modelscope.models.cv.image_portrait_enhancement.align_faces": [
             "numpy",
             "skimage",
             "cv2"
         ],
         "modelscope.models.cv.image_portrait_enhancement.eqface.fqa": [
-            "numpy",
-            "cv2",
             "os",
-            "torch"
+            "torch",
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.image_portrait_enhancement.eqface.model_resnet": [
             "torch"
         ],
         "modelscope.models.cv.image_portrait_enhancement.gpen": [
             "torch",
-            "math",
             "functools",
-            "itertools",
             "operator",
+            "itertools",
+            "math",
             "random"
         ],
         "modelscope.models.cv.image_portrait_enhancement.image_portrait_enhancement": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_portrait_enhancement.losses.helpers": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.image_portrait_enhancement.losses.losses": [
             "torch"
         ],
         "modelscope.models.cv.image_portrait_enhancement.losses.model_irse": [
             "torch"
         ],
         "modelscope.models.cv.image_portrait_enhancement.retinaface.detection": [
-            "numpy",
-            "cv2",
             "os",
-            "torch"
+            "torch",
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.image_portrait_enhancement.retinaface.models.net": [
-            "torchvision",
+            "torch",
             "time",
-            "torch"
+            "torchvision"
         ],
         "modelscope.models.cv.image_portrait_enhancement.retinaface.models.retinaface": [
-            "torchvision",
+            "torch",
             "collections",
-            "torch"
+            "torchvision"
         ],
         "modelscope.models.cv.image_portrait_enhancement.retinaface.utils": [
+            "itertools",
             "numpy",
             "torch",
-            "math",
-            "itertools"
+            "math"
         ],
         "modelscope.models.cv.image_probing_model.backbone": [
-            "torchvision",
-            "collections",
             "torch",
-            "math",
+            "PIL",
             "functools",
+            "torchvision",
+            "operator",
             "numpy",
+            "math",
             "sys",
-            "PIL",
-            "operator"
+            "collections"
         ],
         "modelscope.models.cv.image_probing_model.model": [
-            "typing",
             "os",
-            "json",
-            "torch"
+            "typing",
+            "torch",
+            "json"
         ],
         "modelscope.models.cv.image_probing_model.utils": [
-            "re",
-            "torch"
+            "torch",
+            "re"
         ],
         "modelscope.models.cv.image_quality_assessment_degradation.degradation_model": [
+            "torch",
+            "json",
             "torchvision",
-            "cv2",
+            "numpy",
             "time",
             "collections",
-            "torch",
-            "numpy",
-            "json"
+            "cv2"
         ],
         "modelscope.models.cv.image_quality_assessment_degradation.image_quality_assessment_degradation": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_quality_assessment_man.image_quality_assessment_man": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_quality_assessment_man.maniqa": [
+            "timm",
             "torch",
-            "einops",
-            "timm"
+            "einops"
         ],
         "modelscope.models.cv.image_quality_assessment_man.swin": [
-            "collections",
             "torch",
-            "math",
-            "itertools",
             "einops",
-            "warnings"
+            "itertools",
+            "warnings",
+            "math",
+            "collections"
         ],
         "modelscope.models.cv.image_quality_assessment_mos.backbones.resnet": [
             "os",
             "torch"
         ],
         "modelscope.models.cv.image_quality_assessment_mos.censeo_ivqa_model": [
             "torch"
         ],
         "modelscope.models.cv.image_quality_assessment_mos.heads.simple_head": [
             "torch"
         ],
         "modelscope.models.cv.image_quality_assessment_mos.image_quality_assessment_mos": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.image_reid_person.pass_model": [
-            "os",
             "enum",
+            "os",
             "torch"
         ],
         "modelscope.models.cv.image_reid_person.transreid_model": [
             "itertools",
-            "collections",
             "torch",
+            "collections",
             "functools"
         ],
         "modelscope.models.cv.image_restoration.demoire_models.nets": [
             "torch"
         ],
         "modelscope.models.cv.image_restoration.image_restoration_model": [
-            "numpy",
-            "cv2",
             "os",
-            "torch"
+            "torch",
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.image_semantic_segmentation.ddpm_seg.data_util": [],
         "modelscope.models.cv.image_semantic_segmentation.ddpm_seg.feature_extractors": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_semantic_segmentation.ddpm_seg.pixel_classifier": [
             "os",
-            "collections",
             "torch",
             "numpy",
-            "PIL"
+            "PIL",
+            "collections"
         ],
         "modelscope.models.cv.image_semantic_segmentation.ddpm_seg.utils": [
-            "numpy",
             "PIL",
+            "numpy",
             "torch",
             "random"
         ],
         "modelscope.models.cv.image_semantic_segmentation.ddpm_segmentation_model": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "ddpm_guided_diffusion"
         ],
         "modelscope.models.cv.image_semantic_segmentation.pan_merge.base_panoptic_fusion_head": [
             "abc",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.image_semantic_segmentation.pan_merge.maskformer_semantic_head": [
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.image_semantic_segmentation.semantic_seg_model": [
-            "numpy",
             "os",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.backbone.adapter_modules": [
-            "mmdet",
             "torch",
-            "functools",
             "logging",
-            "timm"
+            "timm",
+            "functools",
+            "mmdet"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.backbone.base.beit": [
             "torch",
+            "timm",
             "math",
-            "functools",
             "mmcv",
-            "mmdet",
-            "timm"
+            "functools",
+            "mmdet"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.backbone.beit_adapter": [
-            "mmdet",
             "torch",
-            "math",
+            "logging",
+            "mmdet",
             "timm",
-            "logging"
+            "math"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.decode_heads.base_decode_head": [
             "mmdet",
-            "abc",
             "torch",
-            "mmcv"
+            "mmcv",
+            "abc"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.decode_heads.mask2former_head_from_mmseg": [
-            "mmdet",
-            "copy",
             "torch",
-            "mmcv"
+            "mmcv",
+            "mmdet",
+            "copy"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.segmentors.base_segmentor": [
-            "abc",
-            "collections",
             "torch",
-            "mmcv",
+            "warnings",
+            "abc",
             "numpy",
-            "warnings"
+            "mmcv",
+            "collections"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.segmentors.encoder_decoder_mask2former": [
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.utils.builder": [
             "mmcv"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.utils.data_process_func": [
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.utils.seg_func": [
             "warnings",
             "torch"
         ],
         "modelscope.models.cv.image_skychange.preprocessor": [
-            "torchvision",
             "torch",
-            "numpy",
-            "typing",
             "cv2",
+            "torchvision",
+            "pdb",
             "json",
-            "numbers",
-            "pdb"
+            "typing",
+            "numpy",
+            "numbers"
         ],
         "modelscope.models.cv.image_skychange.ptsemseg.BlockModules": [
             "torch"
         ],
         "modelscope.models.cv.image_skychange.ptsemseg.hrnet_backnone": [
-            "numpy",
             "os",
-            "torch",
-            "logging"
+            "numpy",
+            "logging",
+            "torch"
         ],
         "modelscope.models.cv.image_skychange.ptsemseg.hrnet_super_and_ocr": [
             "numpy",
             "__future__",
             "torch"
         ],
         "modelscope.models.cv.image_skychange.ptsemseg.unet": [
             "torch"
         ],
         "modelscope.models.cv.image_skychange.skychange": [
-            "torchvision",
             "os",
-            "collections",
             "torch",
-            "numpy",
             "PIL",
             "cv2",
+            "torchvision",
             "json",
-            "numbers",
-            "pdb"
+            "pdb",
+            "numpy",
+            "collections",
+            "numbers"
         ],
         "modelscope.models.cv.image_skychange.skychange_model": [
             "os",
-            "collections",
             "torch",
-            "math",
-            "typing",
             "cv2",
-            "time",
             "json",
-            "pdb"
+            "pdb",
+            "typing",
+            "math",
+            "time",
+            "collections"
         ],
         "modelscope.models.cv.image_to_image_generation.data.transforms": [
             "PIL",
-            "torchvision",
             "math",
-            "random"
+            "random",
+            "torchvision"
         ],
         "modelscope.models.cv.image_to_image_generation.model": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_to_image_generation.models.autoencoder": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_to_image_generation.models.clip": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_to_image_generation.ops.diffusion": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_to_image_generation.ops.losses": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_to_image_translation.data.transforms": [
             "PIL",
-            "torchvision",
             "math",
-            "random"
+            "random",
+            "torchvision"
         ],
         "modelscope.models.cv.image_to_image_translation.model_translation": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_to_image_translation.models.autoencoder": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_to_image_translation.models.clip": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.apps": [
-            "torchvision",
-            "artist",
             "os",
             "torch",
+            "torchvision",
+            "artist",
             "numpy",
             "PIL"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.degradation": [
+            "math",
             "os",
-            "cv2",
             "torch",
-            "math",
-            "random",
+            "scipy",
             "numpy",
-            "scipy"
+            "random",
+            "cv2"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.diffusion": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.losses": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.metrics": [
             "numpy",
-            "scipy",
-            "torch"
+            "torch",
+            "scipy"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.random_color": [
             "colorsys",
             "random"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.random_mask": [
             "numpy",
             "cv2"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.svd": [
             "torch"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.utils": [
-            "binascii",
-            "os",
             "base64",
-            "math",
+            "os",
             "torch",
-            "numpy",
-            "hashlib",
-            "multiprocessing",
+            "zipfile",
             "PIL",
+            "hashlib",
+            "binascii",
             "cv2",
-            "zipfile",
             "json",
-            "io"
+            "io",
+            "numpy",
+            "math",
+            "multiprocessing"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.backbone.resnet_DA": [
-            "torchvision",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.backbone.vit_horizon_pry_image": [
+            "timm",
             "numpy",
-            "torch",
-            "timm"
+            "torch"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.misc.fourier": [
             "numpy",
-            "PIL",
-            "scipy"
+            "scipy",
+            "PIL"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.misc.panostretch": [
             "numpy",
-            "scipy",
-            "functools"
+            "functools",
+            "scipy"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.misc.post_proc": [
             "numpy",
-            "scipy",
-            "sklearn"
+            "sklearn",
+            "scipy"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.modality.layout": [
             "torch",
-            "math",
-            "numpy",
+            "shapely",
             "scipy",
-            "shapely"
+            "numpy",
+            "math"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.panovit": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.utils": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.indoor_layout_estimation.panovit": [
-            "numpy",
             "os",
             "torch",
+            "numpy",
             "yacs"
         ],
         "modelscope.models.cv.language_guided_video_summarization.summarizer": [
             "os",
             "torch",
-            "bmt_clipit",
             "argparse",
-            "numpy",
+            "videofeatures_clipit",
             "typing",
-            "videofeatures_clipit"
+            "bmt_clipit",
+            "numpy"
         ],
         "modelscope.models.cv.language_guided_video_summarization.transformer.layers": [
             "torch"
         ],
         "modelscope.models.cv.language_guided_video_summarization.transformer.models": [
             "numpy",
             "torch"
@@ -12549,184 +12757,184 @@
         ],
         "modelscope.models.cv.language_guided_video_summarization.transformer.sub_layers": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.motion_generation.model": [],
         "modelscope.models.cv.motion_generation.modules.cfg_sampler": [
-            "copy",
-            "torch"
+            "torch",
+            "copy"
         ],
         "modelscope.models.cv.motion_generation.modules.gaussian_diffusion": [
-            "copy",
-            "torch",
             "math",
+            "torch",
+            "enum",
             "numpy",
-            "enum"
+            "copy"
         ],
         "modelscope.models.cv.motion_generation.modules.mdm": [
-            "numpy",
             "clip",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.motion_generation.modules.respace": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.motion_generation.modules.rotation2xyz": [
             "torch"
         ],
         "modelscope.models.cv.motion_generation.modules.smpl": [
-            "contextlib",
             "os",
-            "smplx",
             "torch",
-            "numpy"
+            "contextlib",
+            "numpy",
+            "smplx"
         ],
         "modelscope.models.cv.movie_scene_segmentation.get_model": [],
         "modelscope.models.cv.movie_scene_segmentation.model": [
-            "torchvision",
             "os",
+            "einops",
             "torch",
-            "math",
-            "numpy",
-            "typing",
+            "shotdetect_scenedetect_lgss",
             "PIL",
-            "einops",
             "tqdm",
-            "shotdetect_scenedetect_lgss"
+            "torchvision",
+            "typing",
+            "numpy",
+            "math"
         ],
         "modelscope.models.cv.movie_scene_segmentation.utils.head": [
             "torch"
         ],
         "modelscope.models.cv.movie_scene_segmentation.utils.save_op": [
-            "subprocess",
             "os",
-            "cv2",
+            "subprocess",
+            "tqdm",
             "numpy",
-            "tqdm"
+            "cv2"
         ],
         "modelscope.models.cv.movie_scene_segmentation.utils.shot_encoder": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.movie_scene_segmentation.utils.trn": [
             "torch",
             "transformers"
         ],
         "modelscope.models.cv.nerf_recon_acc.dataloader.nerf_dataset": [
-            "torchvision",
             "os",
             "torch",
-            "math",
-            "numpy",
             "PIL",
-            "json"
+            "torchvision",
+            "json",
+            "numpy",
+            "math"
         ],
         "modelscope.models.cv.nerf_recon_acc.dataloader.read_write_model": [
             "os",
-            "collections",
-            "numpy",
+            "struct",
             "argparse",
-            "struct"
+            "numpy",
+            "collections"
         ],
         "modelscope.models.cv.nerf_recon_acc.nerf_preprocess": [
             "os",
-            "numpy",
             "subprocess",
-            "typing",
             "cv2",
+            "typing",
             "tensorflow",
-            "glob"
+            "glob",
+            "numpy"
         ],
         "modelscope.models.cv.nerf_recon_acc.nerf_recon_acc": [
             "os",
             "torch",
-            "numpy",
+            "tqdm",
             "cv2",
-            "time",
             "glob",
-            "tqdm"
+            "numpy",
+            "time"
         ],
         "modelscope.models.cv.nerf_recon_acc.network.nerf": [
-            "numpy",
-            "tinycudann",
             "torch",
-            "nerfacc"
+            "numpy",
+            "nerfacc",
+            "tinycudann"
         ],
         "modelscope.models.cv.nerf_recon_acc.network.segmenter": [
             "numpy",
             "tensorflow"
         ],
         "modelscope.models.cv.nerf_recon_acc.network.utils": [
-            "tinycudann",
-            "collections",
             "torch",
             "numpy",
             "mcubes",
-            "gc"
+            "collections",
+            "gc",
+            "tinycudann"
         ],
         "modelscope.models.cv.object_detection.mmdet_model": [
-            "numpy",
             "os",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.backbones.vit": [
             "torch",
-            "math",
             "functools",
+            "mmdet",
             "timm",
-            "mmdet"
+            "math"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.dense_heads.anchor_head": [
             "mmdet"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.dense_heads.rpn_head": [
-            "mmdet",
-            "copy",
             "torch",
-            "mmcv"
+            "mmcv",
+            "mmdet",
+            "copy"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.necks.fpn": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.roi_heads.bbox_heads.convfc_bbox_head": [
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.roi_heads.mask_heads.fcn_mask_head": [
             "torch",
-            "numpy",
-            "mmcv",
+            "mmdet",
             "warnings",
-            "mmdet"
+            "numpy",
+            "mmcv"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.utils.checkpoint": [
-            "torchvision",
             "os",
-            "collections",
             "torch",
+            "mmcv",
             "tempfile",
+            "torchvision",
+            "warnings",
             "importlib",
-            "time",
             "io",
-            "mmcv",
-            "warnings",
-            "pkgutil"
+            "pkgutil",
+            "time",
+            "collections"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.utils.convModule_norm": [
             "mmcv"
         ],
         "modelscope.models.cv.object_detection_3d.depe.depe_detect": [
-            "numpy",
             "os",
             "typing",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.assigners.hungarian_assigner_3d": [
             "torch",
             "scipy",
             "mmdet"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.coders.nms_free_coder": [
@@ -12735,374 +12943,410 @@
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.match_costs.match_cost": [
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.util": [
             "numpy",
-            "mmdet3d",
-            "torch"
+            "torch",
+            "mmdet3d"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.nuscenes_dataset": [
-            "numpy",
             "mmdet3d",
+            "numpy",
             "mmdet"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.loading": [
             "numpy",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.transform_3d": [
-            "PIL",
-            "mmdet3d",
-            "copy",
             "torch",
-            "mmcv",
+            "mmdet3d",
             "numpy",
-            "mmdet"
+            "PIL",
+            "mmcv",
+            "mmdet",
+            "copy"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.backbones.vovnet": [
-            "mmdet",
-            "collections",
             "torch",
-            "mmcv"
+            "mmcv",
+            "collections",
+            "mmdet"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.dense_heads.depth_net": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.dense_heads.petrv2_dednhead": [
             "torch",
+            "mmdet",
+            "copy",
             "math",
-            "numpy",
             "mmdet3d",
-            "copy",
-            "mmcv",
-            "mmdet"
+            "numpy",
+            "mmcv"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.detectors.petr3d": [
             "torch",
-            "numpy",
+            "mmdet",
             "mmdet3d",
-            "mmcv",
-            "mmdet"
+            "numpy",
+            "mmcv"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.necks.cp_fpn": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer": [
-            "typing",
-            "copy",
             "torch",
+            "warnings",
+            "typing",
             "math",
             "mmcv",
-            "warnings",
-            "mmdet"
+            "mmdet",
+            "copy"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.positional_encoding": [
-            "torch",
             "math",
-            "mmcv"
+            "mmcv",
+            "torch"
         ],
         "modelscope.models.cv.object_detection_3d.depe.result_vis": [
             "os",
             "pyquaternion",
             "argparse",
-            "numpy",
-            "mmdet3d",
             "cv2",
-            "pickle",
-            "json"
+            "json",
+            "mmdet3d",
+            "numpy",
+            "pickle"
         ],
         "modelscope.models.cv.ocr_detection.model": [
-            "numpy",
             "os",
             "typing",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.ocr_detection.modules.dbnet": [
             "os",
-            "collections",
             "torch",
             "math",
-            "sys"
+            "sys",
+            "collections"
         ],
-        "modelscope.models.cv.ocr_detection.modules.seg_detector_loss": [
+        "modelscope.models.cv.ocr_detection.modules.layers": [
+            "numpy",
+            "torch",
+            "collections"
+        ],
+        "modelscope.models.cv.ocr_detection.modules.mix_ops": [
+            "math",
+            "torch",
+            "numpy"
+        ],
+        "modelscope.models.cv.ocr_detection.modules.proxyless": [
+            "torch",
             "sys",
-            "torch"
+            "re",
+            "numpy"
+        ],
+        "modelscope.models.cv.ocr_detection.modules.seg_detector_loss": [
+            "torch",
+            "sys"
         ],
         "modelscope.models.cv.ocr_detection.preprocessor": [
             "os",
             "torch",
-            "math",
-            "numpy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.models.cv.ocr_detection.utils": [
+            "shapely",
             "numpy",
             "pyclipper",
-            "cv2",
-            "shapely"
+            "cv2"
         ],
         "modelscope.models.cv.ocr_recognition.model": [
             "os",
             "torch"
         ],
-        "modelscope.models.cv.ocr_recognition.modules.convnext": [
+        "modelscope.models.cv.ocr_recognition.modules.CRNN.main_model": [
             "torch"
         ],
-        "modelscope.models.cv.ocr_recognition.modules.convnextvit": [
+        "modelscope.models.cv.ocr_recognition.modules.ConvNextViT.convnext": [
             "torch"
         ],
-        "modelscope.models.cv.ocr_recognition.modules.crnn": [
+        "modelscope.models.cv.ocr_recognition.modules.ConvNextViT.main_model": [
             "torch"
         ],
-        "modelscope.models.cv.ocr_recognition.modules.timm_tinyc": [
-            "copy",
-            "collections",
+        "modelscope.models.cv.ocr_recognition.modules.ConvNextViT.timm_tinyc": [
             "torch",
+            "itertools",
+            "logging",
             "math",
             "functools",
-            "itertools",
-            "logging"
+            "collections",
+            "copy"
         ],
-        "modelscope.models.cv.ocr_recognition.modules.vitstr": [
+        "modelscope.models.cv.ocr_recognition.modules.ConvNextViT.vitstr": [
             "torch",
-            "functools",
             "__future__",
-            "copy",
-            "logging"
+            "logging",
+            "functools",
+            "copy"
+        ],
+        "modelscope.models.cv.ocr_recognition.modules.LightweightEdge.main_model": [
+            "torch",
+            "collections"
+        ],
+        "modelscope.models.cv.ocr_recognition.modules.LightweightEdge.nas_block.layers": [
+            "numpy",
+            "torch",
+            "collections"
+        ],
+        "modelscope.models.cv.ocr_recognition.modules.LightweightEdge.nas_block.mix_ops": [
+            "numpy",
+            "torch"
+        ],
+        "modelscope.models.cv.ocr_recognition.modules.LightweightEdge.nas_block.proxyless": [
+            "torch",
+            "queue",
+            "numpy",
+            "sys",
+            "re"
         ],
         "modelscope.models.cv.ocr_recognition.preprocessor": [
             "os",
             "torch",
-            "numpy",
             "PIL",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.open_vocabulary_detection_vild.vild": [
             "os",
-            "clip",
             "torch",
-            "numpy",
+            "clip",
             "scipy",
             "typing",
-            "tensorflow"
+            "tensorflow",
+            "numpy"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.equi": [
-            "numpy",
+            "torch",
             "__future__",
             "collections",
-            "torch"
+            "numpy"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.layers": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.mobilenet": [
             "torch"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.resnet": [
             "torch"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.unifuse": [
-            "numpy",
+            "torch",
             "__future__",
             "collections",
-            "torch"
+            "numpy"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.util": [
             "numpy",
-            "cv2",
-            "scipy"
+            "scipy",
+            "cv2"
         ],
         "modelscope.models.cv.panorama_depth_estimation.unifuse_model": [
-            "numpy",
-            "torchvision",
             "os",
-            "torch"
+            "torch",
+            "numpy",
+            "torchvision"
         ],
         "modelscope.models.cv.pedestrian_attribute_recognition.model": [
-            "numpy",
-            "torchvision",
             "os",
-            "torch"
+            "torch",
+            "numpy",
+            "torchvision"
         ],
         "modelscope.models.cv.pointcloud_sceneflow_estimation.common": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.pointcloud_sceneflow_estimation.pointnet2_utils": [
+            "torch",
             "typing",
-            "pointnet2_cuda",
-            "torch"
+            "pointnet2_cuda"
         ],
         "modelscope.models.cv.pointcloud_sceneflow_estimation.rcp_model": [
-            "numpy",
             "os",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.pointcloud_sceneflow_estimation.sf_rcp": [
             "torch"
         ],
         "modelscope.models.cv.product_retrieval_embedding.item_detection": [
             "numpy",
             "cv2"
         ],
         "modelscope.models.cv.product_retrieval_embedding.item_embedding": [
             "numpy",
-            "cv2",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.models.cv.product_retrieval_embedding.item_model": [
-            "numpy",
             "os",
             "typing",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.product_segmentation.net": [
             "torch"
         ],
         "modelscope.models.cv.product_segmentation.seg_infer": [
+            "torch",
             "numpy",
             "PIL",
-            "cv2",
-            "torch"
+            "cv2"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.model": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.backbone": [
-            "torchvision",
+            "einops",
             "torch",
-            "einops"
+            "torchvision"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.criterion": [
             "torch"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.matcher": [
             "torch",
             "scipy"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.misc": [
-            "typing",
-            "torchvision",
+            "torch",
             "pickle",
-            "torch"
+            "typing",
+            "torchvision"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.mttr": [
-            "torch",
-            "einops"
+            "einops",
+            "torch"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.multimodal_transformer": [
             "os",
+            "einops",
             "torch",
-            "transformers",
-            "typing",
             "copy",
-            "einops"
+            "typing",
+            "transformers"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.position_encoding_2d": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.postprocessing": [
+            "einops",
             "numpy",
-            "pycocotools",
             "torch",
-            "einops"
+            "pycocotools"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.segmentation": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.swin_transformer": [
             "operator",
             "torch",
             "einops",
-            "functools",
+            "timm",
             "numpy",
-            "timm"
+            "functools"
         ],
         "modelscope.models.cv.robust_image_classification.easyrobust_model": [
             "os",
             "torch"
         ],
         "modelscope.models.cv.salient_detection.models.backbone.Res2Net_v1b": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.salient_detection.models.modules": [
             "torch"
         ],
         "modelscope.models.cv.salient_detection.models.senet": [
             "torch"
         ],
         "modelscope.models.cv.salient_detection.models.u2net": [
             "torch"
         ],
         "modelscope.models.cv.salient_detection.models.utils": [
             "torch"
         ],
         "modelscope.models.cv.salient_detection.salient_model": [
-            "torchvision",
             "os",
             "torch",
-            "PIL",
-            "cv2"
+            "cv2",
+            "torchvision",
+            "PIL"
         ],
         "modelscope.models.cv.shop_segmentation.common": [
             "warnings",
             "torch"
         ],
         "modelscope.models.cv.shop_segmentation.head_fpn": [
-            "numpy",
-            "mmcv",
+            "timm",
             "torch",
-            "timm"
+            "mmcv",
+            "numpy"
         ],
         "modelscope.models.cv.shop_segmentation.models": [
-            "collections",
-            "torch",
+            "timm",
             "math",
-            "timm"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.shop_segmentation.neck_fpn": [
-            "mmcv",
+            "timm",
             "torch",
-            "timm"
+            "mmcv"
         ],
         "modelscope.models.cv.shop_segmentation.shop_seg_base": [
             "torch"
         ],
         "modelscope.models.cv.shop_segmentation.shop_seg_model": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "json",
             "typing",
-            "json"
+            "numpy",
+            "PIL"
         ],
         "modelscope.models.cv.shop_segmentation.utils": [
-            "ftfy",
+            "gzip",
             "os",
             "torch",
             "functools",
-            "gzip",
-            "html",
+            "ftfy",
             "typing",
-            "regex"
+            "regex",
+            "html"
         ],
         "modelscope.models.cv.skin_retouching.detection_model.detection_module": [
             "torch"
         ],
         "modelscope.models.cv.skin_retouching.detection_model.detection_unet_in": [
             "torch"
         ],
@@ -13114,74 +13358,74 @@
         ],
         "modelscope.models.cv.skin_retouching.retinaface.box_utils": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.net": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.network": [
+            "torch",
             "typing",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.predict_single": [
-            "torchvision",
             "torch",
-            "numpy",
+            "torchvision",
             "albumentations",
-            "typing"
+            "typing",
+            "numpy"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.prior_box": [
             "torch",
-            "math",
-            "itertools"
+            "itertools",
+            "math"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.utils": [
-            "typing",
-            "cv2",
-            "re",
             "torch",
             "pathlib",
-            "numpy"
+            "typing",
+            "numpy",
+            "re",
+            "cv2"
         ],
         "modelscope.models.cv.skin_retouching.unet_deploy": [
             "warnings",
             "torch"
         ],
         "modelscope.models.cv.skin_retouching.utils": [
-            "typing",
-            "cv2",
-            "time",
             "torch",
             "einops",
-            "numpy"
+            "typing",
+            "numpy",
+            "time",
+            "cv2"
         ],
         "modelscope.models.cv.skin_retouching.weights_init": [
             "torch"
         ],
         "modelscope.models.cv.stream_yolo.data.data_augment": [
-            "numpy",
-            "cv2",
             "math",
-            "random"
+            "numpy",
+            "random",
+            "cv2"
         ],
         "modelscope.models.cv.stream_yolo.exp.base_exp": [
-            "abc",
-            "torch"
+            "torch",
+            "abc"
         ],
         "modelscope.models.cv.stream_yolo.exp.build": [
-            "sys",
-            "os"
+            "os",
+            "sys"
         ],
         "modelscope.models.cv.stream_yolo.exp.default.streamyolo": [
-            "sys",
             "os",
+            "sys",
             "torch"
         ],
         "modelscope.models.cv.stream_yolo.exp.yolox_base": [
             "os",
             "torch",
             "random"
         ],
@@ -13199,130 +13443,130 @@
         ],
         "modelscope.models.cv.stream_yolo.models.tal_head": [
             "torch"
         ],
         "modelscope.models.cv.stream_yolo.realtime_video_detector": [
             "os",
             "torch",
+            "tqdm",
+            "logging",
             "argparse",
-            "numpy",
             "cv2",
-            "time",
             "json",
-            "logging",
-            "tqdm"
+            "numpy",
+            "time"
         ],
         "modelscope.models.cv.stream_yolo.utils.boxes": [
-            "torchvision",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.stream_yolo.utils.format": [
             "math"
         ],
         "modelscope.models.cv.super_resolution.arch_util": [
-            "torchvision",
-            "collections",
             "torch",
-            "math",
+            "warnings",
             "itertools",
-            "warnings"
+            "math",
+            "collections",
+            "torchvision"
         ],
         "modelscope.models.cv.super_resolution.ecb": [
             "torch"
         ],
         "modelscope.models.cv.super_resolution.ecbsr_model": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.super_resolution.rrdbnet_arch": [
             "torch"
         ],
         "modelscope.models.cv.table_recognition.lineless_table_process": [
             "numpy",
             "shapely",
-            "cv2",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.models.cv.table_recognition.model_lore": [
             "os",
             "torch",
+            "copy",
             "math",
-            "numpy",
             "typing",
-            "copy"
+            "numpy"
         ],
         "modelscope.models.cv.table_recognition.modules.lore_detector": [
+            "math",
             "os",
-            "copy",
             "torch",
-            "math",
-            "numpy"
+            "numpy",
+            "copy"
         ],
         "modelscope.models.cv.table_recognition.modules.lore_processor": [
+            "math",
             "os",
-            "copy",
             "torch",
-            "math",
-            "numpy"
+            "numpy",
+            "copy"
         ],
         "modelscope.models.cv.text_driven_segmentation.clip": [
-            "torchvision",
             "os",
-            "urllib",
             "torch",
-            "pkg_resources",
+            "tqdm",
             "hashlib",
+            "urllib",
+            "torchvision",
+            "warnings",
             "typing",
             "PIL",
-            "warnings",
-            "tqdm"
+            "pkg_resources"
         ],
         "modelscope.models.cv.text_driven_segmentation.lseg_base": [
             "torch"
         ],
         "modelscope.models.cv.text_driven_segmentation.lseg_blocks": [
             "torch"
         ],
         "modelscope.models.cv.text_driven_segmentation.lseg_model": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "json",
             "typing",
-            "json"
+            "numpy",
+            "PIL"
         ],
         "modelscope.models.cv.text_driven_segmentation.lseg_net": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.text_driven_segmentation.lseg_vit": [
-            "types",
+            "timm",
             "torch",
-            "math",
-            "timm"
+            "types",
+            "math"
         ],
         "modelscope.models.cv.text_driven_segmentation.model": [
             "numpy",
             "typing",
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.text_driven_segmentation.simple_tokenizer": [
-            "ftfy",
+            "gzip",
             "os",
-            "functools",
+            "ftfy",
             "regex",
-            "gzip",
+            "functools",
             "html"
         ],
         "modelscope.models.cv.tinynas_classfication.basic_blocks": [
             "numpy",
-            "torch",
-            "uuid"
+            "uuid",
+            "torch"
         ],
         "modelscope.models.cv.tinynas_classfication.global_utils": [],
         "modelscope.models.cv.tinynas_classfication.master_net": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_classfication.model_zoo": [],
         "modelscope.models.cv.tinynas_classfication.plain_net_utils": [
@@ -13358,38 +13602,38 @@
             "random"
         ],
         "modelscope.models.cv.tinynas_detection.damo.augmentations.box_level_augs.color_augs": [
             "torch",
             "random"
         ],
         "modelscope.models.cv.tinynas_detection.damo.augmentations.box_level_augs.gaussian_maps": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.augmentations.box_level_augs.geometric_augs": [
-            "torchvision",
             "copy",
             "torch",
-            "random"
+            "random",
+            "torchvision"
         ],
         "modelscope.models.cv.tinynas_detection.damo.augmentations.scale_aware_aug": [
             "copy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.backbones.darknet": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.backbones.tinynas_csp": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.backbones.tinynas_res": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.base_ops": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.neck_ops": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.ops": [
             "numpy",
@@ -13409,16 +13653,16 @@
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.weight_init": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.heads.gfocal_v2_tiny": [
             "numpy",
-            "torch",
-            "functools"
+            "functools",
+            "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.heads.zero_head": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.losses.distill_loss": [
             "torch"
         ],
@@ -13427,72 +13671,72 @@
             "functools"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.necks.giraffe_config": [
             "networkx",
             "collections"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.necks.giraffe_fpn": [
-            "collections",
             "torch",
-            "math",
             "functools",
-            "numpy",
+            "math",
+            "typing",
             "timm",
-            "typing"
+            "numpy",
+            "collections"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.necks.giraffe_fpn_btn": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.detectors.detector": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.structures.bounding_box": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.structures.boxlist_ops": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.structures.image_list": [
-            "__future__",
-            "torch"
+            "torch",
+            "__future__"
         ],
         "modelscope.models.cv.tinynas_detection.damo.utils.boxes": [
             "numpy",
-            "torchvision",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.tinynas_detection.damo.utils.model_utils": [
-            "copy",
-            "time",
-            "thop",
             "torch",
-            "math"
+            "thop",
+            "math",
+            "time",
+            "copy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.utils.scheduler": [
             "math"
         ],
         "modelscope.models.cv.tinynas_detection.detector": [
-            "torchvision",
             "os",
             "pickle",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.tinynas_detection.tinynas_damoyolo": [],
         "modelscope.models.cv.tinynas_detection.tinynas_detector": [],
         "modelscope.models.cv.tinynas_detection.utils": [
             "os",
-            "easydict",
+            "importlib",
             "tempfile",
             "shutil",
-            "sys",
-            "importlib"
+            "easydict",
+            "sys"
         ],
         "modelscope.models.cv.video_deinterlace.UNet_for_video_deinterlace": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "copy"
         ],
         "modelscope.models.cv.video_deinterlace.deinterlace_arch": [
             "torch"
         ],
         "modelscope.models.cv.video_deinterlace.models.archs": [
@@ -13515,18 +13759,18 @@
         "modelscope.models.cv.video_depth_estimation.configs.default_config": [
             "os",
             "yacs"
         ],
         "modelscope.models.cv.video_depth_estimation.dro_model": [
             "os",
             "torch",
-            "numpy",
+            "tqdm",
             "cv2",
             "glob",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.models.cv.video_depth_estimation.geometry.camera": [
             "torch",
             "functools"
         ],
         "modelscope.models.cv.video_depth_estimation.geometry.camera_utils": [
             "torch"
@@ -13535,123 +13779,123 @@
             "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.geometry.pose_utils": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.models.model_checkpoint": [
-            "numpy",
             "os",
+            "torch",
             "re",
-            "torch"
+            "numpy"
         ],
         "modelscope.models.cv.video_depth_estimation.models.model_utils": [],
         "modelscope.models.cv.video_depth_estimation.models.model_wrapper": [
-            "collections",
             "torch",
-            "numpy",
             "importlib",
+            "numpy",
+            "collections",
             "random"
         ],
         "modelscope.models.cv.video_depth_estimation.models.sfm_model_mf": [
             "torch",
             "random"
         ],
         "modelscope.models.cv.video_depth_estimation.models.sup_model_mf": [],
         "modelscope.models.cv.video_depth_estimation.networks.depth_pose.depth_pose_net": [
             "torch",
             "functools"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.layers.resnet.depth_decoder": [
-            "numpy",
+            "torch",
             "__future__",
             "collections",
-            "torch"
+            "numpy"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.layers.resnet.layers": [
-            "__future__",
-            "torch"
+            "torch",
+            "__future__"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.layers.resnet.pose_decoder": [
+            "torch",
             "__future__",
-            "collections",
-            "torch"
+            "collections"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.layers.resnet.resnet_encoder": [
             "numpy",
-            "torchvision",
             "__future__",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.optim.extractor": [
-            "torchvision",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.optim.update": [
             "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.augmentations": [
+            "cv2",
             "torchvision",
             "numpy",
             "PIL",
-            "cv2",
             "random"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.config": [
             "os",
             "torch",
             "datetime",
             "yacs"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.depth": [
-            "numpy",
-            "torchvision",
+            "torch",
             "matplotlib",
-            "torch"
+            "numpy",
+            "torchvision"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.horovod": [
             "horovod"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.image": [
             "os",
             "torch",
             "functools",
+            "cv2",
             "numpy",
-            "PIL",
-            "cv2"
+            "PIL"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.image_gt": [
-            "PIL",
-            "cv2",
             "torch",
-            "functools"
+            "functools",
+            "PIL",
+            "cv2"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.load": [
             "os",
-            "collections",
             "torch",
-            "importlib",
             "inspect",
+            "logging",
             "warnings",
-            "logging"
+            "importlib",
+            "collections"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.misc": [
             "termcolor"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.types": [
             "numpy",
             "torch",
             "yacs"
         ],
         "modelscope.models.cv.video_frame_interpolation.VFINet_arch": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.VFINet_for_video_frame_interpolation": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "copy"
         ],
         "modelscope.models.cv.video_frame_interpolation.flow_model.corr": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.flow_model.extractor": [
@@ -13661,123 +13905,123 @@
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.flow_model.update": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.interp_model.IFNet_swin": [
+            "timm",
             "numpy",
-            "torch",
-            "timm"
+            "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.interp_model.UNet": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.interp_model.flow_reversal": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.interp_model.refinenet_arch": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.interp_model.transformer_layers": [
             "torch",
+            "timm",
             "math",
-            "functools",
             "sys",
-            "timm"
+            "functools"
         ],
         "modelscope.models.cv.video_frame_interpolation.utils.scene_change_detection": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.utils.utils": [
             "numpy",
             "torch",
             "scipy"
         ],
         "modelscope.models.cv.video_human_matting.model": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing"
+            "torchvision",
+            "typing",
+            "numpy"
         ],
         "modelscope.models.cv.video_human_matting.models.decoder": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.video_human_matting.models.deep_guided_filter": [
             "torch"
         ],
         "modelscope.models.cv.video_human_matting.models.effv2": [
             "torch"
         ],
         "modelscope.models.cv.video_human_matting.models.lraspp": [
             "torch"
         ],
         "modelscope.models.cv.video_human_matting.models.matting": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.video_inpainting.inpainting": [
-            "PIL",
-            "torchvision",
             "os",
-            "cv2",
-            "time",
             "torch",
-            "numpy"
+            "torchvision",
+            "numpy",
+            "PIL",
+            "time",
+            "cv2"
         ],
         "modelscope.models.cv.video_inpainting.inpainting_model": [
-            "numpy",
-            "torchvision",
+            "math",
             "torch",
-            "math"
+            "numpy",
+            "torchvision"
         ],
         "modelscope.models.cv.video_instance_segmentation.head.kernel_frame_iter_head": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.video_instance_segmentation.head.kernel_head": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.video_instance_segmentation.head.kernel_iter_head": [
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.video_instance_segmentation.head.kernel_update_head": [
-            "numpy",
-            "mmdet",
             "torch",
-            "mmcv"
+            "mmcv",
+            "mmdet",
+            "numpy"
         ],
         "modelscope.models.cv.video_instance_segmentation.head.kernel_updator": [
             "torch",
             "mmcv"
         ],
         "modelscope.models.cv.video_instance_segmentation.neck.msdeformattn_decoder": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.video_instance_segmentation.track.kernel_update_head": [
-            "numpy",
-            "mmdet",
             "torch",
-            "mmcv"
+            "mmcv",
+            "mmdet",
+            "numpy"
         ],
         "modelscope.models.cv.video_instance_segmentation.track.mask_hungarian_assigner": [
             "numpy",
-            "mmdet",
+            "torch",
             "scipy",
-            "torch"
+            "mmdet"
         ],
         "modelscope.models.cv.video_instance_segmentation.utils": [
             "numpy",
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.video_instance_segmentation.video_knet": [
@@ -13790,44 +14034,44 @@
         "modelscope.models.cv.video_multi_object_tracking.models.decode": [
             "torch"
         ],
         "modelscope.models.cv.video_multi_object_tracking.models.model": [
             "torch"
         ],
         "modelscope.models.cv.video_multi_object_tracking.models.yolo": [
-            "copy",
+            "math",
             "torch",
-            "math"
+            "copy"
         ],
         "modelscope.models.cv.video_multi_object_tracking.tracker.basetrack": [
             "numpy",
             "collections"
         ],
         "modelscope.models.cv.video_multi_object_tracking.tracker.matching": [
             "numpy",
             "lap",
             "scipy"
         ],
         "modelscope.models.cv.video_multi_object_tracking.tracker.multitracker": [
             "numpy",
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.video_multi_object_tracking.utils.image": [
             "numpy",
             "cv2"
         ],
         "modelscope.models.cv.video_multi_object_tracking.utils.kalman_filter": [
             "numpy",
             "scipy"
         ],
         "modelscope.models.cv.video_multi_object_tracking.utils.utils": [
             "numpy",
-            "cv2",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.models.cv.video_multi_object_tracking.utils.visualization": [
             "numpy",
             "cv2"
         ],
         "modelscope.models.cv.video_object_segmentation.aggregate": [
             "torch"
@@ -13838,125 +14082,125 @@
         "modelscope.models.cv.video_object_segmentation.eval_network": [
             "torch"
         ],
         "modelscope.models.cv.video_object_segmentation.inference_core": [
             "torch"
         ],
         "modelscope.models.cv.video_object_segmentation.inference_memory_bank": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.video_object_segmentation.mod_resnet": [
-            "collections",
+            "math",
             "torch",
-            "math"
+            "collections"
         ],
         "modelscope.models.cv.video_object_segmentation.model": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.video_object_segmentation.modules": [
-            "torchvision",
-            "torch"
+            "torch",
+            "torchvision"
         ],
         "modelscope.models.cv.video_object_segmentation.network": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.backbone.swin_checkpoint": [
-            "torchvision",
             "os",
-            "collections",
             "torch",
             "importlib",
-            "pkgutil"
+            "pkgutil",
+            "collections",
+            "torchvision"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.backbone.swin_transformer": [
-            "numpy",
-            "mmdet",
+            "timm",
             "torch",
-            "timm"
+            "mmdet",
+            "numpy"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.kernel_head": [
             "torch",
             "mmcv"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.kernel_iter_head": [
             "torch",
             "mmdet"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.kernel_update_head": [
-            "numpy",
-            "mmdet",
             "torch",
-            "mmcv"
+            "mmcv",
+            "mmdet",
+            "numpy"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.kernel_updator": [
             "torch",
             "mmcv"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.mask": [
-            "pycocotools",
-            "cv2",
-            "__future__",
             "torch",
-            "numpy"
+            "__future__",
+            "cv2",
+            "numpy",
+            "pycocotools"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.semantic_fpn_wrapper": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.track_heads": [
             "numpy",
-            "torch",
-            "mmcv"
+            "mmcv",
+            "torch"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.neck.fpn": [
             "torch",
             "mmcv"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.track.quasi_dense_embed_tracker": [
             "torch",
-            "mmdet",
-            "mmcv"
+            "mmcv",
+            "mmdet"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.video_k_net": [
-            "numpy",
-            "mmdet",
             "torch",
-            "mmcv"
+            "mmcv",
+            "mmdet",
+            "numpy"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.visualizer": [
             "numpy",
-            "cv2",
-            "hashlib"
+            "hashlib",
+            "cv2"
         ],
         "modelscope.models.cv.video_single_object_tracking.config.ostrack": [
             "easydict"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.layers.attn": [
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.layers.attn_blocks": [
-            "torch",
+            "timm",
             "math",
-            "timm"
+            "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.layers.head": [
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.layers.patch_embed": [
-            "torch",
-            "timm"
+            "timm",
+            "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.ostrack.base_backbone": [
-            "torch",
-            "timm"
+            "timm",
+            "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.ostrack.ostrack": [
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.ostrack.utils": [
             "torch"
         ],
@@ -13976,36 +14220,36 @@
             "torch",
             "functools"
         ],
         "modelscope.models.cv.video_single_object_tracking.tracker.ostrack": [
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.tracker.procontext": [
-            "copy",
-            "torch"
+            "torch",
+            "copy"
         ],
         "modelscope.models.cv.video_single_object_tracking.utils.utils": [
-            "typing",
-            "cv2",
-            "torch",
             "math",
-            "numpy"
+            "torch",
+            "typing",
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.video_stabilization.DUT.DUT_raft": [
-            "numpy",
+            "torch",
             "sys",
-            "cv2",
-            "torch"
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.video_stabilization.DUT.MotionPro": [
             "os",
             "torch",
-            "math",
+            "cv2",
             "numpy",
-            "cv2"
+            "math"
         ],
         "modelscope.models.cv.video_stabilization.DUT.RAFT.corr": [
             "torch",
             "alt_cuda_corr"
         ],
         "modelscope.models.cv.video_stabilization.DUT.RAFT.extractor": [
             "torch"
@@ -14014,162 +14258,162 @@
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.video_stabilization.DUT.RAFT.update": [
             "torch"
         ],
         "modelscope.models.cv.video_stabilization.DUT.Smoother": [
-            "numpy",
+            "math",
             "torch",
-            "math"
+            "numpy"
         ],
         "modelscope.models.cv.video_stabilization.DUT.config": [
-            "__future__",
-            "easydict"
+            "easydict",
+            "__future__"
         ],
         "modelscope.models.cv.video_stabilization.DUT.rf_det_module": [
             "torch"
         ],
         "modelscope.models.cv.video_stabilization.DUT.rf_det_so": [
             "torch"
         ],
         "modelscope.models.cv.video_stabilization.DUTRAFTStabilizer": [
             "os",
             "torch",
-            "math",
             "tempfile",
-            "sys",
-            "numpy",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "math",
+            "sys"
         ],
         "modelscope.models.cv.video_stabilization.utils.IterativeSmooth": [
-            "numpy",
             "os",
+            "math",
             "torch",
-            "math"
+            "numpy"
         ],
         "modelscope.models.cv.video_stabilization.utils.MedianFilter": [
-            "numpy",
-            "cv2",
+            "math",
             "torch",
-            "math"
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.video_stabilization.utils.ProjectionUtils": [
-            "numpy",
-            "cv2",
+            "math",
             "torch",
-            "math"
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.video_stabilization.utils.RAFTUtils": [
             "numpy",
             "torch",
             "scipy"
         ],
         "modelscope.models.cv.video_stabilization.utils.WarpUtils": [
             "numpy",
             "torch",
             "tqdm"
         ],
         "modelscope.models.cv.video_stabilization.utils.image_utils": [
-            "skimage",
-            "torch"
+            "torch",
+            "skimage"
         ],
         "modelscope.models.cv.video_stabilization.utils.math_utils": [
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.video_streaming_perception.longshortnet.exp.longshortnet_base": [],
         "modelscope.models.cv.video_streaming_perception.longshortnet.longshortnet": [
             "os",
             "torch",
+            "tqdm",
+            "logging",
             "argparse",
-            "numpy",
             "cv2",
-            "time",
             "json",
-            "logging",
-            "tqdm"
+            "numpy",
+            "time"
         ],
         "modelscope.models.cv.video_streaming_perception.longshortnet.models.dfp_pafpn_long": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.video_streaming_perception.longshortnet.models.dfp_pafpn_short": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.video_streaming_perception.longshortnet.models.longshort": [
             "torch"
         ],
         "modelscope.models.cv.video_streaming_perception.longshortnet.models.longshort_backbone_neck": [
             "torch"
         ],
         "modelscope.models.cv.video_summarization.base_model": [
             "numpy",
-            "cv2",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.models.cv.video_summarization.kts.cpd_auto": [
             "numpy"
         ],
         "modelscope.models.cv.video_summarization.kts.cpd_nonlin": [
             "numpy"
         ],
         "modelscope.models.cv.video_summarization.pgl_sum": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.video_summarization.summarizer": [
-            "numpy",
             "os",
             "typing",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.video_super_resolution.basicvsr_net": [
             "torch"
         ],
         "modelscope.models.cv.video_super_resolution.common": [
             "torch"
         ],
         "modelscope.models.cv.video_super_resolution.msrresnet_lite_model": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "functools"
         ],
         "modelscope.models.cv.video_super_resolution.real_basicvsr_for_video_super_resolution": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.cv.video_super_resolution.real_basicvsr_net": [
             "torch"
         ],
         "modelscope.models.cv.vidt.backbone": [
             "os",
             "torch",
-            "math",
+            "timm",
             "numpy",
-            "timm"
+            "math"
         ],
         "modelscope.models.cv.vidt.deformable_transformer": [
-            "copy",
             "torch",
-            "math",
             "warnings",
-            "timm"
+            "timm",
+            "math",
+            "copy"
         ],
         "modelscope.models.cv.vidt.fpn_fusion": [
             "torch"
         ],
         "modelscope.models.cv.vidt.head": [
-            "copy",
+            "math",
             "torch",
-            "math"
+            "copy"
         ],
         "modelscope.models.cv.vidt.model": [
             "os",
             "torch"
         ],
         "modelscope.models.cv.virual_tryon.sdafnet": [
             "numpy",
@@ -14180,1057 +14424,1124 @@
             "torch",
             "functools"
         ],
         "modelscope.models.cv.vision_efficient_tuning.head": [
             "torch"
         ],
         "modelscope.models.cv.vision_efficient_tuning.model": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.vision_efficient_tuning.petl": [
-            "torchvision",
-            "collections",
+            "math",
             "torch",
-            "math"
+            "collections",
+            "torchvision"
         ],
         "modelscope.models.cv.vision_efficient_tuning.timm_helpers": [
-            "typing",
-            "torch",
+            "itertools",
             "math",
-            "itertools"
+            "typing",
+            "torch"
         ],
         "modelscope.models.cv.vision_efficient_tuning.timm_vision_transformer": [
-            "collections",
             "torch",
-            "math",
-            "itertools",
+            "logging",
             "functools",
-            "logging"
+            "itertools",
+            "math",
+            "collections"
         ],
         "modelscope.models.cv.vision_efficient_tuning.timm_weight_init": [
-            "warnings",
+            "math",
             "torch",
-            "math"
+            "warnings"
         ],
         "modelscope.models.cv.vision_efficient_tuning.vision_efficient_tuning": [
             "os",
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.models.cv.vision_middleware.backbone": [
             "os",
-            "collections",
             "torch",
-            "math",
+            "typing",
             "numpy",
-            "typing"
+            "math",
+            "collections"
         ],
         "modelscope.models.cv.vision_middleware.head": [
             "numpy",
-            "abc",
+            "mmcv",
             "torch",
-            "mmcv"
+            "abc"
         ],
         "modelscope.models.cv.vision_middleware.model": [
-            "typing",
             "os",
-            "json",
-            "torch"
+            "typing",
+            "torch",
+            "json"
         ],
         "modelscope.models.cv.vision_middleware.vim": [
+            "einops",
             "torch",
-            "math",
-            "einops"
+            "math"
         ],
         "modelscope.models.cv.vop_retrieval.backbone": [
             "os",
-            "urllib",
             "torch",
-            "collections",
-            "numpy",
+            "tqdm",
             "hashlib",
-            "typing",
+            "urllib",
             "warnings",
-            "tqdm"
+            "typing",
+            "numpy",
+            "collections"
         ],
         "modelscope.models.cv.vop_retrieval.basic_utils": [
-            "torchvision",
             "os",
-            "collections",
             "torch",
-            "numpy",
-            "shutil",
+            "zipfile",
             "PIL",
             "cv2",
+            "torchvision",
+            "ujson",
+            "shutil",
+            "numpy",
             "pickle",
-            "zipfile",
-            "random",
-            "ujson"
+            "collections",
+            "random"
         ],
         "modelscope.models.cv.vop_retrieval.model": [
             "os",
             "torch"
         ],
         "modelscope.models.cv.vop_retrieval.model_se": [
             "os",
             "torch"
         ],
         "modelscope.models.cv.vop_retrieval.tokenization_clip": [
-            "ftfy",
+            "gzip",
             "os",
             "torch",
-            "functools",
+            "ftfy",
             "regex",
-            "gzip",
+            "functools",
             "html"
         ],
         "modelscope.models.multi_modal.clip.bert_tokenizer": [
             "os",
-            "six",
+            "__future__",
             "collections",
+            "unicodedata",
             "re",
-            "__future__",
-            "unicodedata"
+            "six"
         ],
         "modelscope.models.multi_modal.clip.configuration_bert": [
             "__future__",
             "logging"
         ],
         "modelscope.models.multi_modal.clip.model": [
             "os",
-            "collections",
             "torch",
-            "numpy",
+            "json",
             "typing",
-            "json"
+            "numpy",
+            "collections"
         ],
         "modelscope.models.multi_modal.clip.modeling_bert": [
             "os",
             "torch",
-            "math",
-            "sys",
             "__future__",
-            "json",
             "logging",
-            "io"
+            "json",
+            "io",
+            "math",
+            "sys"
         ],
         "modelscope.models.multi_modal.clip_interrogator.model": [
-            "dataclasses",
-            "torchvision",
             "os",
-            "torch",
-            "hashlib",
-            "transformers",
-            "PIL",
+            "safetensors",
             "open_clip",
-            "tqdm",
-            "math",
+            "requests",
             "numpy",
-            "safetensors",
+            "math",
+            "transformers",
+            "torch",
+            "dataclasses",
+            "tqdm",
+            "hashlib",
+            "torchvision",
             "typing",
-            "time",
-            "requests"
+            "PIL",
+            "time"
         ],
         "modelscope.models.multi_modal.diffusion.diffusion": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.diffusion.model": [
             "os",
             "torch",
-            "numpy",
+            "json",
             "typing",
-            "json"
+            "numpy"
         ],
         "modelscope.models.multi_modal.diffusion.structbert": [
-            "copy",
-            "six",
-            "__future__",
-            "torch",
             "math",
+            "torch",
+            "json",
+            "__future__",
             "numpy",
-            "json"
+            "copy",
+            "six"
         ],
         "modelscope.models.multi_modal.diffusion.tokenizer": [
-            "six",
-            "unicodedata",
+            "__future__",
             "collections",
-            "__future__"
+            "unicodedata",
+            "six"
         ],
         "modelscope.models.multi_modal.diffusion.unet_generator": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.diffusion.unet_upsampler_1024": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.diffusion.unet_upsampler_256": [
-            "torch",
             "math",
+            "torch",
             "functools"
         ],
         "modelscope.models.multi_modal.dpm_solver_pytorch": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.efficient_diffusion_tuning.efficient_stable_diffusion": [
             "os",
             "torch",
             "functools",
+            "typing",
             "diffusers",
-            "transformers",
-            "typing"
+            "transformers"
         ],
         "modelscope.models.multi_modal.gemm.gemm_base": [
             "os",
-            "collections",
             "torch",
-            "numpy",
+            "json",
             "typing",
-            "json"
+            "numpy",
+            "collections"
         ],
         "modelscope.models.multi_modal.gemm.gemm_model": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing",
             "PIL",
-            "json"
+            "torchvision",
+            "json",
+            "typing",
+            "numpy"
         ],
         "modelscope.models.multi_modal.gemm.tokenizer": [
-            "ftfy",
+            "gzip",
             "os",
             "torch",
-            "functools",
+            "ftfy",
             "regex",
-            "gzip",
+            "functools",
             "html"
         ],
         "modelscope.models.multi_modal.guided_diffusion.gaussian_diffusion": [
-            "numpy",
             "enum",
+            "math",
             "torch",
-            "math"
+            "numpy"
         ],
         "modelscope.models.multi_modal.guided_diffusion.respace": [
             "numpy",
             "torch"
         ],
         "modelscope.models.multi_modal.guided_diffusion.script": [],
         "modelscope.models.multi_modal.guided_diffusion.unet": [
-            "abc",
             "torch",
-            "math",
+            "abc",
             "numpy",
+            "math",
             "transformers"
         ],
         "modelscope.models.multi_modal.mgeo.backbone": [
-            "dataclasses",
             "os",
             "torch",
-            "math",
-            "transformers",
+            "dataclasses",
+            "warnings",
             "typing",
+            "math",
             "random",
-            "warnings"
+            "transformers"
         ],
         "modelscope.models.multi_modal.mgeo.text_classification": [
             "torch"
         ],
         "modelscope.models.multi_modal.mgeo.text_ranking": [
             "torch"
         ],
         "modelscope.models.multi_modal.mgeo.token_classification": [
             "torch"
         ],
         "modelscope.models.multi_modal.mmr.dataloaders.rawvideo_util": [
-            "torchvision",
             "torch",
-            "numpy",
             "PIL",
-            "cv2"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.multi_modal.mmr.models.clip_for_mm_video_embedding": [
             "os",
-            "urllib",
             "torch",
-            "numpy",
+            "PIL",
             "tempfile",
+            "uuid",
             "decord",
+            "urllib",
+            "json",
             "typing",
-            "PIL",
-            "uuid",
-            "random",
-            "json"
+            "numpy",
+            "random"
         ],
         "modelscope.models.multi_modal.mmr.models.dynamic_inverted_softmax": [
             "numpy"
         ],
         "modelscope.models.multi_modal.mmr.models.modeling": [
             "os",
-            "collections",
             "torch",
+            "collections",
             "platform",
             "types"
         ],
         "modelscope.models.multi_modal.mmr.models.module_clip": [
             "os",
-            "urllib",
             "torch",
-            "collections",
+            "tqdm",
             "hashlib",
-            "typing",
+            "urllib",
             "warnings",
-            "tqdm"
+            "typing",
+            "collections"
         ],
         "modelscope.models.multi_modal.mmr.models.module_cross": [
-            "collections",
             "torch",
             "__future__",
+            "logging",
             "json",
-            "logging"
+            "collections"
         ],
         "modelscope.models.multi_modal.mmr.models.tokenization_clip": [
-            "ftfy",
+            "gzip",
             "os",
-            "functools",
+            "ftfy",
             "regex",
-            "gzip",
+            "functools",
             "html"
         ],
         "modelscope.models.multi_modal.mmr.models.until_module": [
+            "math",
             "numpy",
-            "torch",
             "logging",
-            "math"
+            "torch"
         ],
         "modelscope.models.multi_modal.mplug.clip.clip": [
+            "torch",
             "typing",
-            "collections",
-            "torch"
+            "collections"
         ],
         "modelscope.models.multi_modal.mplug.configuration_mplug": [
-            "typing",
-            "os",
             "yaml",
+            "os",
+            "typing",
             "transformers"
         ],
         "modelscope.models.multi_modal.mplug.modeling_mplug": [
             "os",
             "torch",
+            "typing",
             "math",
-            "transformers",
-            "typing"
+            "transformers"
         ],
         "modelscope.models.multi_modal.mplug.mvit": [
-            "collections",
             "torch",
+            "numpy",
+            "timm",
             "fairscale",
             "functools",
-            "numpy",
-            "timm"
+            "collections"
         ],
         "modelscope.models.multi_modal.mplug.predictor": [
-            "__future__",
-            "torch"
+            "torch",
+            "__future__"
         ],
         "modelscope.models.multi_modal.mplug_for_all_tasks": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.multi_modal.mplug_owl.configuration_mplug_owl": [
-            "typing",
             "os",
+            "typing",
             "copy",
             "transformers"
         ],
         "modelscope.models.multi_modal.mplug_owl.modeling_mplug_owl": [
-            "dataclasses",
             "os",
             "torch",
-            "math",
-            "transformers",
-            "typing",
+            "dataclasses",
+            "logging",
             "copy",
+            "typing",
+            "io",
+            "math",
             "random",
-            "logging",
-            "io"
+            "transformers"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.clip": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.decoder": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.gaussian_diffusion": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.model": [
             "os",
             "torch",
-            "math",
-            "numpy",
-            "typing",
             "PIL",
-            "json"
+            "json",
+            "typing",
+            "numpy",
+            "math"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.prior": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.tokenizer": [
-            "ftfy",
+            "gzip",
             "torch",
-            "functools",
+            "ftfy",
             "regex",
-            "gzip",
+            "functools",
             "html",
             "transformers"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.upsampler": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.xglm": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.ofa.configuration_mmspeech": [
             "warnings",
             "transformers"
         ],
         "modelscope.models.multi_modal.ofa.configuration_ofa": [
             "warnings",
             "transformers"
         ],
         "modelscope.models.multi_modal.ofa.generate.incremental_decoding_utils": [
-            "typing",
             "torch",
-            "uuid"
+            "uuid",
+            "typing"
         ],
         "modelscope.models.multi_modal.ofa.generate.multihead_attention": [
+            "math",
             "typing",
-            "fairseq",
             "torch",
-            "math"
+            "fairseq"
         ],
         "modelscope.models.multi_modal.ofa.generate.ngram_repeat_block": [
-            "typing",
-            "fairseq",
             "torch",
+            "warnings",
+            "typing",
             "math",
-            "warnings"
+            "fairseq"
         ],
         "modelscope.models.multi_modal.ofa.generate.search": [
+            "math",
             "typing",
-            "torch",
-            "math"
+            "torch"
         ],
         "modelscope.models.multi_modal.ofa.generate.sequence_generator": [
-            "typing",
-            "sys",
             "torch",
-            "math"
+            "typing",
+            "math",
+            "sys"
         ],
         "modelscope.models.multi_modal.ofa.generate.token_generation_constraints": [
+            "torch",
             "typing",
-            "collections",
-            "torch"
+            "collections"
         ],
         "modelscope.models.multi_modal.ofa.generate.utils": [
-            "collections",
             "torch",
-            "amp_C",
             "itertools",
-            "torch_xla"
+            "amp_C",
+            "torch_xla",
+            "collections"
         ],
         "modelscope.models.multi_modal.ofa.modeling_mmspeech": [
+            "torch",
+            "apex",
             "dataclasses",
+            "packaging",
             "fairseq",
-            "apex",
-            "torch",
-            "math",
-            "numpy",
-            "transformers",
             "typing",
-            "packaging"
+            "numpy",
+            "math",
+            "transformers"
         ],
         "modelscope.models.multi_modal.ofa.modeling_ofa": [
-            "dataclasses",
-            "apex",
             "torch",
-            "math",
-            "transformers",
+            "apex",
+            "dataclasses",
+            "packaging",
             "typing",
+            "math",
             "random",
-            "packaging"
+            "transformers"
         ],
         "modelscope.models.multi_modal.ofa.resnet": [
             "torch"
         ],
         "modelscope.models.multi_modal.ofa.tokenization_ofa": [
-            "typing",
             "os",
+            "typing",
             "collections",
             "transformers"
         ],
         "modelscope.models.multi_modal.ofa.tokenization_ofa_fast": [
-            "typing",
             "json",
+            "typing",
             "tokenizers",
             "transformers"
         ],
         "modelscope.models.multi_modal.ofa.utils.constant": [],
         "modelscope.models.multi_modal.ofa.utils.utils": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.multi_modal.ofa.vit": [
-            "fairseq",
+            "torch",
             "collections",
-            "torch"
+            "fairseq"
         ],
         "modelscope.models.multi_modal.ofa_for_all_tasks": [
             "os",
-            "re",
             "torch",
-            "math",
             "functools",
-            "typing",
             "json",
-            "string"
+            "typing",
+            "string",
+            "math",
+            "re"
         ],
         "modelscope.models.multi_modal.ofa_for_text_to_image_synthesis_model": [
-            "taming",
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "pkg_resources",
-            "typing",
             "PIL",
-            "json"
+            "taming",
+            "torchvision",
+            "json",
+            "typing",
+            "numpy",
+            "pkg_resources"
         ],
         "modelscope.models.multi_modal.rleg.model": [
-            "json",
             "os",
-            "torch"
+            "torch",
+            "json"
         ],
         "modelscope.models.multi_modal.rleg.rleg": [
+            "torch",
             "typing",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.models.multi_modal.soonet.blocks": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.multi_modal.soonet.clip": [
-            "typing",
-            "collections",
             "torch",
+            "warnings",
+            "typing",
             "numpy",
-            "warnings"
+            "collections"
         ],
         "modelscope.models.multi_modal.soonet.model": [
             "os",
             "torch"
         ],
         "modelscope.models.multi_modal.soonet.swin_transformer": [
             "numpy",
             "torch"
         ],
         "modelscope.models.multi_modal.soonet.tokenizer": [
-            "ftfy",
+            "gzip",
             "torch",
-            "functools",
+            "ftfy",
             "regex",
-            "gzip",
+            "functools",
             "html"
         ],
         "modelscope.models.multi_modal.soonet.utils": [
             "numpy",
             "decord",
-            "copy",
-            "tqdm"
+            "tqdm",
+            "copy"
+        ],
+        "modelscope.models.multi_modal.stable_diffusion.stable_diffusion": [
+            "os",
+            "torch",
+            "functools",
+            "typing",
+            "diffusers",
+            "transformers"
         ],
         "modelscope.models.multi_modal.team.team_model": [
-            "torchvision",
             "torch",
-            "numpy",
             "tokenizers",
-            "PIL",
+            "torchvision",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.models.multi_modal.team.utils": [
-            "typing",
-            "collections",
             "torch",
+            "typing",
             "numpy",
+            "collections",
             "transformers"
         ],
         "modelscope.models.multi_modal.video_synthesis.autoencoder": [
             "numpy",
             "torch"
         ],
         "modelscope.models.multi_modal.video_synthesis.diffusion": [
             "torch"
         ],
         "modelscope.models.multi_modal.video_synthesis.text_to_video_synthesis_model": [
             "os",
+            "einops",
             "torch",
             "typing",
-            "einops",
             "open_clip"
         ],
         "modelscope.models.multi_modal.video_synthesis.unet_sd": [
+            "einops",
             "torch",
-            "math",
-            "einops"
+            "math"
         ],
         "modelscope.models.multi_modal.vldoc.conv_fpn_trans": [
-            "apex",
-            "collections",
             "torch",
+            "apex",
             "timm",
+            "collections",
             "random"
         ],
         "modelscope.models.multi_modal.vldoc.convnext": [
+            "timm",
             "os",
-            "torch",
-            "timm"
+            "torch"
         ],
         "modelscope.models.multi_modal.vldoc.model": [
-            "torchvision",
             "os",
-            "re",
             "torch",
-            "math",
-            "sys",
+            "logging",
             "copy",
+            "torchvision",
             "json",
-            "logging"
+            "math",
+            "sys",
+            "re"
         ],
         "modelscope.models.multi_modal.vldoc.modeling_layout_roberta": [
             "os",
             "torch",
-            "math",
             "packaging",
+            "math",
             "transformers"
         ],
         "modelscope.models.multi_modal.vldoc.processing": [
-            "torchvision",
-            "collections",
             "torch",
-            "numpy",
-            "timm",
             "PIL",
+            "cv2",
+            "torchvision",
             "typing",
-            "cv2"
+            "timm",
+            "numpy",
+            "collections"
         ],
         "modelscope.models.multi_modal.vldoc.tokenization": [
             "os",
             "transformers"
         ],
         "modelscope.models.multi_modal.vldoc.transformer_local": [
-            "copy",
-            "torch"
+            "torch",
+            "copy"
         ],
         "modelscope.models.nlp.T5.backbone": [
             "os",
             "torch",
-            "math",
-            "transformers",
-            "typing",
             "copy",
-            "warnings"
+            "warnings",
+            "typing",
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.T5.configuration": [
             "typing",
             "transformers"
         ],
         "modelscope.models.nlp.T5.text2text_generation": [
             "torch",
-            "transformers",
-            "typing",
             "copy",
-            "warnings"
+            "warnings",
+            "typing",
+            "transformers"
         ],
         "modelscope.models.nlp.bart.text_error_correction": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.nlp.bert.backbone": [
             "packaging",
-            "transformers",
             "torch",
-            "math"
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.bert.configuration": [
             "typing",
             "collections",
             "transformers"
         ],
         "modelscope.models.nlp.bert.document_segmentation": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.bert.fill_mask": [],
         "modelscope.models.nlp.bert.sentence_embedding": [
             "torch"
         ],
         "modelscope.models.nlp.bert.siamese_uie": [
-            "copy",
-            "torch"
+            "torch",
+            "copy"
         ],
         "modelscope.models.nlp.bert.text_classification": [],
         "modelscope.models.nlp.bert.text_ranking": [],
         "modelscope.models.nlp.bert.token_classification": [],
         "modelscope.models.nlp.bert.word_alignment": [
             "torch"
         ],
         "modelscope.models.nlp.bloom.backbone": [
             "transformers"
         ],
         "modelscope.models.nlp.canmt.canmt_model": [
+            "torch",
             "typing",
+            "numpy",
             "fairseq",
-            "torch",
-            "math",
-            "numpy"
+            "math"
         ],
         "modelscope.models.nlp.canmt.canmt_translation": [
             "os",
             "torch",
-            "math",
+            "typing",
             "numpy",
-            "typing"
+            "math"
         ],
         "modelscope.models.nlp.canmt.sequence_generator": [
+            "torch",
             "typing",
+            "numpy",
+            "sys",
             "fairseq",
+            "math"
+        ],
+        "modelscope.models.nlp.chatglm.configuration": [
+            "transformers"
+        ],
+        "modelscope.models.nlp.chatglm.quantization": [
+            "bz2",
+            "base64",
+            "torch",
+            "typing",
+            "cpm_kernels",
+            "ctypes",
+            "transformers"
+        ],
+        "modelscope.models.nlp.chatglm.text_generation": [
+            "os",
             "torch",
+            "copy",
+            "warnings",
+            "typing",
             "math",
+            "sys",
+            "re",
+            "transformers"
+        ],
+        "modelscope.models.nlp.chatglm.tokenization": [
+            "os",
+            "typing",
+            "sentencepiece",
             "numpy",
-            "sys"
+            "transformers"
         ],
-        "modelscope.models.nlp.codegeex.codegeex": [
-            "torch",
-            "math"
+        "modelscope.models.nlp.chatglm2.configuration": [
+            "transformers"
         ],
-        "modelscope.models.nlp.codegeex.codegeex_for_code_generation": [
+        "modelscope.models.nlp.chatglm2.quantization": [
+            "base64",
+            "torch",
+            "cpm_kernels",
+            "functools",
+            "bz2",
             "typing",
+            "ctypes",
+            "transformers"
+        ],
+        "modelscope.models.nlp.chatglm2.text_generation": [
+            "torch",
             "copy",
+            "warnings",
+            "typing",
+            "math",
+            "sys",
+            "re",
+            "transformers"
+        ],
+        "modelscope.models.nlp.chatglm2.tokenization": [
+            "os",
+            "typing",
+            "sentencepiece",
+            "transformers"
+        ],
+        "modelscope.models.nlp.codegeex.codegeex": [
+            "math",
             "torch"
         ],
+        "modelscope.models.nlp.codegeex.codegeex_for_code_generation": [
+            "torch",
+            "typing",
+            "copy"
+        ],
         "modelscope.models.nlp.codegeex.codegeex_for_code_translation": [
+            "torch",
             "typing",
-            "copy",
-            "torch"
+            "copy"
         ],
         "modelscope.models.nlp.codegeex.inference": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.codegeex.tokenizer": [
-            "typing",
             "torch",
+            "typing",
             "transformers"
         ],
         "modelscope.models.nlp.csanmt.translation": [
+            "math",
             "typing",
-            "tensorflow",
             "collections",
-            "math"
+            "tensorflow"
         ],
         "modelscope.models.nlp.deberta_v2.backbone": [
+            "torch",
             "typing",
             "collections",
-            "torch",
             "transformers"
         ],
         "modelscope.models.nlp.deberta_v2.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.deberta_v2.fill_mask": [
-            "typing",
             "torch",
+            "typing",
             "transformers"
         ],
         "modelscope.models.nlp.deberta_v2.tokenization": [
+            "os",
             "typing",
             "sentencepiece",
-            "os",
             "unicodedata",
             "transformers"
         ],
         "modelscope.models.nlp.deberta_v2.tokenization_fast": [
-            "typing",
-            "shutil",
             "os",
-            "transformers"
+            "typing",
+            "transformers",
+            "shutil"
         ],
         "modelscope.models.nlp.dgds.backbone": [
             "os",
+            "__future__",
             "torch",
-            "transformers",
-            "__future__"
+            "transformers"
         ],
         "modelscope.models.nlp.dgds.document_grounded_dialog_generate": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.nlp.dgds.document_grounded_dialog_rerank": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.nlp.dgds.document_grounded_dialog_retrieval": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.models.nlp.fid_T5.text_generation": [
+            "io",
             "os",
             "torch",
-            "transformers",
-            "io"
+            "transformers"
         ],
         "modelscope.models.nlp.fid_plug.backbone": [
-            "dataclasses",
             "os",
             "torch",
-            "math",
-            "numpy",
-            "transformers",
+            "dataclasses",
+            "copy",
             "typing",
-            "copy"
+            "numpy",
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.fid_plug.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.fid_plug.text_generation": [
+            "io",
             "os",
             "torch",
-            "transformers",
-            "io"
+            "transformers"
         ],
         "modelscope.models.nlp.glm_130b.generation.strategies": [
             "numpy",
-            "SwissArmyTransformer",
-            "torch"
+            "torch",
+            "SwissArmyTransformer"
         ],
         "modelscope.models.nlp.glm_130b.initialize": [
             "argparse",
+            "torch",
             "time",
-            "SwissArmyTransformer",
-            "torch"
+            "SwissArmyTransformer"
         ],
         "modelscope.models.nlp.glm_130b.quantization.functional": [
             "torch"
         ],
         "modelscope.models.nlp.glm_130b.quantization.layers": [
-            "SwissArmyTransformer",
-            "torch"
+            "torch",
+            "SwissArmyTransformer"
         ],
         "modelscope.models.nlp.glm_130b.text_generation": [
             "os",
-            "re",
             "torch",
             "functools",
-            "sys",
+            "time",
             "SwissArmyTransformer",
-            "typing",
             "copy",
-            "time",
-            "random",
-            "stat"
+            "stat",
+            "typing",
+            "sys",
+            "re",
+            "random"
         ],
         "modelscope.models.nlp.gpt2.backbone": [
             "transformers"
         ],
         "modelscope.models.nlp.gpt3.backbone": [
             "os",
             "torch",
-            "math",
-            "transformers",
             "typing",
-            "addict"
+            "math",
+            "addict",
+            "transformers"
         ],
         "modelscope.models.nlp.gpt3.configuration": [
             "torch",
             "transformers"
         ],
         "modelscope.models.nlp.gpt3.distributed_gpt3": [
             "os",
-            "collections",
             "torch",
-            "math",
-            "transformers",
+            "megatron_util",
             "typing",
-            "megatron_util"
+            "math",
+            "collections",
+            "transformers"
         ],
         "modelscope.models.nlp.gpt3.text_generation": [
+            "torch",
             "typing",
             "collections",
-            "torch",
             "transformers"
         ],
         "modelscope.models.nlp.gpt3.tokenizer": [
             "typing",
             "tokenizers"
         ],
         "modelscope.models.nlp.gpt_moe.backbone": [
             "os",
             "torch",
-            "math",
-            "transformers",
             "typing",
-            "addict"
+            "math",
+            "addict",
+            "transformers"
         ],
         "modelscope.models.nlp.gpt_moe.checkpointing": [
-            "megatron_util",
             "os",
+            "megatron_util",
             "torch"
         ],
         "modelscope.models.nlp.gpt_moe.configuration": [
             "torch",
             "transformers"
         ],
         "modelscope.models.nlp.gpt_moe.distributed_gpt_moe": [
-            "megatron_util",
-            "transformers",
             "torch",
-            "math"
+            "megatron_util",
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.gpt_moe.moe.experts": [
-            "copy",
-            "torch"
+            "torch",
+            "copy"
         ],
         "modelscope.models.nlp.gpt_moe.moe.layer": [
+            "torch",
             "typing",
-            "megatron_util",
-            "torch"
+            "megatron_util"
         ],
         "modelscope.models.nlp.gpt_moe.moe.mappings": [
-            "megatron_util",
-            "torch"
+            "torch",
+            "megatron_util"
         ],
         "modelscope.models.nlp.gpt_moe.moe.sharded_moe": [
-            "apex",
             "torch",
-            "math",
-            "tutel",
+            "apex",
             "scipy",
+            "megatron_util",
             "typing",
-            "megatron_util"
+            "math",
+            "tutel"
         ],
         "modelscope.models.nlp.gpt_moe.moe.utils": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.gpt_moe.text_generation": [
             "typing",
             "transformers"
         ],
         "modelscope.models.nlp.gpt_moe.tokenizer": [
             "tokenizers"
         ],
         "modelscope.models.nlp.gpt_neo.backbone": [
             "transformers"
         ],
         "modelscope.models.nlp.heads.crf_head": [
-            "typing",
             "torch",
+            "typing",
             "transformers"
         ],
         "modelscope.models.nlp.heads.fill_mask_head": [
-            "typing",
             "torch",
+            "typing",
             "transformers"
         ],
         "modelscope.models.nlp.heads.infromation_extraction_head": [
             "torch"
         ],
         "modelscope.models.nlp.heads.text_classification_head": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.heads.text_generation_head": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.heads.text_ranking_head": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.heads.token_classification_head": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.heads.torch_pretrain_head": [
-            "typing",
             "torch",
+            "typing",
             "transformers"
         ],
         "modelscope.models.nlp.hf_transformers.backbone": [
             "transformers"
         ],
         "modelscope.models.nlp.llama.backbone": [
-            "typing",
-            "transformers",
             "torch",
-            "math"
+            "typing",
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.llama.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.llama.convert_llama_weights_to_hf": [
             "os",
             "torch",
-            "math",
             "argparse",
-            "shutil",
+            "gc",
             "json",
-            "gc"
+            "shutil",
+            "math"
         ],
         "modelscope.models.nlp.llama.text_generation": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.llama.tokenization": [
-            "sentencepiece",
             "os",
+            "typing",
+            "sentencepiece",
             "shutil",
-            "transformers",
-            "typing"
+            "transformers"
         ],
         "modelscope.models.nlp.llama.tokenization_fast": [
-            "typing",
-            "shutil",
             "os",
-            "transformers"
+            "typing",
+            "transformers",
+            "shutil"
         ],
         "modelscope.models.nlp.lstm.backbone": [
             "torch"
         ],
         "modelscope.models.nlp.lstm.token_classification": [],
         "modelscope.models.nlp.megatron_bert.backbone": [
-            "transformers",
             "torch",
-            "math"
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.megatron_bert.configuration": [
             "typing",
             "collections",
             "transformers"
         ],
         "modelscope.models.nlp.megatron_bert.fill_mask": [
@@ -15241,471 +15552,471 @@
             "os",
             "torch",
             "argparse",
             "deepspeed",
             "json"
         ],
         "modelscope.models.nlp.mglm.blocklm_utils": [
-            "megatron_util",
-            "copy",
-            "torch",
             "math",
-            "random",
+            "torch",
+            "scipy",
             "numpy",
-            "scipy"
+            "megatron_util",
+            "random",
+            "copy"
         ],
         "modelscope.models.nlp.mglm.configure_data": [
-            "bisect",
             "os",
             "torch",
-            "itertools",
-            "numpy",
+            "bisect",
             "megatron_util",
             "copy",
+            "itertools",
+            "numpy",
             "random"
         ],
         "modelscope.models.nlp.mglm.data_utils.corpora": [
             "os",
-            "collections",
             "torch",
-            "multiprocessing",
-            "random",
-            "json",
             "queue",
-            "tqdm"
+            "tqdm",
+            "json",
+            "multiprocessing",
+            "collections",
+            "random"
         ],
         "modelscope.models.nlp.mglm.data_utils.datasets": [
-            "bisect",
             "os",
-            "torch",
-            "itertools",
+            "bisect",
+            "nltk",
             "pandas",
-            "operator",
-            "tqdm",
-            "csv",
-            "math",
             "numpy",
-            "time",
+            "math",
             "random",
+            "torch",
+            "tqdm",
+            "csv",
+            "operator",
             "json",
-            "nltk"
+            "itertools",
+            "time"
         ],
         "modelscope.models.nlp.mglm.data_utils.extraction": [
-            "json",
             "os",
             "nltk",
+            "json",
             "glob"
         ],
         "modelscope.models.nlp.mglm.data_utils.file_utils": [
-            "botocore",
             "os",
-            "tempfile",
-            "shutil",
-            "hashlib",
             "boto3",
             "__future__",
-            "tqdm",
-            "urllib",
+            "tempfile",
+            "logging",
             "functools",
-            "sys",
-            "pathlib",
+            "urllib",
+            "io",
             "requests",
+            "botocore",
+            "sys",
+            "tqdm",
+            "hashlib",
             "json",
-            "logging",
-            "io"
+            "pathlib",
+            "shutil"
         ],
         "modelscope.models.nlp.mglm.data_utils.lazy_loader": [
+            "mmap",
             "os",
-            "time",
-            "pickle",
             "torch",
-            "mmap",
             "itertools",
-            "numpy"
+            "numpy",
+            "time",
+            "pickle"
         ],
         "modelscope.models.nlp.mglm.data_utils.samplers": [
             "os",
             "torch",
-            "math",
             "numpy",
-            "sys"
+            "sys",
+            "math"
         ],
         "modelscope.models.nlp.mglm.data_utils.sp_tokenizer": [
             "os"
         ],
         "modelscope.models.nlp.mglm.data_utils.tokenization": [
-            "sentencepiece",
             "os",
-            "collections",
             "torch",
+            "nltk",
+            "csv",
             "itertools",
-            "random",
+            "sentencepiece",
             "regex",
-            "nltk",
-            "csv"
+            "collections",
+            "random"
         ],
         "modelscope.models.nlp.mglm.data_utils.tokenization_gpt2": [
-            "regex",
             "os",
-            "functools",
-            "sys",
             "__future__",
-            "json",
             "logging",
-            "io"
+            "functools",
+            "json",
+            "io",
+            "regex",
+            "sys"
         ],
         "modelscope.models.nlp.mglm.data_utils.wordpiece": [
             "os",
-            "collections",
             "__future__",
-            "unicodedata",
             "logging",
-            "io"
+            "io",
+            "collections",
+            "unicodedata"
         ],
         "modelscope.models.nlp.mglm.generation_utils": [
+            "torch",
             "typing",
-            "abc",
             "collections",
-            "torch"
+            "abc"
         ],
         "modelscope.models.nlp.mglm.mglm_for_text_summarization": [
             "os",
             "torch",
-            "numpy",
-            "typing",
             "megatron_util",
+            "typing",
+            "numpy",
             "random"
         ],
         "modelscope.models.nlp.mglm.model.distributed": [
-            "megatron_util",
-            "torch"
+            "torch",
+            "megatron_util"
         ],
         "modelscope.models.nlp.mglm.model.downstream": [
             "torch"
         ],
         "modelscope.models.nlp.mglm.model.modeling_bert": [
             "os",
-            "apex",
             "torch",
-            "math",
-            "tarfile",
+            "__future__",
+            "apex",
+            "logging",
             "tempfile",
-            "shutil",
+            "tarfile",
             "megatron_util",
             "copy",
-            "__future__",
-            "data_utils",
             "json",
-            "logging"
+            "data_utils",
+            "shutil",
+            "math"
         ],
         "modelscope.models.nlp.mglm.model.modeling_glm": [
-            "megatron_util",
-            "torch"
+            "torch",
+            "megatron_util"
         ],
         "modelscope.models.nlp.mglm.model.prompt": [
             "torch",
             "random"
         ],
         "modelscope.models.nlp.mglm.model.transformer": [
-            "megatron_util",
-            "apex",
             "torch",
+            "apex",
             "math",
+            "megatron_util",
             "deepspeed"
         ],
         "modelscope.models.nlp.mglm.process_grid": [
             "os",
             "json",
-            "sys",
             "statistics",
-            "glob"
+            "glob",
+            "sys"
         ],
         "modelscope.models.nlp.mglm.run_test": [
             "sys",
             "test"
         ],
         "modelscope.models.nlp.mglm.tasks.data_utils": [
-            "re",
             "torch",
-            "numpy",
-            "typing",
             "megatron_util",
             "copy",
+            "json",
+            "typing",
+            "numpy",
             "pickle",
-            "json"
+            "re"
         ],
         "modelscope.models.nlp.mglm.tasks.eval_utils": [
-            "tasks",
             "os",
-            "collections",
             "torch",
+            "utils",
+            "megatron_util",
             "datetime",
             "finetune_glm",
             "typing",
-            "megatron_util",
-            "time",
             "sklearn",
-            "random",
-            "utils"
+            "tasks",
+            "time",
+            "collections",
+            "random"
         ],
         "modelscope.models.nlp.mglm.tasks.language_model.dataset": [
-            "tasks",
-            "bisect",
             "torch",
-            "math",
+            "utils",
+            "bisect",
+            "json",
             "itertools",
             "numpy",
-            "json",
-            "utils"
+            "tasks",
+            "math"
         ],
         "modelscope.models.nlp.mglm.tasks.language_model.detokenizer": [
             "re"
         ],
         "modelscope.models.nlp.mglm.tasks.language_model.finetune": [
-            "tasks",
-            "megatron_util",
+            "pretrain_glm",
             "torch",
-            "math",
             "functools",
-            "pretrain_glm",
+            "tasks",
+            "math",
+            "megatron_util",
             "finetune_glm"
         ],
         "modelscope.models.nlp.mglm.tasks.seq2seq.dataset": [
-            "tasks",
             "os",
             "torch",
-            "numpy",
-            "data_utils",
-            "random",
-            "json",
             "utils",
-            "tqdm"
+            "tqdm",
+            "json",
+            "data_utils",
+            "tasks",
+            "numpy",
+            "random"
         ],
         "modelscope.models.nlp.mglm.tasks.seq2seq.evaluate": [
-            "megatron_util",
             "torch",
             "generation_utils",
-            "random",
             "rouge_score",
             "string",
-            "datetime"
+            "megatron_util",
+            "datetime",
+            "random"
         ],
         "modelscope.models.nlp.mglm.tasks.seq2seq.finetune": [
+            "pretrain_glm",
+            "torch",
+            "functools",
             "tasks",
             "megatron_util",
             "collections",
-            "torch",
-            "functools",
-            "pretrain_glm",
             "finetune_glm"
         ],
         "modelscope.models.nlp.mglm.tasks.superglue.dataset": [
             "os",
+            "abc",
+            "pandas",
+            "glob",
+            "numpy",
+            "collections",
             "re",
+            "random",
             "torch",
-            "pandas",
             "utils",
             "tqdm",
-            "glob",
             "csv",
-            "abc",
-            "collections",
-            "numpy",
-            "typing",
             "copy",
-            "data_utils",
-            "random",
-            "json"
+            "json",
+            "typing",
+            "data_utils"
         ],
         "modelscope.models.nlp.mglm.tasks.superglue.evaluate": [
-            "tasks",
             "typing",
             "__future__",
-            "re",
-            "collections",
+            "string",
+            "tasks",
             "functools",
-            "string"
+            "collections",
+            "re"
         ],
         "modelscope.models.nlp.mglm.tasks.superglue.finetune": [
             "tasks",
             "collections",
             "finetune_glm"
         ],
         "modelscope.models.nlp.mglm.tasks.superglue.pvp": [
-            "tasks",
+            "utils",
             "abc",
-            "collections",
-            "math",
-            "numpy",
-            "typing",
             "copy",
-            "random",
+            "typing",
+            "numpy",
             "string",
-            "utils"
+            "tasks",
+            "math",
+            "collections",
+            "random"
         ],
         "modelscope.models.nlp.mglm.test.test_block": [
-            "numpy",
             "argparse",
+            "numpy",
             "blocklm_utils",
             "random"
         ],
         "modelscope.models.nlp.mglm.test.test_rel_shift": [
             "numpy",
+            "matplotlib",
             "learning_rates",
-            "torch",
-            "matplotlib"
+            "torch"
         ],
         "modelscope.models.nlp.mglm.train_utils": [
-            "megatron_util",
-            "apex",
             "torch",
+            "apex",
+            "megatron_util",
             "deepspeed"
         ],
         "modelscope.models.nlp.mglm.utils": [
             "os",
             "torch",
-            "numpy",
             "subprocess",
             "megatron_util",
+            "json",
+            "numpy",
             "time",
-            "random",
-            "json"
+            "random"
         ],
         "modelscope.models.nlp.palm_v2.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.palm_v2.dureader_eval": [
-            "re",
-            "collections",
-            "math",
+            "rouge",
+            "zipfile",
             "argparse",
-            "sys",
-            "numpy",
             "copy",
-            "zipfile",
-            "rouge",
-            "json"
+            "json",
+            "numpy",
+            "math",
+            "sys",
+            "collections",
+            "re"
         ],
         "modelscope.models.nlp.palm_v2.text_generation": [
-            "dataclasses",
             "os",
-            "codecs",
-            "math",
             "torch",
-            "numpy",
-            "transformers",
             "subprocess",
-            "typing",
+            "dataclasses",
             "copy",
-            "json"
+            "codecs",
+            "json",
+            "typing",
+            "numpy",
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.peer.backbone": [
-            "dataclasses",
             "torch",
+            "dataclasses",
+            "typing",
             "math",
-            "transformers",
-            "typing"
+            "transformers"
         ],
         "modelscope.models.nlp.peer.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.peer.sas_utils": [
             "numpy",
-            "nltk",
             "torch",
+            "nltk",
             "random"
         ],
         "modelscope.models.nlp.peer.text_classification": [
-            "copy",
-            "torch"
+            "torch",
+            "copy"
         ],
         "modelscope.models.nlp.plug.AnnealingLR": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.nlp.plug.backbone": [
             "torch",
-            "math",
-            "megatron_util",
             "__future__",
-            "logging"
+            "logging",
+            "megatron_util",
+            "math"
         ],
         "modelscope.models.nlp.plug.configuration": [
             "json",
             "copy",
             "transformers"
         ],
         "modelscope.models.nlp.plug.distributed_plug": [
+            "torch",
             "typing",
-            "megatron_util",
-            "torch"
+            "megatron_util"
         ],
         "modelscope.models.nlp.plug.generator": [
             "torch"
         ],
         "modelscope.models.nlp.plug_mental.adv_utils": [
             "torch"
         ],
         "modelscope.models.nlp.plug_mental.backbone": [
-            "dataclasses",
             "torch",
-            "math",
-            "transformers",
+            "dataclasses",
+            "packaging",
             "typing",
-            "packaging"
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.plug_mental.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.plug_mental.text_classification": [
             "torch"
         ],
         "modelscope.models.nlp.ponet.backbone": [
             "torch",
             "distutils",
+            "packaging",
             "math",
-            "transformers",
-            "packaging"
+            "transformers"
         ],
         "modelscope.models.nlp.ponet.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.ponet.document_segmentation": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.ponet.fill_mask": [
             "torch",
             "transformers"
         ],
         "modelscope.models.nlp.ponet.tokenization": [
             "typing",
             "transformers"
         ],
         "modelscope.models.nlp.space.configuration": [],
         "modelscope.models.nlp.space.dialog_intent_prediction": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.nlp.space.dialog_modeling": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.nlp.space.dialog_state_tracking": [
-            "typing",
             "torch",
+            "typing",
             "transformers"
         ],
         "modelscope.models.nlp.space.model.gen_unified_transformer": [
             "torch"
         ],
         "modelscope.models.nlp.space.model.generator": [
-            "numpy",
+            "math",
             "torch",
-            "math"
+            "numpy"
         ],
         "modelscope.models.nlp.space.model.intent_unified_transformer": [
             "torch"
         ],
         "modelscope.models.nlp.space.model.model_base": [
             "os",
             "torch"
@@ -15732,61 +16043,61 @@
         ],
         "modelscope.models.nlp.space.modules.transformer_block": [
             "torch"
         ],
         "modelscope.models.nlp.space_T_cn.backbone": [
             "os",
             "torch",
-            "math",
-            "tarfile",
+            "__future__",
             "tempfile",
-            "shutil",
-            "numpy",
+            "tarfile",
             "copy",
-            "__future__"
+            "numpy",
+            "shutil",
+            "math"
         ],
         "modelscope.models.nlp.space_T_cn.configuration": [
-            "json",
-            "copy",
             "logging",
-            "__future__"
+            "__future__",
+            "json",
+            "copy"
         ],
         "modelscope.models.nlp.space_T_cn.table_question_answering": [
             "os",
             "torch",
+            "typing",
             "numpy",
-            "transformers",
-            "typing"
+            "transformers"
         ],
         "modelscope.models.nlp.space_T_en.text_to_sql": [
-            "typing",
+            "text2sql_lgesql",
             "os",
-            "torch",
-            "text2sql_lgesql"
+            "typing",
+            "torch"
         ],
         "modelscope.models.nlp.structbert.adv_utils": [
             "torch"
         ],
         "modelscope.models.nlp.structbert.backbone": [
-            "dataclasses",
             "torch",
-            "math",
-            "transformers",
+            "dataclasses",
+            "packaging",
             "typing",
-            "packaging"
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.structbert.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.structbert.faq_question_answering": [
             "os",
-            "collections",
             "torch",
+            "typing",
             "math",
-            "typing"
+            "collections"
         ],
         "modelscope.models.nlp.structbert.fill_mask": [
             "torch",
             "transformers"
         ],
         "modelscope.models.nlp.structbert.text_classification": [
             "torch"
@@ -15805,61 +16116,61 @@
         ],
         "modelscope.models.nlp.task_models.information_extraction": [
             "numpy",
             "typing"
         ],
         "modelscope.models.nlp.task_models.task_model": [
             "os",
-            "abc",
-            "re",
             "torch",
+            "abc",
+            "typing",
             "collections",
-            "typing"
+            "re"
         ],
         "modelscope.models.nlp.task_models.text_classification": [
             "numpy",
             "typing"
         ],
         "modelscope.models.nlp.task_models.text_generation": [
-            "numpy",
-            "typing",
             "torch",
+            "typing",
+            "numpy",
             "transformers"
         ],
         "modelscope.models.nlp.task_models.text_ranking": [
             "numpy",
             "typing"
         ],
         "modelscope.models.nlp.task_models.token_classification": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.unite.configuration": [
             "enum"
         ],
         "modelscope.models.nlp.unite.translation_evaluation": [
-            "dataclasses",
             "torch",
-            "math",
-            "numpy",
-            "transformers",
-            "typing",
+            "dataclasses",
             "packaging",
-            "warnings"
+            "warnings",
+            "typing",
+            "numpy",
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.use.transformer": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.models.nlp.use.user_satisfaction_estimation": [
             "os",
             "torch",
+            "typing",
             "numpy",
-            "transformers",
-            "typing"
+            "transformers"
         ],
         "modelscope.models.nlp.veco.backbone": [
             "transformers"
         ],
         "modelscope.models.nlp.veco.configuration": [
             "transformers"
         ],
@@ -15871,2387 +16182,2410 @@
         ],
         "modelscope.models.nlp.veco.token_classification": [
             "torch",
             "transformers"
         ],
         "modelscope.models.nlp.xlm_roberta.backbone": [
             "packaging",
-            "transformers",
             "torch",
-            "math"
+            "math",
+            "transformers"
         ],
         "modelscope.models.nlp.xlm_roberta.configuration": [
             "typing",
             "collections",
             "transformers"
         ],
         "modelscope.models.science.unifold.config": [
-            "ml_collections",
+            "typing",
             "copy",
-            "typing"
+            "ml_collections"
         ],
         "modelscope.models.science.unifold.data.data_ops": [
             "torch",
+            "unicore",
             "functools",
-            "numpy",
+            "operator",
             "itertools",
-            "unicore",
             "typing",
-            "operator"
+            "numpy"
         ],
         "modelscope.models.science.unifold.data.msa_pairing": [
-            "collections",
-            "numpy",
             "scipy",
+            "pandas",
             "typing",
-            "pandas"
+            "numpy",
+            "collections"
         ],
         "modelscope.models.science.unifold.data.process": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.models.science.unifold.data.process_multimer": [
             "numpy",
             "typing",
             "collections"
         ],
         "modelscope.models.science.unifold.data.protein": [
             "dataclasses",
-            "numpy",
             "typing",
+            "io",
             "Bio",
-            "io"
+            "numpy"
         ],
         "modelscope.models.science.unifold.data.residue_constants": [
-            "typing",
             "os",
-            "collections",
-            "functools",
+            "typing",
+            "unicore",
             "numpy",
-            "unicore"
+            "functools",
+            "collections"
         ],
         "modelscope.models.science.unifold.data.utils": [
-            "functools",
-            "numpy",
             "gzip",
             "scipy",
-            "typing",
+            "functools",
             "copy",
-            "pickle",
-            "json"
+            "json",
+            "typing",
+            "numpy",
+            "pickle"
         ],
         "modelscope.models.science.unifold.dataset": [
             "os",
             "torch",
-            "numpy",
             "unicore",
-            "ml_collections",
-            "typing",
+            "logging",
             "copy",
             "json",
-            "logging"
+            "typing",
+            "numpy",
+            "ml_collections"
         ],
         "modelscope.models.science.unifold.model": [
             "argparse",
             "os",
             "typing",
             "torch"
         ],
         "modelscope.models.science.unifold.modules.alphafold": [
-            "unicore",
-            "torch"
+            "torch",
+            "unicore"
         ],
         "modelscope.models.science.unifold.modules.attentions": [
-            "typing",
-            "unicore",
             "torch",
-            "functools"
+            "typing",
+            "functools",
+            "unicore"
         ],
         "modelscope.models.science.unifold.modules.auxillary_heads": [
+            "torch",
             "typing",
-            "unicore",
-            "torch"
+            "unicore"
         ],
         "modelscope.models.science.unifold.modules.common": [
-            "typing",
-            "unicore",
             "torch",
-            "functools"
+            "typing",
+            "functools",
+            "unicore"
         ],
         "modelscope.models.science.unifold.modules.confidence": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.embedders": [
+            "torch",
             "typing",
-            "unicore",
-            "torch"
+            "unicore"
         ],
         "modelscope.models.science.unifold.modules.evoformer": [
-            "typing",
-            "unicore",
             "torch",
-            "functools"
+            "typing",
+            "functools",
+            "unicore"
         ],
         "modelscope.models.science.unifold.modules.featurization": [
+            "torch",
             "typing",
-            "unicore",
-            "torch"
+            "unicore"
         ],
         "modelscope.models.science.unifold.modules.frame": [
             "numpy",
             "__future__",
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.structure_module": [
+            "torch",
             "typing",
             "unicore",
-            "torch",
             "math"
         ],
         "modelscope.models.science.unifold.modules.template": [
             "torch",
-            "math",
-            "functools",
             "unicore",
-            "typing"
+            "functools",
+            "typing",
+            "math"
         ],
         "modelscope.models.science.unifold.modules.triangle_multiplication": [
-            "typing",
-            "unicore",
             "torch",
-            "functools"
+            "typing",
+            "functools",
+            "unicore"
         ],
         "modelscope.models.science.unifold.msa.mmcif": [
-            "dataclasses",
             "typing",
-            "absl",
-            "collections",
+            "io",
+            "dataclasses",
             "Bio",
+            "absl",
             "functools",
-            "io"
+            "collections"
         ],
         "modelscope.models.science.unifold.msa.msa_identifiers": [
-            "dataclasses",
             "typing",
+            "dataclasses",
             "re"
         ],
         "modelscope.models.science.unifold.msa.parsers": [
-            "dataclasses",
+            "itertools",
             "typing",
+            "dataclasses",
+            "string",
             "collections",
-            "re",
-            "itertools",
-            "string"
+            "re"
         ],
         "modelscope.models.science.unifold.msa.pipeline": [
-            "numpy",
-            "absl",
             "os",
-            "typing"
+            "typing",
+            "numpy",
+            "absl"
         ],
         "modelscope.models.science.unifold.msa.templates": [
-            "dataclasses",
             "os",
+            "dataclasses",
             "abc",
-            "re",
             "functools",
-            "numpy",
             "datetime",
             "typing",
             "absl",
-            "glob"
+            "glob",
+            "numpy",
+            "re"
         ],
         "modelscope.models.science.unifold.msa.tools.hhblits": [
             "os",
             "subprocess",
-            "absl",
             "typing",
+            "absl",
             "glob"
         ],
         "modelscope.models.science.unifold.msa.tools.hhsearch": [
             "os",
             "subprocess",
-            "absl",
             "typing",
+            "absl",
             "glob"
         ],
         "modelscope.models.science.unifold.msa.tools.hmmbuild": [
-            "subprocess",
-            "absl",
             "os",
-            "re"
+            "subprocess",
+            "re",
+            "absl"
         ],
         "modelscope.models.science.unifold.msa.tools.hmmsearch": [
-            "subprocess",
-            "absl",
             "os",
-            "typing"
+            "typing",
+            "subprocess",
+            "absl"
         ],
         "modelscope.models.science.unifold.msa.tools.jackhmmer": [
             "os",
-            "urllib",
-            "concurrent",
             "subprocess",
+            "urllib",
             "typing",
             "absl",
-            "glob"
+            "glob",
+            "concurrent"
         ],
         "modelscope.models.science.unifold.msa.tools.kalign": [
-            "subprocess",
-            "absl",
             "os",
-            "typing"
+            "typing",
+            "subprocess",
+            "absl"
         ],
         "modelscope.models.science.unifold.msa.tools.utils": [
             "typing",
             "contextlib",
+            "tempfile",
             "absl",
             "time",
-            "tempfile",
             "shutil"
         ],
         "modelscope.models.science.unifold.msa.utils": [
-            "typing",
-            "absl",
             "os",
-            "json"
+            "typing",
+            "json",
+            "absl"
         ],
         "modelscope.msdatasets.audio.asr_dataset": [],
         "modelscope.msdatasets.auth.auth_config": [
             "typing",
             "http"
         ],
         "modelscope.msdatasets.context.dataset_context_config": [
             "typing"
         ],
         "modelscope.msdatasets.data_files.data_files_manager": [
-            "typing",
             "os",
+            "typing",
             "datasets"
         ],
         "modelscope.msdatasets.data_loader.data_loader": [
-            "typing",
             "os",
-            "abc",
-            "datasets"
+            "typing",
+            "datasets",
+            "abc"
         ],
         "modelscope.msdatasets.data_loader.data_loader_manager": [
-            "os",
-            "abc",
             "enum",
-            "datasets"
+            "os",
+            "datasets",
+            "abc"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.audio.asr_dataset": [
             "os"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.audio.kws_farfield_dataset": [
             "os",
             "torch",
-            "math",
-            "numpy",
+            "queue",
             "threading",
-            "queue"
+            "math",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.audio.kws_nearfield_dataset": [
             "torch",
             "random"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.audio.kws_nearfield_processor": [
             "torch",
-            "numpy",
-            "kaldiio",
             "torchaudio",
-            "random",
-            "json"
+            "kaldiio",
+            "json",
+            "numpy",
+            "random"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.bad_image_detecting.bad_image_detecting_dataset": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.builder": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.build": [
-            "bisect",
-            "copy",
+            "math",
             "torch",
-            "math"
+            "bisect",
+            "copy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.collate_batch": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.datasets.coco": [
+            "torch",
             "numpy",
-            "torchvision",
             "cv2",
-            "torch"
+            "torchvision"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.datasets.mosaic_wrapper": [
             "torch",
-            "math",
-            "numpy",
             "cv2",
+            "numpy",
+            "math",
             "random"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.evaluation.coco.coco_eval": [
-            "tempfile",
             "os",
+            "torch",
             "collections",
-            "torch"
+            "tempfile"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.samplers.distributed": [
-            "torch",
-            "math"
+            "math",
+            "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.samplers.grouped_batch_sampler": [
-            "torch",
-            "itertools"
+            "itertools",
+            "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.samplers.iteration_based_batch_sampler": [
             "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.transforms.build": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.transforms.transforms": [
-            "torchvision",
-            "cv2",
             "torch",
+            "cv2",
+            "numpy",
             "random",
-            "numpy"
+            "torchvision"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.easycv_base": [
             "os"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.gopro_image_deblurring_dataset": [
             "numpy",
             "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_colorization.image_colorization_dataset": [
             "numpy",
-            "cv2",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_inpainting.aug": [
-            "imgaug",
-            "albumentations"
+            "albumentations",
+            "imgaug"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_inpainting.image_inpainting_dataset": [
             "os",
-            "numpy",
             "enum",
-            "albumentations",
             "cv2",
-            "glob"
+            "albumentations",
+            "glob",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_instance_segmentation_coco_dataset": [
-            "numpy",
             "os",
+            "numpy",
             "pycocotools"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_portrait_enhancement.data_utils": [
-            "cv2",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_portrait_enhancement.image_portrait_enhancement_dataset": [
             "numpy",
             "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_quality_assessment_degradation.image_quality_assessment_degradation_dataset": [
             "torchvision"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_quality_assmessment_mos.image_quality_assessment_mos_dataset": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.language_guided_video_summarization_dataset": [
             "os",
             "torch",
+            "json",
             "numpy",
-            "h5py",
-            "json"
+            "h5py"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.mgeo_ranking_dataset": [
-            "typing",
-            "json",
             "torch",
-            "random"
+            "typing",
+            "random",
+            "json"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.movie_scene_segmentation.movie_scene_segmentation_dataset": [
-            "torchvision",
             "os",
             "torch",
+            "torchvision",
             "copy",
-            "random",
-            "json"
+            "json",
+            "random"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.movie_scene_segmentation.sampler": [
             "numpy",
             "random"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.augmenter": [
             "imgaug"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.data_loader": [
-            "bisect",
             "torch",
-            "math",
+            "bisect",
             "numpy",
+            "math",
             "imgaug"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.image_dataset": [
-            "bisect",
             "os",
             "torch",
-            "math",
+            "logging",
+            "bisect",
             "functools",
-            "numpy",
             "cv2",
-            "logging",
-            "glob"
+            "numpy",
+            "glob",
+            "math"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.measures.iou_evaluator": [
             "numpy",
             "shapely",
             "collections"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.measures.quad_measurer": [
             "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.augment_data": [
+            "math",
             "numpy",
-            "cv2",
             "imgaug",
-            "math"
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.data_process": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.make_border_map": [
             "numpy",
+            "shapely",
             "pyclipper",
-            "cv2",
-            "shapely"
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.make_icdar_data": [
+            "torch",
             "numpy",
-            "cv2",
             "collections",
-            "torch"
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.make_seg_detection_data": [
             "numpy",
+            "shapely",
             "pyclipper",
-            "cv2",
-            "shapely"
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.normalize_image": [
             "numpy",
             "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.random_crop_data": [
             "numpy",
             "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_recognition_dataset": [
             "os",
             "torch",
-            "numpy",
             "PIL",
             "cv2",
-            "six",
+            "json",
+            "numpy",
             "lmdb",
-            "json"
+            "six"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.reds_image_deblurring_dataset": [
             "numpy",
             "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.referring_video_object_segmentation.referring_video_object_segmentation_dataset": [
-            "pycocotools",
-            "torchvision",
-            "os",
             "torch",
-            "numpy",
-            "h5py",
+            "os",
+            "tqdm",
             "pandas",
+            "torchvision",
+            "pycocotools",
             "json",
             "glob",
-            "tqdm"
+            "numpy",
+            "h5py"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.referring_video_object_segmentation.transformers": [
-            "PIL",
-            "torchvision",
             "torch",
-            "random"
+            "random",
+            "PIL",
+            "torchvision"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.data_utils": [
-            "cv2",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.sidd_image_denoising_dataset": [
             "numpy",
             "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.transforms": [
             "random"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.text_ranking_dataset": [
-            "typing",
             "torch",
+            "typing",
             "random"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.torch_custom_dataset": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.veco_dataset": [
             "numpy",
             "typing",
             "datasets"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.video_frame_interpolation.data_utils": [
-            "cv2",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.video_frame_interpolation.video_frame_interpolation_dataset": [
             "numpy",
-            "cv2",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.video_stabilization.video_stabilization_dataset": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.video_summarization_dataset": [
             "os",
             "torch",
+            "json",
             "numpy",
-            "h5py",
-            "json"
+            "h5py"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.video_super_resolution.video_super_resolution_dataset": [
+            "torch",
             "numpy",
-            "cv2",
             "collections",
-            "torch"
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.dataset": [
-            "pandas",
             "os",
-            "datasets",
-            "copy"
+            "tqdm",
+            "copy",
+            "pandas",
+            "datasets"
         ],
         "modelscope.msdatasets.download.dataset_builder": [
             "os",
-            "pyarrow",
             "pandas",
             "typing",
-            "datasets"
+            "datasets",
+            "pyarrow"
         ],
         "modelscope.msdatasets.download.download_config": [
             "typing",
             "datasets"
         ],
         "modelscope.msdatasets.download.download_manager": [
             "datasets"
         ],
         "modelscope.msdatasets.meta.data_meta_config": [],
         "modelscope.msdatasets.meta.data_meta_manager": [
             "os",
             "collections",
+            "json",
             "shutil",
-            "datasets",
-            "json"
+            "datasets"
         ],
         "modelscope.msdatasets.ms_dataset": [
             "os",
-            "numpy",
+            "warnings",
             "typing",
-            "datasets",
-            "warnings"
+            "numpy",
+            "datasets"
         ],
         "modelscope.msdatasets.task_datasets.gopro_image_deblurring_dataset": [],
         "modelscope.msdatasets.task_datasets.reds_image_deblurring_dataset": [],
         "modelscope.msdatasets.task_datasets.sidd_image_denoising": [],
         "modelscope.msdatasets.task_datasets.torch_base_dataset": [],
         "modelscope.msdatasets.task_datasets.video_summarization_dataset": [],
         "modelscope.msdatasets.utils.dataset_utils": [
-            "typing",
             "os",
-            "collections"
+            "typing",
+            "collections",
+            "pandas"
         ],
         "modelscope.msdatasets.utils.delete_utils": [],
         "modelscope.msdatasets.utils.maxcompute_utils": [
-            "pandas",
-            "math"
+            "math",
+            "pandas"
         ],
         "modelscope.msdatasets.utils.oss_utils": [
             "os",
+            "__future__",
             "oss2",
             "multiprocessing",
-            "__future__",
             "datasets"
         ],
         "modelscope.msdatasets.utils.upload_utils": [
             "os",
             "multiprocessing",
             "tqdm"
         ],
         "modelscope.pipelines.audio.ans_dfsmn_pipeline": [
             "os",
-            "collections",
             "torch",
-            "numpy",
-            "sys",
             "librosa",
             "typing",
-            "soundfile",
-            "io"
+            "io",
+            "numpy",
+            "sys",
+            "collections",
+            "soundfile"
         ],
         "modelscope.pipelines.audio.ans_pipeline": [
             "torch",
-            "numpy",
             "librosa",
             "typing",
-            "soundfile",
-            "io"
+            "io",
+            "numpy",
+            "soundfile"
         ],
         "modelscope.pipelines.audio.asr_inference_pipeline": [
-            "typing",
             "yaml",
             "os",
+            "typing",
             "json"
         ],
         "modelscope.pipelines.audio.asr_wenet_inference_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.audio.inverse_text_processing_pipeline": [
-            "typing",
-            "shutil",
+            "yaml",
             "os",
-            "yaml"
+            "typing",
+            "shutil"
         ],
         "modelscope.pipelines.audio.kws_farfield_pipeline": [
             "wave",
-            "numpy",
             "typing",
-            "soundfile",
-            "io"
+            "io",
+            "numpy",
+            "soundfile"
         ],
         "modelscope.pipelines.audio.kws_kwsbp_pipeline": [
-            "json",
             "os",
-            "typing"
+            "typing",
+            "json"
         ],
         "modelscope.pipelines.audio.linear_aec_pipeline": [
             "os",
             "torch",
-            "numpy",
             "scipy",
+            "yaml",
             "importlib",
             "typing",
-            "yaml"
+            "numpy"
         ],
         "modelscope.pipelines.audio.lm_infer_pipeline": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.pipelines.audio.punctuation_processing_pipeline": [
-            "typing",
-            "shutil",
+            "yaml",
             "os",
-            "yaml"
+            "typing",
+            "shutil"
         ],
-        "modelscope.pipelines.audio.separation_pipeline": [
+        "modelscope.pipelines.audio.segmentation_clustering_pipeline": [
             "torch",
+            "torchaudio",
+            "typing",
+            "io",
             "numpy",
+            "soundfile"
+        ],
+        "modelscope.pipelines.audio.separation_pipeline": [
+            "torch",
             "typing",
-            "soundfile",
-            "io"
+            "io",
+            "numpy",
+            "soundfile"
         ],
         "modelscope.pipelines.audio.speaker_change_locating_pipeline": [
             "torch",
-            "numpy",
+            "torchaudio",
             "typing",
-            "soundfile",
-            "io"
+            "io",
+            "numpy",
+            "soundfile"
         ],
         "modelscope.pipelines.audio.speaker_diarization_pipeline": [
             "os",
-            "numpy",
-            "shutil",
-            "typing",
+            "yaml",
             "json",
-            "yaml"
+            "typing",
+            "shutil",
+            "numpy"
         ],
         "modelscope.pipelines.audio.speaker_verification_eres2net_pipeline": [
-            "typing",
-            "soundfile",
             "torch",
-            "io"
+            "typing",
+            "io",
+            "soundfile"
         ],
         "modelscope.pipelines.audio.speaker_verification_light_pipeline": [
-            "typing",
-            "soundfile",
+            "os",
             "torch",
-            "io"
+            "torchaudio",
+            "typing",
+            "io",
+            "numpy",
+            "soundfile"
         ],
         "modelscope.pipelines.audio.speaker_verification_pipeline": [
-            "typing",
-            "shutil",
+            "yaml",
             "os",
-            "yaml"
+            "typing",
+            "shutil"
         ],
         "modelscope.pipelines.audio.speaker_verification_rdino_pipeline": [
-            "typing",
-            "soundfile",
             "torch",
-            "io"
+            "typing",
+            "io",
+            "soundfile"
         ],
         "modelscope.pipelines.audio.text_to_speech_pipeline": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.audio.timestamp_pipeline": [
             "os",
-            "funasr",
-            "typing",
+            "yaml",
             "json",
-            "yaml"
+            "typing",
+            "funasr"
         ],
         "modelscope.pipelines.audio.voice_activity_detection_pipeline": [
             "os",
-            "funasr",
-            "typing",
+            "yaml",
             "json",
-            "yaml"
+            "typing",
+            "funasr"
         ],
         "modelscope.pipelines.base": [
             "os",
-            "abc",
             "torch",
+            "abc",
+            "packaging",
             "functools",
-            "numpy",
-            "multiprocessing",
             "threading",
             "typing",
-            "random",
-            "packaging"
+            "numpy",
+            "multiprocessing",
+            "random"
         ],
         "modelscope.pipelines.builder": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.pipelines.cv.action_detection_pipeline": [
-            "typing",
             "os",
+            "typing",
             "math"
         ],
         "modelscope.pipelines.cv.action_recognition_pipeline": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "math"
         ],
         "modelscope.pipelines.cv.animal_recognition_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing",
             "PIL",
-            "cv2"
+            "cv2",
+            "torchvision",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.arc_face_recognition_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.bad_image_detecting_pipeline": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.pipelines.cv.body_2d_keypoints_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing",
             "PIL",
             "cv2",
-            "json"
+            "torchvision",
+            "json",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.body_3d_keypoints_pipeline": [
             "os",
+            "mpl_toolkits",
             "torch",
             "tempfile",
-            "mpl_toolkits",
-            "numpy",
-            "matplotlib",
             "datetime",
+            "cv2",
+            "matplotlib",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.card_detection_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.cmdssl_video_embedding_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
+            "PIL",
             "decord",
+            "torchvision",
             "typing",
-            "PIL"
+            "numpy"
         ],
         "modelscope.pipelines.cv.content_check_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
             "PIL",
+            "cv2",
+            "torchvision",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.controllable_image_generation_pipeline": [
             "os",
             "torch",
-            "math",
-            "tempfile",
-            "numpy",
             "subprocess",
-            "typing",
+            "tempfile",
             "cv2",
-            "glob"
+            "typing",
+            "numpy",
+            "glob",
+            "math"
         ],
         "modelscope.pipelines.cv.crowd_counting_pipeline": [
-            "torchvision",
             "torch",
+            "PIL",
+            "torchvision",
             "math",
-            "numpy",
             "typing",
-            "PIL"
+            "numpy"
         ],
         "modelscope.pipelines.cv.ddcolor_image_colorization_pipeline": [
-            "torchvision",
             "torch",
-            "numpy",
+            "cv2",
+            "torchvision",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.ddpm_semantic_segmentation_pipeline": [
+            "torch",
             "typing",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.pipelines.cv.face_attribute_recognition_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.face_detection_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.face_emotion_pipeline": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.cv.face_human_hand_detection_pipeline": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.cv.face_image_generation_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.face_liveness_ir_pipeline": [
             "os",
-            "onnxruntime",
             "torch",
+            "cv2",
+            "typing",
             "numpy",
             "PIL",
-            "typing",
-            "cv2"
+            "onnxruntime"
         ],
         "modelscope.pipelines.cv.face_liveness_xc_pipeline": [
             "os",
-            "onnxruntime",
             "torch",
+            "cv2",
+            "typing",
             "numpy",
             "PIL",
-            "typing",
-            "cv2"
+            "onnxruntime"
         ],
         "modelscope.pipelines.cv.face_processing_base_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.face_quality_assessment_pipeline": [
             "os",
-            "onnxruntime",
             "torch",
+            "cv2",
+            "typing",
             "numpy",
             "PIL",
-            "typing",
-            "cv2"
+            "onnxruntime"
         ],
         "modelscope.pipelines.cv.face_recognition_onnx_fm_pipeline": [
             "os",
-            "onnxruntime",
             "torch",
+            "cv2",
+            "typing",
             "numpy",
             "PIL",
-            "typing",
-            "cv2"
+            "onnxruntime"
         ],
         "modelscope.pipelines.cv.face_recognition_onnx_ir_pipeline": [
             "os",
-            "onnxruntime",
             "torch",
+            "cv2",
+            "typing",
             "numpy",
             "PIL",
-            "typing",
-            "cv2"
+            "onnxruntime"
         ],
         "modelscope.pipelines.cv.face_recognition_ood_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.face_recognition_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.face_reconstruction_pipeline": [
             "os",
-            "face_alignment",
             "torch",
-            "numpy",
-            "shutil",
             "scipy",
             "PIL",
-            "typing",
             "cv2",
+            "face_alignment",
+            "typing",
+            "io",
             "tensorflow",
-            "io"
+            "shutil",
+            "numpy"
         ],
         "modelscope.pipelines.cv.facial_expression_recognition_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.facial_landmark_confidence_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.fast_instance_segmentation_pipeline": [
-            "numpy",
-            "torchvision",
+            "torch",
             "typing",
-            "torch"
+            "numpy",
+            "torchvision"
         ],
         "modelscope.pipelines.cv.general_recognition_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing",
             "PIL",
-            "cv2"
+            "cv2",
+            "torchvision",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.hand_static_pipeline": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.cv.hicossl_video_embedding_pipeline": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "math"
         ],
         "modelscope.pipelines.cv.human_reconstruction_pipeline": [
             "os",
             "torch",
-            "numpy",
+            "typing",
             "shutil",
-            "trimesh",
-            "typing"
+            "numpy",
+            "trimesh"
         ],
         "modelscope.pipelines.cv.image_body_reshaping_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.image_bts_depth_estimation_pipeline": [
             "torch",
-            "numpy",
+            "cv2",
             "albumentations",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_cartoon_pipeline": [
             "os",
-            "numpy",
-            "typing",
             "cv2",
-            "tensorflow"
+            "typing",
+            "tensorflow",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_classification_pipeline": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.pipelines.cv.image_color_enhance_pipeline": [
+            "torch",
             "typing",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.pipelines.cv.image_colorization_pipeline": [
-            "torchvision",
             "torch",
-            "numpy",
+            "torchvision",
+            "cv2",
             "typing",
-            "PIL",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.image_debanding_pipeline": [
+            "torch",
             "typing",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.pipelines.cv.image_deblur_pipeline": [
+            "torch",
             "typing",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.pipelines.cv.image_defrcn_fewshot_pipeline": [
-            "numpy",
             "os",
             "typing",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_denoise_pipeline": [
+            "torch",
             "typing",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.pipelines.cv.image_depth_estimation_pipeline": [
             "torch",
-            "numpy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_detection_pipeline": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.cv.image_driving_perception_pipeline": [
-            "numpy",
-            "cv2",
             "os",
-            "typing"
+            "typing",
+            "numpy",
+            "cv2"
         ],
         "modelscope.pipelines.cv.image_face_fusion_pipeline": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.cv.image_human_parsing_pipeline": [
-            "numpy",
-            "torchvision",
+            "torch",
             "typing",
-            "torch"
+            "numpy",
+            "torchvision"
         ],
         "modelscope.pipelines.cv.image_inpainting_pipeline": [
             "torch",
-            "numpy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_inpainting_sdv2_pipeline": [
             "os",
             "torch",
-            "math",
             "tempfile",
-            "sys",
+            "cv2",
+            "typing",
             "numpy",
             "diffusers",
-            "typing",
-            "cv2"
+            "math",
+            "sys"
         ],
         "modelscope.pipelines.cv.image_instance_segmentation_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.image_matching_pipeline": [
             "torch",
-            "numpy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_matting_pipeline": [
             "os",
-            "numpy",
-            "typing",
             "cv2",
-            "tensorflow"
+            "typing",
+            "tensorflow",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_mvs_depth_estimation_pipeline": [
-            "tempfile",
-            "shutil",
             "os",
-            "typing"
+            "typing",
+            "tempfile",
+            "shutil"
         ],
         "modelscope.pipelines.cv.image_open_vocabulary_detection_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.image_paintbyexample_pipeline": [
-            "torchvision",
             "torch",
-            "numpy",
+            "einops",
             "PIL",
+            "torchvision",
+            "cv2",
             "typing",
+            "numpy"
+        ],
+        "modelscope.pipelines.cv.image_panoptic_segmentation_pipeline": [
+            "torch",
+            "PIL",
             "cv2",
-            "einops"
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_portrait_enhancement_pipeline": [
             "torch",
-            "math",
-            "numpy",
             "scipy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.pipelines.cv.image_quality_assessment_degradation_pipeline": [
-            "torchvision",
             "torch",
-            "math",
             "tempfile",
-            "numpy",
+            "cv2",
+            "torchvision",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.pipelines.cv.image_quality_assessment_man_pipeline": [
-            "torchvision",
             "torch",
-            "math",
             "tempfile",
-            "numpy",
+            "cv2",
+            "torchvision",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.pipelines.cv.image_quality_assessment_mos_pipeline": [
-            "torchvision",
             "torch",
-            "math",
             "tempfile",
-            "numpy",
+            "cv2",
+            "torchvision",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.pipelines.cv.image_reid_person_pipeline": [
-            "torchvision",
             "os",
             "torch",
+            "torchvision",
             "math",
             "typing",
             "PIL"
         ],
         "modelscope.pipelines.cv.image_restoration_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.image_salient_detection_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.image_semantic_segmentation_pipeline": [
             "torch",
-            "numpy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_skychange_pipeline": [
+            "cv2",
+            "pdb",
+            "typing",
             "numpy",
             "PIL",
-            "typing",
-            "cv2",
-            "time",
-            "pdb"
+            "time"
         ],
         "modelscope.pipelines.cv.image_structured_model_probing_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "math",
-            "numpy",
+            "torchvision",
             "typing",
+            "numpy",
+            "math",
             "mmcv"
         ],
         "modelscope.pipelines.cv.image_style_transfer_pipeline": [
-            "numpy",
-            "cv2",
             "os",
-            "typing"
+            "typing",
+            "numpy",
+            "cv2"
         ],
         "modelscope.pipelines.cv.image_super_resolution_pipeline": [
             "torch",
-            "numpy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_to_image_generate_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
             "PIL",
+            "cv2",
+            "torchvision",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_to_image_translation_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "sys",
-            "typing",
             "PIL",
             "cv2",
-            "io"
+            "torchvision",
+            "typing",
+            "io",
+            "numpy",
+            "sys"
         ],
         "modelscope.pipelines.cv.indoor_layout_estimation_pipeline": [
             "numpy",
-            "cv2",
-            "typing"
+            "typing",
+            "cv2"
         ],
         "modelscope.pipelines.cv.language_guided_video_summarization_pipeline": [
             "os",
             "clip",
             "torch",
+            "PIL",
             "tempfile",
+            "cv2",
+            "typing",
             "shutil",
             "numpy",
-            "typing",
-            "PIL",
-            "cv2",
             "random"
         ],
         "modelscope.pipelines.cv.license_plate_detection_pipeline": [
             "os",
             "torch",
-            "math",
-            "numpy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.pipelines.cv.lineless_table_recognition_pipeline": [
             "os",
             "torch",
-            "math",
-            "numpy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.pipelines.cv.live_category_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
+            "PIL",
             "decord",
+            "torchvision",
             "typing",
-            "PIL"
+            "numpy"
         ],
         "modelscope.pipelines.cv.mask_face_recognition_pipeline": [
             "os",
-            "collections",
             "torch",
+            "cv2",
+            "typing",
             "numpy",
             "PIL",
-            "typing",
-            "cv2"
+            "collections"
         ],
         "modelscope.pipelines.cv.maskdino_instance_segmentation_pipeline": [
+            "torch",
             "typing",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.pipelines.cv.mobile_image_super_resolution_pipeline": [
-            "torchvision",
-            "skimage",
             "torch",
-            "numpy",
-            "typing"
+            "skimage",
+            "torchvision",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.mog_face_detection_pipeline": [
-            "numpy",
             "os",
-            "typing"
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.motion_generation_pipeline": [
             "os",
             "torch",
             "tempfile",
-            "numpy",
-            "typing"
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.movie_scene_segmentation_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.cv.mtcnn_face_detection_pipeline": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.pipelines.cv.nerf_recon_acc_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.object_detection_3d_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "tempfile",
             "PIL",
+            "tempfile",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.ocr_detection_pipeline": [
             "os",
             "torch",
-            "math",
-            "numpy",
             "tf_slim",
-            "typing",
             "cv2",
-            "tensorflow"
+            "math",
+            "typing",
+            "tensorflow",
+            "numpy"
         ],
         "modelscope.pipelines.cv.ocr_recognition_pipeline": [],
         "modelscope.pipelines.cv.ocr_utils.model_convnext_transformer": [
             "torch"
         ],
         "modelscope.pipelines.cv.ocr_utils.model_dla34": [
-            "numpy",
             "os",
+            "math",
             "torch",
-            "math"
+            "numpy"
         ],
         "modelscope.pipelines.cv.ocr_utils.model_resnet18_half": [
             "os",
             "torch"
         ],
         "modelscope.pipelines.cv.ocr_utils.model_resnet_mutex_v4_linewithchar": [
             "tf_slim",
             "tensorflow"
         ],
         "modelscope.pipelines.cv.ocr_utils.model_vlpt": [
-            "sys",
             "os",
-            "torch",
-            "math"
+            "math",
+            "sys",
+            "torch"
         ],
         "modelscope.pipelines.cv.ocr_utils.ocr_modules.convnext": [
             "torch"
         ],
         "modelscope.pipelines.cv.ocr_utils.ocr_modules.timm_tinyc": [
-            "copy",
-            "collections",
             "torch",
+            "itertools",
+            "logging",
             "math",
             "functools",
-            "itertools",
-            "logging"
+            "collections",
+            "copy"
         ],
         "modelscope.pipelines.cv.ocr_utils.ocr_modules.vitstr": [
             "torch",
-            "functools",
             "__future__",
-            "copy",
-            "logging"
+            "logging",
+            "functools",
+            "copy"
         ],
         "modelscope.pipelines.cv.ocr_utils.ops": [
             "os",
-            "math",
-            "numpy",
-            "shutil",
-            "sys",
-            "absl",
+            "uuid",
             "cv2",
             "tensorflow",
-            "uuid"
+            "absl",
+            "shutil",
+            "numpy",
+            "math",
+            "sys"
         ],
         "modelscope.pipelines.cv.ocr_utils.resnet18_v1": [
             "tf_slim",
             "tensorflow"
         ],
         "modelscope.pipelines.cv.ocr_utils.resnet_utils": [
+            "collections",
             "tf_slim",
-            "tensorflow",
-            "collections"
+            "tensorflow"
         ],
         "modelscope.pipelines.cv.ocr_utils.table_process": [
-            "cv2",
-            "copy",
-            "torch",
             "math",
+            "torch",
+            "copy",
+            "numpy",
             "random",
-            "numpy"
+            "cv2"
         ],
         "modelscope.pipelines.cv.ocr_utils.utils": [
+            "shapely",
             "numpy",
             "pyclipper",
-            "cv2",
-            "shapely"
+            "cv2"
         ],
         "modelscope.pipelines.cv.panorama_depth_estimation_pipeline": [
             "torch",
-            "numpy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.pedestrian_attribute_recognition_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing",
             "PIL",
             "cv2",
-            "json"
+            "torchvision",
+            "json",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.pointcloud_sceneflow_estimation_pipeline": [
-            "numpy",
-            "typing",
             "torch",
-            "plyfile"
+            "typing",
+            "plyfile",
+            "numpy"
         ],
         "modelscope.pipelines.cv.product_retrieval_embedding_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing",
             "PIL",
-            "cv2"
+            "cv2",
+            "torchvision",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.product_segmentation_pipeline": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.cv.realtime_video_object_detection_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing",
             "PIL",
             "cv2",
-            "json"
+            "torchvision",
+            "json",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.referring_video_object_segmentation_pipeline": [
-            "torchvision",
-            "moviepy",
             "torch",
+            "einops",
+            "PIL",
             "tempfile",
-            "numpy",
+            "tqdm",
+            "torchvision",
+            "moviepy",
             "typing",
-            "PIL",
-            "einops",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.pipelines.cv.retina_face_detection_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.shop_segmentation_pipleline": [
             "typing"
         ],
         "modelscope.pipelines.cv.skin_retouching_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
             "PIL",
-            "typing",
             "cv2",
-            "tensorflow"
+            "torchvision",
+            "typing",
+            "tensorflow",
+            "numpy"
         ],
         "modelscope.pipelines.cv.table_recognition_pipeline": [
             "os",
             "torch",
-            "math",
-            "numpy",
             "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.pipelines.cv.tbs_detection_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "typing",
             "PIL",
             "cv2",
-            "colorsys"
+            "colorsys",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.tbs_detection_utils.utils": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "matplotlib",
-            "pandas",
-            "PIL",
             "__future__",
-            "colorsys"
+            "PIL",
+            "pandas",
+            "torchvision",
+            "colorsys",
+            "matplotlib",
+            "numpy"
         ],
         "modelscope.pipelines.cv.text_driven_segmentation_pipleline": [
             "typing"
         ],
         "modelscope.pipelines.cv.tinynas_classification_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "math",
-            "typing"
+            "torchvision",
+            "typing",
+            "math"
         ],
         "modelscope.pipelines.cv.tinynas_detection_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.ulfd_face_detection_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.video_category_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
+            "PIL",
             "decord",
+            "torchvision",
+            "json",
             "typing",
-            "PIL",
-            "json"
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_colorization_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "tempfile",
-            "numpy",
             "subprocess",
             "PIL",
+            "tempfile",
             "cv2",
-            "typing"
+            "torchvision",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_deinterlace_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "math",
-            "tempfile",
-            "numpy",
             "subprocess",
+            "tempfile",
+            "cv2",
+            "torchvision",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.pipelines.cv.video_depth_estimation_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.video_frame_interpolation_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "math",
-            "tempfile",
-            "numpy",
             "subprocess",
-            "typing",
+            "tempfile",
             "cv2",
-            "glob"
+            "torchvision",
+            "typing",
+            "numpy",
+            "glob",
+            "math"
         ],
         "modelscope.pipelines.cv.video_human_matting_pipeline": [
             "os",
-            "moviepy",
             "torch",
-            "numpy",
+            "moviepy",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_inpainting_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.video_instance_segmentation_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "typing",
+            "tqdm",
             "cv2",
-            "mmcv",
-            "tqdm"
+            "typing",
+            "numpy",
+            "mmcv"
         ],
         "modelscope.pipelines.cv.video_multi_object_tracking_pipeline": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.pipelines.cv.video_object_segmentation_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
             "PIL",
-            "typing"
+            "torchvision",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_panoptic_segmentation_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "typing",
+            "tqdm",
             "cv2",
-            "mmcv",
-            "tqdm"
+            "typing",
+            "numpy",
+            "mmcv"
         ],
         "modelscope.pipelines.cv.video_single_object_tracking_pipeline": [
+            "os",
             "typing",
-            "cv2",
-            "os"
+            "cv2"
         ],
         "modelscope.pipelines.cv.video_stabilization_pipeline": [
             "os",
             "torch",
-            "math",
-            "tempfile",
-            "numpy",
             "subprocess",
-            "typing",
+            "tempfile",
             "cv2",
-            "glob"
+            "typing",
+            "numpy",
+            "glob",
+            "math"
         ],
         "modelscope.pipelines.cv.video_summarization_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "typing",
+            "tqdm",
             "cv2",
-            "tqdm"
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_super_resolution_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "math",
-            "tempfile",
-            "numpy",
             "subprocess",
+            "tempfile",
+            "cv2",
+            "torchvision",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.pipelines.cv.vidt_pipeline": [
+            "torch",
             "typing",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.pipelines.cv.virtual_try_on_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "PIL",
+            "cv2",
             "typing",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.cv.vision_efficient_tuning_pipeline": [
-            "numpy",
-            "torchvision",
+            "torch",
             "typing",
-            "torch"
+            "numpy",
+            "torchvision"
         ],
         "modelscope.pipelines.cv.vision_middleware_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "math",
-            "numpy",
+            "torchvision",
             "typing",
+            "numpy",
+            "math",
             "mmcv"
         ],
         "modelscope.pipelines.cv.vop_retrieval_pipeline": [
+            "gzip",
             "os",
-            "collections",
             "torch",
-            "math",
-            "numpy",
-            "gzip",
+            "tqdm",
             "typing",
+            "numpy",
+            "math",
             "pickle",
-            "random",
-            "tqdm"
+            "collections",
+            "random"
         ],
         "modelscope.pipelines.cv.vop_retrieval_se_pipeline": [
+            "gzip",
             "os",
             "torch",
-            "numpy",
-            "gzip",
-            "typing"
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.multi_modal.asr_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.diffusers_wrapped.stable_diffusion.chinese_stable_diffusion_pipeline": [
             "torch",
-            "numpy",
-            "diffusers",
-            "transformers",
-            "typing",
             "PIL",
-            "cv2"
+            "cv2",
+            "typing",
+            "diffusers",
+            "numpy",
+            "transformers"
         ],
         "modelscope.pipelines.multi_modal.diffusers_wrapped.stable_diffusion.stable_diffusion_pipeline": [
+            "os",
             "torch",
-            "numpy",
-            "diffusers",
             "PIL",
+            "torchvision",
+            "cv2",
             "typing",
-            "cv2"
+            "diffusers",
+            "numpy"
         ],
         "modelscope.pipelines.multi_modal.disco_guided_diffusion_pipeline.disco_guided_diffusion": [
-            "torchvision",
-            "clip",
             "os",
+            "clip",
             "torch",
-            "math",
-            "numpy",
-            "importlib",
             "PIL",
+            "gc",
             "cv2",
+            "torchvision",
             "json",
-            "gc"
+            "importlib",
+            "numpy",
+            "math"
         ],
         "modelscope.pipelines.multi_modal.disco_guided_diffusion_pipeline.utils": [
             "torch",
-            "math",
+            "warnings",
             "fractions",
             "numpy",
-            "warnings"
+            "math"
         ],
         "modelscope.pipelines.multi_modal.document_vl_embedding_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.efficient_diffusion_tuning_pipeline": [
-            "torchvision",
             "torch",
-            "numpy",
+            "cv2",
+            "torchvision",
             "typing",
-            "PIL",
-            "cv2"
+            "numpy",
+            "PIL"
         ],
         "modelscope.pipelines.multi_modal.generative_multi_modal_embedding_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.multi_modal.gridvlp_pipeline": [
             "os",
             "torch",
-            "numpy",
-            "transformers",
+            "PIL",
             "traceback",
+            "json",
             "typing",
-            "PIL",
+            "numpy",
             "time",
-            "json"
+            "transformers"
         ],
         "modelscope.pipelines.multi_modal.image_captioning_pipeline": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.pipelines.multi_modal.image_text_retrieval_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.mgeo_ranking_pipeline": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.pipelines.multi_modal.multi_modal_embedding_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.multi_modal.multimodal_dialogue_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.ocr_recognition_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.soonet_video_temporal_grounding_pipeline": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing"
+            "torchvision",
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.multi_modal.sudoku_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.team_multi_modal_similarity_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.multi_modal.text2sql_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.text_to_image_synthesis_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.text_to_video_synthesis_pipeline": [
+            "einops",
             "os",
             "torch",
             "tempfile",
-            "typing",
             "cv2",
-            "einops"
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.video_captioning_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.video_multi_modal_embedding_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.multi_modal.video_question_answering_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.visual_entailment_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.visual_grounding_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.visual_question_answering_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.automatic_post_editing_pipeline": [
-            "sentencepiece",
             "os",
-            "numpy",
-            "html",
             "sacremoses",
             "typing",
             "tensorflow",
-            "jieba"
+            "sentencepiece",
+            "numpy",
+            "jieba",
+            "html"
         ],
         "modelscope.pipelines.nlp.canmt_translation_pipeline": [
-            "typing",
             "os",
-            "sacremoses",
-            "torch"
+            "typing",
+            "torch",
+            "sacremoses"
         ],
         "modelscope.pipelines.nlp.codegeex_code_generation_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.codegeex_code_translation_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.conversational_text_to_sql_pipeline": [
-            "typing",
             "torch",
+            "typing",
             "text2sql_lgesql"
         ],
         "modelscope.pipelines.nlp.dialog_intent_prediction_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.dialog_modeling_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.dialog_state_tracking_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.distributed_gpt3_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.distributed_gpt_moe_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.distributed_plug_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.document_grounded_dialog_generate_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.document_grounded_dialog_rerank_pipeline": [
             "os",
-            "re",
             "torch",
-            "collections",
             "pprint",
-            "sys",
-            "numpy",
-            "transformers",
-            "typing",
             "time",
+            "ujson",
+            "typing",
+            "numpy",
+            "sys",
+            "collections",
+            "re",
             "random",
-            "ujson"
+            "transformers"
         ],
         "modelscope.pipelines.nlp.document_grounded_dialog_retrieval_pipeline": [
-            "faiss",
             "os",
-            "numpy",
+            "faiss",
+            "json",
             "typing",
-            "json"
+            "numpy"
         ],
         "modelscope.pipelines.nlp.document_segmentation_pipeline": [
-            "re",
             "torch",
-            "numpy",
             "typing",
-            "datasets"
+            "numpy",
+            "datasets",
+            "re"
         ],
         "modelscope.pipelines.nlp.extractive_summarization_pipeline": [
-            "re",
             "torch",
-            "numpy",
             "typing",
-            "datasets"
+            "numpy",
+            "datasets",
+            "re"
         ],
         "modelscope.pipelines.nlp.faq_question_answering_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.fasttext_text_classification_pipeline": [
-            "sentencepiece",
             "os",
-            "numpy",
             "fasttext",
-            "typing"
+            "typing",
+            "sentencepiece",
+            "numpy"
         ],
         "modelscope.pipelines.nlp.feature_extraction_pipeline": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.pipelines.nlp.fid_dialogue_pipeline": [
+            "torch",
             "typing",
-            "re",
-            "torch"
+            "re"
         ],
         "modelscope.pipelines.nlp.fill_mask_pipeline": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.nlp.glm130b_text_generation_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.information_extraction_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.interactive_translation_pipeline": [
             "os",
-            "numpy",
             "subword_nmt",
             "sacremoses",
             "typing",
             "tensorflow",
+            "numpy",
             "jieba"
         ],
         "modelscope.pipelines.nlp.language_identification_pipline": [
             "os",
-            "re",
-            "numpy",
             "typing",
-            "tensorflow"
+            "tensorflow",
+            "numpy",
+            "re"
         ],
         "modelscope.pipelines.nlp.mglm_text_summarization_pipeline": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.pipelines.nlp.named_entity_recognition_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.sentence_embedding_pipeline": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.pipelines.nlp.siamese_uie_pipeline": [
             "os",
             "torch",
-            "math",
             "scipy",
-            "typing",
+            "tqdm",
+            "logging",
             "copy",
-            "time",
-            "pathlib",
             "json",
-            "logging",
-            "tqdm"
+            "pathlib",
+            "typing",
+            "math",
+            "time"
         ],
         "modelscope.pipelines.nlp.summarization_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.table_question_answering_pipeline": [
             "os",
             "torch",
-            "transformers",
+            "json",
             "typing",
-            "json"
+            "transformers"
         ],
         "modelscope.pipelines.nlp.text_classification_pipeline": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.pipelines.nlp.text_error_correction_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.text_generation_pipeline": [
-            "typing",
             "os",
+            "typing",
             "torch"
         ],
         "modelscope.pipelines.nlp.text_ranking_pipeline": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.nlp.token_classification_pipeline": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.pipelines.nlp.translation_evaluation_pipeline": [
             "os",
             "torch",
-            "numpy",
             "enum",
-            "typing"
+            "typing",
+            "numpy"
         ],
         "modelscope.pipelines.nlp.translation_pipeline": [
             "os",
-            "numpy",
             "subword_nmt",
             "sacremoses",
             "typing",
             "tensorflow",
+            "numpy",
             "jieba"
         ],
         "modelscope.pipelines.nlp.translation_quality_estimation_pipeline": [
             "os",
             "torch",
-            "transformers",
             "typing",
-            "io"
+            "io",
+            "transformers"
         ],
         "modelscope.pipelines.nlp.user_satisfaction_estimation_pipeline": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.pipelines.nlp.word_alignment_pipeline": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.nlp.word_segmentation_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.zero_shot_classification_pipeline": [
-            "typing",
             "torch",
+            "typing",
             "scipy"
         ],
         "modelscope.pipelines.pipeline_template": [
             "numpy",
             "typing"
         ],
         "modelscope.pipelines.science.protein_structure_pipeline": [
             "os",
             "torch",
-            "numpy",
             "unicore",
+            "json",
             "typing",
-            "time",
-            "json"
+            "numpy",
+            "time"
         ],
         "modelscope.pipelines.util": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.preprocessors.asr": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.preprocessors.audio": [
             "os",
             "torch",
-            "numpy",
             "scipy",
             "typing",
-            "io"
+            "io",
+            "numpy"
         ],
         "modelscope.preprocessors.base": [
-            "typing",
             "os",
+            "typing",
             "abc"
         ],
         "modelscope.preprocessors.builder": [],
         "modelscope.preprocessors.common": [
-            "collections",
             "torch",
-            "numpy",
             "typing",
-            "time"
+            "numpy",
+            "time",
+            "collections"
         ],
         "modelscope.preprocessors.cv.action_detection_mapper": [
-            "copy",
-            "detectron2",
             "torch",
-            "random",
+            "scipy",
             "numpy",
+            "detectron2",
             "decord",
-            "scipy"
+            "random",
+            "copy"
         ],
         "modelscope.preprocessors.cv.bad_image_detecting_preprocessor": [
-            "torchvision",
             "torch",
+            "PIL",
+            "torchvision",
             "math",
-            "numpy",
             "typing",
-            "PIL"
+            "numpy"
         ],
         "modelscope.preprocessors.cv.controllable_image_generation": [
-            "torchvision",
             "os",
             "torch",
-            "math",
-            "numpy",
-            "typing",
             "PIL",
-            "cv2"
+            "cv2",
+            "torchvision",
+            "typing",
+            "numpy",
+            "math"
         ],
         "modelscope.preprocessors.cv.cv2_transforms": [
-            "cv2",
-            "collections",
-            "torch",
             "math",
-            "random",
+            "torch",
+            "numbers",
             "numpy",
-            "numbers"
+            "collections",
+            "random",
+            "cv2"
         ],
         "modelscope.preprocessors.cv.image_classification_preprocessor": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing",
             "PIL",
-            "cv2"
+            "torchvision",
+            "cv2",
+            "typing",
+            "numpy"
         ],
         "modelscope.preprocessors.cv.image_quality_assessment_man": [
-            "torchvision",
             "torch",
+            "PIL",
+            "torchvision",
             "math",
-            "numpy",
             "typing",
-            "PIL"
+            "numpy"
         ],
         "modelscope.preprocessors.cv.image_quality_assessment_mos": [
+            "cv2",
             "torchvision",
-            "math",
-            "numpy",
             "typing",
-            "cv2"
+            "numpy",
+            "math"
         ],
         "modelscope.preprocessors.cv.image_restoration_preprocessor": [
-            "torchvision",
             "torch",
+            "PIL",
+            "torchvision",
             "math",
-            "numpy",
             "typing",
-            "PIL"
+            "numpy"
         ],
         "modelscope.preprocessors.cv.mmcls_preprocessor": [
-            "numpy",
             "os",
-            "typing"
+            "typing",
+            "numpy"
         ],
         "modelscope.preprocessors.cv.timer": [
             "time"
         ],
         "modelscope.preprocessors.cv.util": [
-            "shutil",
             "os",
             "sys",
-            "collections"
+            "collections",
+            "shutil"
         ],
         "modelscope.preprocessors.cv.video_stabilization": [
             "numpy",
-            "cv2",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.preprocessors.cv.video_super_resolution": [
-            "cv2",
+            "os",
             "collections",
-            "os"
+            "cv2"
         ],
         "modelscope.preprocessors.image": [
-            "numpy",
-            "PIL",
-            "typing",
             "cv2",
-            "io"
+            "typing",
+            "io",
+            "numpy",
+            "PIL"
         ],
         "modelscope.preprocessors.kws": [
-            "typing",
+            "yaml",
             "os",
-            "yaml"
+            "typing"
         ],
         "modelscope.preprocessors.movie_scene_segmentation.transforms": [
-            "torchvision",
             "os",
             "torch",
-            "numpy",
-            "typing",
             "PIL",
+            "torchvision",
+            "typing",
+            "numpy",
             "random",
             "numbers"
         ],
         "modelscope.preprocessors.multi_modal": [
-            "torchvision",
             "os",
-            "re",
             "torch",
-            "numpy",
-            "decord",
-            "timm",
-            "typing",
             "PIL",
+            "decord",
+            "torchvision",
             "json",
-            "io"
+            "typing",
+            "io",
+            "timm",
+            "numpy",
+            "re"
         ],
         "modelscope.preprocessors.nlp.bert_seq_cls_tokenizer": [
             "typing",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.canmt_translation": [
             "os",
             "torch",
             "subword_nmt",
             "sacremoses",
             "typing",
             "jieba"
         ],
         "modelscope.preprocessors.nlp.dialog_classification_use_preprocessor": [
-            "typing",
             "torch",
+            "typing",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.document_grounded_dialog_generate_preprocessor": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.document_grounded_dialog_rerank_preprocessor": [
             "os",
             "torch",
-            "transformers",
+            "copy",
             "typing",
-            "copy"
+            "transformers"
         ],
         "modelscope.preprocessors.nlp.document_grounded_dialog_retrieval_preprocessor": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.document_segmentation_preprocessor": [
             "typing"
         ],
         "modelscope.preprocessors.nlp.faq_question_answering_preprocessor": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.feature_extraction_preprocessor": [
             "numpy",
             "typing"
         ],
         "modelscope.preprocessors.nlp.fill_mask_preprocessor": [
             "os",
-            "abc",
-            "re",
             "torch",
+            "abc",
+            "typing",
             "numpy",
-            "typing"
+            "re"
         ],
         "modelscope.preprocessors.nlp.mgeo_ranking_preprocessor": [
-            "typing",
             "torch",
+            "typing",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.mglm_summarization_preprocessor": [
-            "typing",
             "os",
+            "typing",
             "re"
         ],
         "modelscope.preprocessors.nlp.relation_extraction_preprocessor": [
             "typing",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.sentence_embedding_preprocessor": [
@@ -18263,59 +18597,59 @@
         ],
         "modelscope.preprocessors.nlp.space.args": [
             "argparse",
             "json"
         ],
         "modelscope.preprocessors.nlp.space.batch": [],
         "modelscope.preprocessors.nlp.space.data_loader": [
-            "numpy",
             "os",
+            "numpy",
             "math"
         ],
         "modelscope.preprocessors.nlp.space.dialog_intent_prediction_preprocessor": [
-            "json",
             "os",
-            "typing"
+            "typing",
+            "json"
         ],
         "modelscope.preprocessors.nlp.space.dialog_modeling_preprocessor": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.space.dialog_state_tracking_preprocessor": [
             "typing"
         ],
         "modelscope.preprocessors.nlp.space.dst_processors": [
-            "six",
-            "re",
+            "json",
+            "tqdm",
             "logging",
             "numpy",
-            "json",
-            "tqdm"
+            "re",
+            "six"
         ],
         "modelscope.preprocessors.nlp.space.fields.gen_field": [
             "os",
-            "collections",
+            "json",
             "itertools",
-            "numpy",
             "asyncio",
-            "random",
-            "json"
+            "numpy",
+            "collections",
+            "random"
         ],
         "modelscope.preprocessors.nlp.space.fields.intent_field": [
             "os",
-            "re",
-            "collections",
-            "itertools",
-            "numpy",
-            "multiprocessing",
+            "tqdm",
             "time",
-            "random",
             "json",
+            "itertools",
             "glob",
-            "tqdm"
+            "numpy",
+            "multiprocessing",
+            "collections",
+            "re",
+            "random"
         ],
         "modelscope.preprocessors.nlp.space.lazy_dataset": [
             "json"
         ],
         "modelscope.preprocessors.nlp.space.preprocess": [
             "os",
             "glob"
@@ -18323,532 +18657,535 @@
         "modelscope.preprocessors.nlp.space.sampler": [
             "numpy"
         ],
         "modelscope.preprocessors.nlp.space.tensorlistdataset": [
             "torch"
         ],
         "modelscope.preprocessors.nlp.space.tokenizer": [
-            "regex",
             "os",
-            "collections",
-            "functools",
-            "sys",
             "__future__",
+            "logging",
+            "functools",
             "json",
-            "unicodedata",
-            "logging"
+            "regex",
+            "sys",
+            "collections",
+            "unicodedata"
         ],
         "modelscope.preprocessors.nlp.space_T_cn.fields.database": [
             "json",
-            "sqlite3",
-            "tqdm"
+            "tqdm",
+            "sqlite3"
         ],
         "modelscope.preprocessors.nlp.space_T_cn.fields.schema_link": [
             "re"
         ],
         "modelscope.preprocessors.nlp.space_T_cn.fields.struct": [],
         "modelscope.preprocessors.nlp.space_T_cn.table_question_answering_preprocessor": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.space_T_en.conversational_text_to_sql_preprocessor": [
             "os",
             "torch",
-            "text2sql_lgesql",
+            "json",
             "typing",
-            "json"
+            "text2sql_lgesql"
         ],
         "modelscope.preprocessors.nlp.space_T_en.fields.common_utils": [
             "os",
+            "nltk",
             "itertools",
-            "numpy",
             "text2sql_lgesql",
-            "sqlite3",
-            "nltk"
+            "numpy",
+            "sqlite3"
         ],
         "modelscope.preprocessors.nlp.space_T_en.fields.parse": [],
         "modelscope.preprocessors.nlp.space_T_en.fields.preprocess_dataset": [
             "text2sql_lgesql"
         ],
         "modelscope.preprocessors.nlp.space_T_en.fields.process_dataset": [
-            "sys",
             "os",
             "pickle",
-            "text2sql_lgesql"
+            "text2sql_lgesql",
+            "sys"
         ],
         "modelscope.preprocessors.nlp.text_classification_preprocessor": [
             "numpy",
             "typing"
         ],
         "modelscope.preprocessors.nlp.text_clean": [
+            "codecs",
             "sys",
-            "re",
-            "codecs"
+            "re"
         ],
         "modelscope.preprocessors.nlp.text_error_correction": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.text_generation_preprocessor": [
-            "numpy",
             "os",
             "typing",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.preprocessors.nlp.text_ranking_preprocessor": [
             "typing",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.token_classification_preprocessor": [
-            "numpy",
+            "torch",
             "typing",
-            "torch"
+            "numpy"
         ],
         "modelscope.preprocessors.nlp.token_classification_thai_preprocessor": [
             "typing"
         ],
         "modelscope.preprocessors.nlp.token_classification_viet_preprocessor": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.transformers_tokenizer": [
-            "json",
             "os",
             "collections",
+            "json",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.translation_evaluation_preprocessor": [
-            "typing",
             "torch",
+            "typing",
             "transformers"
         ],
         "modelscope.preprocessors.nlp.utils": [
             "os",
-            "collections",
-            "numpy",
-            "transformers",
+            "json",
             "typing",
-            "json"
+            "numpy",
+            "collections",
+            "transformers"
         ],
         "modelscope.preprocessors.nlp.word_alignment_preprocessor": [
             "os",
             "torch",
             "itertools",
-            "numpy",
-            "typing"
+            "typing",
+            "numpy"
         ],
         "modelscope.preprocessors.nlp.zero_shot_classification_preprocessor": [
             "typing"
         ],
         "modelscope.preprocessors.ofa.asr": [
-            "fairseq",
             "os",
             "torch",
+            "fairseq",
             "librosa",
-            "typing",
-            "soundfile",
             "pathlib",
-            "random"
+            "typing",
+            "random",
+            "soundfile"
         ],
         "modelscope.preprocessors.ofa.base": [
             "os",
-            "re",
             "torch",
-            "numpy",
             "torchaudio",
-            "PIL",
             "json",
+            "io",
             "string",
-            "io"
+            "numpy",
+            "PIL",
+            "re"
         ],
         "modelscope.preprocessors.ofa.image_captioning": [
+            "torch",
             "typing",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.preprocessors.ofa.image_classification": [
-            "torchvision",
             "torch",
             "functools",
-            "timm",
+            "torchvision",
             "typing",
+            "timm",
             "PIL"
         ],
         "modelscope.preprocessors.ofa.ocr_recognition": [
-            "torchvision",
-            "zhconv",
             "torch",
-            "typing",
-            "unicodedata2"
+            "zhconv",
+            "unicodedata2",
+            "torchvision",
+            "typing"
         ],
         "modelscope.preprocessors.ofa.sudoku": [
-            "numpy",
+            "torch",
             "typing",
-            "torch"
+            "numpy"
         ],
         "modelscope.preprocessors.ofa.summarization": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.ofa.text2sql": [
             "os",
-            "re",
             "torch",
             "typing",
+            "re",
             "random"
         ],
         "modelscope.preprocessors.ofa.text_classification": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.ofa.text_to_image_synthesis": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.ofa.utils.audio_helper": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.preprocessors.ofa.utils.bridge_content_encoder": [
             "typing",
-            "rapidfuzz",
             "difflib",
-            "sqlite3",
-            "functools"
+            "rapidfuzz",
+            "functools",
+            "sqlite3"
         ],
         "modelscope.preprocessors.ofa.utils.collate": [
             "numpy",
             "typing",
             "torch"
         ],
         "modelscope.preprocessors.ofa.utils.constant": [],
         "modelscope.preprocessors.ofa.utils.get_tables": [
             "sys",
-            "sqlite3",
-            "traceback"
+            "traceback",
+            "sqlite3"
         ],
         "modelscope.preprocessors.ofa.utils.random_help": [
-            "torch_xla",
-            "torch"
+            "torch",
+            "torch_xla"
         ],
         "modelscope.preprocessors.ofa.utils.text2phone": [],
         "modelscope.preprocessors.ofa.utils.transforms": [
-            "PIL",
-            "torchvision",
             "torch",
+            "PIL",
+            "numpy",
             "random",
-            "numpy"
+            "torchvision"
         ],
         "modelscope.preprocessors.ofa.utils.vision_helper": [
             "numpy",
             "cv2"
         ],
         "modelscope.preprocessors.ofa.visual_entailment": [
-            "typing",
-            "torchvision",
             "torch",
-            "PIL"
+            "typing",
+            "PIL",
+            "torchvision"
         ],
         "modelscope.preprocessors.ofa.visual_grounding": [
-            "torchvision",
             "torch",
-            "numpy",
+            "PIL",
+            "torchvision",
             "typing",
-            "PIL"
+            "numpy"
         ],
         "modelscope.preprocessors.ofa.visual_question_answering": [
-            "typing",
-            "torchvision",
             "torch",
-            "PIL"
+            "typing",
+            "PIL",
+            "torchvision"
         ],
         "modelscope.preprocessors.science.uni_fold": [
             "os",
+            "logging",
+            "ipdb",
+            "requests",
+            "numpy",
             "re",
+            "random",
+            "pickle",
+            "gzip",
             "torch",
+            "tqdm",
             "tarfile",
             "hashlib",
             "unittest",
-            "ipdb",
-            "pickle",
-            "tqdm",
-            "numpy",
-            "gzip",
-            "typing",
-            "time",
-            "pathlib",
-            "requests",
-            "random",
             "json",
-            "logging"
+            "pathlib",
+            "typing",
+            "time"
         ],
         "modelscope.preprocessors.tts": [
-            "typing",
             "os",
+            "typing",
             "kantts"
         ],
         "modelscope.preprocessors.video": [
-            "torchvision",
             "os",
-            "urllib",
             "torch",
-            "math",
-            "numpy",
             "tempfile",
-            "decord",
             "uuid",
+            "decord",
+            "torchvision",
+            "urllib",
+            "numpy",
+            "math",
             "random"
         ],
         "modelscope.trainers.audio.ans_trainer": [],
         "modelscope.trainers.audio.asr_trainer": [
             "os",
             "tempfile",
-            "shutil",
+            "json",
             "funasr",
             "typing",
-            "json"
+            "shutil"
         ],
         "modelscope.trainers.audio.kws_farfield_trainer": [
             "os",
             "torch",
-            "math",
-            "numpy",
             "datetime",
             "typing",
-            "pickle",
-            "glob"
+            "numpy",
+            "glob",
+            "math",
+            "pickle"
         ],
         "modelscope.trainers.audio.kws_nearfield_trainer": [
             "os",
-            "re",
             "torch",
             "datetime",
-            "typing",
             "copy",
             "yaml",
-            "tensorboardX"
+            "typing",
+            "tensorboardX",
+            "re"
         ],
         "modelscope.trainers.audio.kws_utils.batch_utils": [
             "os",
-            "collections",
             "torch",
-            "math",
+            "datetime",
+            "typing",
             "numpy",
+            "math",
             "sys",
-            "datetime",
-            "typing"
+            "collections"
         ],
         "modelscope.trainers.audio.kws_utils.det_utils": [
             "os",
             "torch",
-            "numpy",
             "kaldiio",
-            "matplotlib",
             "threading",
             "json",
-            "glob"
+            "matplotlib",
+            "glob",
+            "numpy"
         ],
         "modelscope.trainers.audio.kws_utils.file_utils": [
             "re"
         ],
         "modelscope.trainers.audio.kws_utils.model_utils": [
             "os",
-            "re",
             "torch",
-            "numpy",
             "shutil",
             "yaml",
-            "glob"
+            "glob",
+            "numpy",
+            "re"
         ],
         "modelscope.trainers.audio.kws_utils.runtime_utils": [
             "os",
-            "re",
             "codecs",
-            "collections",
+            "stat",
             "json",
-            "sys",
             "shutil",
-            "stat"
+            "sys",
+            "collections",
+            "re"
         ],
         "modelscope.trainers.audio.separation_trainer": [
             "os",
-            "speechbrain",
             "torch",
-            "numpy",
             "torchaudio",
-            "typing",
+            "speechbrain",
             "tqdm",
-            "csv"
+            "csv",
+            "typing",
+            "numpy"
         ],
         "modelscope.trainers.audio.tts_trainer": [
             "os",
+            "zipfile",
             "tempfile",
-            "shutil",
+            "json",
             "typing",
-            "zipfile",
-            "json"
+            "shutil"
         ],
         "modelscope.trainers.base": [
+            "os",
             "typing",
             "time",
-            "os",
             "abc"
         ],
         "modelscope.trainers.builder": [],
         "modelscope.trainers.cli_argument_parser": [
             "argparse",
             "typing",
             "dataclasses"
         ],
         "modelscope.trainers.cv.action_detection_trainer": [
             "os",
             "torch",
+            "fvcore",
             "typing",
-            "detectron2",
-            "fvcore"
+            "detectron2"
         ],
         "modelscope.trainers.cv.card_detection_scrfd_trainer": [],
         "modelscope.trainers.cv.cartoon_translation_trainer": [
             "os",
-            "numpy",
+            "tqdm",
+            "packaging",
             "typing",
             "tensorflow",
-            "packaging",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.trainers.cv.face_detection_scrfd_trainer": [
-            "typing",
             "os",
+            "typing",
             "time",
             "copy"
         ],
         "modelscope.trainers.cv.image_classifition_trainer": [
             "os",
             "torch",
-            "numpy",
-            "typing",
             "copy",
+            "typing",
+            "numpy",
             "time"
         ],
         "modelscope.trainers.cv.image_defrcn_fewshot_detection_trainer": [
             "os",
-            "collections",
             "torch",
             "typing",
-            "detectron2"
+            "detectron2",
+            "collections"
         ],
         "modelscope.trainers.cv.image_detection_damoyolo_trainer": [
             "os",
             "torch",
-            "math",
-            "easydict",
             "datetime",
             "typing",
+            "easydict",
+            "math",
             "time"
         ],
         "modelscope.trainers.cv.image_inpainting_trainer": [
+            "torch",
             "time",
-            "collections",
-            "torch"
+            "collections"
         ],
         "modelscope.trainers.cv.image_instance_segmentation_trainer": [],
         "modelscope.trainers.cv.image_portrait_enhancement_trainer": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.trainers.cv.movie_scene_segmentation_trainer": [],
         "modelscope.trainers.cv.nerf_recon_acc_trainer": [
             "os",
             "torch",
-            "numpy",
+            "tqdm",
             "datetime",
-            "typing",
             "cv2",
-            "time",
-            "random",
+            "typing",
             "glob",
-            "tqdm"
+            "numpy",
+            "time",
+            "random"
         ],
         "modelscope.trainers.cv.ocr_detection_db_trainer": [
             "os",
             "torch",
-            "math",
-            "easydict",
-            "numpy",
+            "tqdm",
             "datetime",
-            "typing",
             "copy",
-            "time",
-            "tqdm"
+            "typing",
+            "numpy",
+            "easydict",
+            "math",
+            "time"
         ],
         "modelscope.trainers.cv.ocr_recognition_trainer": [
+            "torch",
             "time",
-            "collections",
-            "torch"
+            "collections"
         ],
         "modelscope.trainers.cv.referring_video_object_segmentation_trainer": [
             "os",
             "torch"
         ],
         "modelscope.trainers.cv.vision_efficient_tuning_trainer": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.trainers.default_config": [
             "typing"
         ],
         "modelscope.trainers.hooks.builder": [],
         "modelscope.trainers.hooks.checkpoint.checkpoint_hook": [
             "os",
             "torch",
-            "numpy",
-            "shutil",
+            "json",
             "typing",
-            "random",
-            "json"
+            "shutil",
+            "numpy",
+            "random"
         ],
         "modelscope.trainers.hooks.checkpoint.checkpoint_processor": [
-            "shutil",
             "os",
-            "re"
+            "re",
+            "shutil"
         ],
         "modelscope.trainers.hooks.checkpoint.load_checkpoint_hook": [
             "torch",
-            "numpy",
+            "packaging",
             "typing",
-            "random",
-            "packaging"
+            "numpy",
+            "random"
         ],
         "modelscope.trainers.hooks.clip_clamp_logit_scale_hook": [
             "torch"
         ],
         "modelscope.trainers.hooks.compression.sparsity_hook": [
             "os"
         ],
         "modelscope.trainers.hooks.compression.utils": [
             "torch"
         ],
         "modelscope.trainers.hooks.distributed.ddp_hook": [],
         "modelscope.trainers.hooks.distributed.deepspeed_hook": [
             "os",
             "torch",
-            "shutil",
+            "functools",
+            "deepspeed",
             "megatron_util",
-            "deepspeed"
+            "shutil",
+            "math",
+            "transformers"
         ],
         "modelscope.trainers.hooks.distributed.megatron_hook": [
-            "shutil",
+            "megatron_util",
             "os",
             "torch",
-            "megatron_util"
+            "shutil"
         ],
         "modelscope.trainers.hooks.early_stop_hook": [
             "numpy"
         ],
         "modelscope.trainers.hooks.evaluation_hook": [
             "typing",
             "collections"
@@ -18856,330 +19193,346 @@
         "modelscope.trainers.hooks.hook": [
             "functools"
         ],
         "modelscope.trainers.hooks.iter_timer_hook": [
             "time"
         ],
         "modelscope.trainers.hooks.logger.base": [
-            "numpy",
             "numbers",
+            "torch",
             "abc",
-            "torch"
+            "numpy"
         ],
         "modelscope.trainers.hooks.logger.tensorboard_hook": [
-            "numpy",
             "os",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.trainers.hooks.logger.text_logger_hook": [
             "os",
-            "collections",
             "torch",
             "datetime",
-            "json"
+            "json",
+            "collections"
         ],
         "modelscope.trainers.hooks.lr_scheduler_hook": [],
         "modelscope.trainers.hooks.optimizer.apex_optimizer_hook": [
-            "logging",
             "packaging",
-            "torch"
+            "torch",
+            "logging"
         ],
         "modelscope.trainers.hooks.optimizer.base": [
-            "logging",
-            "torch"
+            "torch",
+            "logging"
         ],
         "modelscope.trainers.hooks.optimizer.torch_optimizer_hook": [
             "logging"
         ],
         "modelscope.trainers.hooks.priority": [
-            "typing",
-            "enum"
+            "enum",
+            "typing"
         ],
         "modelscope.trainers.lrscheduler.builder": [
-            "inspect",
             "packaging",
+            "inspect",
             "torch"
         ],
         "modelscope.trainers.lrscheduler.warmup.base": [
             "torch"
         ],
         "modelscope.trainers.lrscheduler.warmup.warmup": [],
         "modelscope.trainers.multi_modal.clip.clip_trainer": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "math"
         ],
         "modelscope.trainers.multi_modal.clip.clip_trainer_utils": [
             "os",
+            "inspect",
             "torch",
-            "math",
             "functools",
-            "inspect"
+            "math"
         ],
-        "modelscope.trainers.multi_modal.efficient_diffusion_tuning.efficient_diffusion_tuning_trainer": [
+        "modelscope.trainers.multi_modal.dreambooth_diffusion.dreambooth_diffusion_trainer": [
+            "torch",
+            "tqdm",
+            "hashlib",
+            "torchvision",
+            "itertools",
+            "warnings",
+            "pathlib",
             "typing",
-            "torch"
+            "shutil",
+            "diffusers",
+            "PIL",
+            "collections"
+        ],
+        "modelscope.trainers.multi_modal.efficient_diffusion_tuning.efficient_diffusion_tuning_trainer": [
+            "torch",
+            "typing"
+        ],
+        "modelscope.trainers.multi_modal.lora_diffusion.lora_diffusion_trainer": [
+            "diffusers",
+            "torch",
+            "typing"
         ],
         "modelscope.trainers.multi_modal.mgeo_ranking_trainer": [
-            "dataclasses",
+            "torch",
             "typing",
-            "torch"
+            "dataclasses"
         ],
         "modelscope.trainers.multi_modal.mplug.mplug_trainer": [
+            "torch",
             "typing",
-            "collections",
-            "torch"
+            "collections"
         ],
         "modelscope.trainers.multi_modal.ofa.ofa_trainer": [
             "os",
             "torch",
-            "math",
-            "functools",
             "tempfile",
-            "shutil",
+            "functools",
+            "json",
             "typing",
-            "json"
+            "shutil",
+            "math"
         ],
         "modelscope.trainers.multi_modal.ofa.ofa_trainer_utils": [
             "os",
             "torch",
-            "math",
-            "numpy",
             "shutil",
+            "numpy",
+            "math",
             "transformers"
         ],
+        "modelscope.trainers.multi_modal.stable_diffusion.stable_diffusion_trainer": [
+            "torch",
+            "typing"
+        ],
         "modelscope.trainers.multi_modal.team.team_trainer": [
             "os",
-            "collections",
             "torch",
-            "numpy",
             "typing",
-            "sklearn"
+            "sklearn",
+            "numpy",
+            "collections"
         ],
         "modelscope.trainers.multi_modal.team.team_trainer_utils": [
+            "torch",
             "PIL",
-            "torchvision",
-            "torch"
+            "torchvision"
         ],
         "modelscope.trainers.nlp.csanmt_translation_trainer": [
-            "typing",
             "os",
+            "typing",
             "time",
             "tensorflow"
         ],
         "modelscope.trainers.nlp.document_grounded_dialog_generate_trainer": [
             "os",
-            "re",
             "torch",
-            "collections",
-            "sacrebleu",
-            "transformers",
             "rouge",
+            "tqdm",
+            "sacrebleu",
             "json",
             "string",
-            "tqdm"
+            "collections",
+            "re",
+            "transformers"
         ],
         "modelscope.trainers.nlp.document_grounded_dialog_rerank_trainer": [
             "os",
             "torch",
-            "numpy",
-            "transformers",
             "typing",
+            "numpy",
             "time",
-            "random"
+            "random",
+            "transformers"
         ],
         "modelscope.trainers.nlp.document_grounded_dialog_retrieval_trainer": [
-            "faiss",
             "os",
+            "faiss",
             "torch",
-            "numpy",
-            "transformers",
+            "tqdm",
             "json",
-            "tqdm"
+            "numpy",
+            "transformers"
         ],
         "modelscope.trainers.nlp.faq_question_answering_trainer": [
-            "dataclasses",
-            "contextlib",
-            "collections",
             "torch",
             "distutils",
+            "contextlib",
+            "dataclasses",
             "functools",
+            "typing",
             "numpy",
-            "typing"
+            "collections"
         ],
         "modelscope.trainers.nlp.gpt3_trainer": [
-            "typing",
             "os",
+            "typing",
             "torch",
             "copy"
         ],
         "modelscope.trainers.nlp.gpt_moe_trainer": [
             "os",
-            "collections",
             "torch",
+            "megatron_util",
             "typing",
-            "megatron_util"
+            "collections"
         ],
         "modelscope.trainers.nlp.plug_trainer": [
             "os",
             "torch",
-            "typing",
             "megatron_util",
-            "deepspeed"
+            "deepspeed",
+            "typing"
         ],
         "modelscope.trainers.nlp.sentence_embedding_trainer": [
-            "dataclasses",
             "torch",
-            "numpy",
-            "transformers",
+            "dataclasses",
+            "tqdm",
             "typing",
+            "numpy",
             "time",
-            "tqdm"
+            "transformers"
         ],
         "modelscope.trainers.nlp.sequence_classification_trainer": [
             "numpy",
-            "typing",
-            "time"
+            "time",
+            "typing"
         ],
         "modelscope.trainers.nlp.siamese_uie_trainer": [
             "os",
-            "collections",
             "torch",
-            "math",
-            "numpy",
+            "json",
             "typing",
+            "numpy",
+            "math",
             "time",
-            "random",
-            "json"
+            "collections",
+            "random"
         ],
         "modelscope.trainers.nlp.space.dialog_intent_trainer": [
-            "numpy",
             "os",
-            "typing"
+            "typing",
+            "numpy"
         ],
         "modelscope.trainers.nlp.space.dialog_modeling_trainer": [
-            "numpy",
-            "time",
             "os",
-            "typing"
+            "typing",
+            "time",
+            "numpy"
         ],
         "modelscope.trainers.nlp.space.eval": [
-            "collections",
-            "math",
-            "numpy",
-            "sklearn",
+            "nltk",
             "json",
-            "nltk"
+            "sklearn",
+            "numpy",
+            "math",
+            "collections"
         ],
         "modelscope.trainers.nlp.space.metrics.metrics_tracker": [
-            "collections",
-            "math"
+            "math",
+            "collections"
         ],
         "modelscope.trainers.nlp.space.trainer.gen_trainer": [
             "os",
-            "collections",
             "torch",
+            "tqdm",
+            "json",
             "numpy",
-            "transformers",
             "time",
-            "json",
-            "tqdm"
+            "collections",
+            "transformers"
         ],
         "modelscope.trainers.nlp.space.trainer.intent_trainer": [
             "os",
-            "collections",
             "torch",
+            "tqdm",
+            "json",
             "numpy",
-            "transformers",
             "time",
-            "json",
-            "tqdm"
+            "collections",
+            "transformers"
         ],
         "modelscope.trainers.nlp.table_question_answering_trainer": [
             "os",
             "torch",
-            "numpy",
-            "typing",
-            "time",
+            "tqdm",
             "json",
-            "tqdm"
+            "typing",
+            "numpy",
+            "time"
         ],
         "modelscope.trainers.nlp.text_generation_trainer": [
-            "collections",
-            "torch"
+            "torch",
+            "collections"
         ],
         "modelscope.trainers.nlp.text_ranking_trainer": [
-            "dataclasses",
             "torch",
-            "numpy",
+            "dataclasses",
+            "tqdm",
             "typing",
-            "time",
-            "tqdm"
+            "numpy",
+            "time"
         ],
         "modelscope.trainers.nlp.translation_evaluation_trainer": [
             "os",
             "torch",
-            "math",
-            "transformers",
-            "typing",
+            "tqdm",
             "pandas",
+            "typing",
+            "math",
             "random",
-            "tqdm"
+            "transformers"
         ],
         "modelscope.trainers.nlp_trainer": [
-            "numpy",
             "os",
             "typing",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.trainers.optimizer.builder": [
-            "typing",
-            "inspect",
-            "torch"
-        ],
-        "modelscope.trainers.optimizer.child_tuning_adamw_optimizer": [
             "torch",
-            "math",
-            "numpy",
-            "typing",
-            "types"
+            "inspect",
+            "typing"
         ],
         "modelscope.trainers.parallel.builder": [
             "torch"
         ],
         "modelscope.trainers.parallel.utils": [],
         "modelscope.trainers.trainer": [
             "os",
-            "collections",
-            "distutils",
+            "inspect",
             "torch",
+            "distutils",
             "functools",
-            "typing",
-            "inspect",
             "copy",
-            "json"
+            "json",
+            "typing",
+            "collections"
         ],
         "modelscope.trainers.training_args": [
             "dataclasses",
-            "re",
-            "typing",
             "copy",
             "json",
+            "typing",
+            "re",
             "addict"
         ],
         "modelscope.trainers.utils.inference": [
             "os",
-            "collections",
             "torch",
+            "tqdm",
+            "logging",
             "shutil",
             "pickle",
-            "logging",
-            "tqdm"
+            "collections"
         ],
         "modelscope.trainers.utils.log_buffer": [
             "numpy",
             "collections"
         ]
     },
-    "version": "1.6.1"
+    "version": "1.7.0"
 }
```

### Comparing `modelscope-1.6.1/modelscope/utils/ast_utils.py` & `modelscope-1.7.0/modelscope/utils/ast_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/audio/audio_utils.py` & `modelscope-1.7.0/modelscope/utils/audio/audio_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/audio/tts_exceptions.py` & `modelscope-1.7.0/modelscope/utils/audio/tts_exceptions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/checkpoint.py` & `modelscope-1.7.0/modelscope/utils/checkpoint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/chinese_utils.py` & `modelscope-1.7.0/modelscope/utils/chinese_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/config.py` & `modelscope-1.7.0/modelscope/utils/config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/config_ds.py` & `modelscope-1.7.0/modelscope/utils/config_ds.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/constant.py` & `modelscope-1.7.0/modelscope/utils/constant.py`

 * *Files 1% similar despite different names*

```diff
@@ -513,14 +513,16 @@
     'tsv': 'csv',
     'json': 'json',
     'jsonl': 'json',
     'parquet': 'parquet',
     'txt': 'text'
 }
 
+META_FILES_FORMAT = ('.csv', '.jsonl')
+
 
 class DatasetPathName:
     META_NAME = 'meta'
     DATA_FILES_NAME = 'data_files'
     LOCK_FILE_NAME_ANY = 'any'
     LOCK_FILE_NAME_DELIMITER = '-'
```

### Comparing `modelscope-1.6.1/modelscope/utils/cv/image_utils.py` & `modelscope-1.7.0/modelscope/utils/cv/image_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/cv/motion_utils/motion_process.py` & `modelscope-1.7.0/modelscope/utils/cv/motion_utils/motion_process.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/cv/motion_utils/plot_script.py` & `modelscope-1.7.0/modelscope/utils/cv/motion_utils/plot_script.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/cv/motion_utils/rotation_conversions.py` & `modelscope-1.7.0/modelscope/utils/cv/motion_utils/rotation_conversions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/data_collators.py` & `modelscope-1.7.0/modelscope/utils/data_collators.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/data_utils.py` & `modelscope-1.7.0/modelscope/utils/data_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/device.py` & `modelscope-1.7.0/modelscope/utils/device.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/error.py` & `modelscope-1.7.0/modelscope/utils/error.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/file_utils.py` & `modelscope-1.7.0/modelscope/utils/file_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/hub.py` & `modelscope-1.7.0/modelscope/utils/hub.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/import_utils.py` & `modelscope-1.7.0/modelscope/utils/import_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/input_output.py` & `modelscope-1.7.0/modelscope/utils/input_output.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/logger.py` & `modelscope-1.7.0/modelscope/utils/logger.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/megatron_utils.py` & `modelscope-1.7.0/modelscope/utils/megatron_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/metric.py` & `modelscope-1.7.0/modelscope/utils/metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/model_tag.py` & `modelscope-1.7.0/modelscope/utils/model_tag.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/distributed.py` & `modelscope-1.7.0/modelscope/utils/nlp/distributed.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/load_checkpoint.py` & `modelscope-1.7.0/modelscope/utils/nlp/load_checkpoint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/space/args.py` & `modelscope-1.7.0/modelscope/utils/nlp/space/args.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/space/clean_dataset.py` & `modelscope-1.7.0/modelscope/utils/nlp/space/clean_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/space/criterions.py` & `modelscope-1.7.0/modelscope/utils/nlp/space/criterions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/space/db_ops.py` & `modelscope-1.7.0/modelscope/utils/nlp/space/db_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/space/ontology.py` & `modelscope-1.7.0/modelscope/utils/nlp/space/ontology.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/space/utils.py` & `modelscope-1.7.0/modelscope/utils/nlp/space/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/space/utils_dst.py` & `modelscope-1.7.0/modelscope/utils/nlp/space/utils_dst.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/space_T_en/utils.py` & `modelscope-1.7.0/modelscope/utils/nlp/space_T_en/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/nlp/utils.py` & `modelscope-1.7.0/modelscope/utils/nlp/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/plugins.py` & `modelscope-1.7.0/modelscope/utils/plugins.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/registry.py` & `modelscope-1.7.0/modelscope/utils/registry.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/regress_test_utils.py` & `modelscope-1.7.0/modelscope/utils/regress_test_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/service_utils.py` & `modelscope-1.7.0/modelscope/utils/service_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/task_utils.py` & `modelscope-1.7.0/modelscope/utils/task_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/tensor_utils.py` & `modelscope-1.7.0/modelscope/utils/tensor_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/test_utils.py` & `modelscope-1.7.0/modelscope/utils/test_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/timer.py` & `modelscope-1.7.0/modelscope/utils/timer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/torch_utils.py` & `modelscope-1.7.0/modelscope/utils/torch_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/trie.py` & `modelscope-1.7.0/modelscope/utils/trie.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/type_assert.py` & `modelscope-1.7.0/modelscope/utils/type_assert.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope/utils/url_utils.py` & `modelscope-1.7.0/modelscope/utils/url_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.6.1/modelscope.egg-info/PKG-INFO` & `modelscope-1.7.0/modelscope.egg-info/PKG-INFO`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: modelscope
-Version: 1.6.1
+Version: 1.7.0
 Summary: ModelScope: bring the notion of Model-as-a-Service to life.
 Home-page: https://github.com/modelscope/modelscope
 Author: ModelScope team
 Author-email: contact@modelscope.cn
 License: Apache License 2.0
 Description: 
         <p align="center">
@@ -207,20 +207,28 @@
         
         ModelScope Library currently supports popular deep learning framework for model training and inference, including PyTorch, TensorFlow and ONNX. All releases are tested and run on Python 3.7+, Pytorch 1.8+, Tensorflow1.15 or Tensorflow2.0+.
         
         To allow out-of-box usage for all the models on ModelScope, official docker images are provided for all releases. Based on the docker image, developers can skip all environment installation and configuration and use it directly. Currently, the latest version of the CPU image and GPU image can be obtained from:
         
         CPU docker image
         ```shell
-        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.3.0
+        # py37
+        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.6.1
+        
+        # py38
+        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py38-torch1.11.0-tf1.15.5-1.6.1
         ```
         
         GPU docker image
         ```shell
-        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py37-torch1.11.0-tf1.15.5-1.3.0
+        # py37
+        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py37-torch1.11.0-tf1.15.5-1.6.1
+        
+        # py38
+        registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py38-torch1.11.0-tf1.15.5-1.6.1
         ```
         
         ## Setup Local Python Environment
         
         One can also set up local ModelScope environment using pip and conda.  We suggest [anaconda](https://docs.anaconda.com/anaconda/install/) for creating local python environment:
         
         ```shell
```

#### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: modelscope Version: 1.6.1 Summary: ModelScope:
+Metadata-Version: 2.1 Name: modelscope Version: 1.7.0 Summary: ModelScope:
 bring the notion of Model-as-a-Service to life. Home-page: https://github.com/
 modelscope/modelscope Author: ModelScope team Author-email:
 contact@modelscope.cn License: Apache License 2.0 Description:
 
        [https://modelscope.oss-cn-beijing.aliyuncs.com/modelscope.gif]
  [![PyPI](https://img.shields.io/pypi/v/modelscope)](https://pypi.org/project/
   modelscope/)  [![license](https://img.shields.io/github/license/modelscope/
@@ -154,42 +154,46 @@
 supports popular deep learning framework for model training and inference,
 including PyTorch, TensorFlow and ONNX. All releases are tested and run on
 Python 3.7+, Pytorch 1.8+, Tensorflow1.15 or Tensorflow2.0+. To allow out-of-
 box usage for all the models on ModelScope, official docker images are provided
 for all releases. Based on the docker image, developers can skip all
 environment installation and configuration and use it directly. Currently, the
 latest version of the CPU image and GPU image can be obtained from: CPU docker
-image ```shell registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:
-ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.3.0 ``` GPU docker image ```shell
-registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-
-cuda11.3.0-py37-torch1.11.0-tf1.15.5-1.3.0 ``` ## Setup Local Python
-Environment One can also set up local ModelScope environment using pip and
-conda. We suggest [anaconda](https://docs.anaconda.com/anaconda/install/) for
-creating local python environment: ```shell conda create -n modelscope
-python=3.7 conda activate modelscope ``` PyTorch or TensorFlow can be installed
-separately according to each model's requirements. * Install pytorch [doc]
-(https://pytorch.org/get-started/locally/) * Install tensorflow [doc](https://
-www.tensorflow.org/install/pip) After installing the necessary machine-learning
-framework, you can install modelscope library as follows: If you only want to
-play around with the modelscope framework, of trying out model/dataset
-download, you can install the core modelscope components: ```shell pip install
-modelscope ``` If you want to use multi-modal models: ```shell pip install
-modelscope[multi-modal] ``` If you want to use nlp models: ```shell pip install
-modelscope[nlp] -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/
-repo.html ``` If you want to use cv models: ```shell pip install modelscope[cv]
--f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html ``` If you
-want to use audio models: ```shell pip install modelscope[audio] -f https://
-modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html ``` If you want to
-use science models: ```shell pip install modelscope[science] -f https://
-modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html ``` `Notes`: 1.
-Currently, some audio-task models only support python3.7, tensorflow1.15.4
-Linux environments. Most other models can be installed and used on Windows and
-Mac (x86). 2. Some models in the audio field use the third-party library
-SoundFile for wav file processing. On the Linux system, users need to manually
-install libsndfile of SoundFile([doc link](https://github.com/bastibe/python-
+image ```shell # py37 registry.cn-hangzhou.aliyuncs.com/modelscope-repo/
+modelscope:ubuntu20.04-py37-torch1.11.0-tf1.15.5-1.6.1 # py38 registry.cn-
+hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py38-torch1.11.0-
+tf1.15.5-1.6.1 ``` GPU docker image ```shell # py37 registry.cn-
+hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.3.0-py37-
+torch1.11.0-tf1.15.5-1.6.1 # py38 registry.cn-hangzhou.aliyuncs.com/modelscope-
+repo/modelscope:ubuntu20.04-cuda11.3.0-py38-torch1.11.0-tf1.15.5-1.6.1 ``` ##
+Setup Local Python Environment One can also set up local ModelScope environment
+using pip and conda. We suggest [anaconda](https://docs.anaconda.com/anaconda/
+install/) for creating local python environment: ```shell conda create -
+n modelscope python=3.7 conda activate modelscope ``` PyTorch or TensorFlow can
+be installed separately according to each model's requirements. * Install
+pytorch [doc](https://pytorch.org/get-started/locally/) * Install tensorflow
+[doc](https://www.tensorflow.org/install/pip) After installing the necessary
+machine-learning framework, you can install modelscope library as follows: If
+you only want to play around with the modelscope framework, of trying out
+model/dataset download, you can install the core modelscope components:
+```shell pip install modelscope ``` If you want to use multi-modal models:
+```shell pip install modelscope[multi-modal] ``` If you want to use nlp models:
+```shell pip install modelscope[nlp] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` If you want to use cv models:
+```shell pip install modelscope[cv] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` If you want to use audio models:
+```shell pip install modelscope[audio] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` If you want to use science models:
+```shell pip install modelscope[science] -f https://modelscope.oss-cn-
+beijing.aliyuncs.com/releases/repo.html ``` `Notes`: 1. Currently, some audio-
+task models only support python3.7, tensorflow1.15.4 Linux environments. Most
+other models can be installed and used on Windows and Mac (x86). 2. Some models
+in the audio field use the third-party library SoundFile for wav file
+processing. On the Linux system, users need to manually install libsndfile of
+SoundFile([doc link](https://github.com/bastibe/python-
 soundfile#installation)). On Windows and MacOS, it will be installed
 automatically without user operation. For example, on Ubuntu, you can use
 following commands: ```shell sudo apt-get update sudo apt-get install
 libsndfile1 ``` 3. Some models in computer vision need mmcv-full, you can refer
 to mmcv [installation guide](https://github.com/open-mmlab/mmcv#installation),
 a minimal installation is as follows: ```shell pip uninstall mmcv # if you have
 installed mmcv, uninstall it pip install -U openmim mim install mmcv-full ``` #
```

### Comparing `modelscope-1.6.1/modelscope.egg-info/SOURCES.txt` & `modelscope-1.7.0/modelscope.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -14,26 +14,30 @@
 modelscope/cli/__init__.py
 modelscope/cli/base.py
 modelscope/cli/cli.py
 modelscope/cli/download.py
 modelscope/cli/modelcard.py
 modelscope/cli/pipeline.py
 modelscope/cli/plugins.py
+modelscope/cli/template/readme.tpl
+modelscope/cli/template/template.tpl
 modelscope/configs/examples/configuration.py
 modelscope/exporters/__init__.py
 modelscope/exporters/base.py
 modelscope/exporters/builder.py
 modelscope/exporters/tf_model_exporter.py
 modelscope/exporters/torch_model_exporter.py
 modelscope/exporters/audio/__init__.py
 modelscope/exporters/audio/ans_dfsmn_exporter.py
 modelscope/exporters/cv/__init__.py
 modelscope/exporters/cv/cartoon_translation_exporter.py
 modelscope/exporters/cv/face_detection_scrfd_exporter.py
 modelscope/exporters/cv/object_detection_damoyolo_exporter.py
+modelscope/exporters/multi_modal/__init__.py
+modelscope/exporters/multi_modal/stable_diffusion_exporter.py
 modelscope/exporters/nlp/__init__.py
 modelscope/exporters/nlp/csanmt_for_translation_exporter.py
 modelscope/exporters/nlp/model_for_token_classification_exporter.py
 modelscope/exporters/nlp/sbert_for_sequence_classification_exporter.py
 modelscope/exporters/nlp/sbert_for_zero_shot_classification_exporter.py
 modelscope/fileio/__init__.py
 modelscope/fileio/file.py
@@ -146,15 +150,17 @@
 modelscope/models/audio/separation/layer_norm.py
 modelscope/models/audio/separation/mossformer.py
 modelscope/models/audio/separation/mossformer_block.py
 modelscope/models/audio/separation/mossformer_conv_module.py
 modelscope/models/audio/sv/DTDNN.py
 modelscope/models/audio/sv/DTDNN_layers.py
 modelscope/models/audio/sv/ERes2Net.py
+modelscope/models/audio/sv/ERes2Net_aug.py
 modelscope/models/audio/sv/__init__.py
+modelscope/models/audio/sv/cluster_backend.py
 modelscope/models/audio/sv/ecapa_tdnn.py
 modelscope/models/audio/sv/fusion.py
 modelscope/models/audio/sv/generic_speaker_verification.py
 modelscope/models/audio/sv/pooling_layers.py
 modelscope/models/audio/sv/rdino.py
 modelscope/models/audio/sv/speaker_change_locator.py
 modelscope/models/audio/tts/__init__.py
@@ -789,24 +795,35 @@
 modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py
 modelscope/models/cv/ocr_detection/__init__.py
 modelscope/models/cv/ocr_detection/model.py
 modelscope/models/cv/ocr_detection/preprocessor.py
 modelscope/models/cv/ocr_detection/utils.py
 modelscope/models/cv/ocr_detection/modules/__init__.py
 modelscope/models/cv/ocr_detection/modules/dbnet.py
+modelscope/models/cv/ocr_detection/modules/layers.py
+modelscope/models/cv/ocr_detection/modules/mix_ops.py
+modelscope/models/cv/ocr_detection/modules/proxyless.py
 modelscope/models/cv/ocr_detection/modules/seg_detector_loss.py
 modelscope/models/cv/ocr_recognition/__init__.py
 modelscope/models/cv/ocr_recognition/model.py
 modelscope/models/cv/ocr_recognition/preprocessor.py
 modelscope/models/cv/ocr_recognition/modules/__init__.py
-modelscope/models/cv/ocr_recognition/modules/convnext.py
-modelscope/models/cv/ocr_recognition/modules/convnextvit.py
-modelscope/models/cv/ocr_recognition/modules/crnn.py
-modelscope/models/cv/ocr_recognition/modules/timm_tinyc.py
-modelscope/models/cv/ocr_recognition/modules/vitstr.py
+modelscope/models/cv/ocr_recognition/modules/CRNN/__init__.py
+modelscope/models/cv/ocr_recognition/modules/CRNN/main_model.py
+modelscope/models/cv/ocr_recognition/modules/ConvNextViT/__init__.py
+modelscope/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py
+modelscope/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py
+modelscope/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py
+modelscope/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py
+modelscope/models/cv/ocr_recognition/modules/LightweightEdge/__init__.py
+modelscope/models/cv/ocr_recognition/modules/LightweightEdge/main_model.py
+modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/__init__.py
+modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/layers.py
+modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/mix_ops.py
+modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/proxyless.py
 modelscope/models/cv/open_vocabulary_detection_vild/__init__.py
 modelscope/models/cv/open_vocabulary_detection_vild/vild.py
 modelscope/models/cv/panorama_depth_estimation/__init__.py
 modelscope/models/cv/panorama_depth_estimation/unifuse_model.py
 modelscope/models/cv/panorama_depth_estimation/networks/__init__.py
 modelscope/models/cv/panorama_depth_estimation/networks/equi.py
 modelscope/models/cv/panorama_depth_estimation/networks/layers.py
@@ -1295,14 +1312,16 @@
 modelscope/models/multi_modal/soonet/__init__.py
 modelscope/models/multi_modal/soonet/blocks.py
 modelscope/models/multi_modal/soonet/clip.py
 modelscope/models/multi_modal/soonet/model.py
 modelscope/models/multi_modal/soonet/swin_transformer.py
 modelscope/models/multi_modal/soonet/tokenizer.py
 modelscope/models/multi_modal/soonet/utils.py
+modelscope/models/multi_modal/stable_diffusion/__init__.py
+modelscope/models/multi_modal/stable_diffusion/stable_diffusion.py
 modelscope/models/multi_modal/team/__init__.py
 modelscope/models/multi_modal/team/team_model.py
 modelscope/models/multi_modal/team/utils.py
 modelscope/models/multi_modal/video_synthesis/__init__.py
 modelscope/models/multi_modal/video_synthesis/autoencoder.py
 modelscope/models/multi_modal/video_synthesis/diffusion.py
 modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py
@@ -1335,14 +1354,24 @@
 modelscope/models/nlp/bert/word_alignment.py
 modelscope/models/nlp/bloom/__init__.py
 modelscope/models/nlp/bloom/backbone.py
 modelscope/models/nlp/canmt/__init__.py
 modelscope/models/nlp/canmt/canmt_model.py
 modelscope/models/nlp/canmt/canmt_translation.py
 modelscope/models/nlp/canmt/sequence_generator.py
+modelscope/models/nlp/chatglm/__init__.py
+modelscope/models/nlp/chatglm/configuration.py
+modelscope/models/nlp/chatglm/quantization.py
+modelscope/models/nlp/chatglm/text_generation.py
+modelscope/models/nlp/chatglm/tokenization.py
+modelscope/models/nlp/chatglm2/__init__.py
+modelscope/models/nlp/chatglm2/configuration.py
+modelscope/models/nlp/chatglm2/quantization.py
+modelscope/models/nlp/chatglm2/text_generation.py
+modelscope/models/nlp/chatglm2/tokenization.py
 modelscope/models/nlp/codegeex/__init__.py
 modelscope/models/nlp/codegeex/codegeex.py
 modelscope/models/nlp/codegeex/codegeex_for_code_generation.py
 modelscope/models/nlp/codegeex/codegeex_for_code_translation.py
 modelscope/models/nlp/codegeex/inference.py
 modelscope/models/nlp/codegeex/tokenizer.py
 modelscope/models/nlp/csanmt/__init__.py
@@ -1716,14 +1745,15 @@
 modelscope/pipelines/audio/asr_wenet_inference_pipeline.py
 modelscope/pipelines/audio/inverse_text_processing_pipeline.py
 modelscope/pipelines/audio/kws_farfield_pipeline.py
 modelscope/pipelines/audio/kws_kwsbp_pipeline.py
 modelscope/pipelines/audio/linear_aec_pipeline.py
 modelscope/pipelines/audio/lm_infer_pipeline.py
 modelscope/pipelines/audio/punctuation_processing_pipeline.py
+modelscope/pipelines/audio/segmentation_clustering_pipeline.py
 modelscope/pipelines/audio/separation_pipeline.py
 modelscope/pipelines/audio/speaker_change_locating_pipeline.py
 modelscope/pipelines/audio/speaker_diarization_pipeline.py
 modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py
 modelscope/pipelines/audio/speaker_verification_light_pipeline.py
 modelscope/pipelines/audio/speaker_verification_pipeline.py
 modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py
@@ -1785,14 +1815,15 @@
 modelscope/pipelines/cv/image_inpainting_sdv2_pipeline.py
 modelscope/pipelines/cv/image_instance_segmentation_pipeline.py
 modelscope/pipelines/cv/image_matching_pipeline.py
 modelscope/pipelines/cv/image_matting_pipeline.py
 modelscope/pipelines/cv/image_mvs_depth_estimation_pipeline.py
 modelscope/pipelines/cv/image_open_vocabulary_detection_pipeline.py
 modelscope/pipelines/cv/image_paintbyexample_pipeline.py
+modelscope/pipelines/cv/image_panoptic_segmentation_pipeline.py
 modelscope/pipelines/cv/image_portrait_enhancement_pipeline.py
 modelscope/pipelines/cv/image_quality_assessment_degradation_pipeline.py
 modelscope/pipelines/cv/image_quality_assessment_man_pipeline.py
 modelscope/pipelines/cv/image_quality_assessment_mos_pipeline.py
 modelscope/pipelines/cv/image_reid_person_pipeline.py
 modelscope/pipelines/cv/image_restoration_pipeline.py
 modelscope/pipelines/cv/image_salient_detection_pipeline.py
@@ -2058,14 +2089,23 @@
 modelscope/preprocessors/ofa/utils/get_tables.py
 modelscope/preprocessors/ofa/utils/random_help.py
 modelscope/preprocessors/ofa/utils/text2phone.py
 modelscope/preprocessors/ofa/utils/transforms.py
 modelscope/preprocessors/ofa/utils/vision_helper.py
 modelscope/preprocessors/science/__init__.py
 modelscope/preprocessors/science/uni_fold.py
+modelscope/swift/__init__.py
+modelscope/swift/adapter.py
+modelscope/swift/base.py
+modelscope/swift/control_sd_lora.py
+modelscope/swift/lora.py
+modelscope/swift/prompt.py
+modelscope/swift/sd_lora.py
+modelscope/swift/optimizers/__init__.py
+modelscope/swift/optimizers/child_tuning_adamw_optimizer.py
 modelscope/tools/__init__.py
 modelscope/tools/eval.py
 modelscope/tools/speech_tts_autolabel.py
 modelscope/tools/train.py
 modelscope/trainers/__init__.py
 modelscope/trainers/base.py
 modelscope/trainers/builder.py
@@ -2138,21 +2178,27 @@
 modelscope/trainers/lrscheduler/warmup/base.py
 modelscope/trainers/lrscheduler/warmup/warmup.py
 modelscope/trainers/multi_modal/__init__.py
 modelscope/trainers/multi_modal/mgeo_ranking_trainer.py
 modelscope/trainers/multi_modal/clip/__init__.py
 modelscope/trainers/multi_modal/clip/clip_trainer.py
 modelscope/trainers/multi_modal/clip/clip_trainer_utils.py
+modelscope/trainers/multi_modal/dreambooth_diffusion/__init__.py
+modelscope/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py
 modelscope/trainers/multi_modal/efficient_diffusion_tuning/__init__.py
 modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py
+modelscope/trainers/multi_modal/lora_diffusion/__init__.py
+modelscope/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py
 modelscope/trainers/multi_modal/mplug/__init__.py
 modelscope/trainers/multi_modal/mplug/mplug_trainer.py
 modelscope/trainers/multi_modal/ofa/__init__.py
 modelscope/trainers/multi_modal/ofa/ofa_trainer.py
 modelscope/trainers/multi_modal/ofa/ofa_trainer_utils.py
+modelscope/trainers/multi_modal/stable_diffusion/__init__.py
+modelscope/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py
 modelscope/trainers/multi_modal/team/__init__.py
 modelscope/trainers/multi_modal/team/team_trainer.py
 modelscope/trainers/multi_modal/team/team_trainer_utils.py
 modelscope/trainers/nlp/__init__.py
 modelscope/trainers/nlp/csanmt_translation_trainer.py
 modelscope/trainers/nlp/document_grounded_dialog_generate_trainer.py
 modelscope/trainers/nlp/document_grounded_dialog_rerank_trainer.py
@@ -2175,25 +2221,20 @@
 modelscope/trainers/nlp/space/metrics/__init__.py
 modelscope/trainers/nlp/space/metrics/metrics_tracker.py
 modelscope/trainers/nlp/space/trainer/__init__.py
 modelscope/trainers/nlp/space/trainer/gen_trainer.py
 modelscope/trainers/nlp/space/trainer/intent_trainer.py
 modelscope/trainers/optimizer/__init__.py
 modelscope/trainers/optimizer/builder.py
-modelscope/trainers/optimizer/child_tuning_adamw_optimizer.py
 modelscope/trainers/parallel/__init__.py
 modelscope/trainers/parallel/builder.py
 modelscope/trainers/parallel/utils.py
 modelscope/trainers/utils/__init__.py
 modelscope/trainers/utils/inference.py
 modelscope/trainers/utils/log_buffer.py
-modelscope/tuners/__init__.py
-modelscope/tuners/control_sd_lora.py
-modelscope/tuners/lora.py
-modelscope/tuners/sd_lora.py
 modelscope/utils/__init__.py
 modelscope/utils/ast_index_file.py
 modelscope/utils/ast_utils.py
 modelscope/utils/checkpoint.py
 modelscope/utils/chinese_utils.py
 modelscope/utils/config.py
 modelscope/utils/config_ds.py
@@ -2202,31 +2243,33 @@
 modelscope/utils/data_utils.py
 modelscope/utils/device.py
 modelscope/utils/error.py
 modelscope/utils/file_utils.py
 modelscope/utils/hub.py
 modelscope/utils/import_utils.py
 modelscope/utils/input_output.py
+modelscope/utils/input_output_typing.py
 modelscope/utils/json_utils.py
 modelscope/utils/logger.py
 modelscope/utils/megatron_utils.py
 modelscope/utils/metric.py
 modelscope/utils/model_tag.py
 modelscope/utils/plugins.py
+modelscope/utils/pre_compile.py
 modelscope/utils/registry.py
 modelscope/utils/regress_test_utils.py
 modelscope/utils/service_utils.py
+modelscope/utils/streaming_output.py
 modelscope/utils/task_utils.py
 modelscope/utils/tensor_utils.py
 modelscope/utils/test_utils.py
 modelscope/utils/timer.py
 modelscope/utils/torch_utils.py
 modelscope/utils/trie.py
 modelscope/utils/type_assert.py
-modelscope/utils/typing.py
 modelscope/utils/url_utils.py
 modelscope/utils/audio/__init__.py
 modelscope/utils/audio/audio_utils.py
 modelscope/utils/audio/tts_exceptions.py
 modelscope/utils/cv/__init__.py
 modelscope/utils/cv/image_utils.py
 modelscope/utils/cv/motion_utils/__init__.py
```

### Comparing `modelscope-1.6.1/modelscope.egg-info/requires.txt` & `modelscope-1.7.0/modelscope.egg-info/requires.txt`

 * *Files 7% similar despite different names*

```diff
@@ -1,47 +1,49 @@
 addict
 attrs
-datasets<=2.8.0,>=2.7.0
+datasets
 einops
 filelock>=3.3.0
 gast>=0.2.2
 numpy<=1.22.0
 oss2
-pandas<=1.5.3
+pandas<1.4.0
 Pillow>=6.2.0
 pyarrow!=9.0.0,>=6.0.0
 python-dateutil>=2.1
 pyyaml
-requests
+requests>=2.25
 scipy
 setuptools
 simplejson>=3.3.0
 sortedcontainers>=1.5.9
 tqdm>=4.64.0
+urllib3>=1.26
 yapf
 
 [all]
 accelerate
 albumentations>=1.0.3
 av>=9.2.0
 bmt_clipit>=1.0
 chumpy
 clip>=1.0
 control_ldm
 ddpm_guided_diffusion
-diffusers<0.15.0,>=0.13.1
+diffusers<=0.15.0,>=0.13.1
 easydict
 easyrobust
 edit_distance
 face_alignment>=1.3.5
 fairscale>=0.4.1
 fastai>=1.0.51
 ffmpeg>=1.4
 ffmpeg-python>=0.2.0
 ftfy
+fvcore
 imageio>=2.9.0
 imageio-ffmpeg>=0.4.2
 imgaug>=0.4.0
 kornia>=0.5.0
 lap
 lmdb
 lpips
@@ -61,54 +63,61 @@
 open-clip-torch>=2.7.0
 opencv-python
 paint_ldm
 pandas
 panopticapi
 plyfile>=0.7.4
 psutil
+pyclipper
 PyMCubes
 pytorch-lightning
 regex
-scikit-image>=0.19.3
+scikit-image<0.20.0,>=0.19.3
 scikit-learn>=0.20.1
 shapely
 shotdetect_scenedetect_lgss>=0.0.4
 smplx
 tensorflow-estimator>=1.15.1
 tf_slim
+thop
 timm>=0.4.9
 torchmetrics>=0.6.2
 torchsummary>=1.5.1
 torchvision
 transformers>=4.26.0
 trimesh
 ujson
 utils
 videofeatures_clipit>=1.0
 accelerate
-diffusers<0.15.0,>=0.13.1
+cloudpickle
+decord>=0.6.0
+diffusers==0.15.0
+fairseq
 ftfy>=6.0.3
 librosa==0.9.2
 opencv-python
 pycocoevalcap>=1.2
 pycocotools>=2.0.4
+pydot
 pytorch_lightning<=1.7.7
 rapidfuzz
 rouge_score<=0.0.4
 sacrebleu
 safetensors
 soundfile
 taming-transformers-rom1504
 timm
 tokenizers
 torchvision
 transformers>=4.27.1
 unicodedata2
 zhconv
 boto3
+embeddings
 en_core_web_sm>=2.3.5
 filelock
 ftfy
 jieba>=0.42.1
 matplotlib
 megatron_util
 nltk
@@ -119,14 +128,15 @@
 regex
 rouge
 sacremoses>=0.0.41
 scikit_learn
 sentencepiece
 seqeval
 spacy>=2.3.5
+stanza
 subword_nmt>=0.3.8
 termcolor
 tokenizers
 transformers>=4.12.0
 zhconv
 biopython
 iopath
@@ -134,29 +144,26 @@
 lmdb
 ml_collections
 scipy
 tensorboardX
 tokenizers
 
 [audio]
-easyasr>=0.0.2
-funasr>=0.5.0
+funasr>=0.6.5
 kaldiio
 kwsbp>=0.0.6
 matplotlib
-numpy
 py_sound_connect>=0.1
 scipy
 SoundFile>0.10
 tensorboardX
 hyperpyyaml
 librosa==0.9.2
 MinDAEC
 mir_eval>=0.7
-numpy
 rotary_embedding_torch>=0.1.5
 scipy
 SoundFile>0.10
 speechbrain>=0.5.12
 torchaudio
 tqdm
 bitstring
@@ -185,33 +192,30 @@
 tqdm
 traitlets>=5.3.0
 ttsfrd>=0.1.2
 unidecode
 wcwidth>=0.2.5
 
 [audio_asr]
-easyasr>=0.0.2
-funasr>=0.5.0
+funasr>=0.6.5
 
 [audio_kws]
 kaldiio
 kwsbp>=0.0.6
 matplotlib
-numpy
 py_sound_connect>=0.1
 scipy
 SoundFile>0.10
 tensorboardX
 
 [audio_signal]
 hyperpyyaml
 librosa==0.9.2
 MinDAEC
 mir_eval>=0.7
-numpy
 rotary_embedding_torch>=0.1.5
 scipy
 SoundFile>0.10
 speechbrain>=0.5.12
 torchaudio
 tqdm
 
@@ -250,24 +254,25 @@
 albumentations>=1.0.3
 av>=9.2.0
 bmt_clipit>=1.0
 chumpy
 clip>=1.0
 control_ldm
 ddpm_guided_diffusion
-diffusers<0.15.0,>=0.13.1
+diffusers<=0.15.0,>=0.13.1
 easydict
 easyrobust
 edit_distance
 face_alignment>=1.3.5
 fairscale>=0.4.1
 fastai>=1.0.51
 ffmpeg>=1.4
 ffmpeg-python>=0.2.0
 ftfy
+fvcore
 imageio>=2.9.0
 imageio-ffmpeg>=0.4.2
 imgaug>=0.4.0
 kornia>=0.5.0
 lap
 lmdb
 lpips
@@ -287,42 +292,48 @@
 open-clip-torch>=2.7.0
 opencv-python
 paint_ldm
 pandas
 panopticapi
 plyfile>=0.7.4
 psutil
+pyclipper
 PyMCubes
 pytorch-lightning
 regex
-scikit-image>=0.19.3
+scikit-image<0.20.0,>=0.19.3
 scikit-learn>=0.20.1
 shapely
 shotdetect_scenedetect_lgss>=0.0.4
 smplx
 tensorflow-estimator>=1.15.1
 tf_slim
+thop
 timm>=0.4.9
 torchmetrics>=0.6.2
 torchsummary>=1.5.1
 torchvision
 transformers>=4.26.0
 trimesh
 ujson
 utils
 videofeatures_clipit>=1.0
 
 [multi-modal]
 accelerate
-diffusers<0.15.0,>=0.13.1
+cloudpickle
+decord>=0.6.0
+diffusers==0.15.0
+fairseq
 ftfy>=6.0.3
 librosa==0.9.2
 opencv-python
 pycocoevalcap>=1.2
 pycocotools>=2.0.4
+pydot
 pytorch_lightning<=1.7.7
 rapidfuzz
 rouge_score<=0.0.4
 sacrebleu
 safetensors
 soundfile
 taming-transformers-rom1504
@@ -331,14 +342,15 @@
 torchvision
 transformers>=4.27.1
 unicodedata2
 zhconv
 
 [nlp]
 boto3
+embeddings
 en_core_web_sm>=2.3.5
 filelock
 ftfy
 jieba>=0.42.1
 matplotlib
 megatron_util
 nltk
@@ -349,14 +361,15 @@
 regex
 rouge
 sacremoses>=0.0.41
 scikit_learn
 sentencepiece
 seqeval
 spacy>=2.3.5
+stanza
 subword_nmt>=0.3.8
 termcolor
 tokenizers
 transformers>=4.12.0
 zhconv
 
 [science]
```

